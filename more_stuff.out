Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-202-25-false-googlebooks-eng-all-5gram-20120701-on"

$hadoop$D
[1] "mapreduce.job.maps=202"

$hadoop$D
[1] "mapred.reduce.tasks=25"


15/04/15 14:51:27 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/15 14:51:27 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob977159896877183183.jar tmpDir=null
15/04/15 14:51:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 14:51:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 14:51:28 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.149:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.192:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.162:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.163:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.203:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.190:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.199:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/15 14:51:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.195:50010
15/04/15 14:51:29 INFO mapreduce.JobSubmitter: number of splits:202
15/04/15 14:51:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_5055
15/04/15 14:51:29 INFO impl.YarnClientImpl: Submitted application application_1422482982071_5055
15/04/15 14:51:29 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_5055/
15/04/15 14:51:29 INFO mapreduce.Job: Running job: job_1422482982071_5055
15/04/15 14:51:34 INFO mapreduce.Job: Job job_1422482982071_5055 running in uber mode : false
15/04/15 14:51:34 INFO mapreduce.Job:  map 0% reduce 0%
15/04/15 14:51:44 INFO mapreduce.Job:  map 1% reduce 0%
15/04/15 14:51:45 INFO mapreduce.Job:  map 2% reduce 0%
15/04/15 14:51:46 INFO mapreduce.Job:  map 4% reduce 0%
15/04/15 14:51:47 INFO mapreduce.Job:  map 5% reduce 0%
15/04/15 14:51:48 INFO mapreduce.Job:  map 6% reduce 0%
15/04/15 14:51:49 INFO mapreduce.Job:  map 7% reduce 0%
15/04/15 14:51:50 INFO mapreduce.Job:  map 8% reduce 0%
15/04/15 14:51:51 INFO mapreduce.Job:  map 9% reduce 0%
15/04/15 14:51:52 INFO mapreduce.Job:  map 10% reduce 0%
15/04/15 14:51:53 INFO mapreduce.Job:  map 11% reduce 0%
15/04/15 14:51:54 INFO mapreduce.Job:  map 12% reduce 0%
15/04/15 14:51:55 INFO mapreduce.Job:  map 13% reduce 0%
15/04/15 14:51:56 INFO mapreduce.Job:  map 14% reduce 0%
15/04/15 14:51:57 INFO mapreduce.Job:  map 15% reduce 0%
15/04/15 14:51:58 INFO mapreduce.Job:  map 17% reduce 0%
15/04/15 14:52:00 INFO mapreduce.Job:  map 19% reduce 0%
15/04/15 14:52:01 INFO mapreduce.Job:  map 20% reduce 0%
15/04/15 14:52:03 INFO mapreduce.Job:  map 22% reduce 0%
15/04/15 14:52:04 INFO mapreduce.Job:  map 23% reduce 0%
15/04/15 14:52:06 INFO mapreduce.Job:  map 24% reduce 0%
15/04/15 14:52:07 INFO mapreduce.Job:  map 25% reduce 0%
15/04/15 14:52:08 INFO mapreduce.Job:  map 26% reduce 0%
15/04/15 14:52:09 INFO mapreduce.Job:  map 27% reduce 0%
15/04/15 14:52:10 INFO mapreduce.Job:  map 29% reduce 0%
15/04/15 14:52:11 INFO mapreduce.Job:  map 30% reduce 0%
15/04/15 14:52:13 INFO mapreduce.Job:  map 32% reduce 0%
15/04/15 14:52:14 INFO mapreduce.Job:  map 33% reduce 0%
15/04/15 14:52:16 INFO mapreduce.Job:  map 35% reduce 0%
15/04/15 14:52:17 INFO mapreduce.Job:  map 36% reduce 0%
15/04/15 14:52:18 INFO mapreduce.Job:  map 37% reduce 0%
15/04/15 14:52:19 INFO mapreduce.Job:  map 38% reduce 0%
15/04/15 14:52:20 INFO mapreduce.Job:  map 40% reduce 0%
15/04/15 14:52:22 INFO mapreduce.Job:  map 42% reduce 0%
15/04/15 14:52:23 INFO mapreduce.Job:  map 43% reduce 0%
15/04/15 14:52:25 INFO mapreduce.Job:  map 45% reduce 0%
15/04/15 14:52:26 INFO mapreduce.Job:  map 46% reduce 0%
15/04/15 14:52:27 INFO mapreduce.Job:  map 47% reduce 0%
15/04/15 14:52:28 INFO mapreduce.Job:  map 48% reduce 0%
15/04/15 14:52:29 INFO mapreduce.Job:  map 49% reduce 0%
15/04/15 14:52:30 INFO mapreduce.Job:  map 50% reduce 0%
15/04/15 14:52:31 INFO mapreduce.Job:  map 52% reduce 0%
15/04/15 14:52:32 INFO mapreduce.Job:  map 53% reduce 0%
15/04/15 14:52:34 INFO mapreduce.Job:  map 55% reduce 0%
15/04/15 14:52:35 INFO mapreduce.Job:  map 56% reduce 0%
15/04/15 14:52:36 INFO mapreduce.Job:  map 57% reduce 0%
15/04/15 14:52:37 INFO mapreduce.Job:  map 58% reduce 0%
15/04/15 14:52:38 INFO mapreduce.Job:  map 59% reduce 0%
15/04/15 14:52:40 INFO mapreduce.Job:  map 60% reduce 0%
15/04/15 14:52:41 INFO mapreduce.Job:  map 61% reduce 0%
15/04/15 14:52:43 INFO mapreduce.Job:  map 62% reduce 0%
15/04/15 14:52:46 INFO mapreduce.Job:  map 63% reduce 0%
15/04/15 14:52:49 INFO mapreduce.Job:  map 65% reduce 0%
15/04/15 14:52:50 INFO mapreduce.Job:  map 66% reduce 0%
15/04/15 14:52:51 INFO mapreduce.Job:  map 68% reduce 0%
15/04/15 14:52:52 INFO mapreduce.Job:  map 71% reduce 0%
15/04/15 14:52:53 INFO mapreduce.Job:  map 73% reduce 0%
15/04/15 14:52:54 INFO mapreduce.Job:  map 77% reduce 0%
15/04/15 14:52:55 INFO mapreduce.Job:  map 80% reduce 0%
15/04/15 14:52:56 INFO mapreduce.Job:  map 82% reduce 0%
15/04/15 14:52:57 INFO mapreduce.Job:  map 84% reduce 0%
15/04/15 14:52:58 INFO mapreduce.Job:  map 86% reduce 0%
15/04/15 14:52:59 INFO mapreduce.Job:  map 87% reduce 0%
15/04/15 14:53:00 INFO mapreduce.Job:  map 88% reduce 0%
15/04/15 14:53:01 INFO mapreduce.Job:  map 89% reduce 10%
15/04/15 14:53:02 INFO mapreduce.Job:  map 91% reduce 19%
15/04/15 14:53:03 INFO mapreduce.Job:  map 92% reduce 19%
15/04/15 14:53:05 INFO mapreduce.Job:  map 93% reduce 19%
15/04/15 14:53:09 INFO mapreduce.Job:  map 93% reduce 20%
15/04/15 14:53:10 INFO mapreduce.Job:  map 94% reduce 20%
15/04/15 14:53:11 INFO mapreduce.Job:  map 94% reduce 21%
15/04/15 14:53:13 INFO mapreduce.Job:  map 94% reduce 22%
15/04/15 14:53:14 INFO mapreduce.Job:  map 94% reduce 24%
15/04/15 14:53:16 INFO mapreduce.Job:  map 94% reduce 25%
15/04/15 14:53:17 INFO mapreduce.Job:  map 94% reduce 26%
15/04/15 14:53:21 INFO mapreduce.Job:  map 94% reduce 27%
15/04/15 14:53:23 INFO mapreduce.Job:  map 94% reduce 28%
15/04/15 14:53:24 INFO mapreduce.Job:  map 95% reduce 28%
15/04/15 14:53:26 INFO mapreduce.Job:  map 96% reduce 28%
15/04/15 14:53:27 INFO mapreduce.Job:  map 96% reduce 29%
15/04/15 14:53:28 INFO mapreduce.Job:  map 97% reduce 29%
15/04/15 14:53:29 INFO mapreduce.Job:  map 98% reduce 30%
15/04/15 14:53:31 INFO mapreduce.Job:  map 98% reduce 31%
15/04/15 14:53:33 INFO mapreduce.Job:  map 99% reduce 31%
15/04/15 14:53:34 INFO mapreduce.Job:  map 100% reduce 32%
15/04/15 14:53:36 INFO mapreduce.Job:  map 100% reduce 33%
15/04/15 14:53:39 INFO mapreduce.Job:  map 100% reduce 35%
15/04/15 14:53:40 INFO mapreduce.Job:  map 100% reduce 38%
15/04/15 14:53:41 INFO mapreduce.Job:  map 100% reduce 44%
15/04/15 14:53:42 INFO mapreduce.Job:  map 100% reduce 46%
15/04/15 14:53:43 INFO mapreduce.Job:  map 100% reduce 51%
15/04/15 14:53:44 INFO mapreduce.Job:  map 100% reduce 54%
15/04/15 14:53:45 INFO mapreduce.Job:  map 100% reduce 56%
15/04/15 14:53:46 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 14:53:47 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 14:53:48 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 14:53:49 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 14:53:50 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 14:53:51 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 14:53:53 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 14:54:00 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 14:54:11 INFO mapreduce.Job:  map 100% reduce 69%
15/04/15 14:54:23 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 14:54:35 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 14:54:47 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 14:55:02 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 14:55:14 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 14:55:28 INFO mapreduce.Job:  map 100% reduce 75%
15/04/15 14:55:43 INFO mapreduce.Job:  map 100% reduce 76%
15/04/15 14:56:01 INFO mapreduce.Job:  map 100% reduce 77%
15/04/15 14:56:22 INFO mapreduce.Job:  map 100% reduce 78%
15/04/15 14:56:40 INFO mapreduce.Job:  map 100% reduce 79%
15/04/15 14:57:04 INFO mapreduce.Job:  map 100% reduce 80%
15/04/15 14:57:28 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 14:57:52 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 14:58:17 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 14:58:45 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 14:59:16 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 14:59:43 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 15:00:17 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 15:00:59 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 15:01:46 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 15:02:43 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:03:46 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:05:37 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:09:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000021_0, Status : FAILED
Container [pid=39005,containerID=container_1422482982071_5055_01_000279] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000279 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 39098 39085 39005 39005 (cat) 0 0 4231168 138 cat 
	|- 39014 39005 39005 39005 (java) 4314 498 13312217088 586296 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000279/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000279 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000021_0 279 
	|- 39005 9245 39005 39005 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000279/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000279 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000021_0 279 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000279/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000279/stderr  
	|- 39085 39014 39005 39005 (R) 81300 12358 10413838336 2519362 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 
	|- 39096 39085 39005 39005 (cat) 0 25 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:09:20 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 15:09:31 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:09:40 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:09:49 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:10:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000013_0, Status : FAILED
Container [pid=1590,containerID=container_1422482982071_5055_01_000271] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000271 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 1704 1599 1590 1590 (R) 88285 13975 10460639232 2498372 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 
	|- 1718 1704 1590 1590 (cat) 0 0 103391232 152 cat 
	|- 1590 3799 1590 1590 (bash) 0 0 108650496 297 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000271/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000271 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000013_0 271 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000271/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000271/stderr  
	|- 1715 1704 1590 1590 (cat) 1 21 103391232 159 cat 
	|- 1599 1590 1590 1590 (java) 3670 617 13411397632 590670 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000271/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000271 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000013_0 271 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:10:51 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:11:12 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:11:21 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:13:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000018_0, Status : FAILED
Container [pid=33408,containerID=container_1422482982071_5055_01_000276] is running beyond physical memory limits. Current usage: 12.1 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000276 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 33408 9043 33408 33408 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000276/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000276 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000018_0 276 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000276/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000276/stderr  
	|- 33491 33417 33408 33408 (R) 99493 16627 10630721536 2572345 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 
	|- 33417 33408 33408 33408 (java) 4380 791 13314875392 589980 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000276/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000276 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000018_0 276 
	|- 33502 33491 33408 33408 (cat) 0 25 4231168 142 cat 
	|- 33517 33491 33408 33408 (cat) 0 0 4231168 139 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:13:08 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:13:27 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:13:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000015_0, Status : FAILED
Container [pid=11923,containerID=container_1422482982071_5055_01_000273] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000273 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 12026 12015 11923 11923 (cat) 0 25 4231168 143 cat 
	|- 12015 11932 11923 11923 (R) 100805 17908 10446667776 2527379 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 
	|- 12028 12015 11923 11923 (cat) 0 0 4231168 138 cat 
	|- 11932 11923 11923 11923 (java) 4447 605 13312110592 588820 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000273/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000273 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000015_0 273 
	|- 11923 10599 11923 11923 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000273/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000273 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000015_0 273 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000273/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000273/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:13:34 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 15:13:39 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 15:13:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000017_0, Status : FAILED
Container [pid=3287,containerID=container_1422482982071_5055_01_000275] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000275 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 3384 3371 3287 3287 (cat) 0 0 4231168 140 cat 
	|- 3371 3296 3287 3287 (R) 103922 15285 10856435712 2619495 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 
	|- 3382 3371 3287 3287 (cat) 0 46 4231168 142 cat 
	|- 3296 3287 3287 3287 (java) 4478 839 13315088384 529339 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000275/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000275 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000017_0 275 
	|- 3287 10211 3287 3287 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000275/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000275 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000017_0 275 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000275/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000275/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:13:40 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 15:13:42 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 15:13:52 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 15:13:59 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 15:14:04 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:14:08 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:14:11 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:30:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000021_1, Status : FAILED
Container [pid=7972,containerID=container_1422482982071_5055_01_000308] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000308 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 7972 9971 7972 7972 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000308/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000308 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000021_1 308 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000308/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000308/stderr  
	|- 7982 7972 7972 7972 (java) 3691 601 13313179648 587974 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000308/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000308 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000021_1 308 
	|- 8035 8024 7972 7972 (cat) 0 27 4231168 142 cat 
	|- 8037 8024 7972 7972 (cat) 0 0 4231168 138 cat 
	|- 8024 7982 7972 7972 (R) 99809 25166 10394820608 2514752 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:30:43 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:31:04 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:31:17 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:32:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000017_1, Status : FAILED
Container [pid=47582,containerID=container_1422482982071_5055_01_000312] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.7 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000312 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 47582 3816 47582 47582 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000312/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000312 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000017_1 312 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000312/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000312/stderr  
	|- 47592 47582 47582 47582 (java) 5106 893 13414268928 590480 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000312/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000312 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000017_1 312 
	|- 47648 47635 47582 47582 (cat) 0 0 103391232 157 cat 
	|- 47646 47635 47582 47582 (cat) 0 45 103391232 159 cat 
	|- 47635 47592 47582 47582 (R) 93626 14232 10669543424 2557682 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:32:18 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 15:32:27 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000013_1, Status : FAILED
Container [pid=45669,containerID=container_1422482982071_5055_01_000309] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000309 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 45679 45669 45669 45669 (java) 4731 813 13313007616 590480 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000309/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000309 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000013_1 309 
	|- 45733 45722 45669 45669 (cat) 0 25 4231168 142 cat 
	|- 45722 45679 45669 45669 (R) 98625 27378 10353111040 2504569 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 
	|- 45735 45722 45669 45669 (cat) 0 0 4231168 135 cat 
	|- 45669 12336 45669 45669 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000309/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000309 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000013_1 309 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000309/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000309/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:32:28 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 15:32:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000012_0, Status : FAILED
Container [pid=39158,containerID=container_1422482982071_5055_01_000270] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000270 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 39267 39167 39158 39158 (R) 115604 116806 10431352832 2503132 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 
	|- 39279 39267 39158 39158 (cat) 1 26 4231168 142 cat 
	|- 39167 39158 39158 39158 (java) 4431 735 13312446464 587991 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000270/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000270 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000012_0 270 
	|- 39282 39267 39158 39158 (cat) 0 0 4231168 135 cat 
	|- 39158 10887 39158 39158 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000270/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000270 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000012_0 270 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000270/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000270/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:32:39 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 15:32:48 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 15:32:51 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:32:57 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:33:00 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:41:22 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000012_1, Status : FAILED
Container [pid=18335,containerID=container_1422482982071_5055_01_000313] is running beyond physical memory limits. Current usage: 12.1 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000313 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 18445 18434 18335 18335 (cat) 0 29 4231168 142 cat 
	|- 18446 18434 18335 18335 (cat) 0 0 4231168 134 cat 
	|- 18434 18345 18335 18335 (R) 114962 20958 10830905344 2590690 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 
	|- 18335 40699 18335 18335 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000313/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000313 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000012_1 313 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000313/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000313/stderr  
	|- 18345 18335 18335 18335 (java) 4985 996 13311979520 592439 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000313/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000313 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000012_1 313 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:41:23 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:41:41 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:41:56 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:43:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000018_1, Status : FAILED
Container [pid=30226,containerID=container_1422482982071_5055_01_000310] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.4 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000310 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 30336 30325 30226 30226 (cat) 0 24 4231168 142 cat 
	|- 30338 30325 30226 30226 (cat) 0 0 4231168 139 cat 
	|- 30236 30226 30226 30226 (java) 4692 796 13314641920 590731 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000310/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000310 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000018_1 310 
	|- 30325 30236 30226 30226 (R) 101184 76461 10668351488 2528107 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 
	|- 30226 9608 30226 30226 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000310/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000310 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000018_1 310 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000310/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000310/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:48:21 INFO mapreduce.Job:  map 100% reduce 94%
15/04/15 15:48:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000015_1, Status : FAILED
Container [pid=30274,containerID=container_1422482982071_5055_01_000311] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000311 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 30348 30284 30274 30274 (R) 121233 83502 10931593216 2563458 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 
	|- 30274 9608 30274 30274 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000311/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000311 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000015_1 311 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000311/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000311/stderr  
	|- 30284 30274 30274 30274 (java) 3840 699 13311967232 587897 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000311/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000311 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000015_1 311 
	|- 30361 30348 30274 30274 (cat) 0 0 4231168 138 cat 
	|- 30359 30348 30274 30274 (cat) 0 28 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:48:22 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:50:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000021_2, Status : FAILED
Container [pid=40932,containerID=container_1422482982071_5055_01_000314] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000314 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 40998 40985 40932 40932 (cat) 0 0 103391232 155 cat 
	|- 40942 40932 40932 40932 (java) 4502 719 13411119104 587742 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000314/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000314 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000021_2 314 
	|- 40996 40985 40932 40932 (cat) 1 26 103391232 160 cat 
	|- 40932 3820 40932 40932 (bash) 1 0 108650496 297 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000314/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000314 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000021_2 314 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000314/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000314/stderr  
	|- 40985 40942 40932 40932 (R) 98515 14599 10489024512 2513611 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:50:12 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:50:32 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:50:41 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:54:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000017_2, Status : FAILED
Container [pid=12437,containerID=container_1422482982071_5055_01_000315] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000315 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 12437 10599 12437 12437 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000315/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000315 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000017_2 315 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000315/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000315/stderr  
	|- 12447 12437 12437 12437 (java) 4594 824 13314138112 591269 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000315/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000315 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000017_2 315 
	|- 12540 12447 12437 12437 (R) 103178 23814 10343161856 2502110 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 
	|- 12553 12540 12437 12437 (cat) 0 0 4231168 140 cat 
	|- 12551 12540 12437 12437 (cat) 1 45 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:54:11 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 15:54:22 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:54:31 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:54:41 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:57:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000013_2, Status : FAILED
Container [pid=12487,containerID=container_1422482982071_5055_01_000316] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000316 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 12487 10599 12487 12487 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000316/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000316 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000013_2 316 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000316/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000316/stderr  
	|- 12560 12497 12487 12487 (R) 110900 34094 10261671936 2482245 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 
	|- 12571 12560 12487 12487 (cat) 1 25 4231168 142 cat 
	|- 12573 12560 12487 12487 (cat) 0 0 4231168 135 cat 
	|- 12497 12487 12487 12487 (java) 4132 742 13312225280 602243 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000316/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000316 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000013_2 316 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:57:20 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:57:40 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:57:49 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:59:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000018_2, Status : FAILED
Container [pid=18371,containerID=container_1422482982071_5055_01_000318] is running beyond physical memory limits. Current usage: 12.1 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000318 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 18425 18381 18371 18371 (R) 102132 15744 10624069632 2570721 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 
	|- 18436 18425 18371 18371 (cat) 1 28 4231168 142 cat 
	|- 18381 18371 18371 18371 (java) 4757 805 13313527808 588848 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000318/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000318 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000018_2 318 
	|- 18438 18425 18371 18371 (cat) 0 0 4231168 139 cat 
	|- 18371 9550 18371 18371 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000318/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000318 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000018_2 318 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000318/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000318/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:59:55 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 16:00:16 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 16:00:25 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 16:02:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000015_2, Status : FAILED
Container [pid=3953,containerID=container_1422482982071_5055_01_000317] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000317 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 3953 10211 3953 3953 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000317/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000317 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000015_2 317 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000317/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000317/stderr  
	|- 3963 3953 3953 3953 (java) 4788 797 13312286720 505595 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000317/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000317 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000015_2 317 
	|- 4018 4005 3953 3953 (cat) 0 0 4231168 138 cat 
	|- 4005 3963 3953 3953 (R) 116486 17852 10941599744 2648243 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 
	|- 4016 4005 3953 3953 (cat) 0 29 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:02:12 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 16:02:33 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 16:02:48 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 16:03:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_5055_r_000012_2, Status : FAILED
Container [pid=27303,containerID=container_1422482982071_5055_01_000319] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5055_01_000319 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 27303 9754 27303 27303 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000319/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000319 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000012_2 319 1>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000319/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000319/stderr  
	|- 27313 27303 27303 27303 (java) 3591 658 13312864256 585550 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5055/container_1422482982071_5055_01_000319/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5055/container_1422482982071_5055_01_000319 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 37922 attempt_1422482982071_5055_r_000012_2 319 
	|- 27367 27356 27303 27303 (cat) 0 25 4231168 142 cat 
	|- 27356 27313 27303 27303 (R) 107706 23928 10336489472 2487769 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3f954370d4bd 
	|- 27368 27356 27303 27303 (cat) 0 0 4231168 134 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:03:57 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 16:04:14 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 16:04:33 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 16:10:36 INFO mapreduce.Job:  map 100% reduce 100%
15/04/15 16:10:37 INFO mapreduce.Job: Job job_1422482982071_5055 failed with state FAILED due to: Task failed task_1422482982071_5055_r_000021
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/15 16:10:38 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=31863191399
		FILE: Number of bytes written=81368055808
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=27107640365
		HDFS: Number of bytes written=2698908578
		HDFS: Number of read operations=663
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=38
	Job Counters 
		Failed reduce tasks=19
		Killed map tasks=1
		Killed reduce tasks=5
		Launched map tasks=203
		Launched reduce tasks=43
		Data-local map tasks=154
		Rack-local map tasks=49
		Total time spent by all maps in occupied slots (ms)=33667110
		Total time spent by all reduces in occupied slots (ms)=87759494
		Total time spent by all map tasks (ms)=16833555
		Total time spent by all reduce tasks (ms)=43879747
		Total vcore-seconds taken by all map tasks=16833555
		Total vcore-seconds taken by all reduce tasks=43879747
		Total megabyte-seconds taken by all map tasks=136284461280
		Total megabyte-seconds taken by all reduce tasks=526556964000
	Map-Reduce Framework
		Map input records=632973453
		Map output records=567321110
		Map output bytes=48319011069
		Map output materialized bytes=49483447935
		Input split bytes=31916
		Combine input records=0
		Combine output records=0
		Reduce input groups=44903779
		Reduce shuffle bytes=31863214193
		Reduce input records=431123664
		Reduce output records=45129773
		Spilled Records=998444774
		Shuffled Maps =3838
		Failed Shuffles=0
		Merged Map outputs=3838
		GC time elapsed (ms)=132822
		CPU time spent (ms)=31187390
		Physical memory (bytes) snapshot=428526018560
		Virtual memory (bytes) snapshot=2107950731264
		Total committed heap usage (bytes)=599478792192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27107608449
	File Output Format Counters 
		Bytes Written=2698908578
	rmr
		reduce calls=44903779
15/04/15 16:10:38 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/15 16:10:44 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file3f956284ef95

real	79m21.325s
user	0m34.794s
sys	0m4.082s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-202-15-false-googlebooks-eng-all-5gram-20120701-on"

$hadoop$D
[1] "mapreduce.job.maps=202"

$hadoop$D
[1] "mapred.reduce.tasks=15"


15/04/15 16:10:49 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/15 16:10:49 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3321340191339237631.jar tmpDir=null
15/04/15 16:10:50 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 16:10:50 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 16:10:51 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.149:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.192:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.162:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.163:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.203:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.190:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.199:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/15 16:10:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.195:50010
15/04/15 16:10:51 INFO mapreduce.JobSubmitter: number of splits:202
15/04/15 16:10:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_5061
15/04/15 16:10:52 INFO impl.YarnClientImpl: Submitted application application_1422482982071_5061
15/04/15 16:10:52 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_5061/
15/04/15 16:10:52 INFO mapreduce.Job: Running job: job_1422482982071_5061
15/04/15 16:10:57 INFO mapreduce.Job: Job job_1422482982071_5061 running in uber mode : false
15/04/15 16:10:57 INFO mapreduce.Job:  map 0% reduce 0%
15/04/15 16:11:09 INFO mapreduce.Job:  map 2% reduce 0%
15/04/15 16:11:10 INFO mapreduce.Job:  map 3% reduce 0%
15/04/15 16:11:11 INFO mapreduce.Job:  map 4% reduce 0%
15/04/15 16:11:12 INFO mapreduce.Job:  map 5% reduce 0%
15/04/15 16:11:13 INFO mapreduce.Job:  map 6% reduce 0%
15/04/15 16:11:14 INFO mapreduce.Job:  map 7% reduce 0%
15/04/15 16:11:15 INFO mapreduce.Job:  map 8% reduce 0%
15/04/15 16:11:16 INFO mapreduce.Job:  map 10% reduce 0%
15/04/15 16:11:18 INFO mapreduce.Job:  map 11% reduce 0%
15/04/15 16:11:19 INFO mapreduce.Job:  map 13% reduce 0%
15/04/15 16:11:21 INFO mapreduce.Job:  map 14% reduce 0%
15/04/15 16:11:22 INFO mapreduce.Job:  map 16% reduce 0%
15/04/15 16:11:23 INFO mapreduce.Job:  map 17% reduce 0%
15/04/15 16:11:24 INFO mapreduce.Job:  map 18% reduce 0%
15/04/15 16:11:25 INFO mapreduce.Job:  map 19% reduce 0%
15/04/15 16:11:26 INFO mapreduce.Job:  map 20% reduce 0%
15/04/15 16:11:27 INFO mapreduce.Job:  map 21% reduce 0%
15/04/15 16:11:28 INFO mapreduce.Job:  map 22% reduce 0%
15/04/15 16:11:29 INFO mapreduce.Job:  map 23% reduce 0%
15/04/15 16:11:30 INFO mapreduce.Job:  map 24% reduce 0%
15/04/15 16:11:31 INFO mapreduce.Job:  map 26% reduce 0%
15/04/15 16:11:32 INFO mapreduce.Job:  map 27% reduce 0%
15/04/15 16:11:34 INFO mapreduce.Job:  map 29% reduce 0%
15/04/15 16:11:35 INFO mapreduce.Job:  map 30% reduce 0%
15/04/15 16:11:36 INFO mapreduce.Job:  map 31% reduce 0%
15/04/15 16:11:37 INFO mapreduce.Job:  map 32% reduce 0%
15/04/15 16:11:38 INFO mapreduce.Job:  map 33% reduce 0%
15/04/15 16:11:39 INFO mapreduce.Job:  map 34% reduce 0%
15/04/15 16:11:40 INFO mapreduce.Job:  map 36% reduce 0%
15/04/15 16:11:42 INFO mapreduce.Job:  map 37% reduce 0%
15/04/15 16:11:43 INFO mapreduce.Job:  map 39% reduce 0%
15/04/15 16:11:44 INFO mapreduce.Job:  map 40% reduce 0%
15/04/15 16:11:45 INFO mapreduce.Job:  map 41% reduce 0%
15/04/15 16:11:46 INFO mapreduce.Job:  map 42% reduce 0%
15/04/15 16:11:47 INFO mapreduce.Job:  map 43% reduce 0%
15/04/15 16:11:48 INFO mapreduce.Job:  map 44% reduce 0%
15/04/15 16:11:49 INFO mapreduce.Job:  map 46% reduce 0%
15/04/15 16:11:51 INFO mapreduce.Job:  map 47% reduce 0%
15/04/15 16:11:52 INFO mapreduce.Job:  map 49% reduce 0%
15/04/15 16:11:53 INFO mapreduce.Job:  map 50% reduce 0%
15/04/15 16:11:54 INFO mapreduce.Job:  map 51% reduce 0%
15/04/15 16:11:55 INFO mapreduce.Job:  map 52% reduce 0%
15/04/15 16:11:56 INFO mapreduce.Job:  map 53% reduce 0%
15/04/15 16:11:57 INFO mapreduce.Job:  map 54% reduce 0%
15/04/15 16:11:58 INFO mapreduce.Job:  map 56% reduce 0%
15/04/15 16:12:00 INFO mapreduce.Job:  map 57% reduce 0%
15/04/15 16:12:01 INFO mapreduce.Job:  map 59% reduce 0%
15/04/15 16:12:03 INFO mapreduce.Job:  map 60% reduce 0%
15/04/15 16:12:04 INFO mapreduce.Job:  map 61% reduce 0%
15/04/15 16:12:06 INFO mapreduce.Job:  map 62% reduce 0%
15/04/15 16:12:08 INFO mapreduce.Job:  map 63% reduce 0%
15/04/15 16:12:12 INFO mapreduce.Job:  map 64% reduce 0%
15/04/15 16:12:14 INFO mapreduce.Job:  map 66% reduce 0%
15/04/15 16:12:15 INFO mapreduce.Job:  map 68% reduce 0%
15/04/15 16:12:16 INFO mapreduce.Job:  map 70% reduce 0%
15/04/15 16:12:17 INFO mapreduce.Job:  map 73% reduce 0%
15/04/15 16:12:18 INFO mapreduce.Job:  map 77% reduce 0%
15/04/15 16:12:19 INFO mapreduce.Job:  map 79% reduce 0%
15/04/15 16:12:20 INFO mapreduce.Job:  map 81% reduce 0%
15/04/15 16:12:21 INFO mapreduce.Job:  map 84% reduce 0%
15/04/15 16:12:22 INFO mapreduce.Job:  map 87% reduce 0%
15/04/15 16:12:23 INFO mapreduce.Job:  map 89% reduce 0%
15/04/15 16:12:24 INFO mapreduce.Job:  map 90% reduce 0%
15/04/15 16:12:25 INFO mapreduce.Job:  map 91% reduce 10%
15/04/15 16:12:26 INFO mapreduce.Job:  map 92% reduce 12%
15/04/15 16:12:27 INFO mapreduce.Job:  map 93% reduce 12%
15/04/15 16:12:34 INFO mapreduce.Job:  map 94% reduce 13%
15/04/15 16:12:37 INFO mapreduce.Job:  map 94% reduce 16%
15/04/15 16:12:39 INFO mapreduce.Job:  map 94% reduce 17%
15/04/15 16:12:40 INFO mapreduce.Job:  map 94% reduce 18%
15/04/15 16:12:41 INFO mapreduce.Job:  map 94% reduce 19%
15/04/15 16:12:43 INFO mapreduce.Job:  map 94% reduce 20%
15/04/15 16:12:46 INFO mapreduce.Job:  map 94% reduce 23%
15/04/15 16:12:48 INFO mapreduce.Job:  map 95% reduce 23%
15/04/15 16:12:49 INFO mapreduce.Job:  map 96% reduce 24%
15/04/15 16:12:51 INFO mapreduce.Job:  map 96% reduce 25%
15/04/15 16:12:52 INFO mapreduce.Job:  map 97% reduce 26%
15/04/15 16:12:53 INFO mapreduce.Job:  map 97% reduce 27%
15/04/15 16:12:54 INFO mapreduce.Job:  map 98% reduce 27%
15/04/15 16:12:55 INFO mapreduce.Job:  map 98% reduce 28%
15/04/15 16:12:56 INFO mapreduce.Job:  map 99% reduce 28%
15/04/15 16:12:58 INFO mapreduce.Job:  map 99% reduce 30%
15/04/15 16:12:59 INFO mapreduce.Job:  map 100% reduce 30%
15/04/15 16:13:01 INFO mapreduce.Job:  map 100% reduce 31%
15/04/15 16:13:02 INFO mapreduce.Job:  map 100% reduce 33%
15/04/15 16:13:10 INFO mapreduce.Job:  map 100% reduce 45%
15/04/15 16:13:11 INFO mapreduce.Job:  map 100% reduce 50%
15/04/15 16:13:12 INFO mapreduce.Job:  map 100% reduce 53%
15/04/15 16:13:13 INFO mapreduce.Job:  map 100% reduce 57%
15/04/15 16:13:14 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 16:13:15 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 16:13:16 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 16:13:17 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 16:13:19 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 16:13:20 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 16:13:46 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 16:14:11 INFO mapreduce.Job:  map 100% reduce 69%
15/04/15 16:14:36 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 16:15:11 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 16:15:47 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 16:16:29 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 16:17:08 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 16:17:59 INFO mapreduce.Job:  map 100% reduce 75%
15/04/15 16:18:56 INFO mapreduce.Job:  map 100% reduce 76%
15/04/15 16:20:08 INFO mapreduce.Job:  map 100% reduce 77%
15/04/15 16:21:24 INFO mapreduce.Job:  map 100% reduce 78%
15/04/15 16:23:02 INFO mapreduce.Job:  map 100% reduce 79%
15/04/15 16:24:04 INFO mapreduce.Job:  map 100% reduce 80%
15/04/15 16:25:13 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 16:25:54 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 16:27:12 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 16:28:17 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 16:28:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_5061_r_000010_0, Status : FAILED
Container [pid=3574,containerID=container_1422482982071_5061_01_000267] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5061_01_000267 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 3584 3574 3574 3574 (java) 6229 908 13312241664 591183 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000267/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000267 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000010_0 267 
	|- 3697 3681 3574 3574 (cat) 0 0 4231168 140 cat 
	|- 3574 9022 3574 3574 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000267/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000267 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000010_0 267 1>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000267/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000267/stderr  
	|- 3692 3681 3574 3574 (cat) 1 24 4231168 142 cat 
	|- 3681 3584 3574 3574 (R) 79453 13945 10505474048 2499891 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce46c36fb3263f 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:28:56 INFO mapreduce.Job:  map 100% reduce 80%
15/04/15 16:29:09 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 16:29:18 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 16:29:37 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 16:29:49 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 16:29:52 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 16:30:17 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 16:31:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_5061_r_000013_0, Status : FAILED
Container [pid=4145,containerID=container_1422482982071_5061_01_000270] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5061_01_000270 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 4287 4276 4145 4145 (cat) 0 29 4231168 142 cat 
	|- 4308 4276 4145 4145 (cat) 0 0 4231168 140 cat 
	|- 4276 4155 4145 4145 (R) 90350 15796 10336280576 2500429 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce46c36fb3263f 
	|- 4145 9067 4145 4145 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000270/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000270 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000013_0 270 1>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000270/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000270/stderr  
	|- 4155 4145 4145 4145 (java) 6249 947 13314486272 619980 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000270/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000270 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000013_0 270 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:31:01 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 16:31:08 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 16:31:22 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 16:31:31 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 16:31:43 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 16:31:46 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 16:32:07 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 16:32:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_5061_r_000011_0, Status : FAILED
Container [pid=41607,containerID=container_1422482982071_5061_01_000268] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5061_01_000268 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 41607 9245 41607 41607 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000268/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000268 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000011_0 268 1>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000268/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000268/stderr  
	|- 41723 41700 41607 41607 (cat) 0 0 4231168 140 cat 
	|- 41700 41616 41607 41607 (R) 102572 13065 10415251456 2519740 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce46c36fb3263f 
	|- 41711 41700 41607 41607 (cat) 1 31 4231168 142 cat 
	|- 41616 41607 41607 41607 (java) 5367 974 13313765376 591628 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000268/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000268 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000011_0 268 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:32:39 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 16:32:50 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 16:32:59 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 16:33:11 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 16:33:20 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 16:33:23 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 16:34:25 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 16:34:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_5061_r_000008_0, Status : FAILED
Container [pid=34184,containerID=container_1422482982071_5061_01_000265] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5061_01_000265 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 34184 11042 34184 34184 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000265/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000265 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000008_0 265 1>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000265/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000265/stderr  
	|- 34302 34290 34184 34184 (cat) 0 0 4231168 136 cat 
	|- 34290 34193 34184 34184 (R) 107848 19461 10554826752 2553783 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce46c36fb3263f 
	|- 34301 34290 34184 34184 (cat) 1 24 4231168 143 cat 
	|- 34193 34184 34184 34184 (java) 6469 1084 13312577536 587422 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000265/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000265 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000008_0 265 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:34:26 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 16:34:36 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 16:35:01 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 16:35:16 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 16:35:22 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 16:35:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_5061_r_000012_0, Status : FAILED
Container [pid=29615,containerID=container_1422482982071_5061_01_000269] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5061_01_000269 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 29749 29737 29615 29615 (cat) 0 0 4231168 134 cat 
	|- 29748 29737 29615 29615 (cat) 1 26 4231168 142 cat 
	|- 29737 29624 29615 29615 (R) 111742 21396 10458439680 2530238 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce46c36fb3263f 
	|- 29615 9754 29615 29615 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000269/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000269 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000012_0 269 1>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000269/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000269/stderr  
	|- 29624 29615 29615 29615 (java) 5768 1221 13312917504 590642 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000269/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000269 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000012_0 269 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:35:25 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 16:35:37 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 16:35:55 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 16:36:13 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 16:36:19 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 16:36:22 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 16:38:25 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 16:47:16 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 16:47:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_5061_r_000010_1, Status : FAILED
Container [pid=39030,containerID=container_1422482982071_5061_01_000287] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5061_01_000287 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 39098 39086 39030 39030 (cat) 0 0 4231168 140 cat 
	|- 39097 39086 39030 39030 (cat) 0 25 4231168 142 cat 
	|- 39086 39040 39030 39030 (R) 88398 14653 10428944384 2501559 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce46c36fb3263f 
	|- 39040 39030 39030 39030 (java) 6083 1029 13312094208 590126 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000287/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000287 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000010_1 287 
	|- 39030 8938 39030 39030 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000287/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000287 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000010_1 287 1>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000287/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000287/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:47:17 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 16:47:37 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 16:47:49 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 16:47:58 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 16:48:01 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 16:49:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_5061_r_000013_1, Status : FAILED
Container [pid=42985,containerID=container_1422482982071_5061_01_000288] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5061_01_000288 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 43072 43060 42985 42985 (cat) 0 0 103391232 158 cat 
	|- 42995 42985 42985 42985 (java) 5115 806 13412974592 586946 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000288/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000288 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000013_1 288 
	|- 43071 43060 42985 42985 (cat) 0 30 103391232 159 cat 
	|- 43060 42995 42985 42985 (R) 93111 14729 10451111936 2504357 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce46c36fb3263f 
	|- 42985 3820 42985 42985 (bash) 0 0 108650496 295 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000288/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000288 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000013_1 288 1>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000288/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000288/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:49:50 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 16:50:11 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 16:50:32 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 16:50:45 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 16:50:48 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 16:55:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_5061_r_000008_1, Status : FAILED
Container [pid=45842,containerID=container_1422482982071_5061_01_000290] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5061_01_000290 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 45909 45898 45842 45842 (cat) 0 22 4231168 142 cat 
	|- 45898 45852 45842 45842 (R) 101986 16232 10405548032 2517371 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce46c36fb3263f 
	|- 45911 45898 45842 45842 (cat) 0 0 4231168 137 cat 
	|- 45842 8824 45842 45842 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000290/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000290 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000008_1 290 1>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000290/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000290/stderr  
	|- 45852 45842 45842 45842 (java) 5331 694 13312290816 586920 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000290/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000290 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000008_1 290 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:55:06 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 16:55:27 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 16:55:36 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 16:56:01 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 16:56:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_5061_r_000012_1, Status : FAILED
Container [pid=11175,containerID=container_1422482982071_5061_01_000291] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 21.8 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5061_01_000291 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 11243 11230 11175 11175 (cat) 0 0 4231168 135 cat 
	|- 11230 11185 11175 11175 (R) 105160 17510 10026061824 2424678 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce46c36fb3263f 
	|- 11241 11230 11175 11175 (cat) 0 24 4231168 143 cat 
	|- 11175 9971 11175 11175 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000291/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000291 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000012_1 291 1>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000291/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000291/stderr  
	|- 11185 11175 11175 11175 (java) 5318 939 13313130496 647033 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000291/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000291 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000012_1 291 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:56:49 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 16:57:02 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 16:57:18 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 16:57:36 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 16:57:45 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 17:00:09 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 17:06:22 INFO mapreduce.Job:  map 100% reduce 93%
15/04/15 17:06:22 INFO mapreduce.Job: Task Id : attempt_1422482982071_5061_r_000013_2, Status : FAILED
Container [pid=16168,containerID=container_1422482982071_5061_01_000293] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5061_01_000293 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 16178 16168 16168 16168 (java) 6133 992 13315825664 610719 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000293/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000293 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000013_2 293 
	|- 16226 16178 16168 16168 (R) 80663 12299 10387263488 2467210 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce46c36fb3263f 
	|- 16238 16226 16168 16168 (cat) 0 0 4231168 141 cat 
	|- 16237 16226 16168 16168 (cat) 0 31 4231168 142 cat 
	|- 16168 9793 16168 16168 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000293/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000293 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000013_2 293 1>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000293/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000293/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 17:06:23 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 17:06:42 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 17:07:01 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 17:07:04 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 17:07:07 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 17:15:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_5061_r_000010_2, Status : FAILED
Container [pid=21032,containerID=container_1422482982071_5061_01_000292] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5061_01_000292 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 21137 21124 21032 21032 (cat) 0 0 4231168 139 cat 
	|- 21124 21042 21032 21032 (R) 115169 46177 10463735808 2531578 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce46c36fb3263f 
	|- 21136 21124 21032 21032 (cat) 1 28 4231168 142 cat 
	|- 21042 21032 21032 21032 (java) 5185 845 13311885312 591360 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000292/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000292 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000010_2 292 
	|- 21032 10523 21032 21032 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000292/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000292 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000010_2 292 1>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000292/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000292/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 17:15:04 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 17:15:21 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 17:15:33 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 17:15:45 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 17:15:48 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 17:17:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_5061_r_000008_2, Status : FAILED
Container [pid=43411,containerID=container_1422482982071_5061_01_000294] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5061_01_000294 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 43411 10887 43411 43411 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000294/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000294 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000008_2 294 1>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000294/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000294/stderr  
	|- 43481 43470 43411 43411 (cat) 0 25 4231168 142 cat 
	|- 43482 43470 43411 43411 (cat) 0 0 4231168 136 cat 
	|- 43421 43411 43411 43411 (java) 6084 1111 13313187840 589642 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000294/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000294 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000008_2 294 
	|- 43470 43421 43411 43411 (R) 109052 17731 10438733824 2525440 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce46c36fb3263f 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 17:17:09 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 17:17:20 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 17:17:39 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 17:17:57 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 17:21:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_5061_r_000012_2, Status : FAILED
Container [pid=35393,containerID=container_1422482982071_5061_01_000295] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5061_01_000295 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 35393 11042 35393 35393 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000295/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000295 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000012_2 295 1>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000295/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000295/stderr  
	|- 35481 35469 35393 35393 (cat) 0 0 4231168 134 cat 
	|- 35403 35393 35393 35393 (java) 6683 1332 13312892928 590317 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5061/container_1422482982071_5061_01_000295/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5061/container_1422482982071_5061_01_000295 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.168 50232 attempt_1422482982071_5061_r_000012_2 295 
	|- 35480 35469 35393 35393 (cat) 0 27 4231168 142 cat 
	|- 35469 35403 35393 35393 (R) 108343 34277 10593763328 2563309 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce46c36fb3263f 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 17:21:34 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 17:21:51 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 17:22:10 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 17:22:25 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 17:25:39 INFO mapreduce.Job:  map 100% reduce 100%
15/04/15 17:25:39 INFO mapreduce.Job: Job job_1422482982071_5061 failed with state FAILED due to: Task failed task_1422482982071_5061_r_000013
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/15 17:25:39 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=32427914237
		FILE: Number of bytes written=81931950289
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=27107640365
		HDFS: Number of bytes written=2604103406
		HDFS: Number of read operations=639
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=22
	Job Counters 
		Failed reduce tasks=14
		Killed map tasks=1
		Killed reduce tasks=3
		Launched map tasks=203
		Launched reduce tasks=28
		Data-local map tasks=152
		Rack-local map tasks=51
		Total time spent by all maps in occupied slots (ms)=34096314
		Total time spent by all reduces in occupied slots (ms)=70976776
		Total time spent by all map tasks (ms)=17048157
		Total time spent by all reduce tasks (ms)=35488388
		Total vcore-seconds taken by all map tasks=17048157
		Total vcore-seconds taken by all reduce tasks=35488388
		Total megabyte-seconds taken by all map tasks=138021879072
		Total megabyte-seconds taken by all reduce tasks=425860656000
	Map-Reduce Framework
		Map input records=632973453
		Map output records=567321113
		Map output bytes=48319013103
		Map output materialized bytes=49483437845
		Input split bytes=31916
		Combine input records=0
		Combine output records=0
		Reduce input groups=43334661
		Reduce shuffle bytes=32427927335
		Reduce input records=415715515
		Reduce output records=43549397
		Spilled Records=983036628
		Shuffled Maps =2222
		Failed Shuffles=0
		Merged Map outputs=2222
		GC time elapsed (ms)=146767
		CPU time spent (ms)=34234580
		Physical memory (bytes) snapshot=418180583424
		Virtual memory (bytes) snapshot=2000580915200
		Total committed heap usage (bytes)=582748475392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27107608449
	File Output Format Counters 
		Bytes Written=2604103406
	rmr
		reduce calls=43334661
15/04/15 17:25:39 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/15 17:25:44 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file46c368921b88

real	75m0.237s
user	0m33.309s
sys	0m3.755s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-202-5-false-googlebooks-eng-all-5gram-20120701-on"

$hadoop$D
[1] "mapreduce.job.maps=202"

$hadoop$D
[1] "mapred.reduce.tasks=5"


15/04/15 17:25:49 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/15 17:25:49 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5376010021913819044.jar tmpDir=null
15/04/15 17:25:49 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 17:25:49 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 17:25:50 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.149:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.192:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.162:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.163:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.203:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.190:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.199:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/15 17:25:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.195:50010
15/04/15 17:25:50 INFO mapreduce.JobSubmitter: number of splits:202
15/04/15 17:25:50 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_5070
15/04/15 17:25:51 INFO impl.YarnClientImpl: Submitted application application_1422482982071_5070
15/04/15 17:25:51 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_5070/
15/04/15 17:25:51 INFO mapreduce.Job: Running job: job_1422482982071_5070
15/04/15 17:25:56 INFO mapreduce.Job: Job job_1422482982071_5070 running in uber mode : false
15/04/15 17:25:56 INFO mapreduce.Job:  map 0% reduce 0%
15/04/15 17:26:06 INFO mapreduce.Job:  map 2% reduce 0%
15/04/15 17:26:07 INFO mapreduce.Job:  map 4% reduce 0%
15/04/15 17:26:08 INFO mapreduce.Job:  map 5% reduce 0%
15/04/15 17:26:09 INFO mapreduce.Job:  map 6% reduce 0%
15/04/15 17:26:10 INFO mapreduce.Job:  map 7% reduce 0%
15/04/15 17:26:12 INFO mapreduce.Job:  map 9% reduce 0%
15/04/15 17:26:13 INFO mapreduce.Job:  map 10% reduce 0%
15/04/15 17:26:15 INFO mapreduce.Job:  map 12% reduce 0%
15/04/15 17:26:16 INFO mapreduce.Job:  map 13% reduce 0%
15/04/15 17:26:18 INFO mapreduce.Job:  map 15% reduce 0%
15/04/15 17:26:19 INFO mapreduce.Job:  map 16% reduce 0%
15/04/15 17:26:21 INFO mapreduce.Job:  map 18% reduce 0%
15/04/15 17:26:22 INFO mapreduce.Job:  map 19% reduce 0%
15/04/15 17:26:23 INFO mapreduce.Job:  map 20% reduce 0%
15/04/15 17:26:24 INFO mapreduce.Job:  map 21% reduce 0%
15/04/15 17:26:25 INFO mapreduce.Job:  map 22% reduce 0%
15/04/15 17:26:26 INFO mapreduce.Job:  map 23% reduce 0%
15/04/15 17:26:27 INFO mapreduce.Job:  map 24% reduce 0%
15/04/15 17:26:28 INFO mapreduce.Job:  map 25% reduce 0%
15/04/15 17:26:29 INFO mapreduce.Job:  map 26% reduce 0%
15/04/15 17:26:30 INFO mapreduce.Job:  map 28% reduce 0%
15/04/15 17:26:32 INFO mapreduce.Job:  map 29% reduce 0%
15/04/15 17:26:33 INFO mapreduce.Job:  map 31% reduce 0%
15/04/15 17:26:34 INFO mapreduce.Job:  map 32% reduce 0%
15/04/15 17:26:36 INFO mapreduce.Job:  map 34% reduce 0%
15/04/15 17:26:37 INFO mapreduce.Job:  map 35% reduce 0%
15/04/15 17:26:38 INFO mapreduce.Job:  map 36% reduce 0%
15/04/15 17:26:39 INFO mapreduce.Job:  map 37% reduce 0%
15/04/15 17:26:40 INFO mapreduce.Job:  map 38% reduce 0%
15/04/15 17:26:41 INFO mapreduce.Job:  map 39% reduce 0%
15/04/15 17:26:42 INFO mapreduce.Job:  map 40% reduce 0%
15/04/15 17:26:43 INFO mapreduce.Job:  map 41% reduce 0%
15/04/15 17:26:44 INFO mapreduce.Job:  map 42% reduce 0%
15/04/15 17:26:45 INFO mapreduce.Job:  map 44% reduce 0%
15/04/15 17:26:47 INFO mapreduce.Job:  map 45% reduce 0%
15/04/15 17:26:48 INFO mapreduce.Job:  map 47% reduce 0%
15/04/15 17:26:50 INFO mapreduce.Job:  map 48% reduce 0%
15/04/15 17:26:51 INFO mapreduce.Job:  map 50% reduce 0%
15/04/15 17:26:52 INFO mapreduce.Job:  map 51% reduce 0%
15/04/15 17:26:54 INFO mapreduce.Job:  map 53% reduce 0%
15/04/15 17:26:55 INFO mapreduce.Job:  map 54% reduce 0%
15/04/15 17:26:56 INFO mapreduce.Job:  map 55% reduce 0%
15/04/15 17:26:57 INFO mapreduce.Job:  map 56% reduce 0%
15/04/15 17:26:58 INFO mapreduce.Job:  map 57% reduce 0%
15/04/15 17:26:59 INFO mapreduce.Job:  map 58% reduce 0%
15/04/15 17:27:00 INFO mapreduce.Job:  map 59% reduce 0%
15/04/15 17:27:02 INFO mapreduce.Job:  map 60% reduce 0%
15/04/15 17:27:04 INFO mapreduce.Job:  map 61% reduce 0%
15/04/15 17:27:06 INFO mapreduce.Job:  map 62% reduce 0%
15/04/15 17:27:10 INFO mapreduce.Job:  map 63% reduce 0%
15/04/15 17:27:13 INFO mapreduce.Job:  map 64% reduce 0%
15/04/15 17:27:14 INFO mapreduce.Job:  map 65% reduce 0%
15/04/15 17:27:15 INFO mapreduce.Job:  map 68% reduce 0%
15/04/15 17:27:16 INFO mapreduce.Job:  map 70% reduce 0%
15/04/15 17:27:17 INFO mapreduce.Job:  map 73% reduce 0%
15/04/15 17:27:18 INFO mapreduce.Job:  map 76% reduce 0%
15/04/15 17:27:19 INFO mapreduce.Job:  map 79% reduce 0%
15/04/15 17:27:20 INFO mapreduce.Job:  map 80% reduce 0%
15/04/15 17:27:21 INFO mapreduce.Job:  map 82% reduce 0%
15/04/15 17:27:22 INFO mapreduce.Job:  map 83% reduce 0%
15/04/15 17:27:23 INFO mapreduce.Job:  map 84% reduce 0%
15/04/15 17:27:24 INFO mapreduce.Job:  map 86% reduce 5%
15/04/15 17:27:25 INFO mapreduce.Job:  map 88% reduce 5%
15/04/15 17:27:26 INFO mapreduce.Job:  map 89% reduce 5%
15/04/15 17:27:27 INFO mapreduce.Job:  map 90% reduce 5%
15/04/15 17:27:28 INFO mapreduce.Job:  map 91% reduce 5%
15/04/15 17:27:31 INFO mapreduce.Job:  map 92% reduce 5%
15/04/15 17:27:36 INFO mapreduce.Job:  map 93% reduce 6%
15/04/15 17:27:39 INFO mapreduce.Job:  map 93% reduce 7%
15/04/15 17:27:42 INFO mapreduce.Job:  map 93% reduce 8%
15/04/15 17:27:45 INFO mapreduce.Job:  map 93% reduce 10%
15/04/15 17:27:51 INFO mapreduce.Job:  map 94% reduce 11%
15/04/15 17:27:52 INFO mapreduce.Job:  map 94% reduce 12%
15/04/15 17:27:53 INFO mapreduce.Job:  map 95% reduce 12%
15/04/15 17:27:55 INFO mapreduce.Job:  map 95% reduce 13%
15/04/15 17:27:56 INFO mapreduce.Job:  map 96% reduce 13%
15/04/15 17:27:58 INFO mapreduce.Job:  map 97% reduce 13%
15/04/15 17:27:59 INFO mapreduce.Job:  map 98% reduce 13%
15/04/15 17:28:00 INFO mapreduce.Job:  map 98% reduce 14%
15/04/15 17:28:01 INFO mapreduce.Job:  map 98% reduce 15%
15/04/15 17:28:02 INFO mapreduce.Job:  map 99% reduce 15%
15/04/15 17:28:04 INFO mapreduce.Job:  map 99% reduce 16%
15/04/15 17:28:05 INFO mapreduce.Job:  map 100% reduce 16%
15/04/15 17:28:07 INFO mapreduce.Job:  map 100% reduce 17%
15/04/15 17:28:13 INFO mapreduce.Job:  map 100% reduce 19%
15/04/15 17:28:16 INFO mapreduce.Job:  map 100% reduce 20%
15/04/15 17:28:22 INFO mapreduce.Job:  map 100% reduce 21%
15/04/15 17:28:23 INFO mapreduce.Job:  map 100% reduce 22%
15/04/15 17:28:28 INFO mapreduce.Job:  map 100% reduce 24%
15/04/15 17:28:32 INFO mapreduce.Job:  map 100% reduce 25%
15/04/15 17:28:37 INFO mapreduce.Job:  map 100% reduce 26%
15/04/15 17:28:40 INFO mapreduce.Job:  map 100% reduce 27%
15/04/15 17:28:44 INFO mapreduce.Job:  map 100% reduce 28%
15/04/15 17:28:46 INFO mapreduce.Job:  map 100% reduce 29%
15/04/15 17:28:49 INFO mapreduce.Job:  map 100% reduce 30%
15/04/15 17:28:55 INFO mapreduce.Job:  map 100% reduce 31%
15/04/15 17:28:56 INFO mapreduce.Job:  map 100% reduce 36%
15/04/15 17:28:58 INFO mapreduce.Job:  map 100% reduce 42%
15/04/15 17:29:00 INFO mapreduce.Job:  map 100% reduce 44%
15/04/15 17:29:02 INFO mapreduce.Job:  map 100% reduce 49%
15/04/15 17:29:05 INFO mapreduce.Job:  map 100% reduce 51%
15/04/15 17:29:08 INFO mapreduce.Job:  map 100% reduce 53%
15/04/15 17:29:14 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 17:29:32 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 17:32:30 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 17:42:44 INFO mapreduce.Job:  map 100% reduce 69%
15/04/15 17:46:34 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 17:48:27 INFO mapreduce.Job: Task Id : attempt_1422482982071_5070_r_000001_0, Status : FAILED
Container [pid=36625,containerID=container_1422482982071_5070_01_000257] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 21.8 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5070_01_000257 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 36791 36779 36625 36625 (cat) 0 0 4231168 142 cat 
	|- 36625 9608 36625 36625 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000257/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000257 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000001_0 257 1>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000257/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000257/stderr  
	|- 36635 36625 36625 36625 (java) 11618 1586 13315575808 645363 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000257/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000257 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000001_0 257 
	|- 36790 36779 36625 36625 (cat) 0 42 4231168 142 cat 
	|- 36779 36635 36625 36625 (R) 98207 17268 10045087744 2429337 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce54d336489c53 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 17:48:28 INFO mapreduce.Job:  map 100% reduce 56%
15/04/15 17:48:39 INFO mapreduce.Job:  map 100% reduce 57%
15/04/15 17:48:48 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 17:49:00 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 17:49:12 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 17:49:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_5070_r_000002_0, Status : FAILED
Container [pid=8640,containerID=container_1422482982071_5070_01_000258] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5070_01_000258 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 8640 9067 8640 8640 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000258/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000258 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000002_0 258 1>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000258/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000258/stderr  
	|- 8649 8640 8640 8640 (java) 11147 1797 13314101248 717809 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000258/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000258 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000002_0 258 
	|- 8775 8764 8640 8640 (cat) 1 24 4231168 142 cat 
	|- 8776 8764 8640 8640 (cat) 0 0 4231168 134 cat 
	|- 8764 8649 8640 8640 (R) 93215 26806 9822392320 2374954 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce54d336489c53 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 17:49:17 INFO mapreduce.Job:  map 100% reduce 47%
15/04/15 17:49:29 INFO mapreduce.Job:  map 100% reduce 48%
15/04/15 17:49:37 INFO mapreduce.Job:  map 100% reduce 49%
15/04/15 17:49:39 INFO mapreduce.Job:  map 100% reduce 50%
15/04/15 17:49:56 INFO mapreduce.Job:  map 100% reduce 51%
15/04/15 17:50:01 INFO mapreduce.Job:  map 100% reduce 52%
15/04/15 17:50:11 INFO mapreduce.Job:  map 100% reduce 53%
15/04/15 17:50:19 INFO mapreduce.Job:  map 100% reduce 54%
15/04/15 17:50:23 INFO mapreduce.Job:  map 100% reduce 57%
15/04/15 17:50:26 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 17:50:28 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 17:50:29 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 17:50:37 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 17:50:53 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 17:51:11 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 17:51:23 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 17:56:16 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 17:57:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_5070_r_000003_0, Status : FAILED
Container [pid=18807,containerID=container_1422482982071_5070_01_000259] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.8 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5070_01_000259 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 18816 18807 18807 18807 (java) 10557 1732 13312806912 637130 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000259/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000259 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000003_0 259 
	|- 18956 18944 18807 18807 (cat) 0 0 4231168 138 cat 
	|- 18955 18944 18807 18807 (cat) 0 26 4231168 142 cat 
	|- 18944 18816 18807 18807 (R) 99445 72800 10104512512 2443845 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce54d336489c53 
	|- 18807 9517 18807 18807 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000259/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000259 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000003_0 259 1>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000259/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000259/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 17:57:44 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 17:57:55 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 17:58:02 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 17:58:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_5070_r_000000_0, Status : FAILED
Container [pid=19060,containerID=container_1422482982071_5070_01_000256] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5070_01_000256 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 19060 10599 19060 19060 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000256/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000256 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000000_0 256 1>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000256/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000256/stderr  
	|- 19069 19060 19060 19060 (java) 11781 1810 13313822720 651963 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000256/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000256 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000000_0 256 
	|- 19202 19190 19060 19060 (cat) 0 0 4231168 142 cat 
	|- 19190 19069 19060 19060 (R) 145952 24502 10283266048 2487518 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce54d336489c53 
	|- 19201 19190 19060 19060 (cat) 0 52 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 17:58:03 INFO mapreduce.Job:  map 100% reduce 46%
15/04/15 17:58:14 INFO mapreduce.Job:  map 100% reduce 47%
15/04/15 17:58:15 INFO mapreduce.Job:  map 100% reduce 48%
15/04/15 17:58:24 INFO mapreduce.Job:  map 100% reduce 49%
15/04/15 17:58:35 INFO mapreduce.Job:  map 100% reduce 50%
15/04/15 17:58:36 INFO mapreduce.Job:  map 100% reduce 51%
15/04/15 17:58:49 INFO mapreduce.Job:  map 100% reduce 52%
15/04/15 17:58:57 INFO mapreduce.Job:  map 100% reduce 53%
15/04/15 17:59:09 INFO mapreduce.Job:  map 100% reduce 54%
15/04/15 17:59:18 INFO mapreduce.Job:  map 100% reduce 55%
15/04/15 17:59:22 INFO mapreduce.Job:  map 100% reduce 56%
15/04/15 17:59:35 INFO mapreduce.Job:  map 100% reduce 57%
15/04/15 17:59:47 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 18:00:08 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 18:00:15 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 18:08:14 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 18:10:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_5070_r_000001_1, Status : FAILED
Container [pid=7717,containerID=container_1422482982071_5070_01_000262] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 21.9 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5070_01_000262 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 7717 10269 7717 7717 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000262/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000262 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000001_1 262 1>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000262/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000262/stderr  
	|- 7783 7727 7717 7717 (R) 102378 15880 10202267648 2467743 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce54d336489c53 
	|- 7727 7717 7717 7717 (java) 10880 1892 13316104192 643433 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000262/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000262 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000001_1 262 
	|- 7795 7783 7717 7717 (cat) 0 41 4231168 142 cat 
	|- 7796 7783 7717 7717 (cat) 0 0 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 18:10:13 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 18:10:24 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 18:10:34 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 18:10:47 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 18:10:59 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 18:11:22 INFO mapreduce.Job: Task Id : attempt_1422482982071_5070_r_000002_1, Status : FAILED
Container [pid=41406,containerID=container_1422482982071_5070_01_000263] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5070_01_000263 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 41503 41492 41406 41406 (cat) 0 26 4231168 142 cat 
	|- 41406 9043 41406 41406 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000263/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000263 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000002_1 263 1>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000263/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000263/stderr  
	|- 41504 41492 41406 41406 (cat) 0 0 4231168 134 cat 
	|- 41415 41406 41406 41406 (java) 13211 2748 13313740800 702888 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000263/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000263 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000002_1 263 
	|- 41492 41415 41406 41406 (R) 101237 18558 9885593600 2390415 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce54d336489c53 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 18:11:23 INFO mapreduce.Job:  map 100% reduce 50%
15/04/15 18:11:26 INFO mapreduce.Job:  map 100% reduce 51%
15/04/15 18:11:34 INFO mapreduce.Job:  map 100% reduce 52%
15/04/15 18:11:40 INFO mapreduce.Job:  map 100% reduce 53%
15/04/15 18:11:49 INFO mapreduce.Job:  map 100% reduce 54%
15/04/15 18:11:53 INFO mapreduce.Job:  map 100% reduce 55%
15/04/15 18:12:07 INFO mapreduce.Job:  map 100% reduce 56%
15/04/15 18:12:11 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 18:12:14 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 18:12:17 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 18:12:20 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 18:12:31 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 18:12:41 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 18:13:00 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 18:13:23 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 18:13:26 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 18:15:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_5070_r_000003_1, Status : FAILED
Container [pid=48383,containerID=container_1422482982071_5070_01_000264] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5070_01_000264 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 48457 48446 48383 48383 (cat) 0 24 103391232 159 cat 
	|- 48458 48446 48383 48383 (cat) 0 0 103391232 155 cat 
	|- 48446 48392 48383 48383 (R) 81957 12333 9916694528 2373913 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce54d336489c53 
	|- 48392 48383 48383 48383 (java) 11564 2183 13412331520 701101 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000264/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000264 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000003_1 264 
	|- 48383 3817 48383 48383 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000264/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000264 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000003_1 264 1>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000264/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000264/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 18:15:59 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 18:16:10 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 18:16:20 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 18:16:41 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 18:17:02 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 18:17:20 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 18:17:33 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 18:17:54 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 18:18:21 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 18:18:24 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 18:31:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_5070_r_000000_1, Status : FAILED
Container [pid=29020,containerID=container_1422482982071_5070_01_000265] is running beyond physical memory limits. Current usage: 12.6 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5070_01_000265 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 29030 29020 29020 29020 (java) 13903 2610 13313507328 638435 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000265/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000265 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000000_1 265 
	|- 29020 10365 29020 29020 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000265/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000265 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000000_1 265 1>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000265/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000265/stderr  
	|- 29095 29084 29020 29020 (cat) 1 51 4231168 142 cat 
	|- 29084 29030 29020 29020 (R) 165898 24962 10977271808 2656920 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce54d336489c53 
	|- 29096 29084 29020 29020 (cat) 0 0 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 18:31:58 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 18:32:09 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 18:32:18 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 18:32:27 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 18:32:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_5070_r_000001_2, Status : FAILED
Container [pid=27186,containerID=container_1422482982071_5070_01_000266] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.9 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5070_01_000266 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 27491 27196 27186 27186 (R) 108280 13223 10211028992 2469850 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce54d336489c53 
	|- 27186 10523 27186 27186 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000266/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000266 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000001_2 266 1>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000266/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000266/stderr  
	|- 27196 27186 27186 27186 (java) 10747 1755 13314883584 615027 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000266/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000266 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000001_2 266 
	|- 27502 27491 27186 27186 (cat) 1 41 4231168 143 cat 
	|- 27503 27491 27186 27186 (cat) 0 0 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 18:32:36 INFO mapreduce.Job:  map 100% reduce 49%
15/04/15 18:32:37 INFO mapreduce.Job:  map 100% reduce 50%
15/04/15 18:32:49 INFO mapreduce.Job:  map 100% reduce 51%
15/04/15 18:32:58 INFO mapreduce.Job:  map 100% reduce 52%
15/04/15 18:33:01 INFO mapreduce.Job:  map 100% reduce 53%
15/04/15 18:33:10 INFO mapreduce.Job:  map 100% reduce 54%
15/04/15 18:33:16 INFO mapreduce.Job:  map 100% reduce 55%
15/04/15 18:33:28 INFO mapreduce.Job:  map 100% reduce 56%
15/04/15 18:33:35 INFO mapreduce.Job:  map 100% reduce 57%
15/04/15 18:33:43 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 18:33:46 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 18:33:56 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 18:34:08 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 18:34:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_5070_r_000002_2, Status : FAILED
Container [pid=9332,containerID=container_1422482982071_5070_01_000267] is running beyond physical memory limits. Current usage: 12.1 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5070_01_000267 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 9342 9332 9332 9332 (java) 10306 1852 13314777088 660664 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000267/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000267 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000002_2 267 
	|- 9390 9342 9332 9332 (R) 108357 17765 10336722944 2500555 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce54d336489c53 
	|- 9332 10269 9332 9332 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000267/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000267 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000002_2 267 1>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000267/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000267/stderr  
	|- 9401 9390 9332 9332 (cat) 0 27 4231168 142 cat 
	|- 9402 9390 9332 9332 (cat) 0 0 4231168 134 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 18:34:27 INFO mapreduce.Job:  map 100% reduce 53%
15/04/15 18:34:29 INFO mapreduce.Job:  map 100% reduce 54%
15/04/15 18:34:32 INFO mapreduce.Job:  map 100% reduce 57%
15/04/15 18:34:35 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 18:34:38 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 18:34:39 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 18:34:49 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 18:35:08 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 18:35:26 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 18:35:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_5070_r_000003_2, Status : FAILED
Container [pid=21909,containerID=container_1422482982071_5070_01_000268] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5070_01_000268 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 21919 21909 21909 21909 (java) 10538 1899 13312372736 615405 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000268/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000268 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000003_2 268 
	|- 22042 22031 21909 21909 (cat) 0 25 4231168 142 cat 
	|- 22043 22031 21909 21909 (cat) 0 0 4231168 139 cat 
	|- 22031 21919 21909 21909 (R) 88547 14018 10499465216 2540269 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce54d336489c53 
	|- 21909 9517 21909 21909 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5070/container_1422482982071_5070_01_000268/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000268 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 46331 attempt_1422482982071_5070_r_000003_2 268 1>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000268/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5070/container_1422482982071_5070_01_000268/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 18:35:29 INFO mapreduce.Job:  map 100% reduce 51%
15/04/15 18:35:44 INFO mapreduce.Job:  map 100% reduce 52%
15/04/15 18:35:50 INFO mapreduce.Job:  map 100% reduce 53%
15/04/15 18:35:57 INFO mapreduce.Job:  map 100% reduce 54%
15/04/15 18:36:09 INFO mapreduce.Job:  map 100% reduce 55%
15/04/15 18:36:18 INFO mapreduce.Job:  map 100% reduce 56%
15/04/15 18:36:27 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 18:36:30 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 18:36:36 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 18:36:45 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 18:37:08 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 18:37:22 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 18:37:38 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 18:37:41 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 18:53:02 INFO mapreduce.Job:  map 100% reduce 100%
15/04/15 18:53:03 INFO mapreduce.Job: Job job_1422482982071_5070 failed with state FAILED due to: Task failed task_1422482982071_5070_r_000003
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/15 18:53:03 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=8609021628
		FILE: Number of bytes written=58112033550
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=27107640365
		HDFS: Number of bytes written=709797763
		HDFS: Number of read operations=609
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed reduce tasks=12
		Killed map tasks=1
		Killed reduce tasks=4
		Launched map tasks=203
		Launched reduce tasks=17
		Data-local map tasks=147
		Rack-local map tasks=56
		Total time spent by all maps in occupied slots (ms)=35989220
		Total time spent by all reduces in occupied slots (ms)=51206470
		Total time spent by all map tasks (ms)=17994610
		Total time spent by all reduce tasks (ms)=25603235
		Total vcore-seconds taken by all map tasks=17994610
		Total vcore-seconds taken by all reduce tasks=25603235
		Total megabyte-seconds taken by all map tasks=145684362560
		Total megabyte-seconds taken by all reduce tasks=307238820000
	Map-Reduce Framework
		Map input records=632973453
		Map output records=567321149
		Map output bytes=48319013225
		Map output materialized bytes=49483425933
		Input split bytes=31916
		Combine input records=0
		Combine output records=0
		Reduce input groups=11812520
		Reduce shuffle bytes=8609022786
		Reduce input records=113539187
		Reduce output records=11870728
		Spilled Records=680860336
		Shuffled Maps =202
		Failed Shuffles=0
		Merged Map outputs=202
		GC time elapsed (ms)=92227
		CPU time spent (ms)=22472040
		Physical memory (bytes) snapshot=395810963456
		Virtual memory (bytes) snapshot=1868117524480
		Total committed heap usage (bytes)=561800675328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27107608449
	File Output Format Counters 
		Bytes Written=709797763
	rmr
		reduce calls=11812520
15/04/15 18:53:03 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/15 18:53:09 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file54d34fb0b730

real	87m25.532s
user	0m35.500s
sys	0m4.262s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-250-25-false-googlebooks-eng-all-5gram-20120701-on"

$hadoop$D
[1] "mapreduce.job.maps=250"

$hadoop$D
[1] "mapred.reduce.tasks=25"


15/04/15 18:53:15 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/15 18:53:15 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1528939496173619968.jar tmpDir=null
15/04/15 18:53:16 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 18:53:16 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 18:53:17 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.149:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.192:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.162:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.163:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.203:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.190:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.199:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/15 18:53:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.195:50010
15/04/15 18:53:17 INFO mapreduce.JobSubmitter: number of splits:250
15/04/15 18:53:17 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_5075
15/04/15 18:53:18 INFO impl.YarnClientImpl: Submitted application application_1422482982071_5075
15/04/15 18:53:18 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_5075/
15/04/15 18:53:18 INFO mapreduce.Job: Running job: job_1422482982071_5075
15/04/15 18:53:23 INFO mapreduce.Job: Job job_1422482982071_5075 running in uber mode : false
15/04/15 18:53:23 INFO mapreduce.Job:  map 0% reduce 0%
15/04/15 18:53:34 INFO mapreduce.Job:  map 2% reduce 0%
15/04/15 18:53:35 INFO mapreduce.Job:  map 3% reduce 0%
15/04/15 18:53:36 INFO mapreduce.Job:  map 4% reduce 0%
15/04/15 18:53:37 INFO mapreduce.Job:  map 6% reduce 0%
15/04/15 18:53:38 INFO mapreduce.Job:  map 7% reduce 0%
15/04/15 18:53:39 INFO mapreduce.Job:  map 8% reduce 0%
15/04/15 18:53:40 INFO mapreduce.Job:  map 10% reduce 0%
15/04/15 18:53:41 INFO mapreduce.Job:  map 11% reduce 0%
15/04/15 18:53:42 INFO mapreduce.Job:  map 12% reduce 0%
15/04/15 18:53:43 INFO mapreduce.Job:  map 13% reduce 0%
15/04/15 18:53:44 INFO mapreduce.Job:  map 14% reduce 0%
15/04/15 18:53:45 INFO mapreduce.Job:  map 15% reduce 0%
15/04/15 18:53:46 INFO mapreduce.Job:  map 17% reduce 0%
15/04/15 18:53:47 INFO mapreduce.Job:  map 18% reduce 0%
15/04/15 18:53:48 INFO mapreduce.Job:  map 19% reduce 0%
15/04/15 18:53:49 INFO mapreduce.Job:  map 21% reduce 0%
15/04/15 18:53:50 INFO mapreduce.Job:  map 22% reduce 0%
15/04/15 18:53:51 INFO mapreduce.Job:  map 23% reduce 0%
15/04/15 18:53:52 INFO mapreduce.Job:  map 24% reduce 0%
15/04/15 18:53:54 INFO mapreduce.Job:  map 26% reduce 0%
15/04/15 18:53:55 INFO mapreduce.Job:  map 27% reduce 0%
15/04/15 18:53:56 INFO mapreduce.Job:  map 28% reduce 0%
15/04/15 18:53:57 INFO mapreduce.Job:  map 30% reduce 0%
15/04/15 18:53:58 INFO mapreduce.Job:  map 31% reduce 0%
15/04/15 18:53:59 INFO mapreduce.Job:  map 32% reduce 0%
15/04/15 18:54:00 INFO mapreduce.Job:  map 34% reduce 0%
15/04/15 18:54:01 INFO mapreduce.Job:  map 35% reduce 0%
15/04/15 18:54:02 INFO mapreduce.Job:  map 36% reduce 0%
15/04/15 18:54:03 INFO mapreduce.Job:  map 38% reduce 0%
15/04/15 18:54:04 INFO mapreduce.Job:  map 39% reduce 0%
15/04/15 18:54:05 INFO mapreduce.Job:  map 40% reduce 0%
15/04/15 18:54:06 INFO mapreduce.Job:  map 42% reduce 0%
15/04/15 18:54:07 INFO mapreduce.Job:  map 43% reduce 0%
15/04/15 18:54:08 INFO mapreduce.Job:  map 44% reduce 0%
15/04/15 18:54:09 INFO mapreduce.Job:  map 46% reduce 0%
15/04/15 18:54:10 INFO mapreduce.Job:  map 47% reduce 0%
15/04/15 18:54:11 INFO mapreduce.Job:  map 48% reduce 0%
15/04/15 18:54:12 INFO mapreduce.Job:  map 50% reduce 0%
15/04/15 18:54:13 INFO mapreduce.Job:  map 51% reduce 0%
15/04/15 18:54:14 INFO mapreduce.Job:  map 52% reduce 0%
15/04/15 18:54:15 INFO mapreduce.Job:  map 54% reduce 0%
15/04/15 18:54:16 INFO mapreduce.Job:  map 55% reduce 0%
15/04/15 18:54:17 INFO mapreduce.Job:  map 56% reduce 0%
15/04/15 18:54:18 INFO mapreduce.Job:  map 57% reduce 0%
15/04/15 18:54:19 INFO mapreduce.Job:  map 58% reduce 0%
15/04/15 18:54:20 INFO mapreduce.Job:  map 59% reduce 0%
15/04/15 18:54:21 INFO mapreduce.Job:  map 60% reduce 0%
15/04/15 18:54:24 INFO mapreduce.Job:  map 61% reduce 0%
15/04/15 18:54:26 INFO mapreduce.Job:  map 62% reduce 0%
15/04/15 18:54:27 INFO mapreduce.Job:  map 63% reduce 0%
15/04/15 18:54:28 INFO mapreduce.Job:  map 67% reduce 0%
15/04/15 18:54:29 INFO mapreduce.Job:  map 70% reduce 0%
15/04/15 18:54:30 INFO mapreduce.Job:  map 73% reduce 0%
15/04/15 18:54:31 INFO mapreduce.Job:  map 76% reduce 0%
15/04/15 18:54:32 INFO mapreduce.Job:  map 80% reduce 0%
15/04/15 18:54:33 INFO mapreduce.Job:  map 82% reduce 0%
15/04/15 18:54:34 INFO mapreduce.Job:  map 85% reduce 0%
15/04/15 18:54:35 INFO mapreduce.Job:  map 86% reduce 0%
15/04/15 18:54:36 INFO mapreduce.Job:  map 87% reduce 0%
15/04/15 18:54:37 INFO mapreduce.Job:  map 89% reduce 9%
15/04/15 18:54:38 INFO mapreduce.Job:  map 89% reduce 19%
15/04/15 18:54:39 INFO mapreduce.Job:  map 90% reduce 19%
15/04/15 18:54:42 INFO mapreduce.Job:  map 91% reduce 19%
15/04/15 18:54:45 INFO mapreduce.Job:  map 92% reduce 19%
15/04/15 18:54:47 INFO mapreduce.Job:  map 92% reduce 20%
15/04/15 18:54:50 INFO mapreduce.Job:  map 93% reduce 23%
15/04/15 18:54:53 INFO mapreduce.Job:  map 93% reduce 25%
15/04/15 18:54:54 INFO mapreduce.Job:  map 94% reduce 25%
15/04/15 18:54:56 INFO mapreduce.Job:  map 94% reduce 26%
15/04/15 18:54:57 INFO mapreduce.Job:  map 95% reduce 26%
15/04/15 18:54:59 INFO mapreduce.Job:  map 96% reduce 27%
15/04/15 18:55:01 INFO mapreduce.Job:  map 97% reduce 27%
15/04/15 18:55:02 INFO mapreduce.Job:  map 98% reduce 30%
15/04/15 18:55:03 INFO mapreduce.Job:  map 99% reduce 30%
15/04/15 18:55:05 INFO mapreduce.Job:  map 99% reduce 32%
15/04/15 18:55:06 INFO mapreduce.Job:  map 100% reduce 32%
15/04/15 18:55:08 INFO mapreduce.Job:  map 100% reduce 36%
15/04/15 18:55:11 INFO mapreduce.Job:  map 100% reduce 49%
15/04/15 18:55:12 INFO mapreduce.Job:  map 100% reduce 52%
15/04/15 18:55:14 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 18:55:15 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 18:55:17 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 18:55:18 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 18:55:21 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 18:55:32 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 18:55:44 INFO mapreduce.Job:  map 100% reduce 69%
15/04/15 18:55:54 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 18:56:08 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 18:56:20 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 18:56:35 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 18:56:48 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 18:57:01 INFO mapreduce.Job:  map 100% reduce 75%
15/04/15 18:57:16 INFO mapreduce.Job:  map 100% reduce 76%
15/04/15 18:57:37 INFO mapreduce.Job:  map 100% reduce 77%
15/04/15 18:57:58 INFO mapreduce.Job:  map 100% reduce 78%
15/04/15 18:58:16 INFO mapreduce.Job:  map 100% reduce 79%
15/04/15 18:58:41 INFO mapreduce.Job:  map 100% reduce 80%
15/04/15 18:59:07 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 18:59:31 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 19:00:00 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 19:00:31 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 19:00:59 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 19:01:28 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 19:02:05 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 19:02:48 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 19:03:39 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 19:04:41 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:05:41 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:07:47 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:12:33 INFO mapreduce.Job:  map 100% reduce 94%
15/04/15 19:12:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000021_0, Status : FAILED
Container [pid=28909,containerID=container_1422482982071_5075_01_000324] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000324 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 29395 28918 28909 28909 (R) 90673 12935 10630025216 2540916 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 
	|- 29406 29395 28909 28909 (cat) 1 26 4231168 142 cat 
	|- 29408 29395 28909 28909 (cat) 0 0 4231168 138 cat 
	|- 28918 28909 28909 28909 (java) 4092 677 13312176128 590064 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000324/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000324 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000021_0 324 
	|- 28909 9763 28909 28909 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000324/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000324 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000021_0 324 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000324/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000324/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:12:34 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:12:55 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:13:07 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:14:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000017_0, Status : FAILED
Container [pid=46523,containerID=container_1422482982071_5075_01_000320] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000320 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 46532 46523 46523 46523 (java) 5167 742 13315706880 590452 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000320/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000320 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000017_0 320 
	|- 46952 46939 46523 46523 (cat) 0 0 4231168 140 cat 
	|- 46950 46939 46523 46523 (cat) 1 48 4231168 142 cat 
	|- 46523 8938 46523 46523 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000320/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000320 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000017_0 320 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000320/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000320/stderr  
	|- 46939 46532 46523 46523 (R) 101338 14398 10351955968 2504286 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:14:37 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 19:14:49 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:15:04 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:15:07 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:18:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000013_0, Status : FAILED
Container [pid=1487,containerID=container_1422482982071_5075_01_000316] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000316 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 2009 1998 1487 1487 (cat) 0 25 4231168 142 cat 
	|- 1487 10211 1487 1487 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000316/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000316 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000013_0 316 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000316/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000316/stderr  
	|- 1998 1498 1487 1487 (R) 116789 19905 10810564608 2604605 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 
	|- 2011 1998 1487 1487 (cat) 0 0 4231168 135 cat 
	|- 1498 1487 1487 1487 (java) 4889 658 13312946176 474548 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000316/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000316 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000013_0 316 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:18:03 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:18:22 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:18:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000015_0, Status : FAILED
Container [pid=33361,containerID=container_1422482982071_5075_01_000318] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000318 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 33819 33806 33361 33361 (cat) 0 0 4231168 138 cat 
	|- 33806 33370 33361 33361 (R) 119192 20378 10586009600 2561429 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 
	|- 33817 33806 33361 33361 (cat) 0 27 4231168 142 cat 
	|- 33370 33361 33361 33361 (java) 4910 717 13312081920 591239 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000318/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000318 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000015_0 318 
	|- 33361 9431 33361 33361 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000318/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000318 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000015_0 318 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000318/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000318/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:18:34 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 19:18:37 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:18:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000018_0, Status : FAILED
Container [pid=6976,containerID=container_1422482982071_5075_01_000321] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000321 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 6976 10444 6976 6976 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000321/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000321 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000018_0 321 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000321/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000321/stderr  
	|- 7441 6985 6976 6976 (R) 108945 30753 10287927296 2488623 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 
	|- 7452 7441 6976 6976 (cat) 0 27 4231168 142 cat 
	|- 7454 7441 6976 6976 (cat) 0 0 4231168 140 cat 
	|- 6985 6976 6976 6976 (java) 4276 765 13314301952 591585 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000321/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000321 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000018_0 321 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:18:38 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 19:18:45 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 19:18:51 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 19:19:03 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:19:09 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:19:14 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:22:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000012_0, Status : FAILED
Container [pid=8320,containerID=container_1422482982071_5075_01_000315] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000315 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 8747 8735 8320 8320 (cat) 0 0 4231168 134 cat 
	|- 8320 29409 8320 8320 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000315/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000315 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000012_0 315 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000315/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000315/stderr  
	|- 8746 8735 8320 8320 (cat) 0 26 4231168 142 cat 
	|- 8735 8329 8320 8320 (R) 114038 47947 10435936256 2510385 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 
	|- 8329 8320 8320 8320 (java) 4758 834 13312761856 590904 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000315/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000315 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000012_0 315 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:35:22 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000017_1, Status : FAILED
Container [pid=14927,containerID=container_1422482982071_5075_01_000330] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000330 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 14990 14979 14927 14927 (cat) 0 50 4231168 142 cat 
	|- 14992 14979 14927 14927 (cat) 0 0 4231168 140 cat 
	|- 14937 14927 14927 14927 (java) 4013 689 13313953792 589417 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000330/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000330 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000017_1 330 
	|- 14927 10211 14927 14927 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000330/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000330 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000017_1 330 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000330/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000330/stderr  
	|- 14979 14937 14927 14927 (R) 103942 16725 10385739776 2512535 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:35:23 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 19:35:34 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:35:43 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:35:56 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:37:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000015_1, Status : FAILED
Container [pid=2385,containerID=container_1422482982071_5075_01_000332] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000332 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 2516 2505 2385 2385 (cat) 0 25 103391232 159 cat 
	|- 2395 2385 2385 2385 (java) 3945 691 13411061760 589456 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000332/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000332 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000015_1 332 
	|- 2518 2505 2385 2385 (cat) 0 0 103391232 155 cat 
	|- 2505 2395 2385 2385 (R) 95901 14506 10467028992 2508276 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 
	|- 2385 3817 2385 2385 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000332/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000332 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000015_1 332 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000332/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000332/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:37:36 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:37:54 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:38:16 INFO mapreduce.Job:  map 100% reduce 93%
15/04/15 19:38:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000013_1, Status : FAILED
Container [pid=2338,containerID=container_1422482982071_5075_01_000331] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000331 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 2348 2338 2338 2338 (java) 4411 721 13411778560 590057 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000331/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000331 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000013_1 331 
	|- 2447 2421 2338 2338 (cat) 0 23 103391232 159 cat 
	|- 2421 2348 2338 2338 (R) 102476 15397 10456080384 2505598 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 
	|- 2338 3817 2338 2338 (bash) 0 0 108650496 297 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000331/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000331 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000013_1 331 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000331/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000331/stderr  
	|- 2451 2421 2338 2338 (cat) 0 0 103391232 152 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:38:20 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:38:32 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:38:53 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:38:56 INFO mapreduce.Job:  map 100% reduce 93%
15/04/15 19:41:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000018_1, Status : FAILED
Container [pid=2453,containerID=container_1422482982071_5075_01_000333] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000333 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 2453 3817 2453 2453 (bash) 0 0 108650496 295 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000333/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000333 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000018_1 333 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000333/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000333/stderr  
	|- 2538 2525 2453 2453 (cat) 0 0 103391232 156 cat 
	|- 2525 2463 2453 2453 (R) 115196 18112 10397630464 2491329 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 
	|- 2536 2525 2453 2453 (cat) 0 27 103391232 159 cat 
	|- 2463 2453 2453 2453 (java) 4203 777 13412962304 589152 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000333/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000333 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000018_1 333 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:41:35 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:41:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000012_1, Status : FAILED
Container [pid=34299,containerID=container_1422482982071_5075_01_000334] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.4 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000334 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 34299 9261 34299 34299 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000334/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000334 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000012_1 334 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000334/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000334/stderr  
	|- 34309 34299 34299 34299 (java) 4978 1028 13312876544 586246 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000334/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000334 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000012_1 334 
	|- 34364 34352 34299 34299 (cat) 0 0 4231168 134 cat 
	|- 34352 34309 34299 34299 (R) 105648 18945 10724777984 2570860 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 
	|- 34363 34352 34299 34299 (cat) 0 27 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:41:57 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 19:42:08 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:42:09 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:42:23 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:42:34 INFO mapreduce.Job:  map 100% reduce 93%
15/04/15 19:44:12 INFO mapreduce.Job:  map 100% reduce 94%
15/04/15 19:55:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000017_2, Status : FAILED
Container [pid=8348,containerID=container_1422482982071_5075_01_000335] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000335 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 8402 8358 8348 8348 (R) 100776 14869 10498093056 2515855 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 
	|- 8415 8402 8348 8348 (cat) 0 0 103391232 157 cat 
	|- 8413 8402 8348 8348 (cat) 1 45 103391232 159 cat 
	|- 8348 3816 8348 8348 (bash) 0 0 108650496 297 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000335/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000335 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000017_2 335 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000335/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000335/stderr  
	|- 8358 8348 8348 8348 (java) 4205 694 13413261312 588682 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000335/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000335 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000017_2 335 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:55:18 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:55:40 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:55:52 INFO mapreduce.Job:  map 100% reduce 93%
15/04/15 19:57:12 INFO mapreduce.Job:  map 100% reduce 94%
15/04/15 19:57:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000015_2, Status : FAILED
Container [pid=30675,containerID=container_1422482982071_5075_01_000336] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000336 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 30685 30675 30675 30675 (java) 4818 850 13312458752 592289 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000336/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000336 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000015_2 336 
	|- 30675 40699 30675 30675 (bash) 0 1 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000336/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000336 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000015_2 336 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000336/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000336/stderr  
	|- 30742 30729 30675 30675 (cat) 0 0 4231168 139 cat 
	|- 30740 30729 30675 30675 (cat) 0 26 4231168 142 cat 
	|- 30729 30685 30675 30675 (R) 100055 17905 10341830656 2501814 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:57:56 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:58:14 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:58:29 INFO mapreduce.Job:  map 100% reduce 93%
15/04/15 19:58:36 INFO mapreduce.Job:  map 100% reduce 94%
15/04/15 19:59:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000013_2, Status : FAILED
Container [pid=11237,containerID=container_1422482982071_5075_01_000337] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000337 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 11237 3799 11237 11237 (bash) 0 0 108650496 295 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000337/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000337 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000013_2 337 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000337/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000337/stderr  
	|- 11301 11290 11237 11237 (cat) 0 23 103391232 160 cat 
	|- 11247 11237 11237 11237 (java) 4700 781 13411221504 587465 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000337/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000337 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000013_2 337 
	|- 11303 11290 11237 11237 (cat) 0 0 103391232 153 cat 
	|- 11290 11247 11237 11237 (R) 103114 18638 10478522368 2511046 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:59:16 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:59:28 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:59:50 INFO mapreduce.Job:  map 100% reduce 93%
15/04/15 19:59:53 INFO mapreduce.Job:  map 100% reduce 94%
15/04/15 20:04:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000018_2, Status : FAILED
Container [pid=41163,containerID=container_1422482982071_5075_01_000338] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000338 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 41173 41163 41163 41163 (java) 5125 895 13313368064 591364 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000338/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000338 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000018_2 338 
	|- 41215 41173 41163 41163 (R) 109928 25854 10517475328 2544665 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 
	|- 41163 6181 41163 41163 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000338/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000338 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000018_2 338 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000338/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000338/stderr  
	|- 41226 41215 41163 41163 (cat) 0 26 4231168 142 cat 
	|- 41228 41215 41163 41163 (cat) 0 0 4231168 140 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:04:52 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 20:05:03 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 20:05:22 INFO mapreduce.Job:  map 100% reduce 93%
15/04/15 20:05:25 INFO mapreduce.Job:  map 100% reduce 94%
15/04/15 20:15:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_5075_r_000012_2, Status : FAILED
Container [pid=30182,containerID=container_1422482982071_5075_01_000339] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5075_01_000339 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 30182 9763 30182 30182 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000339/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000339 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000012_2 339 1>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000339/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000339/stderr  
	|- 30249 30238 30182 30182 (cat) 0 26 4231168 142 cat 
	|- 30238 30192 30182 30182 (R) 111820 84522 10550706176 2552798 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5d1f295cd6c4 
	|- 30250 30238 30182 30182 (cat) 0 0 4231168 134 cat 
	|- 30192 30182 30182 30182 (java) 4310 800 13312749568 590246 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5075/container_1422482982071_5075_01_000339/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5075/container_1422482982071_5075_01_000339 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.194 37115 attempt_1422482982071_5075_r_000012_2 339 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:16:08 INFO mapreduce.Job:  map 100% reduce 100%
15/04/15 20:16:08 INFO mapreduce.Job: Job job_1422482982071_5075 failed with state FAILED due to: Task failed task_1422482982071_5075_r_000017
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/15 20:16:09 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=34293657868
		FILE: Number of bytes written=83802646581
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=27107649938
		HDFS: Number of bytes written=2841066845
		HDFS: Number of read operations=810
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Failed reduce tasks=17
		Killed map tasks=1
		Killed reduce tasks=4
		Launched map tasks=251
		Launched reduce tasks=41
		Data-local map tasks=183
		Rack-local map tasks=68
		Total time spent by all maps in occupied slots (ms)=35292890
		Total time spent by all reduces in occupied slots (ms)=85734238
		Total time spent by all map tasks (ms)=17646445
		Total time spent by all reduce tasks (ms)=42867119
		Total vcore-seconds taken by all map tasks=17646445
		Total vcore-seconds taken by all reduce tasks=42867119
		Total megabyte-seconds taken by all map tasks=142865618720
		Total megabyte-seconds taken by all reduce tasks=514405428000
	Map-Reduce Framework
		Map input records=632973453
		Map output records=567302094
		Map output bytes=48318414022
		Map output materialized bytes=49482820653
		Input split bytes=39500
		Combine input records=0
		Combine output records=0
		Reduce input groups=47268737
		Reduce shuffle bytes=34293687616
		Reduce input records=453691214
		Reduce output records=47506759
		Spilled Records=1020993308
		Shuffled Maps =5000
		Failed Shuffles=0
		Merged Map outputs=5000
		GC time elapsed (ms)=167411
		CPU time spent (ms)=34620070
		Physical memory (bytes) snapshot=524256907264
		Virtual memory (bytes) snapshot=2562516951040
		Total committed heap usage (bytes)=734535282688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27107610438
	File Output Format Counters 
		Bytes Written=2841066845
	rmr
		reduce calls=47268737
15/04/15 20:16:09 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/15 20:16:15 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file5d1f4ad6a20e

real	83m5.650s
user	0m39.471s
sys	0m4.473s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-250-15-false-googlebooks-eng-all-5gram-20120701-on"

$hadoop$D
[1] "mapreduce.job.maps=250"

$hadoop$D
[1] "mapred.reduce.tasks=15"


15/04/15 20:16:21 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/15 20:16:21 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8574213496065254082.jar tmpDir=null
15/04/15 20:16:22 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 20:16:22 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 20:16:23 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.149:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.192:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.162:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.163:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.203:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.190:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.199:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/15 20:16:23 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.195:50010
15/04/15 20:16:23 INFO mapreduce.JobSubmitter: number of splits:250
15/04/15 20:16:24 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_5079
15/04/15 20:16:24 INFO impl.YarnClientImpl: Submitted application application_1422482982071_5079
15/04/15 20:16:24 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_5079/
15/04/15 20:16:24 INFO mapreduce.Job: Running job: job_1422482982071_5079
15/04/15 20:16:31 INFO mapreduce.Job: Job job_1422482982071_5079 running in uber mode : false
15/04/15 20:16:31 INFO mapreduce.Job:  map 0% reduce 0%
15/04/15 20:16:41 INFO mapreduce.Job:  map 1% reduce 0%
15/04/15 20:16:42 INFO mapreduce.Job:  map 3% reduce 0%
15/04/15 20:16:43 INFO mapreduce.Job:  map 4% reduce 0%
15/04/15 20:16:44 INFO mapreduce.Job:  map 6% reduce 0%
15/04/15 20:16:45 INFO mapreduce.Job:  map 8% reduce 0%
15/04/15 20:16:47 INFO mapreduce.Job:  map 9% reduce 0%
15/04/15 20:16:48 INFO mapreduce.Job:  map 11% reduce 0%
15/04/15 20:16:49 INFO mapreduce.Job:  map 12% reduce 0%
15/04/15 20:16:50 INFO mapreduce.Job:  map 13% reduce 0%
15/04/15 20:16:51 INFO mapreduce.Job:  map 15% reduce 0%
15/04/15 20:16:52 INFO mapreduce.Job:  map 16% reduce 0%
15/04/15 20:16:53 INFO mapreduce.Job:  map 17% reduce 0%
15/04/15 20:16:54 INFO mapreduce.Job:  map 19% reduce 0%
15/04/15 20:16:55 INFO mapreduce.Job:  map 20% reduce 0%
15/04/15 20:16:56 INFO mapreduce.Job:  map 21% reduce 0%
15/04/15 20:16:57 INFO mapreduce.Job:  map 23% reduce 0%
15/04/15 20:16:58 INFO mapreduce.Job:  map 24% reduce 0%
15/04/15 20:16:59 INFO mapreduce.Job:  map 25% reduce 0%
15/04/15 20:17:00 INFO mapreduce.Job:  map 27% reduce 0%
15/04/15 20:17:01 INFO mapreduce.Job:  map 28% reduce 0%
15/04/15 20:17:02 INFO mapreduce.Job:  map 29% reduce 0%
15/04/15 20:17:03 INFO mapreduce.Job:  map 31% reduce 0%
15/04/15 20:17:04 INFO mapreduce.Job:  map 32% reduce 0%
15/04/15 20:17:05 INFO mapreduce.Job:  map 33% reduce 0%
15/04/15 20:17:06 INFO mapreduce.Job:  map 35% reduce 0%
15/04/15 20:17:07 INFO mapreduce.Job:  map 36% reduce 0%
15/04/15 20:17:08 INFO mapreduce.Job:  map 37% reduce 0%
15/04/15 20:17:09 INFO mapreduce.Job:  map 39% reduce 0%
15/04/15 20:17:11 INFO mapreduce.Job:  map 40% reduce 0%
15/04/15 20:17:12 INFO mapreduce.Job:  map 42% reduce 0%
15/04/15 20:17:13 INFO mapreduce.Job:  map 43% reduce 0%
15/04/15 20:17:14 INFO mapreduce.Job:  map 44% reduce 0%
15/04/15 20:17:15 INFO mapreduce.Job:  map 46% reduce 0%
15/04/15 20:17:16 INFO mapreduce.Job:  map 47% reduce 0%
15/04/15 20:17:17 INFO mapreduce.Job:  map 48% reduce 0%
15/04/15 20:17:18 INFO mapreduce.Job:  map 50% reduce 0%
15/04/15 20:17:19 INFO mapreduce.Job:  map 51% reduce 0%
15/04/15 20:17:20 INFO mapreduce.Job:  map 52% reduce 0%
15/04/15 20:17:21 INFO mapreduce.Job:  map 54% reduce 0%
15/04/15 20:17:22 INFO mapreduce.Job:  map 55% reduce 0%
15/04/15 20:17:23 INFO mapreduce.Job:  map 56% reduce 0%
15/04/15 20:17:24 INFO mapreduce.Job:  map 57% reduce 0%
15/04/15 20:17:25 INFO mapreduce.Job:  map 58% reduce 0%
15/04/15 20:17:26 INFO mapreduce.Job:  map 59% reduce 0%
15/04/15 20:17:27 INFO mapreduce.Job:  map 60% reduce 0%
15/04/15 20:17:28 INFO mapreduce.Job:  map 61% reduce 0%
15/04/15 20:17:30 INFO mapreduce.Job:  map 62% reduce 0%
15/04/15 20:17:32 INFO mapreduce.Job:  map 63% reduce 0%
15/04/15 20:17:35 INFO mapreduce.Job:  map 64% reduce 0%
15/04/15 20:17:36 INFO mapreduce.Job:  map 65% reduce 0%
15/04/15 20:17:37 INFO mapreduce.Job:  map 68% reduce 0%
15/04/15 20:17:38 INFO mapreduce.Job:  map 71% reduce 0%
15/04/15 20:17:39 INFO mapreduce.Job:  map 75% reduce 0%
15/04/15 20:17:40 INFO mapreduce.Job:  map 79% reduce 0%
15/04/15 20:17:41 INFO mapreduce.Job:  map 81% reduce 0%
15/04/15 20:17:42 INFO mapreduce.Job:  map 83% reduce 0%
15/04/15 20:17:43 INFO mapreduce.Job:  map 86% reduce 0%
15/04/15 20:17:44 INFO mapreduce.Job:  map 87% reduce 0%
15/04/15 20:17:45 INFO mapreduce.Job:  map 89% reduce 0%
15/04/15 20:17:46 INFO mapreduce.Job:  map 91% reduce 0%
15/04/15 20:17:47 INFO mapreduce.Job:  map 91% reduce 12%
15/04/15 20:17:48 INFO mapreduce.Job:  map 92% reduce 12%
15/04/15 20:17:49 INFO mapreduce.Job:  map 93% reduce 12%
15/04/15 20:17:54 INFO mapreduce.Job:  map 94% reduce 12%
15/04/15 20:18:00 INFO mapreduce.Job:  map 94% reduce 13%
15/04/15 20:18:03 INFO mapreduce.Job:  map 94% reduce 14%
15/04/15 20:18:06 INFO mapreduce.Job:  map 94% reduce 17%
15/04/15 20:18:07 INFO mapreduce.Job:  map 95% reduce 17%
15/04/15 20:18:09 INFO mapreduce.Job:  map 96% reduce 19%
15/04/15 20:18:10 INFO mapreduce.Job:  map 97% reduce 19%
15/04/15 20:18:12 INFO mapreduce.Job:  map 98% reduce 21%
15/04/15 20:18:15 INFO mapreduce.Job:  map 99% reduce 24%
15/04/15 20:18:16 INFO mapreduce.Job:  map 100% reduce 24%
15/04/15 20:18:18 INFO mapreduce.Job:  map 100% reduce 27%
15/04/15 20:18:20 INFO mapreduce.Job:  map 100% reduce 28%
15/04/15 20:18:21 INFO mapreduce.Job:  map 100% reduce 32%
15/04/15 20:18:24 INFO mapreduce.Job:  map 100% reduce 36%
15/04/15 20:18:27 INFO mapreduce.Job:  map 100% reduce 40%
15/04/15 20:18:30 INFO mapreduce.Job:  map 100% reduce 47%
15/04/15 20:18:33 INFO mapreduce.Job:  map 100% reduce 54%
15/04/15 20:18:35 INFO mapreduce.Job:  map 100% reduce 55%
15/04/15 20:18:36 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 20:18:38 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 20:18:39 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 20:18:41 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 20:18:42 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 20:19:00 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 20:19:27 INFO mapreduce.Job:  map 100% reduce 69%
15/04/15 20:19:54 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 20:20:30 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 20:21:04 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 20:21:47 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 20:22:32 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 20:23:25 INFO mapreduce.Job:  map 100% reduce 75%
15/04/15 20:24:27 INFO mapreduce.Job:  map 100% reduce 76%
15/04/15 20:25:33 INFO mapreduce.Job:  map 100% reduce 77%
15/04/15 20:26:24 INFO mapreduce.Job:  map 100% reduce 78%
15/04/15 20:27:42 INFO mapreduce.Job:  map 100% reduce 79%
15/04/15 20:28:58 INFO mapreduce.Job:  map 100% reduce 80%
15/04/15 20:29:41 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 20:30:40 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 20:31:40 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 20:32:44 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 20:34:12 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:34:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_5079_r_000010_0, Status : FAILED
Container [pid=2539,containerID=container_1422482982071_5079_01_000313] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.9 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5079_01_000313 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 2549 2539 2539 2539 (java) 5494 714 13312397312 616601 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000313/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000313 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000010_0 313 
	|- 2539 9412 2539 2539 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000313/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000313 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000010_0 313 1>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000313/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000313/stderr  
	|- 2705 2693 2539 2539 (cat) 0 0 4231168 140 cat 
	|- 2704 2693 2539 2539 (cat) 1 26 4231168 142 cat 
	|- 2693 2549 2539 2539 (R) 83558 12768 10213855232 2470539 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce62e719031ac8 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:34:36 INFO mapreduce.Job:  map 100% reduce 80%
15/04/15 20:34:47 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 20:34:58 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 20:35:16 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 20:35:19 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 20:35:22 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:35:27 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 20:36:52 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 20:37:23 INFO mapreduce.Job: Task Id : attempt_1422482982071_5079_r_000011_0, Status : FAILED
Container [pid=16552,containerID=container_1422482982071_5079_01_000314] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5079_01_000314 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 16664 16561 16552 16552 (R) 98687 14103 10261196800 2482130 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce62e719031ac8 
	|- 16552 10211 16552 16552 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000314/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000314 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000011_0 314 1>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000314/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000314/stderr  
	|- 16678 16664 16552 16552 (cat) 0 0 4231168 139 cat 
	|- 16561 16552 16552 16552 (java) 5978 681 13312712704 618604 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000314/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000314 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000011_0 314 
	|- 16677 16664 16552 16552 (cat) 0 31 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:37:24 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 20:37:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_5079_r_000012_0, Status : FAILED
Container [pid=16687,containerID=container_1422482982071_5079_01_000315] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5079_01_000315 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 16687 3946 16687 16687 (bash) 0 0 108650496 297 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000315/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000315 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000012_0 315 1>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000315/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000315/stderr  
	|- 16814 16697 16687 16687 (R) 98134 15191 10068398080 2410935 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce62e719031ac8 
	|- 16697 16687 16687 16687 (java) 5819 890 13411282944 666065 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000315/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000315 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000012_0 315 
	|- 16826 16814 16687 16687 (cat) 0 0 103391232 151 cat 
	|- 16825 16814 16687 16687 (cat) 0 27 103391232 159 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:37:34 INFO mapreduce.Job:  map 100% reduce 78%
15/04/15 20:37:35 INFO mapreduce.Job:  map 100% reduce 79%
15/04/15 20:37:45 INFO mapreduce.Job:  map 100% reduce 80%
15/04/15 20:37:54 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 20:38:07 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 20:38:10 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 20:38:19 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:38:38 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 20:38:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_5079_r_000013_0, Status : FAILED
Container [pid=34536,containerID=container_1422482982071_5079_01_000316] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.9 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5079_01_000316 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 34662 34651 34536 34536 (cat) 1 30 4231168 142 cat 
	|- 34663 34651 34536 34536 (cat) 0 0 4231168 140 cat 
	|- 34651 34545 34536 34536 (R) 102453 18234 10194366464 2465782 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce62e719031ac8 
	|- 34545 34536 34536 34536 (java) 5911 723 13314056192 628664 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000316/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000316 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000013_0 316 
	|- 34536 9420 34536 34536 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000316/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000316 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000013_0 316 1>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000316/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000316/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:38:42 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 20:38:57 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 20:39:14 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:39:24 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 20:39:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_5079_r_000008_0, Status : FAILED
Container [pid=4118,containerID=container_1422482982071_5079_01_000311] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 21.9 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5079_01_000311 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 4127 4118 4118 4118 (java) 5757 764 13312278528 611961 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000311/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000311 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000008_0 311 
	|- 4211 4127 4118 4118 (R) 107139 17881 10200039424 2467197 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce62e719031ac8 
	|- 4223 4211 4118 4118 (cat) 0 0 4231168 137 cat 
	|- 4222 4211 4118 4118 (cat) 1 26 4231168 142 cat 
	|- 4118 9245 4118 4118 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000311/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000311 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000008_0 311 1>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000311/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000311/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:39:25 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 20:39:27 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 20:39:30 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 20:39:35 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 20:39:52 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:40:06 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 20:40:15 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 20:40:18 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 20:42:56 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 20:55:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_5079_r_000010_1, Status : FAILED
Container [pid=10355,containerID=container_1422482982071_5079_01_000319] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5079_01_000319 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 10421 10409 10355 10355 (cat) 0 0 4231168 140 cat 
	|- 10420 10409 10355 10355 (cat) 1 25 4231168 142 cat 
	|- 10365 10355 10355 10355 (java) 5294 837 13313064960 590213 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000319/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000319 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000010_1 319 
	|- 10355 11626 10355 10355 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000319/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000319 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000010_1 319 1>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000319/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000319/stderr  
	|- 10409 10365 10355 10355 (R) 96359 21254 10316173312 2495519 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce62e719031ac8 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:55:04 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:55:25 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 20:55:37 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 20:55:49 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 20:55:52 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 20:57:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_5079_r_000013_1, Status : FAILED
Container [pid=37699,containerID=container_1422482982071_5079_01_000322] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.7 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5079_01_000322 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 37709 37699 37699 37699 (java) 5097 777 13413974016 591711 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000322/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000322 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000013_1 322 
	|- 37754 37709 37699 37699 (R) 93166 13350 10667069440 2549859 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce62e719031ac8 
	|- 37699 3810 37699 37699 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000322/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000322 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000013_1 322 1>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000322/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000322/stderr  
	|- 37765 37754 37699 37699 (cat) 0 28 103391232 159 cat 
	|- 37766 37754 37699 37699 (cat) 0 0 103391232 156 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:57:18 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:57:39 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 20:58:01 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 20:58:14 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 20:58:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_5079_r_000011_1, Status : FAILED
Container [pid=25806,containerID=container_1422482982071_5079_01_000320] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5079_01_000320 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 25806 9793 25806 25806 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000320/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000320 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000011_1 320 1>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000320/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000320/stderr  
	|- 25816 25806 25806 25806 (java) 5856 970 13312389120 589739 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000320/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000320 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000011_1 320 
	|- 25899 25816 25806 25806 (R) 98965 23189 10604920832 2566014 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce62e719031ac8 
	|- 25911 25899 25806 25806 (cat) 0 0 4231168 139 cat 
	|- 25910 25899 25806 25806 (cat) 0 29 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:58:39 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:59:00 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 20:59:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_5079_r_000012_1, Status : FAILED
Container [pid=37628,containerID=container_1422482982071_5079_01_000321] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5079_01_000321 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 37696 37683 37628 37628 (cat) 0 25 103391232 159 cat 
	|- 37683 37637 37628 37628 (R) 106282 16502 10447765504 2503555 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce62e719031ac8 
	|- 37637 37628 37628 37628 (java) 5599 1026 13411774464 593162 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000321/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000321 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000012_1 321 
	|- 37628 3810 37628 37628 (bash) 0 0 108650496 297 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000321/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000321 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000012_1 321 1>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000321/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000321/stderr  
	|- 37697 37683 37628 37628 (cat) 0 0 103391232 151 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:59:11 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 20:59:13 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 20:59:23 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 20:59:25 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 20:59:28 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:59:33 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 20:59:57 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 21:00:09 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 21:00:13 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 21:03:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_5079_r_000008_1, Status : FAILED
Container [pid=5919,containerID=container_1422482982071_5079_01_000323] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5079_01_000323 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 5979 5929 5919 5919 (R) 113396 27630 10439770112 2525693 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce62e719031ac8 
	|- 5919 10433 5919 5919 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000323/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000323 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000008_1 323 1>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000323/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000323/stderr  
	|- 5929 5919 5919 5919 (java) 5707 997 13312421888 590864 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000323/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000323 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000008_1 323 
	|- 5991 5979 5919 5919 (cat) 0 0 4231168 136 cat 
	|- 5990 5979 5919 5919 (cat) 0 25 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:03:48 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 21:04:09 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 21:04:27 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 21:04:39 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 21:12:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_5079_r_000010_2, Status : FAILED
Container [pid=38376,containerID=container_1422482982071_5079_01_000324] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5079_01_000324 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 38431 38386 38376 38376 (R) 85109 15049 10572795904 2509295 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce62e719031ac8 
	|- 38443 38431 38376 38376 (cat) 0 0 103391232 157 cat 
	|- 38442 38431 38376 38376 (cat) 0 24 103391232 159 cat 
	|- 38376 3828 38376 38376 (bash) 0 0 108650496 297 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000324/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000324 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000010_2 324 1>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000324/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000324/stderr  
	|- 38386 38376 38376 38376 (java) 6168 1068 13411618816 589768 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000324/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000324 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000010_2 324 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:12:39 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 21:12:59 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 21:13:11 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 21:13:33 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 21:13:36 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 21:14:21 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 21:14:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_5079_r_000013_2, Status : FAILED
Container [pid=43607,containerID=container_1422482982071_5079_01_000325] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5079_01_000325 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 43617 43607 43607 43607 (java) 6138 1071 13314355200 590634 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000325/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000325 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000013_2 325 
	|- 43607 9608 43607 43607 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000325/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000325 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000013_2 325 1>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000325/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000325/stderr  
	|- 43674 43662 43607 43607 (cat) 0 0 4231168 139 cat 
	|- 43662 43617 43607 43607 (R) 83776 12613 10364133376 2507228 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce62e719031ac8 
	|- 43673 43662 43607 43607 (cat) 0 29 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:14:22 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 21:14:42 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 21:15:03 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 21:15:08 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 21:15:11 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 21:20:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_5079_r_000011_2, Status : FAILED
Container [pid=13372,containerID=container_1422482982071_5079_01_000326] is running beyond physical memory limits. Current usage: 12.1 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5079_01_000326 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 13439 13427 13372 13372 (cat) 0 0 4231168 139 cat 
	|- 13372 9022 13372 13372 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000326/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000326 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000011_2 326 1>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000326/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000326/stderr  
	|- 13382 13372 13372 13372 (java) 5891 945 13313138688 589622 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000326/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000326 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000011_2 326 
	|- 13427 13382 13372 13372 (R) 105168 18668 10654760960 2578213 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce62e719031ac8 
	|- 13438 13427 13372 13372 (cat) 0 32 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:20:09 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 21:20:29 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 21:20:41 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 21:20:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_5079_r_000012_2, Status : FAILED
Container [pid=25069,containerID=container_1422482982071_5079_01_000327] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5079_01_000327 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 25138 25127 25069 25069 (cat) 1 26 103391232 159 cat 
	|- 25127 25079 25069 25069 (R) 104505 18905 10436247552 2500743 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce62e719031ac8 
	|- 25069 3801 25069 25069 (bash) 0 0 108650496 297 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000327/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000327 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000012_2 327 1>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000327/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000327/stderr  
	|- 25139 25127 25069 25069 (cat) 0 0 103391232 151 cat 
	|- 25079 25069 25069 25069 (java) 6991 1358 13411733504 588168 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000327/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000327 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000012_2 327 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:20:47 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 21:21:03 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 21:21:05 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 21:21:11 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 21:21:39 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 21:21:51 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 21:25:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_5079_r_000008_2, Status : FAILED
Container [pid=43753,containerID=container_1422482982071_5079_01_000328] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5079_01_000328 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 43808 43763 43753 43753 (R) 106243 19598 10475327488 2532705 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce62e719031ac8 
	|- 43819 43808 43753 43753 (cat) 1 24 4231168 142 cat 
	|- 43753 9608 43753 43753 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000328/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000328 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000008_2 328 1>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000328/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000328/stderr  
	|- 43820 43808 43753 43753 (cat) 0 0 4231168 136 cat 
	|- 43763 43753 43753 43753 (java) 5034 817 13312929792 590062 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5079/container_1422482982071_5079_01_000328/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5079/container_1422482982071_5079_01_000328 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 40125 attempt_1422482982071_5079_r_000008_2 328 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:25:38 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 21:25:59 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 21:26:11 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 21:26:30 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 21:34:13 INFO mapreduce.Job:  map 100% reduce 100%
15/04/15 21:34:13 INFO mapreduce.Job: Job job_1422482982071_5079 failed with state FAILED due to: Task failed task_1422482982071_5079_r_000013
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/15 21:34:13 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=28819804724
		FILE: Number of bytes written=78327760056
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=27107649938
		HDFS: Number of bytes written=2367352978
		HDFS: Number of read operations=780
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Failed reduce tasks=16
		Killed map tasks=1
		Killed reduce tasks=5
		Launched map tasks=251
		Launched reduce tasks=31
		Data-local map tasks=184
		Rack-local map tasks=67
		Total time spent by all maps in occupied slots (ms)=36219448
		Total time spent by all reduces in occupied slots (ms)=75359442
		Total time spent by all map tasks (ms)=18109724
		Total time spent by all reduce tasks (ms)=37679721
		Total vcore-seconds taken by all map tasks=18109724
		Total vcore-seconds taken by all reduce tasks=37679721
		Total megabyte-seconds taken by all map tasks=146616325504
		Total megabyte-seconds taken by all reduce tasks=452156652000
	Map-Reduce Framework
		Map input records=632973453
		Map output records=567302172
		Map output bytes=48318419843
		Map output materialized bytes=49482811651
		Input split bytes=39500
		Combine input records=0
		Combine output records=0
		Reduce input groups=39395339
		Reduce shuffle bytes=28819819514
		Reduce input records=377682733
		Reduce output records=39590337
		Spilled Records=944984905
		Shuffled Maps =2500
		Failed Shuffles=0
		Merged Map outputs=2500
		GC time elapsed (ms)=136850
		CPU time spent (ms)=32456120
		Physical memory (bytes) snapshot=511059197952
		Virtual memory (bytes) snapshot=2428085772288
		Total committed heap usage (bytes)=713838395392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27107610438
	File Output Format Counters 
		Bytes Written=2367352978
	rmr
		reduce calls=39395339
15/04/15 21:34:13 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/15 21:34:20 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file62e74bacc44f

real	78m5.265s
user	0m39.669s
sys	0m4.219s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-250-5-false-googlebooks-eng-all-5gram-20120701-on"

$hadoop$D
[1] "mapreduce.job.maps=250"

$hadoop$D
[1] "mapred.reduce.tasks=5"


15/04/15 21:34:26 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/15 21:34:26 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7262248045773831903.jar tmpDir=null
15/04/15 21:34:26 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 21:34:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 21:34:28 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.149:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.192:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.162:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.163:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.203:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.190:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.199:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/15 21:34:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.195:50010
15/04/15 21:34:28 INFO mapreduce.JobSubmitter: number of splits:250
15/04/15 21:34:28 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_5082
15/04/15 21:34:29 INFO impl.YarnClientImpl: Submitted application application_1422482982071_5082
15/04/15 21:34:29 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_5082/
15/04/15 21:34:29 INFO mapreduce.Job: Running job: job_1422482982071_5082
15/04/15 21:34:34 INFO mapreduce.Job: Job job_1422482982071_5082 running in uber mode : false
15/04/15 21:34:34 INFO mapreduce.Job:  map 0% reduce 0%
15/04/15 21:34:44 INFO mapreduce.Job:  map 1% reduce 0%
15/04/15 21:34:45 INFO mapreduce.Job:  map 2% reduce 0%
15/04/15 21:34:46 INFO mapreduce.Job:  map 3% reduce 0%
15/04/15 21:34:47 INFO mapreduce.Job:  map 5% reduce 0%
15/04/15 21:34:48 INFO mapreduce.Job:  map 6% reduce 0%
15/04/15 21:34:49 INFO mapreduce.Job:  map 7% reduce 0%
15/04/15 21:34:50 INFO mapreduce.Job:  map 8% reduce 0%
15/04/15 21:34:51 INFO mapreduce.Job:  map 10% reduce 0%
15/04/15 21:34:52 INFO mapreduce.Job:  map 11% reduce 0%
15/04/15 21:34:53 INFO mapreduce.Job:  map 12% reduce 0%
15/04/15 21:34:54 INFO mapreduce.Job:  map 13% reduce 0%
15/04/15 21:34:55 INFO mapreduce.Job:  map 14% reduce 0%
15/04/15 21:34:56 INFO mapreduce.Job:  map 16% reduce 0%
15/04/15 21:34:57 INFO mapreduce.Job:  map 17% reduce 0%
15/04/15 21:34:58 INFO mapreduce.Job:  map 18% reduce 0%
15/04/15 21:34:59 INFO mapreduce.Job:  map 19% reduce 0%
15/04/15 21:35:00 INFO mapreduce.Job:  map 21% reduce 0%
15/04/15 21:35:01 INFO mapreduce.Job:  map 22% reduce 0%
15/04/15 21:35:02 INFO mapreduce.Job:  map 23% reduce 0%
15/04/15 21:35:03 INFO mapreduce.Job:  map 24% reduce 0%
15/04/15 21:35:04 INFO mapreduce.Job:  map 25% reduce 0%
15/04/15 21:35:05 INFO mapreduce.Job:  map 27% reduce 0%
15/04/15 21:35:06 INFO mapreduce.Job:  map 28% reduce 0%
15/04/15 21:35:07 INFO mapreduce.Job:  map 29% reduce 0%
15/04/15 21:35:08 INFO mapreduce.Job:  map 31% reduce 0%
15/04/15 21:35:09 INFO mapreduce.Job:  map 32% reduce 0%
15/04/15 21:35:10 INFO mapreduce.Job:  map 33% reduce 0%
15/04/15 21:35:11 INFO mapreduce.Job:  map 34% reduce 0%
15/04/15 21:35:12 INFO mapreduce.Job:  map 36% reduce 0%
15/04/15 21:35:13 INFO mapreduce.Job:  map 37% reduce 0%
15/04/15 21:35:14 INFO mapreduce.Job:  map 38% reduce 0%
15/04/15 21:35:15 INFO mapreduce.Job:  map 40% reduce 0%
15/04/15 21:35:16 INFO mapreduce.Job:  map 41% reduce 0%
15/04/15 21:35:17 INFO mapreduce.Job:  map 42% reduce 0%
15/04/15 21:35:18 INFO mapreduce.Job:  map 44% reduce 0%
15/04/15 21:35:19 INFO mapreduce.Job:  map 45% reduce 0%
15/04/15 21:35:20 INFO mapreduce.Job:  map 46% reduce 0%
15/04/15 21:35:21 INFO mapreduce.Job:  map 47% reduce 0%
15/04/15 21:35:22 INFO mapreduce.Job:  map 48% reduce 0%
15/04/15 21:35:23 INFO mapreduce.Job:  map 50% reduce 0%
15/04/15 21:35:24 INFO mapreduce.Job:  map 51% reduce 0%
15/04/15 21:35:25 INFO mapreduce.Job:  map 52% reduce 0%
15/04/15 21:35:26 INFO mapreduce.Job:  map 54% reduce 0%
15/04/15 21:35:27 INFO mapreduce.Job:  map 55% reduce 0%
15/04/15 21:35:28 INFO mapreduce.Job:  map 56% reduce 0%
15/04/15 21:35:29 INFO mapreduce.Job:  map 57% reduce 0%
15/04/15 21:35:30 INFO mapreduce.Job:  map 59% reduce 0%
15/04/15 21:35:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_5082_m_000013_0, Status : FAILED
Error: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:334)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRawBytes(TypedBytesInput.java:218)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRaw(TypedBytesInput.java:152)
	at org.apache.hadoop.streaming.io.TypedBytesOutputReader.readKeyValue(TypedBytesOutputReader.java:56)
	at org.apache.hadoop.streaming.PipeMapRed$MROutputThread.run(PipeMapRed.java:376)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:35:32 INFO mapreduce.Job:  map 60% reduce 0%
15/04/15 21:35:33 INFO mapreduce.Job:  map 61% reduce 0%
15/04/15 21:35:36 INFO mapreduce.Job:  map 62% reduce 0%
15/04/15 21:35:38 INFO mapreduce.Job:  map 63% reduce 0%
15/04/15 21:35:41 INFO mapreduce.Job:  map 64% reduce 0%
15/04/15 21:35:42 INFO mapreduce.Job:  map 66% reduce 0%
15/04/15 21:35:43 INFO mapreduce.Job:  map 69% reduce 0%
15/04/15 21:35:44 INFO mapreduce.Job:  map 73% reduce 0%
15/04/15 21:35:45 INFO mapreduce.Job:  map 77% reduce 0%
15/04/15 21:35:46 INFO mapreduce.Job:  map 80% reduce 0%
15/04/15 21:35:47 INFO mapreduce.Job:  map 82% reduce 0%
15/04/15 21:35:48 INFO mapreduce.Job:  map 84% reduce 0%
15/04/15 21:35:49 INFO mapreduce.Job:  map 87% reduce 0%
15/04/15 21:35:50 INFO mapreduce.Job:  map 88% reduce 0%
15/04/15 21:35:51 INFO mapreduce.Job:  map 90% reduce 0%
15/04/15 21:35:52 INFO mapreduce.Job:  map 91% reduce 4%
15/04/15 21:35:54 INFO mapreduce.Job:  map 92% reduce 4%
15/04/15 21:35:56 INFO mapreduce.Job:  map 92% reduce 5%
15/04/15 21:35:58 INFO mapreduce.Job:  map 93% reduce 5%
15/04/15 21:36:01 INFO mapreduce.Job:  map 93% reduce 6%
15/04/15 21:36:02 INFO mapreduce.Job:  map 93% reduce 7%
15/04/15 21:36:03 INFO mapreduce.Job:  map 94% reduce 7%
15/04/15 21:36:05 INFO mapreduce.Job:  map 94% reduce 8%
15/04/15 21:36:11 INFO mapreduce.Job:  map 95% reduce 9%
15/04/15 21:36:12 INFO mapreduce.Job:  map 96% reduce 9%
15/04/15 21:36:13 INFO mapreduce.Job:  map 97% reduce 9%
15/04/15 21:36:14 INFO mapreduce.Job:  map 97% reduce 10%
15/04/15 21:36:15 INFO mapreduce.Job:  map 97% reduce 11%
15/04/15 21:36:17 INFO mapreduce.Job:  map 98% reduce 12%
15/04/15 21:36:18 INFO mapreduce.Job:  map 99% reduce 12%
15/04/15 21:36:20 INFO mapreduce.Job:  map 100% reduce 12%
15/04/15 21:36:23 INFO mapreduce.Job:  map 100% reduce 13%
15/04/15 21:36:24 INFO mapreduce.Job:  map 100% reduce 14%
15/04/15 21:36:30 INFO mapreduce.Job:  map 100% reduce 15%
15/04/15 21:36:33 INFO mapreduce.Job:  map 100% reduce 16%
15/04/15 21:36:36 INFO mapreduce.Job:  map 100% reduce 17%
15/04/15 21:36:39 INFO mapreduce.Job:  map 100% reduce 18%
15/04/15 21:36:42 INFO mapreduce.Job:  map 100% reduce 19%
15/04/15 21:36:45 INFO mapreduce.Job:  map 100% reduce 20%
15/04/15 21:36:51 INFO mapreduce.Job:  map 100% reduce 21%
15/04/15 21:36:54 INFO mapreduce.Job:  map 100% reduce 22%
15/04/15 21:36:55 INFO mapreduce.Job:  map 100% reduce 23%
15/04/15 21:37:01 INFO mapreduce.Job:  map 100% reduce 24%
15/04/15 21:37:06 INFO mapreduce.Job:  map 100% reduce 25%
15/04/15 21:37:07 INFO mapreduce.Job:  map 100% reduce 26%
15/04/15 21:37:09 INFO mapreduce.Job:  map 100% reduce 27%
15/04/15 21:37:13 INFO mapreduce.Job:  map 100% reduce 28%
15/04/15 21:37:18 INFO mapreduce.Job:  map 100% reduce 29%
15/04/15 21:37:19 INFO mapreduce.Job:  map 100% reduce 30%
15/04/15 21:37:25 INFO mapreduce.Job:  map 100% reduce 31%
15/04/15 21:37:28 INFO mapreduce.Job:  map 100% reduce 32%
15/04/15 21:37:34 INFO mapreduce.Job:  map 100% reduce 36%
15/04/15 21:37:35 INFO mapreduce.Job:  map 100% reduce 38%
15/04/15 21:37:37 INFO mapreduce.Job:  map 100% reduce 48%
15/04/15 21:37:38 INFO mapreduce.Job:  map 100% reduce 50%
15/04/15 21:37:40 INFO mapreduce.Job:  map 100% reduce 51%
15/04/15 21:37:41 INFO mapreduce.Job:  map 100% reduce 53%
15/04/15 21:37:46 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 21:37:49 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 21:40:32 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 21:50:25 INFO mapreduce.Job:  map 100% reduce 69%
15/04/15 21:53:53 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 21:55:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_5082_r_000003_0, Status : FAILED
Container [pid=11857,containerID=container_1422482982071_5082_01_000309] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 21.8 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5082_01_000309 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 11971 11960 11857 11857 (cat) 0 26 4231168 142 cat 
	|- 11960 11866 11857 11857 (R) 84637 24070 10080178176 2437437 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce677b7a778ece 
	|- 11857 11626 11857 11857 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000309/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000309 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000003_0 309 1>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000309/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000309/stderr  
	|- 11972 11960 11857 11857 (cat) 0 0 4231168 138 cat 
	|- 11866 11857 11857 11857 (java) 13299 2407 13313323008 673031 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000309/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000309 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000003_0 309 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:55:58 INFO mapreduce.Job:  map 100% reduce 57%
15/04/15 21:56:09 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 21:56:27 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 21:56:36 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 21:56:45 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 21:57:06 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 21:57:18 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 21:57:39 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 21:57:52 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 21:59:16 INFO mapreduce.Job:  map 100% reduce 78%
15/04/15 21:59:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_5082_r_000002_0, Status : FAILED
Container [pid=3909,containerID=container_1422482982071_5082_01_000308] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 21.8 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5082_01_000308 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 3918 3909 3909 3909 (java) 13624 2686 13314985984 669799 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000308/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000308 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000002_0 308 
	|- 4017 4004 3909 3909 (cat) 0 0 4231168 134 cat 
	|- 4004 3918 3909 3909 (R) 104605 23477 10105409536 2439194 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce677b7a778ece 
	|- 3909 8968 3909 3909 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000308/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000308 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000002_0 308 1>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000308/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000308/stderr  
	|- 4016 4004 3909 3909 (cat) 0 25 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:59:17 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 21:59:27 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 21:59:51 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 22:00:10 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:00:22 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:00:40 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:01:01 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:01:13 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:01:28 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 22:01:31 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 22:02:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_5082_r_000001_0, Status : FAILED
Container [pid=44102,containerID=container_1422482982071_5082_01_000307] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5082_01_000307 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 44284 44273 44102 44102 (cat) 1 44 4231168 143 cat 
	|- 44285 44273 44102 44102 (cat) 0 0 4231168 142 cat 
	|- 44273 44111 44102 44102 (R) 112622 33380 10440323072 2472109 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce677b7a778ece 
	|- 44111 44102 44102 44102 (java) 12948 2238 13314289664 654133 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000307/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000307 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000001_0 307 
	|- 44102 6181 44102 44102 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000307/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000307 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000001_0 307 1>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000307/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000307/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:02:05 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 22:02:16 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 22:02:25 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 22:02:46 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:03:04 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:03:17 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:03:39 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:03:57 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:04:12 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 22:04:15 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 22:04:36 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 22:10:08 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 22:10:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_5082_r_000000_0, Status : FAILED
Container [pid=13082,containerID=container_1422482982071_5082_01_000306] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.4 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5082_01_000306 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 13091 13082 13082 13082 (java) 13127 2406 13315366912 681713 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000306/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000306 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000000_0 306 
	|- 13229 13218 13082 13082 (cat) 1 51 4231168 142 cat 
	|- 13218 13091 13082 13082 (R) 145924 51459 10761523200 2396797 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce677b7a778ece 
	|- 13082 9143 13082 13082 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000306/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000306 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000000_0 306 1>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000306/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000306/stderr  
	|- 13232 13218 13082 13082 (cat) 0 0 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:10:33 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 22:10:45 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 22:11:07 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:11:19 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:11:35 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:11:53 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:12:05 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:12:33 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 22:12:42 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 22:13:43 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 22:14:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_5082_r_000003_1, Status : FAILED
Container [pid=17461,containerID=container_1422482982071_5082_01_000311] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5082_01_000311 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 17471 17461 17461 17461 (java) 10280 1742 13312155648 630402 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000311/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000311 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000003_1 311 
	|- 17570 17553 17461 17461 (cat) 0 0 4231168 138 cat 
	|- 17461 9067 17461 17461 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000311/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000311 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000003_1 311 1>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000311/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000311/stderr  
	|- 17553 17471 17461 17461 (R) 84049 15389 10336571392 2452344 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce677b7a778ece 
	|- 17566 17553 17461 17461 (cat) 0 25 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:14:27 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 22:14:38 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 22:14:47 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:15:05 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:15:15 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:15:39 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:15:57 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:16:21 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 22:16:30 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 22:16:33 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 22:24:03 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 22:30:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_5082_r_000001_1, Status : FAILED
Container [pid=34267,containerID=container_1422482982071_5082_01_000313] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5082_01_000313 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 34277 34267 34267 34267 (java) 10789 1670 13314125824 627568 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000313/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000313 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000001_1 313 
	|- 34267 40699 34267 34267 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000313/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000313 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000001_1 313 1>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000313/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000313/stderr  
	|- 34383 34372 34267 34267 (cat) 1 39 4231168 142 cat 
	|- 34385 34372 34267 34267 (cat) 0 0 4231168 142 cat 
	|- 34372 34277 34267 34267 (R) 97412 56830 10269278208 2444046 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce677b7a778ece 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:30:02 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 22:30:13 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:30:23 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:30:39 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:31:00 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:31:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_5082_r_000002_1, Status : FAILED
Container [pid=34180,containerID=container_1422482982071_5082_01_000312] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5082_01_000312 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 34180 40699 34180 34180 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000312/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000312 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000002_1 312 1>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000312/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000312/stderr  
	|- 34190 34180 34180 34180 (java) 11673 1870 13312868352 601663 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000312/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000312 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000002_1 312 
	|- 34262 34251 34180 34180 (cat) 0 26 4231168 142 cat 
	|- 34263 34251 34180 34180 (cat) 0 0 4231168 134 cat 
	|- 34251 34190 34180 34180 (R) 111432 66027 10569814016 2552682 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce677b7a778ece 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:31:06 INFO mapreduce.Job:  map 100% reduce 51%
15/04/15 22:31:17 INFO mapreduce.Job:  map 100% reduce 52%
15/04/15 22:31:26 INFO mapreduce.Job:  map 100% reduce 53%
15/04/15 22:31:32 INFO mapreduce.Job:  map 100% reduce 54%
15/04/15 22:31:38 INFO mapreduce.Job:  map 100% reduce 55%
15/04/15 22:31:47 INFO mapreduce.Job:  map 100% reduce 56%
15/04/15 22:31:57 INFO mapreduce.Job:  map 100% reduce 57%
15/04/15 22:32:18 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 22:32:21 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:32:24 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:32:27 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:32:39 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 22:32:54 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 22:33:15 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 22:36:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_5082_r_000003_2, Status : FAILED
Container [pid=7061,containerID=container_1422482982071_5082_01_000315] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5082_01_000315 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 7071 7061 7061 7061 (java) 11337 1871 13312737280 630398 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000315/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000315 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000003_2 315 
	|- 7644 7633 7061 7061 (cat) 0 28 4231168 142 cat 
	|- 7061 9245 7061 7061 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000315/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000315 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000003_2 315 1>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000315/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000315/stderr  
	|- 7633 7071 7061 7061 (R) 100294 19709 10379104256 2461164 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce677b7a778ece 
	|- 7645 7633 7061 7061 (cat) 0 0 4231168 139 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:36:33 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:36:44 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:37:02 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:37:15 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:37:42 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:38:03 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 22:38:25 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 22:38:46 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 22:43:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_5082_r_000000_1, Status : FAILED
Container [pid=37191,containerID=container_1422482982071_5082_01_000314] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5082_01_000314 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 37514 37201 37191 37191 (R) 155738 30133 10371985408 2509177 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce677b7a778ece 
	|- 37528 37514 37191 37191 (cat) 0 0 4231168 142 cat 
	|- 37191 10689 37191 37191 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000314/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000314 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000000_1 314 1>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000314/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000314/stderr  
	|- 37526 37514 37191 37191 (cat) 0 51 4231168 142 cat 
	|- 37201 37191 37191 37191 (java) 13384 2380 13315854336 632083 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000314/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000314 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000000_1 314 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:43:43 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 22:43:54 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:44:03 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:44:16 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:44:37 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:44:49 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:45:16 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 22:45:34 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 22:45:54 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 22:53:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_5082_r_000001_2, Status : FAILED
Container [pid=20316,containerID=container_1422482982071_5082_01_000316] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.8 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5082_01_000316 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 20410 20326 20316 20316 (R) 106497 17855 10733797376 2522518 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce677b7a778ece 
	|- 20421 20410 20316 20316 (cat) 0 41 103391232 159 cat 
	|- 20425 20410 20316 20316 (cat) 0 0 103391232 160 cat 
	|- 20316 3946 20316 20316 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000316/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000316 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000001_2 316 1>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000316/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000316/stderr  
	|- 20326 20316 20316 20316 (java) 13337 2294 13414428672 601992 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000316/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000316 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000001_2 316 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:53:14 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 22:53:25 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:53:34 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:53:46 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:54:14 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:54:26 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:54:41 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 22:55:08 INFO mapreduce.Job:  map 100% reduce 69%
15/04/15 22:55:11 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 22:55:14 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 22:55:17 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 22:55:48 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 22:59:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_5082_r_000002_2, Status : FAILED
Container [pid=14150,containerID=container_1422482982071_5082_01_000317] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 21.8 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5082_01_000317 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 14150 10444 14150 14150 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000317/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000317 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000002_2 317 1>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000317/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000317/stderr  
	|- 14160 14150 14150 14150 (java) 11595 2202 13313503232 658372 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5082/container_1422482982071_5082_01_000317/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5082/container_1422482982071_5082_01_000317 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 37095 attempt_1422482982071_5082_r_000002_2 317 
	|- 14224 14212 14150 14150 (cat) 0 0 4231168 134 cat 
	|- 14223 14212 14150 14150 (cat) 0 25 4231168 142 cat 
	|- 14212 14160 14150 14150 (R) 108008 50702 10089136128 2414927 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce677b7a778ece 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:59:45 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:59:56 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 23:00:14 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 23:00:27 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 23:00:45 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 23:01:07 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 23:01:37 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 23:01:49 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 23:02:10 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 23:02:26 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 23:02:27 INFO mapreduce.Job:  map 100% reduce 100%
15/04/15 23:02:27 INFO mapreduce.Job: Job job_1422482982071_5082 failed with state FAILED due to: Task failed task_1422482982071_5082_r_000003
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/15 23:02:27 INFO mapreduce.Job: Counters: 56
	File System Counters
		FILE: Number of bytes read=8609234377
		FILE: Number of bytes written=58116235622
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=27107649938
		HDFS: Number of bytes written=709797686
		HDFS: Number of read operations=753
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed map tasks=1
		Failed reduce tasks=12
		Killed map tasks=1
		Killed reduce tasks=3
		Launched map tasks=252
		Launched reduce tasks=16
		Other local map tasks=2
		Data-local map tasks=185
		Rack-local map tasks=65
		Total time spent by all maps in occupied slots (ms)=36962204
		Total time spent by all reduces in occupied slots (ms)=49061018
		Total time spent by all map tasks (ms)=18481102
		Total time spent by all reduce tasks (ms)=24530509
		Total vcore-seconds taken by all map tasks=18481102
		Total vcore-seconds taken by all reduce tasks=24530509
		Total megabyte-seconds taken by all map tasks=149623001792
		Total megabyte-seconds taken by all reduce tasks=294366108000
	Map-Reduce Framework
		Map input records=632973453
		Map output records=567302151
		Map output bytes=48318407527
		Map output materialized bytes=49482784275
		Input split bytes=39500
		Combine input records=0
		Combine output records=0
		Reduce input groups=11812478
		Reduce shuffle bytes=8609235823
		Reduce input records=113537882
		Reduce output records=11870699
		Spilled Records=680840033
		Shuffled Maps =250
		Failed Shuffles=0
		Merged Map outputs=250
		GC time elapsed (ms)=111449
		CPU time spent (ms)=22574760
		Physical memory (bytes) snapshot=489146822656
		Virtual memory (bytes) snapshot=2308157112320
		Total committed heap usage (bytes)=694843904000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27107610438
	File Output Format Counters 
		Bytes Written=709797686
	rmr
		reduce calls=11812478
15/04/15 23:02:27 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/15 23:02:33 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file677b3d528cb

real	88m12.937s
user	0m38.250s
sys	0m4.348s

15/04/09 12:44:11 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 35
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-35-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4239347147749978548.jar tmpDir=null
15/04/09 12:44:15 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 12:44:15 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 12:44:16 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 12:44:16 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 12:44:17 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 12:44:17 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4312
15/04/09 12:44:17 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4312
15/04/09 12:44:17 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4312/
15/04/09 12:44:17 INFO mapreduce.Job: Running job: job_1422482982071_4312
15/04/09 12:44:24 INFO mapreduce.Job: Job job_1422482982071_4312 running in uber mode : false
15/04/09 12:44:24 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 12:44:35 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 12:44:36 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 12:44:37 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 12:44:38 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 12:44:39 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 12:44:40 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 12:44:41 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 12:44:42 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 12:44:43 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 12:44:44 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 12:44:45 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 12:44:46 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 12:44:47 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 12:44:48 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 12:44:49 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 12:44:51 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 12:44:59 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 12:45:00 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 12:45:01 INFO mapreduce.Job:  map 76% reduce 0%
15/04/09 12:45:02 INFO mapreduce.Job:  map 83% reduce 0%
15/04/09 12:45:03 INFO mapreduce.Job:  map 87% reduce 0%
15/04/09 12:45:04 INFO mapreduce.Job:  map 94% reduce 0%
15/04/09 12:45:05 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 12:45:06 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 12:45:09 INFO mapreduce.Job:  map 100% reduce 8%
15/04/09 12:45:10 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 12:45:12 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 12:45:13 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 12:45:15 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 12:45:16 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 12:45:19 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 12:45:22 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 12:45:25 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 12:45:26 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 12:45:28 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 12:45:31 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 12:45:34 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 12:45:37 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 12:45:39 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 12:45:40 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 12:45:41 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 12:45:43 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 12:45:46 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 12:45:47 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 12:45:50 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 12:45:53 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 12:45:56 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 12:46:05 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 12:46:11 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 12:46:21 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 12:46:42 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 12:46:53 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 12:48:09 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 12:48:34 INFO mapreduce.Job: Job job_1422482982071_4312 completed successfully
15/04/09 12:48:34 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=10382210428
		FILE: Number of bytes written=20772544181
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=50
		Launched reduce tasks=36
		Data-local map tasks=33
		Rack-local map tasks=17
		Total time spent by all maps in occupied slots (ms)=3615196
		Total time spent by all reduces in occupied slots (ms)=4466564
		Total time spent by all map tasks (ms)=1807598
		Total time spent by all reduce tasks (ms)=2233282
		Total vcore-seconds taken by all map tasks=1807598
		Total vcore-seconds taken by all reduce tasks=2233282
		Total megabyte-seconds taken by all map tasks=14634313408
		Total megabyte-seconds taken by all reduce tasks=26799384000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382220718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382220718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1750
		Failed Shuffles=0
		Merged Map outputs=1750
		GC time elapsed (ms)=99873
		CPU time spent (ms)=4669980
		Physical memory (bytes) snapshot=114795003904
		Virtual memory (bytes) snapshot=926245834752
		Total committed heap usage (bytes)=212162887680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 12:48:34 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	4m27.374s
user	0m14.243s
sys	0m4.009s
15/04/09 12:48:38 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 35
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-35-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob166589068865194744.jar tmpDir=null
15/04/09 12:48:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 12:48:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 12:48:44 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 12:48:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 12:48:44 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 12:48:45 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4313
15/04/09 12:48:45 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4313
15/04/09 12:48:45 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4313/
15/04/09 12:48:45 INFO mapreduce.Job: Running job: job_1422482982071_4313
15/04/09 12:48:51 INFO mapreduce.Job: Job job_1422482982071_4313 running in uber mode : false
15/04/09 12:48:51 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 12:49:02 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 12:49:03 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 12:49:04 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 12:49:05 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 12:49:06 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 12:49:07 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 12:49:08 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 12:49:09 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 12:49:10 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 12:49:11 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 12:49:12 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 12:49:13 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 12:49:14 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 12:49:15 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 12:49:16 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 12:49:19 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 12:49:27 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 12:49:28 INFO mapreduce.Job:  map 79% reduce 0%
15/04/09 12:49:29 INFO mapreduce.Job:  map 83% reduce 0%
15/04/09 12:49:30 INFO mapreduce.Job:  map 89% reduce 0%
15/04/09 12:49:31 INFO mapreduce.Job:  map 94% reduce 0%
15/04/09 12:49:32 INFO mapreduce.Job:  map 98% reduce 0%
15/04/09 12:49:33 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 12:49:34 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 12:49:37 INFO mapreduce.Job:  map 100% reduce 7%
15/04/09 12:49:38 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 12:49:39 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 12:49:40 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 12:49:41 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 12:49:42 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 12:49:44 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 12:49:45 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 12:49:46 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 12:49:47 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 12:49:48 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 12:49:50 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 12:49:51 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 12:49:53 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 12:49:54 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 12:49:56 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 12:49:59 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 12:50:00 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 12:50:01 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 12:50:02 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 12:50:03 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 12:50:05 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 12:50:06 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 12:50:08 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 12:50:09 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 12:50:11 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 12:50:12 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 12:50:15 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 12:50:18 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 12:50:21 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 12:50:27 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 12:50:33 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 12:50:42 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 12:50:51 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 12:51:13 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 12:51:23 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 12:52:37 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 12:53:03 INFO mapreduce.Job: Job job_1422482982071_4313 completed successfully
15/04/09 12:53:04 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=10382210428
		FILE: Number of bytes written=20772544181
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=50
		Launched reduce tasks=36
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=3600148
		Total time spent by all reduces in occupied slots (ms)=4444598
		Total time spent by all map tasks (ms)=1800074
		Total time spent by all reduce tasks (ms)=2222299
		Total vcore-seconds taken by all map tasks=1800074
		Total vcore-seconds taken by all reduce tasks=2222299
		Total megabyte-seconds taken by all map tasks=14573399104
		Total megabyte-seconds taken by all reduce tasks=26667588000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382220718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382220718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1750
		Failed Shuffles=0
		Merged Map outputs=1750
		GC time elapsed (ms)=98375
		CPU time spent (ms)=4665880
		Physical memory (bytes) snapshot=114939445248
		Virtual memory (bytes) snapshot=926661541888
		Total committed heap usage (bytes)=212163649536
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 12:53:04 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	4m29.922s
user	0m13.809s
sys	0m4.483s
15/04/09 12:53:06 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 35
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-35-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1719257252110173719.jar tmpDir=null
15/04/09 12:53:10 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 12:53:11 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 12:53:12 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 12:53:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 12:53:13 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 12:53:14 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4315
15/04/09 12:53:14 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4315
15/04/09 12:53:14 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4315/
15/04/09 12:53:14 INFO mapreduce.Job: Running job: job_1422482982071_4315
15/04/09 12:53:20 INFO mapreduce.Job: Job job_1422482982071_4315 running in uber mode : false
15/04/09 12:53:20 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 12:53:31 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 12:53:32 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 12:53:34 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 12:53:35 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 12:53:37 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 12:53:38 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 12:53:39 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 12:53:40 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 12:53:41 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 12:53:42 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 12:53:43 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 12:53:44 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 12:53:45 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 12:53:47 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 12:53:55 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 12:53:56 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 12:53:57 INFO mapreduce.Job:  map 76% reduce 0%
15/04/09 12:53:58 INFO mapreduce.Job:  map 79% reduce 0%
15/04/09 12:53:59 INFO mapreduce.Job:  map 85% reduce 0%
15/04/09 12:54:00 INFO mapreduce.Job:  map 91% reduce 0%
15/04/09 12:54:01 INFO mapreduce.Job:  map 97% reduce 0%
15/04/09 12:54:02 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 12:54:03 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 12:54:06 INFO mapreduce.Job:  map 100% reduce 4%
15/04/09 12:54:07 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 12:54:08 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 12:54:10 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 12:54:11 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 12:54:12 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 12:54:13 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 12:54:14 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 12:54:16 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 12:54:17 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 12:54:19 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 12:54:20 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 12:54:22 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 12:54:23 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 12:54:25 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 12:54:26 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 12:54:28 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 12:54:29 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 12:54:31 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 12:54:32 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 12:54:34 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 12:54:35 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 12:54:38 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 12:54:40 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 12:54:41 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 12:54:43 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 12:54:44 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 12:54:47 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 12:54:50 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 12:54:54 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 12:55:02 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 12:55:10 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 12:55:18 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 12:55:39 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 12:55:52 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 12:57:25 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 12:57:54 INFO mapreduce.Job: Job job_1422482982071_4315 completed successfully
15/04/09 12:57:55 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=10382210428
		FILE: Number of bytes written=20772544181
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=50
		Launched reduce tasks=36
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=3649754
		Total time spent by all reduces in occupied slots (ms)=4544070
		Total time spent by all map tasks (ms)=1824877
		Total time spent by all reduce tasks (ms)=2272035
		Total vcore-seconds taken by all map tasks=1824877
		Total vcore-seconds taken by all reduce tasks=2272035
		Total megabyte-seconds taken by all map tasks=14774204192
		Total megabyte-seconds taken by all reduce tasks=27264420000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382220718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382220718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1750
		Failed Shuffles=0
		Merged Map outputs=1750
		GC time elapsed (ms)=100317
		CPU time spent (ms)=4718150
		Physical memory (bytes) snapshot=115290316800
		Virtual memory (bytes) snapshot=926860808192
		Total committed heap usage (bytes)=212163416064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 12:57:55 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	4m51.020s
user	0m13.436s
sys	0m3.188s
15/04/09 12:57:58 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 25
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-25-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob881515688574645948.jar tmpDir=null
15/04/09 12:58:03 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 12:58:04 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 12:58:05 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 12:58:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 12:58:06 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 12:58:06 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4316
15/04/09 12:58:07 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4316
15/04/09 12:58:07 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4316/
15/04/09 12:58:07 INFO mapreduce.Job: Running job: job_1422482982071_4316
15/04/09 12:58:13 INFO mapreduce.Job: Job job_1422482982071_4316 running in uber mode : false
15/04/09 12:58:13 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 12:58:23 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 12:58:24 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 12:58:25 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 12:58:26 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 12:58:27 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 12:58:28 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 12:58:29 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 12:58:30 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 12:58:31 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 12:58:32 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 12:58:33 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 12:58:34 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 12:58:36 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 12:58:37 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 12:58:40 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 12:58:49 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 12:58:50 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 12:58:51 INFO mapreduce.Job:  map 81% reduce 0%
15/04/09 12:58:52 INFO mapreduce.Job:  map 85% reduce 0%
15/04/09 12:58:53 INFO mapreduce.Job:  map 94% reduce 0%
15/04/09 12:58:54 INFO mapreduce.Job:  map 96% reduce 0%
15/04/09 12:58:55 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 12:58:58 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 12:58:59 INFO mapreduce.Job:  map 100% reduce 1%
15/04/09 12:59:00 INFO mapreduce.Job:  map 100% reduce 28%
15/04/09 12:59:01 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 12:59:03 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 12:59:04 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 12:59:06 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 12:59:07 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 12:59:09 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 12:59:10 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 12:59:13 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 12:59:14 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 12:59:16 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 12:59:17 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 12:59:19 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 12:59:20 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 12:59:22 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 12:59:23 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 12:59:25 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 12:59:28 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 12:59:29 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 12:59:32 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 12:59:33 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 12:59:34 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 12:59:35 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 12:59:37 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 12:59:38 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 12:59:40 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 12:59:42 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 12:59:44 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 12:59:46 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 12:59:49 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 12:59:50 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 12:59:53 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 12:59:57 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 13:00:04 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 13:00:06 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 13:00:08 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 13:00:09 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 13:00:15 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 13:00:21 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 13:00:33 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 13:00:57 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 13:01:09 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 13:02:13 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 13:02:53 INFO mapreduce.Job: Job job_1422482982071_4316 completed successfully
15/04/09 13:02:53 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=10382210368
		FILE: Number of bytes written=20771579791
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=225
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=50
		Launched reduce tasks=26
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=3723604
		Total time spent by all reduces in occupied slots (ms)=4408106
		Total time spent by all map tasks (ms)=1861802
		Total time spent by all reduce tasks (ms)=2204053
		Total vcore-seconds taken by all map tasks=1861802
		Total vcore-seconds taken by all reduce tasks=2204053
		Total megabyte-seconds taken by all map tasks=15073148992
		Total megabyte-seconds taken by all reduce tasks=26448636000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382217718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382217718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1250
		Failed Shuffles=0
		Merged Map outputs=1250
		GC time elapsed (ms)=98297
		CPU time spent (ms)=4744790
		Physical memory (bytes) snapshot=112589479936
		Virtual memory (bytes) snapshot=793393299456
		Total committed heap usage (bytes)=191112380416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 13:02:53 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	4m58.531s
user	0m14.615s
sys	0m4.751s
15/04/09 13:02:56 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 25
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-25-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4346185279827214165.jar tmpDir=null
15/04/09 13:02:59 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:02:59 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:03:00 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 13:03:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 13:03:01 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 13:03:02 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4318
15/04/09 13:03:02 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4318
15/04/09 13:03:02 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4318/
15/04/09 13:03:02 INFO mapreduce.Job: Running job: job_1422482982071_4318
15/04/09 13:03:08 INFO mapreduce.Job: Job job_1422482982071_4318 running in uber mode : false
15/04/09 13:03:08 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 13:03:18 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 13:03:19 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 13:03:21 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 13:03:22 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 13:03:23 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 13:03:24 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 13:03:25 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 13:03:26 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 13:03:27 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 13:03:28 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 13:03:29 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 13:03:30 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 13:03:31 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 13:03:32 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 13:03:42 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 13:03:43 INFO mapreduce.Job:  map 73% reduce 0%
15/04/09 13:03:44 INFO mapreduce.Job:  map 79% reduce 0%
15/04/09 13:03:45 INFO mapreduce.Job:  map 83% reduce 0%
15/04/09 13:03:46 INFO mapreduce.Job:  map 93% reduce 0%
15/04/09 13:03:47 INFO mapreduce.Job:  map 98% reduce 0%
15/04/09 13:03:48 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 13:03:53 INFO mapreduce.Job:  map 100% reduce 32%
15/04/09 13:03:54 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 13:03:56 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 13:03:57 INFO mapreduce.Job:  map 100% reduce 51%
15/04/09 13:03:59 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 13:04:00 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 13:04:02 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 13:04:03 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 13:04:05 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 13:04:07 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 13:04:08 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 13:04:09 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 13:04:11 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 13:04:12 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 13:04:14 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 13:04:15 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 13:04:18 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 13:04:20 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 13:04:21 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 13:04:24 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 13:04:26 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 13:04:27 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 13:04:28 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 13:04:30 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 13:04:32 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 13:04:33 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 13:04:36 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 13:04:38 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 13:04:39 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 13:04:42 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 13:04:46 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 13:04:51 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 13:04:54 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 13:04:55 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 13:04:59 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 13:05:06 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 13:05:08 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 13:05:12 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 13:05:15 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 13:05:28 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 13:05:43 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 13:05:58 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 13:07:11 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 13:07:59 INFO mapreduce.Job: Job job_1422482982071_4318 completed successfully
15/04/09 13:07:59 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=10382210368
		FILE: Number of bytes written=20771579791
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=225
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=50
		Launched reduce tasks=26
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=3520448
		Total time spent by all reduces in occupied slots (ms)=4412534
		Total time spent by all map tasks (ms)=1760224
		Total time spent by all reduce tasks (ms)=2206267
		Total vcore-seconds taken by all map tasks=1760224
		Total vcore-seconds taken by all reduce tasks=2206267
		Total megabyte-seconds taken by all map tasks=14250773504
		Total megabyte-seconds taken by all reduce tasks=26475204000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382217718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382217718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1250
		Failed Shuffles=0
		Merged Map outputs=1250
		GC time elapsed (ms)=86483
		CPU time spent (ms)=4622150
		Physical memory (bytes) snapshot=112641277952
		Virtual memory (bytes) snapshot=793426714624
		Total committed heap usage (bytes)=191110676480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 13:07:59 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	5m6.240s
user	0m14.107s
sys	0m1.676s
15/04/09 13:08:03 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 25
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-25-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7354738052416125291.jar tmpDir=null
15/04/09 13:08:06 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:08:06 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:08:07 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 13:08:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 13:08:07 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 13:08:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4319
15/04/09 13:08:08 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4319
15/04/09 13:08:08 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4319/
15/04/09 13:08:08 INFO mapreduce.Job: Running job: job_1422482982071_4319
15/04/09 13:08:14 INFO mapreduce.Job: Job job_1422482982071_4319 running in uber mode : false
15/04/09 13:08:14 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 13:08:24 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 13:08:25 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 13:08:26 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 13:08:27 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 13:08:28 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 13:08:30 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 13:08:32 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 13:08:33 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 13:08:35 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 13:08:36 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 13:08:38 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 13:08:39 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 13:08:42 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 13:08:50 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 13:08:51 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 13:08:52 INFO mapreduce.Job:  map 77% reduce 0%
15/04/09 13:08:53 INFO mapreduce.Job:  map 82% reduce 0%
15/04/09 13:08:54 INFO mapreduce.Job:  map 87% reduce 0%
15/04/09 13:08:55 INFO mapreduce.Job:  map 94% reduce 0%
15/04/09 13:08:56 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 13:08:57 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 13:09:00 INFO mapreduce.Job:  map 100% reduce 3%
15/04/09 13:09:01 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 13:09:02 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 13:09:03 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 13:09:04 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 13:09:05 INFO mapreduce.Job:  map 100% reduce 51%
15/04/09 13:09:06 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 13:09:07 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 13:09:08 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 13:09:10 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 13:09:11 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 13:09:13 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 13:09:14 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 13:09:16 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 13:09:19 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 13:09:22 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 13:09:23 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 13:09:25 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 13:09:26 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 13:09:29 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 13:09:31 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 13:09:32 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 13:09:34 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 13:09:35 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 13:09:36 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 13:09:37 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 13:09:38 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 13:09:41 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 13:09:43 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 13:09:46 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 13:09:49 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 13:09:52 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 13:09:56 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 13:10:00 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 13:10:03 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 13:10:06 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 13:10:08 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 13:10:09 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 13:10:11 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 13:10:15 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 13:10:29 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 13:10:55 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 13:11:07 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 13:12:03 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 13:12:44 INFO mapreduce.Job: Job job_1422482982071_4319 completed successfully
15/04/09 13:12:44 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=10382210368
		FILE: Number of bytes written=20771579791
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=225
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=50
		Launched reduce tasks=26
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=3687404
		Total time spent by all reduces in occupied slots (ms)=4253488
		Total time spent by all map tasks (ms)=1843702
		Total time spent by all reduce tasks (ms)=2126744
		Total vcore-seconds taken by all map tasks=1843702
		Total vcore-seconds taken by all reduce tasks=2126744
		Total megabyte-seconds taken by all map tasks=14926611392
		Total megabyte-seconds taken by all reduce tasks=25520928000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382217718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382217718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1250
		Failed Shuffles=0
		Merged Map outputs=1250
		GC time elapsed (ms)=95766
		CPU time spent (ms)=4669420
		Physical memory (bytes) snapshot=112597139456
		Virtual memory (bytes) snapshot=792816656384
		Total committed heap usage (bytes)=191113048064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 13:12:44 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	4m44.983s
user	0m11.298s
sys	0m2.328s
15/04/09 13:12:47 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 15
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-15-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob929507901720214838.jar tmpDir=null
15/04/09 13:12:51 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:12:51 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:12:51 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 13:12:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 13:12:52 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 13:12:52 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 13:12:52 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 13:12:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4321
15/04/09 13:12:53 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4321
15/04/09 13:12:53 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4321/
15/04/09 13:12:53 INFO mapreduce.Job: Running job: job_1422482982071_4321
15/04/09 13:12:58 INFO mapreduce.Job: Job job_1422482982071_4321 running in uber mode : false
15/04/09 13:12:58 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 13:13:08 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 13:13:09 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 13:13:10 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 13:13:11 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 13:13:12 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 13:13:13 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 13:13:14 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 13:13:15 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 13:13:16 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 13:13:17 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 13:13:18 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 13:13:19 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 13:13:20 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 13:13:21 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 13:13:22 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 13:13:33 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 13:13:34 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 13:13:35 INFO mapreduce.Job:  map 79% reduce 0%
15/04/09 13:13:36 INFO mapreduce.Job:  map 85% reduce 0%
15/04/09 13:13:37 INFO mapreduce.Job:  map 97% reduce 0%
15/04/09 13:13:38 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 13:13:39 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 13:13:44 INFO mapreduce.Job:  map 100% reduce 20%
15/04/09 13:13:45 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 13:13:47 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 13:13:48 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 13:13:50 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 13:13:51 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 13:13:54 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 13:13:57 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 13:14:00 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 13:14:03 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 13:14:06 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 13:14:08 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 13:14:12 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 13:14:13 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 13:14:15 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 13:14:16 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 13:14:18 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 13:14:22 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 13:14:25 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 13:14:28 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 13:14:32 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 13:14:34 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 13:14:37 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 13:14:40 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 13:14:43 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 13:14:46 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 13:14:47 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 13:14:50 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 13:14:55 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 13:14:58 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 13:15:02 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 13:15:05 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 13:15:10 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 13:15:11 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 13:15:16 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 13:15:22 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 13:15:29 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 13:15:37 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 13:15:45 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 13:16:15 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 13:16:27 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 13:16:56 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 13:17:03 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 13:17:30 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 13:18:02 INFO mapreduce.Job: Job job_1422482982071_4321 completed successfully
15/04/09 13:18:02 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=10382210326
		FILE: Number of bytes written=20770615419
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=195
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Launched map tasks=50
		Launched reduce tasks=15
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=3584894
		Total time spent by all reduces in occupied slots (ms)=4043882
		Total time spent by all map tasks (ms)=1792447
		Total time spent by all reduce tasks (ms)=2021941
		Total vcore-seconds taken by all map tasks=1792447
		Total vcore-seconds taken by all reduce tasks=2021941
		Total megabyte-seconds taken by all map tasks=14511650912
		Total megabyte-seconds taken by all reduce tasks=24263292000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382214718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382214718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=88809
		CPU time spent (ms)=4654170
		Physical memory (bytes) snapshot=111187824640
		Virtual memory (bytes) snapshot=659773878272
		Total committed heap usage (bytes)=170057613312
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 13:18:02 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	5m17.778s
user	0m14.800s
sys	0m1.396s
15/04/09 13:18:05 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 15
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-15-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3187670380415113.jar tmpDir=null
15/04/09 13:18:07 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:18:07 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:18:08 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 13:18:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 13:18:08 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 13:18:09 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4322
15/04/09 13:18:09 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4322
15/04/09 13:18:09 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4322/
15/04/09 13:18:09 INFO mapreduce.Job: Running job: job_1422482982071_4322
15/04/09 13:18:16 INFO mapreduce.Job: Job job_1422482982071_4322 running in uber mode : false
15/04/09 13:18:16 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 13:18:27 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 13:18:28 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 13:18:30 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 13:18:31 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 13:18:33 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 13:18:34 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 13:18:36 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 13:18:37 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 13:18:39 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 13:18:40 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 13:18:43 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 13:18:52 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 13:18:53 INFO mapreduce.Job:  map 73% reduce 0%
15/04/09 13:18:54 INFO mapreduce.Job:  map 77% reduce 0%
15/04/09 13:18:55 INFO mapreduce.Job:  map 85% reduce 0%
15/04/09 13:18:56 INFO mapreduce.Job:  map 91% reduce 0%
15/04/09 13:18:57 INFO mapreduce.Job:  map 96% reduce 0%
15/04/09 13:18:58 INFO mapreduce.Job:  map 97% reduce 0%
15/04/09 13:18:59 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 13:19:00 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 13:19:02 INFO mapreduce.Job:  map 100% reduce 2%
15/04/09 13:19:03 INFO mapreduce.Job:  map 100% reduce 26%
15/04/09 13:19:04 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 13:19:06 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 13:19:07 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 13:19:09 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 13:19:10 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 13:19:12 INFO mapreduce.Job:  map 100% reduce 51%
15/04/09 13:19:13 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 13:19:15 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 13:19:16 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 13:19:19 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 13:19:22 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 13:19:25 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 13:19:27 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 13:19:28 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 13:19:30 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 13:19:31 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 13:19:33 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 13:19:36 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 13:19:39 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 13:19:40 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 13:19:42 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 13:19:45 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 13:19:48 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 13:19:51 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 13:19:53 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 13:19:56 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 13:19:58 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 13:20:03 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 13:20:05 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 13:20:08 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 13:20:11 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 13:20:14 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 13:20:19 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 13:20:23 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 13:20:26 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 13:20:32 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 13:20:36 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 13:20:44 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 13:20:46 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 13:20:50 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 13:21:03 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 13:21:36 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 13:21:47 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 13:22:11 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 13:22:17 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 13:22:44 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 13:23:07 INFO mapreduce.Job: Job job_1422482982071_4322 completed successfully
15/04/09 13:23:07 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=10382210326
		FILE: Number of bytes written=20770615419
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=195
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Launched map tasks=50
		Launched reduce tasks=15
		Data-local map tasks=30
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=3762570
		Total time spent by all reduces in occupied slots (ms)=3974738
		Total time spent by all map tasks (ms)=1881285
		Total time spent by all reduce tasks (ms)=1987369
		Total vcore-seconds taken by all map tasks=1881285
		Total vcore-seconds taken by all reduce tasks=1987369
		Total megabyte-seconds taken by all map tasks=15230883360
		Total megabyte-seconds taken by all reduce tasks=23848428000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382214718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382214718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=86976
		CPU time spent (ms)=4695090
		Physical memory (bytes) snapshot=111155699712
		Virtual memory (bytes) snapshot=659968905216
		Total committed heap usage (bytes)=170062008320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 13:23:07 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	5m4.639s
user	0m12.375s
sys	0m0.799s
15/04/09 13:23:10 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 15
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-15-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2720607086962915989.jar tmpDir=null
15/04/09 13:23:12 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:23:12 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:23:13 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 13:23:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 13:23:13 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 13:23:13 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4324
15/04/09 13:23:14 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4324
15/04/09 13:23:14 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4324/
15/04/09 13:23:14 INFO mapreduce.Job: Running job: job_1422482982071_4324
15/04/09 13:23:20 INFO mapreduce.Job: Job job_1422482982071_4324 running in uber mode : false
15/04/09 13:23:20 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 13:23:30 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 13:23:31 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 13:23:32 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 13:23:35 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 13:23:36 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 13:23:37 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 13:23:38 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 13:23:39 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 13:23:40 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 13:23:41 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 13:23:42 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 13:23:44 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 13:23:45 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 13:23:47 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 13:23:57 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 13:23:58 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 13:23:59 INFO mapreduce.Job:  map 79% reduce 0%
15/04/09 13:24:00 INFO mapreduce.Job:  map 82% reduce 0%
15/04/09 13:24:01 INFO mapreduce.Job:  map 90% reduce 0%
15/04/09 13:24:02 INFO mapreduce.Job:  map 95% reduce 0%
15/04/09 13:24:03 INFO mapreduce.Job:  map 98% reduce 0%
15/04/09 13:24:04 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 13:24:07 INFO mapreduce.Job:  map 100% reduce 5%
15/04/09 13:24:08 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 13:24:11 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 13:24:14 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 13:24:15 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 13:24:17 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 13:24:18 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 13:24:20 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 13:24:21 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 13:24:23 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 13:24:24 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 13:24:27 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 13:24:30 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 13:24:32 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 13:24:35 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 13:24:36 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 13:24:38 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 13:24:41 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 13:24:42 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 13:24:44 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 13:24:47 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 13:24:50 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 13:24:53 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 13:24:56 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 13:24:57 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 13:25:00 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 13:25:03 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 13:25:06 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 13:25:09 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 13:25:12 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 13:25:14 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 13:25:17 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 13:25:21 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 13:25:24 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 13:25:30 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 13:25:31 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 13:25:38 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 13:25:49 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 13:25:50 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 13:25:59 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 13:26:07 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 13:26:34 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 13:26:43 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 13:27:13 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 13:27:20 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 13:27:48 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 13:28:21 INFO mapreduce.Job: Job job_1422482982071_4324 completed successfully
15/04/09 13:28:21 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=10382210326
		FILE: Number of bytes written=20770615419
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=195
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Launched map tasks=50
		Launched reduce tasks=15
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=3794332
		Total time spent by all reduces in occupied slots (ms)=3959766
		Total time spent by all map tasks (ms)=1897166
		Total time spent by all reduce tasks (ms)=1979883
		Total vcore-seconds taken by all map tasks=1897166
		Total vcore-seconds taken by all reduce tasks=1979883
		Total megabyte-seconds taken by all map tasks=15359455936
		Total megabyte-seconds taken by all reduce tasks=23758596000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382214718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382214718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=97082
		CPU time spent (ms)=4681950
		Physical memory (bytes) snapshot=111191650304
		Virtual memory (bytes) snapshot=659174416384
		Total committed heap usage (bytes)=170061770752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 13:28:21 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	5m13.825s
user	0m13.170s
sys	0m0.824s
15/04/09 13:28:24 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 35
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-35-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2994435691680557671.jar tmpDir=null
15/04/09 13:28:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:28:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:28:28 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 13:28:28 INFO mapreduce.JobSubmitter: number of splits:75
15/04/09 13:28:28 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4325
15/04/09 13:28:29 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4325
15/04/09 13:28:29 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4325/
15/04/09 13:28:29 INFO mapreduce.Job: Running job: job_1422482982071_4325
15/04/09 13:28:35 INFO mapreduce.Job: Job job_1422482982071_4325 running in uber mode : false
15/04/09 13:28:35 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 13:28:46 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 13:28:47 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 13:28:49 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 13:28:50 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 13:28:52 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 13:28:53 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 13:28:55 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 13:28:56 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 13:28:58 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 13:28:59 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 13:29:02 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 13:29:11 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 13:29:12 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 13:29:13 INFO mapreduce.Job:  map 80% reduce 0%
15/04/09 13:29:14 INFO mapreduce.Job:  map 90% reduce 0%
15/04/09 13:29:16 INFO mapreduce.Job:  map 96% reduce 0%
15/04/09 13:29:17 INFO mapreduce.Job:  map 98% reduce 0%
15/04/09 13:29:18 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 13:29:23 INFO mapreduce.Job:  map 100% reduce 27%
15/04/09 13:29:24 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 13:29:25 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 13:29:26 INFO mapreduce.Job:  map 100% reduce 46%
15/04/09 13:29:27 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 13:29:29 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 13:29:30 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 13:29:32 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 13:29:33 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 13:29:34 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 13:29:35 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 13:29:36 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 13:29:38 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 13:29:39 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 13:29:41 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 13:29:42 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 13:29:44 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 13:29:45 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 13:29:47 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 13:29:50 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 13:29:51 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 13:29:53 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 13:29:54 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 13:29:56 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 13:29:57 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 13:29:59 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 13:30:00 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 13:30:03 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 13:30:04 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 13:30:06 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 13:30:09 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 13:30:15 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 13:30:18 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 13:30:19 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 13:30:21 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 13:30:27 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 13:30:30 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 13:30:36 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 13:30:42 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 13:30:48 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 13:30:52 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 13:31:09 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 13:31:13 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 13:31:23 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 13:32:10 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 13:34:03 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 13:34:31 INFO mapreduce.Job: Job job_1422482982071_4325 completed successfully
15/04/09 13:34:31 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=16787700639
		FILE: Number of bytes written=33585925047
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=330
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=75
		Launched reduce tasks=36
		Data-local map tasks=51
		Rack-local map tasks=24
		Total time spent by all maps in occupied slots (ms)=5496142
		Total time spent by all reduces in occupied slots (ms)=6961838
		Total time spent by all map tasks (ms)=2748071
		Total time spent by all reduce tasks (ms)=3480919
		Total vcore-seconds taken by all map tasks=2748071
		Total vcore-seconds taken by all reduce tasks=3480919
		Total megabyte-seconds taken by all map tasks=22248382816
		Total megabyte-seconds taken by all reduce tasks=41771028000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787716173
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787716173
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =2625
		Failed Shuffles=0
		Merged Map outputs=2625
		GC time elapsed (ms)=139341
		CPU time spent (ms)=7124100
		Physical memory (bytes) snapshot=170078236672
		Virtual memory (bytes) snapshot=1156611055616
		Total committed heap usage (bytes)=281404805120
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/09 13:34:31 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	6m9.965s
user	0m13.859s
sys	0m0.787s
15/04/09 13:34:33 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 35
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-35-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5445381191454904531.jar tmpDir=null
15/04/09 13:34:36 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:34:36 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:34:36 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 13:34:37 INFO mapreduce.JobSubmitter: number of splits:75
15/04/09 13:34:37 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4328
15/04/09 13:34:37 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4328
15/04/09 13:34:37 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4328/
15/04/09 13:34:37 INFO mapreduce.Job: Running job: job_1422482982071_4328
15/04/09 13:34:43 INFO mapreduce.Job: Job job_1422482982071_4328 running in uber mode : false
15/04/09 13:34:43 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 13:34:53 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 13:34:54 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 13:34:55 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 13:34:56 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 13:34:57 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 13:34:58 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 13:34:59 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 13:35:00 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 13:35:01 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 13:35:03 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 13:35:04 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 13:35:06 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 13:35:07 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 13:35:19 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 13:35:20 INFO mapreduce.Job:  map 73% reduce 0%
15/04/09 13:35:21 INFO mapreduce.Job:  map 83% reduce 0%
15/04/09 13:35:22 INFO mapreduce.Job:  map 92% reduce 0%
15/04/09 13:35:23 INFO mapreduce.Job:  map 96% reduce 0%
15/04/09 13:35:24 INFO mapreduce.Job:  map 98% reduce 0%
15/04/09 13:35:25 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 13:35:30 INFO mapreduce.Job:  map 100% reduce 20%
15/04/09 13:35:31 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 13:35:33 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 13:35:34 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 13:35:36 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 13:35:37 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 13:35:39 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 13:35:40 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 13:35:42 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 13:35:43 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 13:35:45 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 13:35:46 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 13:35:48 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 13:35:49 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 13:35:51 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 13:35:52 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 13:35:54 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 13:35:55 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 13:35:57 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 13:35:58 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 13:36:00 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 13:36:01 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 13:36:03 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 13:36:04 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 13:36:07 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 13:36:10 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 13:36:13 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 13:36:18 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 13:36:21 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 13:36:23 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 13:36:25 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 13:36:30 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 13:36:35 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 13:36:38 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 13:36:42 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 13:36:46 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 13:36:50 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 13:37:05 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 13:37:14 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 13:37:17 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 13:37:26 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 13:38:11 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 13:41:01 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 13:41:30 INFO mapreduce.Job: Job job_1422482982071_4328 completed successfully
15/04/09 13:41:31 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=16787700639
		FILE: Number of bytes written=33585925047
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=330
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=75
		Launched reduce tasks=36
		Data-local map tasks=50
		Rack-local map tasks=25
		Total time spent by all maps in occupied slots (ms)=5417808
		Total time spent by all reduces in occupied slots (ms)=6870626
		Total time spent by all map tasks (ms)=2708904
		Total time spent by all reduce tasks (ms)=3435313
		Total vcore-seconds taken by all map tasks=2708904
		Total vcore-seconds taken by all reduce tasks=3435313
		Total megabyte-seconds taken by all map tasks=21931286784
		Total megabyte-seconds taken by all reduce tasks=41223756000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787716173
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787716173
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =2625
		Failed Shuffles=0
		Merged Map outputs=2625
		GC time elapsed (ms)=91871
		CPU time spent (ms)=6854280
		Physical memory (bytes) snapshot=169777594368
		Virtual memory (bytes) snapshot=1156421906432
		Total committed heap usage (bytes)=281400737792
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/09 13:41:31 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	6m59.832s
user	0m14.042s
sys	0m0.843s
15/04/09 13:41:33 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 35
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-35-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob9098830141318026355.jar tmpDir=null
15/04/09 13:41:35 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:41:35 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:41:36 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 13:41:36 INFO mapreduce.JobSubmitter: number of splits:75
15/04/09 13:41:37 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4330
15/04/09 13:41:37 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4330
15/04/09 13:41:37 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4330/
15/04/09 13:41:37 INFO mapreduce.Job: Running job: job_1422482982071_4330
15/04/09 13:41:42 INFO mapreduce.Job: Job job_1422482982071_4330 running in uber mode : false
15/04/09 13:41:42 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 13:41:53 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 13:41:54 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 13:41:56 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 13:41:57 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 13:41:59 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 13:42:00 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 13:42:02 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 13:42:03 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 13:42:04 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 13:42:05 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 13:42:06 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 13:42:09 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 13:42:19 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 13:42:20 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 13:42:21 INFO mapreduce.Job:  map 80% reduce 0%
15/04/09 13:42:22 INFO mapreduce.Job:  map 86% reduce 0%
15/04/09 13:42:23 INFO mapreduce.Job:  map 95% reduce 0%
15/04/09 13:42:24 INFO mapreduce.Job:  map 97% reduce 0%
15/04/09 13:42:25 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 13:42:27 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 13:42:30 INFO mapreduce.Job:  map 100% reduce 23%
15/04/09 13:42:31 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 13:42:33 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 13:42:34 INFO mapreduce.Job:  map 100% reduce 47%
15/04/09 13:42:36 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 13:42:37 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 13:42:39 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 13:42:40 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 13:42:41 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 13:42:42 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 13:42:43 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 13:42:44 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 13:42:45 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 13:42:46 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 13:42:48 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 13:42:49 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 13:42:50 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 13:42:52 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 13:42:54 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 13:42:55 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 13:42:57 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 13:42:59 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 13:43:01 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 13:43:03 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 13:43:04 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 13:43:05 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 13:43:07 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 13:43:08 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 13:43:10 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 13:43:11 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 13:43:14 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 13:43:16 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 13:43:19 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 13:43:23 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 13:43:25 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 13:43:29 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 13:43:31 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 13:43:36 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 13:43:40 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 13:43:44 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 13:43:52 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 13:43:58 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 13:44:17 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 13:44:23 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 13:44:32 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 13:45:14 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 13:47:01 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 13:47:35 INFO mapreduce.Job: Job job_1422482982071_4330 completed successfully
15/04/09 13:47:35 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=16787700639
		FILE: Number of bytes written=33585925047
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=330
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=75
		Launched reduce tasks=36
		Data-local map tasks=49
		Rack-local map tasks=26
		Total time spent by all maps in occupied slots (ms)=5492396
		Total time spent by all reduces in occupied slots (ms)=6939376
		Total time spent by all map tasks (ms)=2746198
		Total time spent by all reduce tasks (ms)=3469688
		Total vcore-seconds taken by all map tasks=2746198
		Total vcore-seconds taken by all reduce tasks=3469688
		Total megabyte-seconds taken by all map tasks=22233219008
		Total megabyte-seconds taken by all reduce tasks=41636256000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787716173
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787716173
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =2625
		Failed Shuffles=0
		Merged Map outputs=2625
		GC time elapsed (ms)=133706
		CPU time spent (ms)=7082750
		Physical memory (bytes) snapshot=170078113792
		Virtual memory (bytes) snapshot=1157037314048
		Total committed heap usage (bytes)=281403281408
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/09 13:47:35 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	6m4.370s
user	0m13.208s
sys	0m0.813s
15/04/09 13:47:38 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 25
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-25-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2733823750626202678.jar tmpDir=null
15/04/09 13:47:40 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:47:40 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:47:41 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 13:47:41 INFO mapreduce.JobSubmitter: number of splits:75
15/04/09 13:47:42 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4331
15/04/09 13:47:42 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4331
15/04/09 13:47:42 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4331/
15/04/09 13:47:42 INFO mapreduce.Job: Running job: job_1422482982071_4331
15/04/09 13:47:49 INFO mapreduce.Job: Job job_1422482982071_4331 running in uber mode : false
15/04/09 13:47:49 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 13:48:00 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 13:48:01 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 13:48:03 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 13:48:04 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 13:48:06 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 13:48:07 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 13:48:09 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 13:48:10 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 13:48:12 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 13:48:13 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 13:48:16 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 13:48:26 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 13:48:27 INFO mapreduce.Job:  map 73% reduce 0%
15/04/09 13:48:28 INFO mapreduce.Job:  map 81% reduce 0%
15/04/09 13:48:29 INFO mapreduce.Job:  map 89% reduce 0%
15/04/09 13:48:30 INFO mapreduce.Job:  map 95% reduce 0%
15/04/09 13:48:31 INFO mapreduce.Job:  map 97% reduce 0%
15/04/09 13:48:32 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 13:48:34 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 13:48:37 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 13:48:38 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 13:48:40 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 13:48:43 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 13:48:44 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 13:48:46 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 13:48:47 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 13:48:49 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 13:48:52 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 13:48:55 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 13:48:58 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 13:49:01 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 13:49:02 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 13:49:05 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 13:49:07 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 13:49:10 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 13:49:13 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 13:49:17 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 13:49:19 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 13:49:22 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 13:49:23 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 13:49:25 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 13:49:28 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 13:49:29 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 13:49:34 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 13:49:37 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 13:49:40 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 13:49:41 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 13:49:44 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 13:49:47 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 13:49:50 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 13:49:53 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 13:49:58 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 13:50:03 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 13:50:14 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 13:50:20 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 13:50:23 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 13:50:24 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 13:50:29 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 13:50:38 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 13:50:57 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 13:51:33 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 13:52:04 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 13:53:46 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 13:54:42 INFO mapreduce.Job: Job job_1422482982071_4331 completed successfully
15/04/09 13:54:43 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=16787700591
		FILE: Number of bytes written=33584953169
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=300
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=75
		Launched reduce tasks=26
		Data-local map tasks=52
		Rack-local map tasks=23
		Total time spent by all maps in occupied slots (ms)=5645284
		Total time spent by all reduces in occupied slots (ms)=6708398
		Total time spent by all map tasks (ms)=2822642
		Total time spent by all reduce tasks (ms)=3354199
		Total vcore-seconds taken by all map tasks=2822642
		Total vcore-seconds taken by all reduce tasks=3354199
		Total megabyte-seconds taken by all map tasks=22852109632
		Total megabyte-seconds taken by all reduce tasks=40250388000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787711673
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787711673
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1875
		Failed Shuffles=0
		Merged Map outputs=1875
		GC time elapsed (ms)=103323
		CPU time spent (ms)=7005250
		Physical memory (bytes) snapshot=168181977088
		Virtual memory (bytes) snapshot=1023172706304
		Total committed heap usage (bytes)=260353097728
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/09 13:54:43 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	7m7.603s
user	0m13.976s
sys	0m0.836s
15/04/09 13:54:45 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 25
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-25-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob261742858825724978.jar tmpDir=null
15/04/09 13:54:48 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:54:48 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:54:49 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 13:54:49 INFO mapreduce.JobSubmitter: number of splits:75
15/04/09 13:54:50 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4333
15/04/09 13:54:50 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4333
15/04/09 13:54:50 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4333/
15/04/09 13:54:50 INFO mapreduce.Job: Running job: job_1422482982071_4333
15/04/09 13:54:56 INFO mapreduce.Job: Job job_1422482982071_4333 running in uber mode : false
15/04/09 13:54:56 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 13:55:07 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 13:55:08 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 13:55:10 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 13:55:11 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 13:55:12 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 13:55:13 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 13:55:14 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 13:55:16 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 13:55:17 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 13:55:19 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 13:55:20 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 13:55:23 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 13:55:33 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 13:55:34 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 13:55:35 INFO mapreduce.Job:  map 81% reduce 0%
15/04/09 13:55:36 INFO mapreduce.Job:  map 87% reduce 0%
15/04/09 13:55:37 INFO mapreduce.Job:  map 94% reduce 0%
15/04/09 13:55:38 INFO mapreduce.Job:  map 98% reduce 0%
15/04/09 13:55:39 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 13:55:40 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 13:55:44 INFO mapreduce.Job:  map 100% reduce 9%
15/04/09 13:55:45 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 13:55:46 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 13:55:47 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 13:55:48 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 13:55:49 INFO mapreduce.Job:  map 100% reduce 44%
15/04/09 13:55:50 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 13:55:51 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 13:55:52 INFO mapreduce.Job:  map 100% reduce 51%
15/04/09 13:55:53 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 13:55:54 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 13:55:55 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 13:55:56 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 13:55:57 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 13:55:58 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 13:56:00 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 13:56:01 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 13:56:02 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 13:56:04 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 13:56:07 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 13:56:08 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 13:56:09 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 13:56:12 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 13:56:15 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 13:56:18 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 13:56:20 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 13:56:22 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 13:56:25 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 13:56:28 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 13:56:30 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 13:56:31 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 13:56:33 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 13:56:36 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 13:56:37 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 13:56:39 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 13:56:43 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 13:56:45 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 13:56:46 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 13:56:49 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 13:56:54 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 13:56:57 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 13:57:01 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 13:57:06 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 13:57:12 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 13:57:20 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 13:57:26 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 13:57:31 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 13:57:33 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 13:57:35 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 13:57:40 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 13:57:59 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 13:58:38 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 13:59:05 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 14:00:26 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 14:01:19 INFO mapreduce.Job: Job job_1422482982071_4333 completed successfully
15/04/09 14:01:19 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=16787700591
		FILE: Number of bytes written=33584953169
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=300
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=75
		Launched reduce tasks=26
		Data-local map tasks=50
		Rack-local map tasks=25
		Total time spent by all maps in occupied slots (ms)=5582438
		Total time spent by all reduces in occupied slots (ms)=6283590
		Total time spent by all map tasks (ms)=2791219
		Total time spent by all reduce tasks (ms)=3141795
		Total vcore-seconds taken by all map tasks=2791219
		Total vcore-seconds taken by all reduce tasks=3141795
		Total megabyte-seconds taken by all map tasks=22597709024
		Total megabyte-seconds taken by all reduce tasks=37701540000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787711673
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787711673
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1875
		Failed Shuffles=0
		Merged Map outputs=1875
		GC time elapsed (ms)=111429
		CPU time spent (ms)=6974290
		Physical memory (bytes) snapshot=168142753792
		Virtual memory (bytes) snapshot=1023375663104
		Total committed heap usage (bytes)=260353794048
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/09 14:01:19 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	6m36.739s
user	0m13.349s
sys	0m0.893s
15/04/09 14:01:22 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 25
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-25-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6816853630194752230.jar tmpDir=null
15/04/09 14:01:25 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 14:01:25 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 14:01:25 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 14:01:26 INFO mapreduce.JobSubmitter: number of splits:75
15/04/09 14:01:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4335
15/04/09 14:01:27 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4335
15/04/09 14:01:27 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4335/
15/04/09 14:01:27 INFO mapreduce.Job: Running job: job_1422482982071_4335
15/04/09 14:01:33 INFO mapreduce.Job: Job job_1422482982071_4335 running in uber mode : false
15/04/09 14:01:33 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 14:01:44 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 14:01:45 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 14:01:47 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 14:01:48 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 14:01:50 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 14:01:51 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 14:01:53 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 14:01:54 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 14:01:55 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 14:01:56 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 14:01:57 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 14:02:00 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 14:02:10 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 14:02:11 INFO mapreduce.Job:  map 76% reduce 0%
15/04/09 14:02:12 INFO mapreduce.Job:  map 81% reduce 0%
15/04/09 14:02:13 INFO mapreduce.Job:  map 92% reduce 0%
15/04/09 14:02:14 INFO mapreduce.Job:  map 97% reduce 0%
15/04/09 14:02:15 INFO mapreduce.Job:  map 98% reduce 0%
15/04/09 14:02:16 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 14:02:20 INFO mapreduce.Job:  map 100% reduce 25%
15/04/09 14:02:21 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 14:02:23 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 14:02:24 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 14:02:26 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 14:02:27 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 14:02:29 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 14:02:30 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 14:02:32 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 14:02:33 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 14:02:35 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 14:02:36 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 14:02:39 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 14:02:41 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 14:02:42 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 14:02:46 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 14:02:49 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 14:02:52 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 14:02:54 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 14:02:55 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 14:02:59 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 14:03:01 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 14:03:04 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 14:03:07 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 14:03:10 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 14:03:13 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 14:03:16 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 14:03:19 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 14:03:22 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 14:03:24 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 14:03:27 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 14:03:31 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 14:03:34 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 14:03:38 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 14:03:42 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 14:03:46 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 14:03:55 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 14:04:01 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 14:04:07 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 14:04:10 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 14:04:16 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 14:04:20 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 14:04:34 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 14:05:18 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 14:05:48 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 14:06:56 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 14:07:45 INFO mapreduce.Job: Job job_1422482982071_4335 completed successfully
15/04/09 14:07:45 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=16787700591
		FILE: Number of bytes written=33584953169
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=300
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=75
		Launched reduce tasks=26
		Data-local map tasks=51
		Rack-local map tasks=24
		Total time spent by all maps in occupied slots (ms)=5560064
		Total time spent by all reduces in occupied slots (ms)=6274680
		Total time spent by all map tasks (ms)=2780032
		Total time spent by all reduce tasks (ms)=3137340
		Total vcore-seconds taken by all map tasks=2780032
		Total vcore-seconds taken by all reduce tasks=3137340
		Total megabyte-seconds taken by all map tasks=22507139072
		Total megabyte-seconds taken by all reduce tasks=37648080000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787711673
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787711673
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1875
		Failed Shuffles=0
		Merged Map outputs=1875
		GC time elapsed (ms)=110789
		CPU time spent (ms)=6983580
		Physical memory (bytes) snapshot=168093102080
		Virtual memory (bytes) snapshot=1022568624128
		Total committed heap usage (bytes)=260352536576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/09 14:07:45 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	6m25.392s
user	0m12.961s
sys	0m0.836s
15/04/09 14:07:47 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 15
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-15-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6424856039554298535.jar tmpDir=null
15/04/09 14:07:50 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 14:07:50 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 14:07:50 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 14:07:51 INFO mapreduce.JobSubmitter: number of splits:75
15/04/09 14:07:51 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4337
15/04/09 14:07:52 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4337
15/04/09 14:07:52 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4337/
15/04/09 14:07:52 INFO mapreduce.Job: Running job: job_1422482982071_4337
15/04/09 14:07:57 INFO mapreduce.Job: Job job_1422482982071_4337 running in uber mode : false
15/04/09 14:07:57 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 14:08:08 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 14:08:09 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 14:08:11 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 14:08:12 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 14:08:14 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 14:08:15 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 14:08:17 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 14:08:18 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 14:08:20 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 14:08:21 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 14:08:24 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 14:08:35 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 14:08:36 INFO mapreduce.Job:  map 77% reduce 0%
15/04/09 14:08:37 INFO mapreduce.Job:  map 87% reduce 0%
15/04/09 14:08:38 INFO mapreduce.Job:  map 93% reduce 0%
15/04/09 14:08:39 INFO mapreduce.Job:  map 96% reduce 0%
15/04/09 14:08:40 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 14:08:42 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 14:08:45 INFO mapreduce.Job:  map 100% reduce 11%
15/04/09 14:08:46 INFO mapreduce.Job:  map 100% reduce 31%
15/04/09 14:08:48 INFO mapreduce.Job:  map 100% reduce 32%
15/04/09 14:08:49 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 14:08:52 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 14:08:55 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 14:08:57 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 14:08:58 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 14:09:01 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 14:09:04 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 14:09:07 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 14:09:09 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 14:09:10 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 14:09:11 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 14:09:13 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 14:09:14 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 14:09:17 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 14:09:19 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 14:09:22 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 14:09:24 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 14:09:26 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 14:09:28 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 14:09:29 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 14:09:31 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 14:09:33 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 14:09:38 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 14:09:41 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 14:09:44 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 14:09:47 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 14:09:50 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 14:09:54 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 14:09:57 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 14:10:03 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 14:10:06 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 14:10:12 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 14:10:14 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 14:10:17 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 14:10:20 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 14:10:24 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 14:10:27 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 14:10:33 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 14:10:38 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 14:10:41 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 14:10:45 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 14:10:51 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 14:10:59 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 14:11:04 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 14:11:18 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 14:11:33 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 14:11:49 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 14:12:27 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 14:12:55 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 14:13:19 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 14:13:46 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 14:14:35 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 14:15:20 INFO mapreduce.Job: Job job_1422482982071_4337 completed successfully
15/04/09 14:15:20 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=16787700561
		FILE: Number of bytes written=33583981309
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Launched map tasks=75
		Launched reduce tasks=15
		Data-local map tasks=53
		Rack-local map tasks=22
		Total time spent by all maps in occupied slots (ms)=5675290
		Total time spent by all reduces in occupied slots (ms)=5910804
		Total time spent by all map tasks (ms)=2837645
		Total time spent by all reduce tasks (ms)=2955402
		Total vcore-seconds taken by all map tasks=2837645
		Total vcore-seconds taken by all reduce tasks=2955402
		Total megabyte-seconds taken by all map tasks=22973573920
		Total megabyte-seconds taken by all reduce tasks=35464824000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787707173
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787707173
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1125
		Failed Shuffles=0
		Merged Map outputs=1125
		GC time elapsed (ms)=113817
		CPU time spent (ms)=7028480
		Physical memory (bytes) snapshot=167093010432
		Virtual memory (bytes) snapshot=888541229056
		Total committed heap usage (bytes)=239302901760
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/09 14:15:20 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	7m35.158s
user	0m13.631s
sys	0m0.892s
15/04/09 14:15:22 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 15
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-15-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4081288146609072064.jar tmpDir=null
15/04/09 14:15:25 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 14:15:25 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 14:15:26 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 14:15:26 INFO mapreduce.JobSubmitter: number of splits:75
15/04/09 14:15:27 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4339
15/04/09 14:15:27 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4339
15/04/09 14:15:27 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4339/
15/04/09 14:15:27 INFO mapreduce.Job: Running job: job_1422482982071_4339
15/04/09 14:15:33 INFO mapreduce.Job: Job job_1422482982071_4339 running in uber mode : false
15/04/09 14:15:33 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 14:15:44 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 14:15:45 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 14:15:47 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 14:15:48 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 14:15:50 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 14:15:51 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 14:15:52 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 14:15:53 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 14:15:54 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 14:15:55 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 14:15:57 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 14:15:58 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 14:16:02 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 14:16:12 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 14:16:13 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 14:16:14 INFO mapreduce.Job:  map 79% reduce 0%
15/04/09 14:16:15 INFO mapreduce.Job:  map 86% reduce 0%
15/04/09 14:16:16 INFO mapreduce.Job:  map 94% reduce 0%
15/04/09 14:16:17 INFO mapreduce.Job:  map 98% reduce 0%
15/04/09 14:16:18 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 14:16:23 INFO mapreduce.Job:  map 100% reduce 12%
15/04/09 14:16:24 INFO mapreduce.Job:  map 100% reduce 32%
15/04/09 14:16:27 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 14:16:29 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 14:16:30 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 14:16:32 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 14:16:33 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 14:16:35 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 14:16:36 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 14:16:38 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 14:16:39 INFO mapreduce.Job:  map 100% reduce 44%
15/04/09 14:16:41 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 14:16:42 INFO mapreduce.Job:  map 100% reduce 46%
15/04/09 14:16:43 INFO mapreduce.Job:  map 100% reduce 47%
15/04/09 14:16:45 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 14:16:46 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 14:16:47 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 14:16:48 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 14:16:49 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 14:16:51 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 14:16:53 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 14:16:56 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 14:16:58 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 14:17:00 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 14:17:02 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 14:17:05 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 14:17:08 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 14:17:09 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 14:17:14 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 14:17:15 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 14:17:18 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 14:17:20 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 14:17:23 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 14:17:25 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 14:17:29 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 14:17:30 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 14:17:33 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 14:17:37 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 14:17:41 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 14:17:45 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 14:17:48 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 14:17:51 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 14:17:54 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 14:18:00 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 14:18:03 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 14:18:09 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 14:18:13 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 14:18:19 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 14:18:22 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 14:18:31 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 14:18:37 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 14:18:42 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 14:18:55 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 14:19:16 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 14:19:34 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 14:20:07 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 14:20:53 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 14:21:00 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 14:21:15 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 14:21:17 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 14:22:08 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 14:22:41 INFO mapreduce.Job: Job job_1422482982071_4339 completed successfully
15/04/09 14:22:41 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=16787700561
		FILE: Number of bytes written=33583981309
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Launched map tasks=75
		Launched reduce tasks=15
		Data-local map tasks=50
		Rack-local map tasks=25
		Total time spent by all maps in occupied slots (ms)=5749216
		Total time spent by all reduces in occupied slots (ms)=5925796
		Total time spent by all map tasks (ms)=2874608
		Total time spent by all reduce tasks (ms)=2962898
		Total vcore-seconds taken by all map tasks=2874608
		Total vcore-seconds taken by all reduce tasks=2962898
		Total megabyte-seconds taken by all map tasks=23272826368
		Total megabyte-seconds taken by all reduce tasks=35554776000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787707173
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787707173
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1125
		Failed Shuffles=0
		Merged Map outputs=1125
		GC time elapsed (ms)=111575
		CPU time spent (ms)=7046160
		Physical memory (bytes) snapshot=167099060224
		Virtual memory (bytes) snapshot=889539805184
		Total committed heap usage (bytes)=239302868992
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/09 14:22:41 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	7m21.562s
user	0m13.205s
sys	0m0.926s
15/04/09 14:22:44 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 15
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-15-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob652578297028655726.jar tmpDir=null
15/04/09 14:22:47 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 14:22:47 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 14:22:48 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 14:22:48 INFO mapreduce.JobSubmitter: number of splits:75
15/04/09 14:22:49 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4342
15/04/09 14:22:49 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4342
15/04/09 14:22:49 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4342/
15/04/09 14:22:49 INFO mapreduce.Job: Running job: job_1422482982071_4342
15/04/09 14:22:54 INFO mapreduce.Job: Job job_1422482982071_4342 running in uber mode : false
15/04/09 14:22:54 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 14:23:04 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 14:23:05 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 14:23:06 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 14:23:07 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 14:23:08 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 14:23:09 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 14:23:10 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 14:23:11 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 14:23:12 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 14:23:13 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 14:23:14 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 14:23:15 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 14:23:16 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 14:23:17 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 14:23:18 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 14:23:32 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 14:23:33 INFO mapreduce.Job:  map 84% reduce 0%
15/04/09 14:23:34 INFO mapreduce.Job:  map 88% reduce 0%
15/04/09 14:23:35 INFO mapreduce.Job:  map 97% reduce 0%
15/04/09 14:23:36 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 14:23:37 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 14:23:42 INFO mapreduce.Job:  map 100% reduce 5%
15/04/09 14:23:43 INFO mapreduce.Job:  map 100% reduce 19%
15/04/09 14:23:44 INFO mapreduce.Job:  map 100% reduce 29%
15/04/09 14:23:46 INFO mapreduce.Job:  map 100% reduce 32%
15/04/09 14:23:47 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 14:23:49 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 14:23:50 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 14:23:52 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 14:23:53 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 14:23:54 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 14:23:55 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 14:23:56 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 14:23:58 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 14:23:59 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 14:24:01 INFO mapreduce.Job:  map 100% reduce 44%
15/04/09 14:24:02 INFO mapreduce.Job:  map 100% reduce 47%
15/04/09 14:24:04 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 14:24:07 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 14:24:08 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 14:24:11 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 14:24:13 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 14:24:14 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 14:24:17 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 14:24:19 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 14:24:20 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 14:24:23 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 14:24:24 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 14:24:26 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 14:24:28 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 14:24:30 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 14:24:33 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 14:24:36 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 14:24:39 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 14:24:43 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 14:24:50 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 14:24:52 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 14:24:55 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 14:25:00 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 14:25:04 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 14:25:09 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 14:25:12 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 14:25:14 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 14:25:18 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 14:25:21 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 14:25:27 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 14:25:32 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 14:25:36 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 14:25:42 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 14:25:47 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 14:25:55 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 14:26:07 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 14:26:14 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 14:26:24 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 14:26:40 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 14:26:58 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 14:27:34 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 14:27:49 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 14:28:25 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 14:28:38 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 14:29:10 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 14:29:59 INFO mapreduce.Job: Job job_1422482982071_4342 completed successfully
15/04/09 14:29:59 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=16787700561
		FILE: Number of bytes written=33583981309
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Launched map tasks=75
		Launched reduce tasks=15
		Data-local map tasks=51
		Rack-local map tasks=24
		Total time spent by all maps in occupied slots (ms)=5503930
		Total time spent by all reduces in occupied slots (ms)=6017552
		Total time spent by all map tasks (ms)=2751965
		Total time spent by all reduce tasks (ms)=3008776
		Total vcore-seconds taken by all map tasks=2751965
		Total vcore-seconds taken by all reduce tasks=3008776
		Total megabyte-seconds taken by all map tasks=22279908640
		Total megabyte-seconds taken by all reduce tasks=36105312000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787707173
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787707173
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1125
		Failed Shuffles=0
		Merged Map outputs=1125
		GC time elapsed (ms)=112652
		CPU time spent (ms)=7000990
		Physical memory (bytes) snapshot=166838136832
		Virtual memory (bytes) snapshot=889739849728
		Total committed heap usage (bytes)=239299039232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/09 14:29:59 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	7m17.914s
user	0m14.484s
sys	0m0.885s
15/04/09 14:30:02 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 35
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-35-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4316905183352372341.jar tmpDir=null
15/04/09 14:30:05 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 14:30:05 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 14:30:05 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 14:30:06 INFO mapreduce.JobSubmitter: number of splits:134
15/04/09 14:30:06 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4344
15/04/09 14:30:07 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4344
15/04/09 14:30:07 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4344/
15/04/09 14:30:07 INFO mapreduce.Job: Running job: job_1422482982071_4344
15/04/09 14:30:12 INFO mapreduce.Job: Job job_1422482982071_4344 running in uber mode : false
15/04/09 14:30:12 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 14:30:23 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 14:30:24 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 14:30:26 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 14:30:27 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 14:30:28 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 14:30:29 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 14:30:30 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 14:30:31 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 14:30:32 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 14:30:33 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 14:30:35 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 14:30:36 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 14:30:37 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 14:30:51 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 14:30:52 INFO mapreduce.Job:  map 78% reduce 0%
15/04/09 14:30:53 INFO mapreduce.Job:  map 86% reduce 0%
15/04/09 14:30:54 INFO mapreduce.Job:  map 95% reduce 0%
15/04/09 14:30:55 INFO mapreduce.Job:  map 98% reduce 0%
15/04/09 14:30:56 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 14:31:01 INFO mapreduce.Job:  map 100% reduce 28%
15/04/09 14:31:02 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 14:31:04 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 14:31:05 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 14:31:07 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 14:31:08 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 14:31:10 INFO mapreduce.Job:  map 100% reduce 46%
15/04/09 14:31:11 INFO mapreduce.Job:  map 100% reduce 47%
15/04/09 14:31:14 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 14:31:17 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 14:31:19 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 14:31:20 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 14:31:23 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 14:31:28 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 14:31:31 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 14:31:34 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 14:31:37 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 14:31:41 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 14:31:44 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 14:31:45 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 14:31:47 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 14:31:50 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 14:31:53 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 14:31:56 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 14:31:59 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 14:32:02 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 14:32:05 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 14:32:08 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 14:32:11 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 14:32:14 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 14:32:17 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 14:32:20 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 14:32:23 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 14:32:26 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 14:32:32 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 14:32:38 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 14:32:41 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 14:32:53 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 14:32:56 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 14:33:02 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 14:33:11 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 14:33:26 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 14:33:44 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 14:34:13 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 14:34:22 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 14:34:46 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 14:36:21 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 14:40:10 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 14:41:19 INFO mapreduce.Job: Job job_1422482982071_4344 completed successfully
15/04/09 14:41:19 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=30424216069
		FILE: Number of bytes written=60864621112
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=507
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Killed reduce tasks=2
		Launched map tasks=134
		Launched reduce tasks=37
		Data-local map tasks=61
		Rack-local map tasks=73
		Total time spent by all maps in occupied slots (ms)=10220406
		Total time spent by all reduces in occupied slots (ms)=12858488
		Total time spent by all map tasks (ms)=5110203
		Total time spent by all reduce tasks (ms)=6429244
		Total vcore-seconds taken by all map tasks=5110203
		Total vcore-seconds taken by all reduce tasks=6429244
		Total megabyte-seconds taken by all map tasks=41372203488
		Total megabyte-seconds taken by all reduce tasks=77150928000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424243933
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424243933
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =4690
		Failed Shuffles=0
		Merged Map outputs=4690
		GC time elapsed (ms)=172384
		CPU time spent (ms)=12816360
		Physical memory (bytes) snapshot=298855030784
		Virtual memory (bytes) snapshot=1698006704128
		Total committed heap usage (bytes)=444812660736
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/09 14:41:19 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	11m19.937s
user	0m15.061s
sys	0m1.047s
15/04/09 14:41:22 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 35
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-35-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1684336698432272748.jar tmpDir=null
15/04/09 14:41:25 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 14:41:25 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 14:41:26 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 14:41:26 INFO mapreduce.JobSubmitter: number of splits:134
15/04/09 14:41:27 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4348
15/04/09 14:41:27 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4348
15/04/09 14:41:27 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4348/
15/04/09 14:41:27 INFO mapreduce.Job: Running job: job_1422482982071_4348
15/04/09 14:41:32 INFO mapreduce.Job: Job job_1422482982071_4348 running in uber mode : false
15/04/09 14:41:32 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 14:41:42 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 14:41:43 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 14:41:44 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 14:41:45 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 14:41:46 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 14:41:47 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 14:41:48 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 14:41:49 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 14:41:50 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 14:41:51 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 14:41:52 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 14:41:53 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 14:41:54 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 14:41:55 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 14:41:56 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 14:42:09 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 14:42:10 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 14:42:11 INFO mapreduce.Job:  map 82% reduce 0%
15/04/09 14:42:12 INFO mapreduce.Job:  map 91% reduce 0%
15/04/09 14:42:13 INFO mapreduce.Job:  map 96% reduce 0%
15/04/09 14:42:14 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 14:42:17 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 14:42:21 INFO mapreduce.Job:  map 100% reduce 1%
15/04/09 14:42:22 INFO mapreduce.Job:  map 100% reduce 27%
15/04/09 14:42:23 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 14:42:25 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 14:42:26 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 14:42:28 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 14:42:29 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 14:42:31 INFO mapreduce.Job:  map 100% reduce 44%
15/04/09 14:42:32 INFO mapreduce.Job:  map 100% reduce 46%
15/04/09 14:42:34 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 14:42:35 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 14:42:37 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 14:42:38 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 14:42:40 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 14:42:43 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 14:42:46 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 14:42:48 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 14:42:49 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 14:42:50 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 14:42:51 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 14:42:52 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 14:42:54 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 14:42:56 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 14:42:59 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 14:43:00 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 14:43:02 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 14:43:05 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 14:43:08 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 14:43:11 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 14:43:14 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 14:43:17 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 14:43:21 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 14:43:23 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 14:43:26 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 14:43:30 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 14:43:33 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 14:43:36 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 14:43:39 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 14:43:44 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 14:43:48 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 14:43:51 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 14:43:54 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 14:43:59 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 14:44:02 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 14:44:08 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 14:44:14 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 14:44:21 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 14:44:32 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 14:44:43 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 14:45:02 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 14:45:24 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 14:45:43 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 14:45:58 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 14:47:26 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 14:51:13 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 14:52:36 INFO mapreduce.Job: Job job_1422482982071_4348 completed successfully
15/04/09 14:52:36 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=30424216069
		FILE: Number of bytes written=60864621112
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=507
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Killed reduce tasks=2
		Launched map tasks=134
		Launched reduce tasks=37
		Data-local map tasks=65
		Rack-local map tasks=69
		Total time spent by all maps in occupied slots (ms)=10016076
		Total time spent by all reduces in occupied slots (ms)=12324356
		Total time spent by all map tasks (ms)=5008038
		Total time spent by all reduce tasks (ms)=6162178
		Total vcore-seconds taken by all map tasks=5008038
		Total vcore-seconds taken by all reduce tasks=6162178
		Total megabyte-seconds taken by all map tasks=40545075648
		Total megabyte-seconds taken by all reduce tasks=73946136000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424243933
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424243933
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =4690
		Failed Shuffles=0
		Merged Map outputs=4690
		GC time elapsed (ms)=193920
		CPU time spent (ms)=12759920
		Physical memory (bytes) snapshot=298744872960
		Virtual memory (bytes) snapshot=1698419466240
		Total committed heap usage (bytes)=444808122368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/09 14:52:36 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	11m17.111s
user	0m15.790s
sys	0m1.029s
15/04/09 14:52:39 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 35
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-35-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob931400357550478969.jar tmpDir=null
15/04/09 14:52:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 14:52:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 14:52:43 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 14:52:43 INFO mapreduce.JobSubmitter: number of splits:134
15/04/09 14:52:44 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4352
15/04/09 14:52:44 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4352
15/04/09 14:52:44 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4352/
15/04/09 14:52:44 INFO mapreduce.Job: Running job: job_1422482982071_4352
15/04/09 14:52:51 INFO mapreduce.Job: Job job_1422482982071_4352 running in uber mode : false
15/04/09 14:52:51 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 14:53:01 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 14:53:02 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 14:53:03 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 14:53:04 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 14:53:05 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 14:53:06 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 14:53:07 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 14:53:08 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 14:53:09 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 14:53:10 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 14:53:11 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 14:53:12 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 14:53:13 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 14:53:14 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 14:53:15 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 14:53:29 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 14:53:30 INFO mapreduce.Job:  map 78% reduce 0%
15/04/09 14:53:31 INFO mapreduce.Job:  map 88% reduce 0%
15/04/09 14:53:32 INFO mapreduce.Job:  map 91% reduce 0%
15/04/09 14:53:33 INFO mapreduce.Job:  map 97% reduce 0%
15/04/09 14:53:34 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 14:53:35 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 14:53:39 INFO mapreduce.Job:  map 100% reduce 11%
15/04/09 14:53:40 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 14:53:42 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 14:53:43 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 14:53:44 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 14:53:45 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 14:53:46 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 14:53:48 INFO mapreduce.Job:  map 100% reduce 44%
15/04/09 14:53:49 INFO mapreduce.Job:  map 100% reduce 47%
15/04/09 14:53:51 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 14:53:52 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 14:53:54 INFO mapreduce.Job:  map 100% reduce 51%
15/04/09 14:53:55 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 14:53:58 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 14:54:01 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 14:54:04 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 14:54:06 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 14:54:07 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 14:54:10 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 14:54:11 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 14:54:13 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 14:54:16 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 14:54:19 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 14:54:22 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 14:54:25 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 14:54:28 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 14:54:29 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 14:54:34 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 14:54:37 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 14:54:40 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 14:54:43 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 14:54:46 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 14:54:49 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 14:54:52 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 14:54:59 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 14:55:02 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 14:55:05 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 14:55:09 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 14:55:14 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 14:55:20 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 14:55:24 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 14:55:30 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 14:55:38 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 14:55:45 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 14:55:54 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 14:56:09 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 14:56:27 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 14:56:51 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 14:57:04 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 14:57:29 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 14:58:40 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 15:02:32 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 15:03:47 INFO mapreduce.Job: Job job_1422482982071_4352 completed successfully
15/04/09 15:03:47 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=30424216069
		FILE: Number of bytes written=60864621112
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=507
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=134
		Launched reduce tasks=36
		Data-local map tasks=65
		Rack-local map tasks=69
		Total time spent by all maps in occupied slots (ms)=10121704
		Total time spent by all reduces in occupied slots (ms)=12308584
		Total time spent by all map tasks (ms)=5060852
		Total time spent by all reduce tasks (ms)=6154292
		Total vcore-seconds taken by all map tasks=5060852
		Total vcore-seconds taken by all reduce tasks=6154292
		Total megabyte-seconds taken by all map tasks=40972657792
		Total megabyte-seconds taken by all reduce tasks=73851504000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424243933
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424243933
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =4690
		Failed Shuffles=0
		Merged Map outputs=4690
		GC time elapsed (ms)=188679
		CPU time spent (ms)=12828500
		Physical memory (bytes) snapshot=298989797376
		Virtual memory (bytes) snapshot=1697433391104
		Total committed heap usage (bytes)=444804894720
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/09 15:03:47 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	11m10.418s
user	0m14.776s
sys	0m0.993s
15/04/09 15:03:49 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 25
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-25-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8599861799613908837.jar tmpDir=null
15/04/09 15:03:52 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 15:03:52 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 15:03:53 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 15:03:54 INFO mapreduce.JobSubmitter: number of splits:134
15/04/09 15:03:54 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4354
15/04/09 15:03:54 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4354
15/04/09 15:03:54 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4354/
15/04/09 15:03:54 INFO mapreduce.Job: Running job: job_1422482982071_4354
15/04/09 15:04:01 INFO mapreduce.Job: Job job_1422482982071_4354 running in uber mode : false
15/04/09 15:04:01 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 15:04:11 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 15:04:12 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 15:04:13 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 15:04:14 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 15:04:15 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 15:04:17 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 15:04:18 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 15:04:19 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 15:04:20 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 15:04:21 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 15:04:22 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 15:04:23 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 15:04:24 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 15:04:25 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 15:04:39 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 15:04:40 INFO mapreduce.Job:  map 76% reduce 0%
15/04/09 15:04:41 INFO mapreduce.Job:  map 85% reduce 0%
15/04/09 15:04:42 INFO mapreduce.Job:  map 91% reduce 0%
15/04/09 15:04:43 INFO mapreduce.Job:  map 98% reduce 0%
15/04/09 15:04:44 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 15:04:45 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 15:04:50 INFO mapreduce.Job:  map 100% reduce 12%
15/04/09 15:04:51 INFO mapreduce.Job:  map 100% reduce 27%
15/04/09 15:04:52 INFO mapreduce.Job:  map 100% reduce 30%
15/04/09 15:04:54 INFO mapreduce.Job:  map 100% reduce 31%
15/04/09 15:04:56 INFO mapreduce.Job:  map 100% reduce 32%
15/04/09 15:04:58 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 15:05:00 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 15:05:01 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 15:05:03 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 15:05:06 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 15:05:07 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 15:05:09 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 15:05:12 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 15:05:14 INFO mapreduce.Job:  map 100% reduce 44%
15/04/09 15:05:15 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 15:05:16 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 15:05:17 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 15:05:18 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 15:05:19 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 15:05:21 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 15:05:22 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 15:05:23 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 15:05:24 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 15:05:25 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 15:05:27 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 15:05:30 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 15:05:32 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 15:05:35 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 15:05:38 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 15:05:41 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 15:05:46 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 15:05:52 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 15:05:56 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 15:06:01 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 15:06:06 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 15:06:08 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 15:06:13 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 15:06:17 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 15:06:22 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 15:06:25 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 15:06:28 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 15:06:32 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 15:06:36 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 15:06:40 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 15:06:46 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 15:06:53 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 15:06:57 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 15:06:58 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 15:07:06 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 15:07:15 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 15:07:21 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 15:07:33 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 15:07:49 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 15:08:02 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 15:08:04 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 15:08:11 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 15:08:23 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 15:08:43 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 15:09:02 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 15:10:22 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 15:11:09 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 15:13:30 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 15:15:35 INFO mapreduce.Job: Job job_1422482982071_4354 completed successfully
15/04/09 15:15:35 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=30424216039
		FILE: Number of bytes written=60863631542
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=477
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=134
		Launched reduce tasks=26
		Data-local map tasks=60
		Rack-local map tasks=74
		Total time spent by all maps in occupied slots (ms)=10238458
		Total time spent by all reduces in occupied slots (ms)=11584792
		Total time spent by all map tasks (ms)=5119229
		Total time spent by all reduce tasks (ms)=5792396
		Total vcore-seconds taken by all map tasks=5119229
		Total vcore-seconds taken by all reduce tasks=5792396
		Total megabyte-seconds taken by all map tasks=41445277984
		Total megabyte-seconds taken by all reduce tasks=69508752000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424235893
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424235893
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =3350
		Failed Shuffles=0
		Merged Map outputs=3350
		GC time elapsed (ms)=215117
		CPU time spent (ms)=12936380
		Physical memory (bytes) snapshot=297516036096
		Virtual memory (bytes) snapshot=1563599859712
		Total committed heap usage (bytes)=423761752064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/09 15:15:35 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	11m48.499s
user	0m15.788s
sys	0m1.062s
15/04/09 15:15:38 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 25
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-25-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1135594856916015995.jar tmpDir=null
15/04/09 15:15:41 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 15:15:41 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 15:15:41 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 15:15:42 INFO mapreduce.JobSubmitter: number of splits:134
15/04/09 15:15:42 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4356
15/04/09 15:15:43 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4356
15/04/09 15:15:43 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4356/
15/04/09 15:15:43 INFO mapreduce.Job: Running job: job_1422482982071_4356
15/04/09 15:15:48 INFO mapreduce.Job: Job job_1422482982071_4356 running in uber mode : false
15/04/09 15:15:48 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 15:15:59 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 15:16:00 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 15:16:02 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 15:16:03 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 15:16:05 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 15:16:06 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 15:16:08 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 15:16:09 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 15:16:11 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 15:16:12 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 15:16:13 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 15:16:26 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 15:16:27 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 15:16:28 INFO mapreduce.Job:  map 81% reduce 0%
15/04/09 15:16:29 INFO mapreduce.Job:  map 89% reduce 0%
15/04/09 15:16:30 INFO mapreduce.Job:  map 96% reduce 0%
15/04/09 15:16:31 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 15:16:37 INFO mapreduce.Job:  map 100% reduce 14%
15/04/09 15:16:38 INFO mapreduce.Job:  map 100% reduce 30%
15/04/09 15:16:42 INFO mapreduce.Job:  map 100% reduce 31%
15/04/09 15:16:44 INFO mapreduce.Job:  map 100% reduce 32%
15/04/09 15:16:45 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 15:16:47 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 15:16:48 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 15:16:50 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 15:16:51 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 15:16:53 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 15:16:54 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 15:16:56 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 15:16:59 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 15:17:00 INFO mapreduce.Job:  map 100% reduce 44%
15/04/09 15:17:02 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 15:17:03 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 15:17:04 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 15:17:05 INFO mapreduce.Job:  map 100% reduce 51%
15/04/09 15:17:06 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 15:17:07 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 15:17:08 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 15:17:09 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 15:17:11 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 15:17:12 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 15:17:14 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 15:17:15 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 15:17:18 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 15:17:21 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 15:17:24 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 15:17:27 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 15:17:32 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 15:17:36 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 15:17:42 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 15:17:46 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 15:17:49 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 15:17:54 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 15:17:57 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 15:18:03 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 15:18:07 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 15:18:10 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 15:18:13 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 15:18:17 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 15:18:21 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 15:18:27 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 15:18:33 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 15:18:39 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 15:18:42 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 15:18:46 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 15:18:55 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 15:19:02 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 15:19:09 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 15:19:24 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 15:19:39 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 15:19:46 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 15:19:53 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 15:19:57 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 15:20:09 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 15:20:19 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 15:20:57 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 15:22:05 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 15:22:54 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 15:25:46 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 15:28:00 INFO mapreduce.Job: Job job_1422482982071_4356 completed successfully
15/04/09 15:28:00 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=30424216039
		FILE: Number of bytes written=60863631542
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=477
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=134
		Launched reduce tasks=26
		Data-local map tasks=62
		Rack-local map tasks=72
		Total time spent by all maps in occupied slots (ms)=10170684
		Total time spent by all reduces in occupied slots (ms)=11777808
		Total time spent by all map tasks (ms)=5085342
		Total time spent by all reduce tasks (ms)=5888904
		Total vcore-seconds taken by all map tasks=5085342
		Total vcore-seconds taken by all reduce tasks=5888904
		Total megabyte-seconds taken by all map tasks=41170928832
		Total megabyte-seconds taken by all reduce tasks=70666848000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424235893
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424235893
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =3350
		Failed Shuffles=0
		Merged Map outputs=3350
		GC time elapsed (ms)=214772
		CPU time spent (ms)=12889870
		Physical memory (bytes) snapshot=297472393216
		Virtual memory (bytes) snapshot=1564591370240
		Total committed heap usage (bytes)=423758778368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/09 15:28:00 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	12m24.411s
user	0m15.913s
sys	0m1.038s
15/04/09 15:28:02 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 25
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-25-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6928172879716617557.jar tmpDir=null
15/04/09 15:28:06 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 15:28:06 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 15:28:07 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 15:28:07 INFO mapreduce.JobSubmitter: number of splits:134
15/04/09 15:28:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4357
15/04/09 15:28:08 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4357
15/04/09 15:28:08 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4357/
15/04/09 15:28:08 INFO mapreduce.Job: Running job: job_1422482982071_4357
15/04/09 15:28:14 INFO mapreduce.Job: Job job_1422482982071_4357 running in uber mode : false
15/04/09 15:28:14 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 15:28:26 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 15:28:27 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 15:28:29 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 15:28:30 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 15:28:32 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 15:28:33 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 15:28:35 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 15:28:36 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 15:28:38 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 15:28:39 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 15:28:53 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 15:28:54 INFO mapreduce.Job:  map 73% reduce 0%
15/04/09 15:28:55 INFO mapreduce.Job:  map 83% reduce 0%
15/04/09 15:28:56 INFO mapreduce.Job:  map 92% reduce 0%
15/04/09 15:28:57 INFO mapreduce.Job:  map 98% reduce 0%
15/04/09 15:28:58 INFO mapreduce.Job:  map 99% reduce 0%
15/04/09 15:28:59 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 15:29:03 INFO mapreduce.Job:  map 100% reduce 3%
15/04/09 15:29:04 INFO mapreduce.Job:  map 100% reduce 25%
15/04/09 15:29:05 INFO mapreduce.Job:  map 100% reduce 29%
15/04/09 15:29:07 INFO mapreduce.Job:  map 100% reduce 30%
15/04/09 15:29:08 INFO mapreduce.Job:  map 100% reduce 31%
15/04/09 15:29:10 INFO mapreduce.Job:  map 100% reduce 32%
15/04/09 15:29:11 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 15:29:13 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 15:29:14 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 15:29:16 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 15:29:17 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 15:29:19 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 15:29:20 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 15:29:22 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 15:29:23 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 15:29:25 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 15:29:28 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 15:29:31 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 15:29:33 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 15:29:34 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 15:29:36 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 15:29:37 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 15:29:38 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 15:29:41 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 15:29:44 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 15:29:47 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 15:29:50 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 15:29:53 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 15:29:59 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 15:30:03 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 15:30:08 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 15:30:12 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 15:30:15 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 15:30:20 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 15:30:23 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 15:30:29 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 15:30:32 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 15:30:35 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 15:30:41 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 15:30:44 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 15:30:48 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 15:30:52 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 15:30:57 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 15:31:03 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 15:31:09 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 15:31:15 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 15:31:22 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 15:31:27 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 15:31:36 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 15:31:48 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 15:31:58 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 15:32:12 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 15:32:19 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 15:32:28 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 15:32:31 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 15:32:43 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 15:33:08 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 15:34:23 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 15:35:08 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 15:37:58 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 15:39:58 INFO mapreduce.Job: Job job_1422482982071_4357 completed successfully
15/04/09 15:39:58 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=30424216039
		FILE: Number of bytes written=60863631542
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=477
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=134
		Launched reduce tasks=26
		Data-local map tasks=60
		Rack-local map tasks=74
		Total time spent by all maps in occupied slots (ms)=10196878
		Total time spent by all reduces in occupied slots (ms)=11530110
		Total time spent by all map tasks (ms)=5098439
		Total time spent by all reduce tasks (ms)=5765055
		Total vcore-seconds taken by all map tasks=5098439
		Total vcore-seconds taken by all reduce tasks=5765055
		Total megabyte-seconds taken by all map tasks=41276962144
		Total megabyte-seconds taken by all reduce tasks=69180660000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424235893
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424235893
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =3350
		Failed Shuffles=0
		Merged Map outputs=3350
		GC time elapsed (ms)=187991
		CPU time spent (ms)=12808590
		Physical memory (bytes) snapshot=297762951168
		Virtual memory (bytes) snapshot=1564176502784
		Total committed heap usage (bytes)=423760891904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/09 15:39:58 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	11m57.936s
user	0m16.428s
sys	0m1.100s
15/04/09 15:40:00 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 15
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-15-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1601799812128934307.jar tmpDir=null
15/04/09 15:40:03 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 15:40:03 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 15:40:04 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 15:40:04 INFO mapreduce.JobSubmitter: number of splits:134
15/04/09 15:40:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4360
15/04/09 15:40:05 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4360
15/04/09 15:40:05 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4360/
15/04/09 15:40:05 INFO mapreduce.Job: Running job: job_1422482982071_4360
15/04/09 15:40:11 INFO mapreduce.Job: Job job_1422482982071_4360 running in uber mode : false
15/04/09 15:40:11 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 15:40:22 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 15:40:23 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 15:40:24 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 15:40:25 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 15:40:26 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 15:40:27 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 15:40:28 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 15:40:29 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 15:40:30 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 15:40:31 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 15:40:32 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 15:40:33 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 15:40:34 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 15:40:35 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 15:40:36 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 15:40:50 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 15:40:51 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 15:40:52 INFO mapreduce.Job:  map 78% reduce 0%
15/04/09 15:40:53 INFO mapreduce.Job:  map 88% reduce 0%
15/04/09 15:40:54 INFO mapreduce.Job:  map 94% reduce 0%
15/04/09 15:40:55 INFO mapreduce.Job:  map 97% reduce 0%
15/04/09 15:40:56 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 15:41:01 INFO mapreduce.Job:  map 100% reduce 1%
15/04/09 15:41:02 INFO mapreduce.Job:  map 100% reduce 6%
15/04/09 15:41:03 INFO mapreduce.Job:  map 100% reduce 19%
15/04/09 15:41:06 INFO mapreduce.Job:  map 100% reduce 20%
15/04/09 15:41:24 INFO mapreduce.Job:  map 100% reduce 22%
15/04/09 15:41:25 INFO mapreduce.Job:  map 100% reduce 23%
15/04/09 15:41:26 INFO mapreduce.Job:  map 100% reduce 24%
15/04/09 15:41:27 INFO mapreduce.Job:  map 100% reduce 29%
15/04/09 15:41:29 INFO mapreduce.Job:  map 100% reduce 30%
15/04/09 15:41:30 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 15:41:33 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 15:41:36 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 15:41:39 INFO mapreduce.Job:  map 100% reduce 47%
15/04/09 15:41:40 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 15:41:42 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 15:41:45 INFO mapreduce.Job:  map 100% reduce 51%
15/04/09 15:41:48 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 15:41:49 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 15:41:56 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 15:41:57 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 15:41:59 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 15:42:00 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 15:42:04 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 15:42:07 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 15:42:10 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 15:42:13 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 15:42:16 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 15:42:24 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 15:42:31 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 15:42:38 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 15:42:44 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 15:42:47 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 15:42:50 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 15:42:51 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 15:42:54 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 15:42:56 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 15:43:02 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 15:43:14 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 15:43:20 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 15:43:27 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 15:43:35 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 15:43:45 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 15:43:54 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 15:43:57 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 15:44:03 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 15:44:12 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 15:44:21 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 15:44:30 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 15:44:36 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 15:44:45 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 15:45:00 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 15:45:14 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 15:45:21 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 15:45:35 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 15:45:50 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 15:46:11 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 15:46:36 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 15:47:40 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 15:48:54 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 15:49:52 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 15:50:40 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 15:50:46 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 15:52:27 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 15:53:45 INFO mapreduce.Job: Job job_1422482982071_4360 completed successfully
15/04/09 15:53:46 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=30424216021
		FILE: Number of bytes written=60862641984
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=447
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Launched map tasks=134
		Launched reduce tasks=15
		Data-local map tasks=62
		Rack-local map tasks=72
		Total time spent by all maps in occupied slots (ms)=10318270
		Total time spent by all reduces in occupied slots (ms)=11243178
		Total time spent by all map tasks (ms)=5159135
		Total time spent by all reduce tasks (ms)=5621589
		Total vcore-seconds taken by all map tasks=5159135
		Total vcore-seconds taken by all reduce tasks=5621589
		Total megabyte-seconds taken by all map tasks=41768356960
		Total megabyte-seconds taken by all reduce tasks=67459068000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424227853
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424227853
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =2010
		Failed Shuffles=0
		Merged Map outputs=2010
		GC time elapsed (ms)=212596
		CPU time spent (ms)=13080030
		Physical memory (bytes) snapshot=291907035136
		Virtual memory (bytes) snapshot=1430967435264
		Total committed heap usage (bytes)=402821570560
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/09 15:53:46 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	13m47.901s
user	0m15.703s
sys	0m1.101s
15/04/09 15:53:48 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 15
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-15-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7407491856389733877.jar tmpDir=null
15/04/09 15:53:51 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 15:53:52 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 15:53:52 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 15:53:53 INFO mapreduce.JobSubmitter: number of splits:134
15/04/09 15:53:53 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4362
15/04/09 15:53:54 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4362
15/04/09 15:53:54 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4362/
15/04/09 15:53:54 INFO mapreduce.Job: Running job: job_1422482982071_4362
15/04/09 15:54:00 INFO mapreduce.Job: Job job_1422482982071_4362 running in uber mode : false
15/04/09 15:54:00 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 15:54:11 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 15:54:12 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 15:54:13 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 15:54:14 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 15:54:15 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 15:54:17 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 15:54:18 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 15:54:20 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 15:54:21 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 15:54:22 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 15:54:23 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 15:54:24 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 15:54:25 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 15:54:39 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 15:54:40 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 15:54:41 INFO mapreduce.Job:  map 84% reduce 0%
15/04/09 15:54:42 INFO mapreduce.Job:  map 91% reduce 0%
15/04/09 15:54:43 INFO mapreduce.Job:  map 95% reduce 0%
15/04/09 15:54:44 INFO mapreduce.Job:  map 98% reduce 0%
15/04/09 15:54:45 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 15:54:50 INFO mapreduce.Job:  map 100% reduce 17%
15/04/09 15:54:51 INFO mapreduce.Job:  map 100% reduce 20%
15/04/09 15:55:10 INFO mapreduce.Job:  map 100% reduce 21%
15/04/09 15:55:13 INFO mapreduce.Job:  map 100% reduce 22%
15/04/09 15:55:15 INFO mapreduce.Job:  map 100% reduce 25%
15/04/09 15:55:16 INFO mapreduce.Job:  map 100% reduce 30%
15/04/09 15:55:18 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 15:55:19 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 15:55:21 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 15:55:22 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 15:55:24 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 15:55:25 INFO mapreduce.Job:  map 100% reduce 44%
15/04/09 15:55:26 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 15:55:27 INFO mapreduce.Job:  map 100% reduce 46%
15/04/09 15:55:28 INFO mapreduce.Job:  map 100% reduce 47%
15/04/09 15:55:30 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 15:55:32 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 15:55:34 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 15:55:36 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 15:55:40 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 15:55:43 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 15:55:46 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 15:55:49 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 15:55:51 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 15:55:53 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 15:55:56 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 15:55:59 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 15:56:02 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 15:56:04 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 15:56:10 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 15:56:21 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 15:56:24 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 15:56:28 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 15:56:31 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 15:56:35 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 15:56:38 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 15:56:41 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 15:56:46 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 15:56:52 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 15:57:00 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 15:57:12 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 15:57:14 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 15:57:25 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 15:57:32 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 15:57:37 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 15:57:44 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 15:57:52 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 15:58:01 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 15:58:08 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 15:58:15 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 15:58:23 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 15:58:33 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 15:58:50 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 15:58:59 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 15:59:05 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 15:59:17 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 15:59:38 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 16:00:02 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 16:00:21 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 16:01:26 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 16:02:33 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 16:03:38 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 16:04:00 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 16:04:16 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 16:05:42 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 16:06:36 INFO mapreduce.Job: Job job_1422482982071_4362 completed successfully
15/04/09 16:06:36 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=30424216021
		FILE: Number of bytes written=60862641984
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=447
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Launched map tasks=134
		Launched reduce tasks=15
		Data-local map tasks=62
		Rack-local map tasks=72
		Total time spent by all maps in occupied slots (ms)=10388776
		Total time spent by all reduces in occupied slots (ms)=11077064
		Total time spent by all map tasks (ms)=5194388
		Total time spent by all reduce tasks (ms)=5538532
		Total vcore-seconds taken by all map tasks=5194388
		Total vcore-seconds taken by all reduce tasks=5538532
		Total megabyte-seconds taken by all map tasks=42053765248
		Total megabyte-seconds taken by all reduce tasks=66462384000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424227853
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424227853
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =2010
		Failed Shuffles=0
		Merged Map outputs=2010
		GC time elapsed (ms)=217307
		CPU time spent (ms)=13029800
		Physical memory (bytes) snapshot=291643977728
		Virtual memory (bytes) snapshot=1430935150592
		Total committed heap usage (bytes)=402777493504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/09 16:06:36 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	12m50.332s
user	0m16.713s
sys	0m1.035s
15/04/09 16:06:39 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 15
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-15-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6905586172834990703.jar tmpDir=null
15/04/09 16:06:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 16:06:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 16:06:42 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 16:06:43 INFO mapreduce.JobSubmitter: number of splits:134
15/04/09 16:06:43 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4364
15/04/09 16:06:43 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4364
15/04/09 16:06:44 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4364/
15/04/09 16:06:44 INFO mapreduce.Job: Running job: job_1422482982071_4364
15/04/09 16:06:49 INFO mapreduce.Job: Job job_1422482982071_4364 running in uber mode : false
15/04/09 16:06:49 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 16:07:00 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 16:07:01 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 16:07:03 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 16:07:04 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 16:07:05 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 16:07:06 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 16:07:07 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 16:07:09 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 16:07:10 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 16:07:12 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 16:07:13 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 16:07:14 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 16:07:28 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 16:07:29 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 16:07:30 INFO mapreduce.Job:  map 83% reduce 0%
15/04/09 16:07:31 INFO mapreduce.Job:  map 89% reduce 0%
15/04/09 16:07:32 INFO mapreduce.Job:  map 94% reduce 0%
15/04/09 16:07:33 INFO mapreduce.Job:  map 98% reduce 0%
15/04/09 16:07:34 INFO mapreduce.Job:  map 100% reduce 0%
15/04/09 16:07:39 INFO mapreduce.Job:  map 100% reduce 10%
15/04/09 16:07:40 INFO mapreduce.Job:  map 100% reduce 18%
15/04/09 16:07:41 INFO mapreduce.Job:  map 100% reduce 20%
15/04/09 16:08:00 INFO mapreduce.Job:  map 100% reduce 21%
15/04/09 16:08:01 INFO mapreduce.Job:  map 100% reduce 24%
15/04/09 16:08:03 INFO mapreduce.Job:  map 100% reduce 27%
15/04/09 16:08:04 INFO mapreduce.Job:  map 100% reduce 29%
15/04/09 16:08:05 INFO mapreduce.Job:  map 100% reduce 30%
15/04/09 16:08:06 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 16:08:07 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 16:08:09 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 16:08:10 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 16:08:11 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 16:08:12 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 16:08:13 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 16:08:14 INFO mapreduce.Job:  map 100% reduce 46%
15/04/09 16:08:16 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 16:08:20 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 16:08:21 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 16:08:23 INFO mapreduce.Job:  map 100% reduce 51%
15/04/09 16:08:26 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 16:08:29 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 16:08:32 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 16:08:34 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 16:08:35 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 16:08:40 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 16:08:41 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 16:08:46 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 16:08:49 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 16:08:50 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 16:08:53 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 16:08:58 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 16:09:06 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 16:09:14 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 16:09:17 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 16:09:23 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 16:09:26 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 16:09:33 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 16:09:36 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 16:09:39 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 16:09:46 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 16:09:56 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 16:10:02 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 16:10:10 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 16:10:20 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 16:10:21 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 16:10:30 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 16:10:36 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 16:10:43 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 16:10:54 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 16:11:02 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 16:11:07 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 16:11:16 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 16:11:28 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 16:11:42 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 16:11:55 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 16:12:05 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 16:12:18 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 16:12:44 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 16:13:08 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 16:14:19 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 16:15:33 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 16:16:05 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 16:18:04 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 16:19:29 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 16:20:58 INFO mapreduce.Job: Job job_1422482982071_4364 completed successfully
15/04/09 16:20:58 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=30424216021
		FILE: Number of bytes written=60862641984
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=447
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Launched map tasks=134
		Launched reduce tasks=15
		Data-local map tasks=64
		Rack-local map tasks=70
		Total time spent by all maps in occupied slots (ms)=10394280
		Total time spent by all reduces in occupied slots (ms)=11107778
		Total time spent by all map tasks (ms)=5197140
		Total time spent by all reduce tasks (ms)=5553889
		Total vcore-seconds taken by all map tasks=5197140
		Total vcore-seconds taken by all reduce tasks=5553889
		Total megabyte-seconds taken by all map tasks=42076045440
		Total megabyte-seconds taken by all reduce tasks=66646668000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424227853
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424227853
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =2010
		Failed Shuffles=0
		Merged Map outputs=2010
		GC time elapsed (ms)=205577
		CPU time spent (ms)=13042250
		Physical memory (bytes) snapshot=291658383360
		Virtual memory (bytes) snapshot=1429974831104
		Total committed heap usage (bytes)=402741170176
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/09 16:20:58 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	14m22.290s
user	0m16.191s
sys	0m1.127s
15/04/09 16:21:01 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 35
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-35-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5857658937299666052.jar tmpDir=null
15/04/09 16:21:04 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 16:21:04 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 16:21:04 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 16:21:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 16:21:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 16:21:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 16:21:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 16:21:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 16:21:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 16:21:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 16:21:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 16:21:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 16:21:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 16:21:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 16:21:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 16:21:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 16:21:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 16:21:05 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 16:21:05 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 16:21:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4365
15/04/09 16:21:06 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4365
15/04/09 16:21:06 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4365/
15/04/09 16:21:06 INFO mapreduce.Job: Running job: job_1422482982071_4365
15/04/09 16:21:12 INFO mapreduce.Job: Job job_1422482982071_4365 running in uber mode : false
15/04/09 16:21:12 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 16:21:18 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 16:21:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4365_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 16:21:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4365_m_000017_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 16:21:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4365_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 16:21:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4365_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 16:21:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4365_m_000021_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 16:21:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4365_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 16:21:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4365_m_000045_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 16:21:19 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 16:21:22 INFO mapreduce.Job: Task Id : attempt_1422482982071_4365_m_000016_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 16:21:24 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 16:21:30 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 16:21:35 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 16:21:40 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 16:21:46 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 16:21:52 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 16:21:58 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 16:22:04 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 16:22:10 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 16:22:15 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 16:22:20 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 16:22:26 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 16:22:33 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 16:22:39 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 16:22:44 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 16:22:50 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 16:22:55 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 16:23:00 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 16:23:06 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 16:23:12 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 16:23:18 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 16:23:24 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 16:23:30 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 16:23:36 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 16:23:42 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 16:23:48 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 16:23:54 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 16:24:00 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 16:24:06 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 16:24:12 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 16:24:18 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 16:24:24 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 16:24:30 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 16:24:36 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 16:24:42 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 16:24:48 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 16:24:54 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 16:25:00 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 16:25:06 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 16:25:11 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 16:25:17 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 16:25:22 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 16:25:28 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 16:25:35 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 16:25:41 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 16:25:46 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 16:25:52 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 16:25:58 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 16:26:04 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 16:26:10 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 16:26:15 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 16:26:20 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 16:26:26 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 16:26:32 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 16:26:38 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 16:26:44 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 16:26:50 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 16:26:55 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 16:27:01 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 16:27:06 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 16:27:12 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 16:27:17 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 16:27:23 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 16:27:29 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 16:27:35 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 16:27:43 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 16:27:45 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 16:27:47 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 16:27:50 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 16:27:51 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 16:27:52 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 16:27:53 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 16:27:54 INFO mapreduce.Job:  map 76% reduce 0%
15/04/09 16:27:55 INFO mapreduce.Job:  map 77% reduce 1%
15/04/09 16:27:56 INFO mapreduce.Job:  map 77% reduce 8%
15/04/09 16:27:57 INFO mapreduce.Job:  map 79% reduce 10%
15/04/09 16:27:58 INFO mapreduce.Job:  map 80% reduce 11%
15/04/09 16:27:59 INFO mapreduce.Job:  map 82% reduce 13%
15/04/09 16:28:00 INFO mapreduce.Job:  map 82% reduce 14%
15/04/09 16:28:01 INFO mapreduce.Job:  map 83% reduce 14%
15/04/09 16:28:02 INFO mapreduce.Job:  map 86% reduce 17%
15/04/09 16:28:03 INFO mapreduce.Job:  map 88% reduce 18%
15/04/09 16:28:04 INFO mapreduce.Job:  map 90% reduce 18%
15/04/09 16:28:05 INFO mapreduce.Job:  map 90% reduce 22%
15/04/09 16:28:06 INFO mapreduce.Job:  map 90% reduce 24%
15/04/09 16:28:07 INFO mapreduce.Job:  map 91% reduce 24%
15/04/09 16:28:08 INFO mapreduce.Job:  map 92% reduce 25%
15/04/09 16:28:09 INFO mapreduce.Job:  map 94% reduce 26%
15/04/09 16:28:11 INFO mapreduce.Job:  map 94% reduce 27%
15/04/09 16:28:12 INFO mapreduce.Job:  map 95% reduce 27%
15/04/09 16:28:14 INFO mapreduce.Job:  map 96% reduce 28%
15/04/09 16:28:15 INFO mapreduce.Job:  map 97% reduce 29%
15/04/09 16:28:17 INFO mapreduce.Job:  map 98% reduce 30%
15/04/09 16:28:18 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 16:28:20 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 16:28:21 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 16:28:53 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 16:29:00 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 16:29:01 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 16:29:02 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 16:29:03 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 16:29:04 INFO mapreduce.Job:  map 100% reduce 44%
15/04/09 16:29:05 INFO mapreduce.Job:  map 100% reduce 51%
15/04/09 16:29:06 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 16:29:07 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 16:29:08 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 16:29:09 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 16:29:10 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 16:29:11 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 16:29:13 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 16:29:16 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 16:29:22 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 16:29:37 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 16:30:01 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 16:30:26 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 16:30:47 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 16:31:10 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 16:31:32 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 16:31:58 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 16:32:13 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 16:32:35 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 16:32:53 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 16:33:09 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 16:33:25 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 16:33:53 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 16:34:18 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 16:34:43 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 16:34:49 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 16:35:07 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 16:35:22 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 16:35:41 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 16:36:02 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 16:36:16 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 16:36:43 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 16:37:07 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 16:37:35 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 16:38:21 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 16:38:59 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 16:40:00 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 16:41:39 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 16:43:34 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 16:46:36 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 16:52:34 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 16:54:54 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 17:14:49 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 17:21:36 INFO mapreduce.Job: Job job_1422482982071_4365 completed successfully
15/04/09 17:21:36 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210428
		FILE: Number of bytes written=20772542876
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Failed map tasks=8
		Killed reduce tasks=2
		Launched map tasks=58
		Launched reduce tasks=37
		Other local map tasks=8
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=40774436
		Total time spent by all reduces in occupied slots (ms)=63691778
		Total time spent by all map tasks (ms)=20387218
		Total time spent by all reduce tasks (ms)=31845889
		Total vcore-seconds taken by all map tasks=20387218
		Total vcore-seconds taken by all reduce tasks=31845889
		Total megabyte-seconds taken by all map tasks=165054916928
		Total megabyte-seconds taken by all reduce tasks=382150668000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382220718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382220718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1750
		Failed Shuffles=0
		Merged Map outputs=1750
		GC time elapsed (ms)=152742
		CPU time spent (ms)=56419150
		Physical memory (bytes) snapshot=114748547072
		Virtual memory (bytes) snapshot=927220064256
		Total committed heap usage (bytes)=212164284416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 17:21:36 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	60m37.919s
user	0m26.878s
sys	0m2.797s
15/04/09 17:21:39 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 35
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-35-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6192491024438914441.jar tmpDir=null
15/04/09 17:21:41 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 17:21:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 17:21:43 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 17:21:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 17:21:43 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 17:21:43 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4372
15/04/09 17:21:44 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4372
15/04/09 17:21:44 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4372/
15/04/09 17:21:44 INFO mapreduce.Job: Running job: job_1422482982071_4372
15/04/09 17:21:50 INFO mapreduce.Job: Job job_1422482982071_4372 running in uber mode : false
15/04/09 17:21:50 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 17:21:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4372_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:21:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4372_m_000017_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:21:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4372_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:21:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4372_m_000037_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:21:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4372_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:21:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4372_m_000046_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:21:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4372_m_000030_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:21:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4372_m_000004_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:21:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4372_m_000016_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:22:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4372_m_000046_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:22:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4372_m_000016_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:22:02 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 17:22:07 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 17:22:13 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 17:22:19 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 17:22:25 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 17:22:31 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 17:22:37 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 17:22:42 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 17:22:48 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 17:22:54 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 17:23:00 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 17:23:05 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 17:23:11 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 17:23:16 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 17:23:22 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 17:23:29 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 17:23:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4372_m_000017_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:23:37 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 17:23:43 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 17:23:49 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 17:23:55 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 17:24:01 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 17:24:07 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 17:24:13 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 17:24:19 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 17:24:26 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 17:24:32 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 17:24:38 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 17:24:44 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 17:24:50 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 17:24:57 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 17:25:03 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 17:25:09 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 17:25:15 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 17:25:20 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 17:25:26 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 17:25:32 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 17:25:38 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 17:25:44 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 17:25:49 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 17:25:55 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 17:26:00 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 17:26:06 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 17:26:12 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 17:26:18 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 17:26:24 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 17:26:29 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 17:26:35 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 17:26:41 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 17:26:47 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 17:26:52 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 17:26:58 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 17:27:03 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 17:27:09 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 17:27:15 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 17:27:21 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 17:27:27 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 17:27:33 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 17:27:39 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 17:27:45 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 17:27:51 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 17:27:56 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 17:28:02 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 17:28:08 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 17:28:13 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 17:28:19 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 17:28:28 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 17:28:30 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 17:28:31 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 17:28:32 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 17:28:34 INFO mapreduce.Job:  map 73% reduce 0%
15/04/09 17:28:35 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 17:28:37 INFO mapreduce.Job:  map 77% reduce 0%
15/04/09 17:28:38 INFO mapreduce.Job:  map 78% reduce 0%
15/04/09 17:28:39 INFO mapreduce.Job:  map 79% reduce 0%
15/04/09 17:28:40 INFO mapreduce.Job:  map 81% reduce 0%
15/04/09 17:28:41 INFO mapreduce.Job:  map 81% reduce 10%
15/04/09 17:28:42 INFO mapreduce.Job:  map 82% reduce 14%
15/04/09 17:28:43 INFO mapreduce.Job:  map 83% reduce 14%
15/04/09 17:28:44 INFO mapreduce.Job:  map 85% reduce 16%
15/04/09 17:28:45 INFO mapreduce.Job:  map 88% reduce 18%
15/04/09 17:28:46 INFO mapreduce.Job:  map 90% reduce 18%
15/04/09 17:28:47 INFO mapreduce.Job:  map 91% reduce 22%
15/04/09 17:28:48 INFO mapreduce.Job:  map 91% reduce 24%
15/04/09 17:28:49 INFO mapreduce.Job:  map 93% reduce 25%
15/04/09 17:28:50 INFO mapreduce.Job:  map 94% reduce 26%
15/04/09 17:28:51 INFO mapreduce.Job:  map 94% reduce 28%
15/04/09 17:28:56 INFO mapreduce.Job:  map 95% reduce 28%
15/04/09 17:28:57 INFO mapreduce.Job:  map 95% reduce 29%
15/04/09 17:29:04 INFO mapreduce.Job:  map 96% reduce 29%
15/04/09 17:29:15 INFO mapreduce.Job:  map 97% reduce 29%
15/04/09 17:29:17 INFO mapreduce.Job:  map 97% reduce 30%
15/04/09 17:29:20 INFO mapreduce.Job:  map 98% reduce 30%
15/04/09 17:29:21 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 17:29:25 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 17:29:27 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 17:29:31 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 17:29:55 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 17:29:58 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 17:29:59 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 17:30:00 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 17:30:01 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 17:30:02 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 17:30:03 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 17:30:04 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 17:30:05 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 17:30:06 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 17:30:08 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 17:30:10 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 17:30:12 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 17:30:18 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 17:30:36 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 17:30:59 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 17:31:24 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 17:31:45 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 17:32:11 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 17:32:31 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 17:32:59 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 17:33:17 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 17:33:39 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 17:33:56 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 17:34:17 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 17:34:29 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 17:34:56 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 17:35:23 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 17:35:45 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 17:35:59 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 17:36:15 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 17:36:31 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 17:36:46 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 17:37:07 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 17:37:26 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 17:37:40 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 17:38:17 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 17:38:43 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 17:39:22 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 17:40:14 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 17:41:23 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 17:42:37 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 17:45:11 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 17:47:41 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 17:54:35 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 17:56:49 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 18:15:18 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 18:22:23 INFO mapreduce.Job: Job job_1422482982071_4372 completed successfully
15/04/09 18:22:23 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210428
		FILE: Number of bytes written=20772542876
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Failed map tasks=12
		Killed reduce tasks=2
		Launched map tasks=62
		Launched reduce tasks=37
		Other local map tasks=12
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=41363368
		Total time spent by all reduces in occupied slots (ms)=65307102
		Total time spent by all map tasks (ms)=20681684
		Total time spent by all reduce tasks (ms)=32653551
		Total vcore-seconds taken by all map tasks=20681684
		Total vcore-seconds taken by all reduce tasks=32653551
		Total megabyte-seconds taken by all map tasks=167438913664
		Total megabyte-seconds taken by all reduce tasks=391842612000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382220718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382220718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1750
		Failed Shuffles=0
		Merged Map outputs=1750
		GC time elapsed (ms)=135613
		CPU time spent (ms)=57084410
		Physical memory (bytes) snapshot=115191558144
		Virtual memory (bytes) snapshot=926827016192
		Total committed heap usage (bytes)=212164231168
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 18:22:23 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	60m46.564s
user	0m27.324s
sys	0m2.842s
15/04/09 18:22:25 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 35
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-35-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2799512240574126184.jar tmpDir=null
15/04/09 18:22:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 18:22:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 18:22:28 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 18:22:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 18:22:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 18:22:29 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 18:22:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4384
15/04/09 18:22:30 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4384
15/04/09 18:22:30 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4384/
15/04/09 18:22:30 INFO mapreduce.Job: Running job: job_1422482982071_4384
15/04/09 18:22:35 INFO mapreduce.Job: Job job_1422482982071_4384 running in uber mode : false
15/04/09 18:22:35 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 18:22:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4384_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 18:22:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4384_m_000022_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 18:22:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4384_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 18:22:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4384_m_000025_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 18:22:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4384_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 18:22:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4384_m_000012_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 18:22:45 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 18:22:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4384_m_000025_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 18:22:51 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 18:22:57 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 18:23:03 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 18:23:08 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 18:23:14 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 18:23:20 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 18:23:26 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 18:23:32 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 18:23:38 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 18:23:43 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 18:23:49 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 18:23:54 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 18:24:00 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 18:24:06 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 18:24:11 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 18:24:17 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 18:24:23 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 18:24:29 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 18:24:34 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 18:24:40 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 18:24:45 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 18:24:51 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 18:24:57 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 18:25:02 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 18:25:08 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 18:25:14 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 18:25:20 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 18:25:25 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 18:25:31 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 18:25:37 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 18:25:43 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 18:25:49 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 18:25:56 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 18:26:02 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 18:26:08 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 18:26:14 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 18:26:20 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 18:26:26 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 18:26:32 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 18:26:38 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 18:26:44 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 18:26:49 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 18:26:55 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 18:27:01 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 18:27:07 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 18:27:13 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 18:27:19 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 18:27:25 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 18:27:31 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 18:27:37 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 18:27:43 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 18:27:48 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 18:27:54 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 18:28:00 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 18:28:06 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 18:28:12 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 18:28:18 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 18:28:24 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 18:28:29 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 18:28:35 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 18:28:42 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 18:28:47 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 18:28:53 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 18:28:59 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 18:29:06 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 18:29:09 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 18:29:11 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 18:29:13 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 18:29:14 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 18:29:15 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 18:29:16 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 18:29:17 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 18:29:19 INFO mapreduce.Job:  map 76% reduce 0%
15/04/09 18:29:20 INFO mapreduce.Job:  map 78% reduce 0%
15/04/09 18:29:22 INFO mapreduce.Job:  map 80% reduce 9%
15/04/09 18:29:23 INFO mapreduce.Job:  map 80% reduce 12%
15/04/09 18:29:24 INFO mapreduce.Job:  map 82% reduce 12%
15/04/09 18:29:25 INFO mapreduce.Job:  map 84% reduce 15%
15/04/09 18:29:26 INFO mapreduce.Job:  map 87% reduce 17%
15/04/09 18:29:27 INFO mapreduce.Job:  map 89% reduce 17%
15/04/09 18:29:28 INFO mapreduce.Job:  map 90% reduce 21%
15/04/09 18:29:29 INFO mapreduce.Job:  map 90% reduce 23%
15/04/09 18:29:30 INFO mapreduce.Job:  map 91% reduce 23%
15/04/09 18:29:31 INFO mapreduce.Job:  map 91% reduce 24%
15/04/09 18:29:32 INFO mapreduce.Job:  map 92% reduce 25%
15/04/09 18:29:34 INFO mapreduce.Job:  map 94% reduce 25%
15/04/09 18:29:35 INFO mapreduce.Job:  map 95% reduce 27%
15/04/09 18:29:36 INFO mapreduce.Job:  map 96% reduce 27%
15/04/09 18:29:37 INFO mapreduce.Job:  map 96% reduce 28%
15/04/09 18:29:38 INFO mapreduce.Job:  map 96% reduce 29%
15/04/09 18:29:40 INFO mapreduce.Job:  map 97% reduce 29%
15/04/09 18:29:41 INFO mapreduce.Job:  map 97% reduce 30%
15/04/09 18:29:44 INFO mapreduce.Job:  map 97% reduce 31%
15/04/09 18:29:46 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 18:29:51 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 18:29:53 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 18:30:17 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 18:30:19 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 18:30:21 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 18:30:22 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 18:30:23 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 18:30:24 INFO mapreduce.Job:  map 100% reduce 51%
15/04/09 18:30:25 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 18:30:26 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 18:30:27 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 18:30:29 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 18:30:30 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 18:30:33 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 18:30:36 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 18:30:42 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 18:30:57 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 18:31:22 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 18:31:49 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 18:32:13 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 18:32:40 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 18:33:07 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 18:33:35 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 18:33:50 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 18:34:11 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 18:34:26 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 18:34:46 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 18:35:03 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 18:35:32 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 18:35:52 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 18:36:16 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 18:36:24 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 18:36:47 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 18:37:06 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 18:37:14 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 18:37:34 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 18:37:49 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 18:38:15 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 18:38:39 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 18:39:01 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 18:39:46 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 18:40:20 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 18:41:23 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 18:42:43 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 18:45:09 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 18:48:07 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 18:55:58 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 18:56:00 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 19:15:54 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 19:22:39 INFO mapreduce.Job: Job job_1422482982071_4384 completed successfully
15/04/09 19:22:39 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210428
		FILE: Number of bytes written=20772542876
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Failed map tasks=7
		Killed reduce tasks=2
		Launched map tasks=57
		Launched reduce tasks=37
		Other local map tasks=7
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=40923614
		Total time spent by all reduces in occupied slots (ms)=63778632
		Total time spent by all map tasks (ms)=20461807
		Total time spent by all reduce tasks (ms)=31889316
		Total vcore-seconds taken by all map tasks=20461807
		Total vcore-seconds taken by all reduce tasks=31889316
		Total megabyte-seconds taken by all map tasks=165658789472
		Total megabyte-seconds taken by all reduce tasks=382671792000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382220718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382220718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1750
		Failed Shuffles=0
		Merged Map outputs=1750
		GC time elapsed (ms)=153109
		CPU time spent (ms)=56911300
		Physical memory (bytes) snapshot=115196174336
		Virtual memory (bytes) snapshot=926634127360
		Total committed heap usage (bytes)=212163149824
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 19:22:39 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	60m16.091s
user	0m26.368s
sys	0m2.861s
15/04/09 19:22:42 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 25
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-25-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4483528166784626951.jar tmpDir=null
15/04/09 19:22:45 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 19:22:45 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 19:22:45 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 19:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 19:22:46 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 19:22:46 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4388
15/04/09 19:22:47 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4388
15/04/09 19:22:47 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4388/
15/04/09 19:22:47 INFO mapreduce.Job: Running job: job_1422482982071_4388
15/04/09 19:22:53 INFO mapreduce.Job: Job job_1422482982071_4388 running in uber mode : false
15/04/09 19:22:53 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 19:22:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:22:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:22:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:22:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000025_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:22:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000024_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:22:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000049_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:22:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000047_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:22:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000046_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:22:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000023_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:22:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:22:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000020_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:22:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000008_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:22:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000027_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:23:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000038_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/09 19:23:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:23:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000020_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:23:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4388_m_000027_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:23:05 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 19:23:11 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 19:23:17 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 19:23:23 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 19:23:28 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 19:23:34 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 19:23:39 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 19:23:45 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 19:23:52 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 19:23:58 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 19:24:05 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 19:24:12 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 19:24:18 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 19:24:24 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 19:24:30 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 19:24:36 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 19:24:42 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 19:24:49 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 19:24:55 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 19:25:01 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 19:25:07 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 19:25:13 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 19:25:19 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 19:25:25 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 19:25:31 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 19:25:37 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 19:25:43 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 19:25:50 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 19:25:56 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 19:26:02 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 19:26:08 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 19:26:15 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 19:26:21 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 19:26:27 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 19:26:33 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 19:26:39 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 19:26:45 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 19:26:52 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 19:26:58 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 19:27:05 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 19:27:11 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 19:27:17 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 19:27:23 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 19:27:29 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 19:27:35 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 19:27:41 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 19:27:47 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 19:27:54 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 19:28:00 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 19:28:06 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 19:28:12 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 19:28:19 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 19:28:25 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 19:28:31 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 19:28:37 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 19:28:43 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 19:28:50 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 19:28:56 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 19:29:02 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 19:29:08 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 19:29:14 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 19:29:22 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 19:29:24 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 19:29:27 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 19:29:28 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 19:29:29 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 19:29:31 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 19:29:32 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 19:29:35 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 19:29:37 INFO mapreduce.Job:  map 72% reduce 4%
15/04/09 19:29:38 INFO mapreduce.Job:  map 73% reduce 9%
15/04/09 19:29:39 INFO mapreduce.Job:  map 74% reduce 9%
15/04/09 19:29:40 INFO mapreduce.Job:  map 75% reduce 10%
15/04/09 19:29:41 INFO mapreduce.Job:  map 75% reduce 11%
15/04/09 19:29:43 INFO mapreduce.Job:  map 75% reduce 12%
15/04/09 19:29:44 INFO mapreduce.Job:  map 76% reduce 12%
15/04/09 19:29:47 INFO mapreduce.Job:  map 77% reduce 13%
15/04/09 19:29:51 INFO mapreduce.Job:  map 78% reduce 13%
15/04/09 19:29:55 INFO mapreduce.Job:  map 79% reduce 14%
15/04/09 19:30:07 INFO mapreduce.Job:  map 80% reduce 14%
15/04/09 19:30:14 INFO mapreduce.Job:  map 81% reduce 14%
15/04/09 19:30:17 INFO mapreduce.Job:  map 81% reduce 15%
15/04/09 19:30:18 INFO mapreduce.Job:  map 82% reduce 15%
15/04/09 19:30:19 INFO mapreduce.Job:  map 83% reduce 15%
15/04/09 19:30:20 INFO mapreduce.Job:  map 84% reduce 16%
15/04/09 19:30:21 INFO mapreduce.Job:  map 86% reduce 18%
15/04/09 19:30:22 INFO mapreduce.Job:  map 87% reduce 18%
15/04/09 19:30:24 INFO mapreduce.Job:  map 88% reduce 20%
15/04/09 19:30:25 INFO mapreduce.Job:  map 88% reduce 21%
15/04/09 19:30:27 INFO mapreduce.Job:  map 89% reduce 22%
15/04/09 19:30:28 INFO mapreduce.Job:  map 90% reduce 22%
15/04/09 19:30:30 INFO mapreduce.Job:  map 90% reduce 23%
15/04/09 19:30:34 INFO mapreduce.Job:  map 91% reduce 23%
15/04/09 19:30:36 INFO mapreduce.Job:  map 91% reduce 24%
15/04/09 19:30:37 INFO mapreduce.Job:  map 92% reduce 24%
15/04/09 19:30:38 INFO mapreduce.Job:  map 92% reduce 25%
15/04/09 19:30:47 INFO mapreduce.Job:  map 93% reduce 25%
15/04/09 19:30:48 INFO mapreduce.Job:  map 93% reduce 26%
15/04/09 19:30:49 INFO mapreduce.Job:  map 94% reduce 26%
15/04/09 19:30:50 INFO mapreduce.Job:  map 95% reduce 26%
15/04/09 19:30:51 INFO mapreduce.Job:  map 95% reduce 27%
15/04/09 19:30:52 INFO mapreduce.Job:  map 95% reduce 28%
15/04/09 19:30:53 INFO mapreduce.Job:  map 96% reduce 28%
15/04/09 19:30:54 INFO mapreduce.Job:  map 96% reduce 29%
15/04/09 19:30:55 INFO mapreduce.Job:  map 97% reduce 29%
15/04/09 19:30:56 INFO mapreduce.Job:  map 97% reduce 30%
15/04/09 19:30:58 INFO mapreduce.Job:  map 99% reduce 30%
15/04/09 19:30:59 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 19:31:01 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 19:31:02 INFO mapreduce.Job:  map 100% reduce 32%
15/04/09 19:31:03 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 19:31:04 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 19:31:05 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 19:31:06 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 19:31:07 INFO mapreduce.Job:  map 100% reduce 44%
15/04/09 19:31:08 INFO mapreduce.Job:  map 100% reduce 47%
15/04/09 19:31:09 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 19:31:10 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 19:31:11 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 19:31:12 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 19:31:13 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 19:31:14 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 19:31:15 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 19:31:16 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 19:31:19 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 19:31:26 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 19:31:38 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 19:31:57 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 19:32:37 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 19:33:17 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 19:33:58 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 19:34:23 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 19:34:52 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 19:35:27 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 19:36:14 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 19:36:48 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 19:37:12 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 19:37:45 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 19:38:09 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 19:38:27 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 19:38:42 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 19:39:11 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 19:39:36 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 19:40:08 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 19:40:47 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 19:41:34 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 19:42:19 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 19:42:48 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 19:43:44 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 19:45:46 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 19:46:32 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 19:46:50 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 19:47:14 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 19:48:07 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 19:48:17 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 19:49:44 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 19:52:55 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 19:58:17 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 20:01:46 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 20:16:09 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 20:28:31 INFO mapreduce.Job: Job job_1422482982071_4388 completed successfully
15/04/09 20:28:31 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210368
		FILE: Number of bytes written=20771578616
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=225
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Failed map tasks=17
		Killed reduce tasks=1
		Launched map tasks=67
		Launched reduce tasks=26
		Other local map tasks=17
		Data-local map tasks=30
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=43421022
		Total time spent by all reduces in occupied slots (ms)=62587462
		Total time spent by all map tasks (ms)=21710511
		Total time spent by all reduce tasks (ms)=31293731
		Total vcore-seconds taken by all map tasks=21710511
		Total vcore-seconds taken by all reduce tasks=31293731
		Total megabyte-seconds taken by all map tasks=175768297056
		Total megabyte-seconds taken by all reduce tasks=375524772000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382217718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382217718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1250
		Failed Shuffles=0
		Merged Map outputs=1250
		GC time elapsed (ms)=125028
		CPU time spent (ms)=58327960
		Physical memory (bytes) snapshot=112713543680
		Virtual memory (bytes) snapshot=793391599616
		Total committed heap usage (bytes)=191112589312
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 20:28:31 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	65m52.391s
user	0m26.853s
sys	0m3.027s
15/04/09 20:28:33 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 25
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-25-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5344097177975172864.jar tmpDir=null
15/04/09 20:28:36 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 20:28:36 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 20:28:37 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 20:28:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 20:28:37 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 20:28:37 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4392
15/04/09 20:28:38 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4392
15/04/09 20:28:38 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4392/
15/04/09 20:28:38 INFO mapreduce.Job: Running job: job_1422482982071_4392
15/04/09 20:28:43 INFO mapreduce.Job: Job job_1422482982071_4392 running in uber mode : false
15/04/09 20:28:43 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 20:28:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4392_m_000039_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 20:28:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4392_m_000021_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 20:28:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4392_m_000031_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 20:28:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4392_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 20:28:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4392_m_000015_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 20:28:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4392_m_000045_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 20:28:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4392_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 20:28:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4392_m_000025_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 20:28:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4392_m_000044_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 20:28:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4392_m_000022_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 20:28:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4392_m_000017_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 20:28:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4392_m_000045_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 20:28:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4392_m_000015_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 20:28:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4392_m_000044_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 20:28:55 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 20:29:01 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 20:29:07 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 20:29:14 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 20:29:19 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 20:29:24 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 20:29:30 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 20:29:36 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 20:29:42 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 20:29:48 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 20:29:53 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 20:29:59 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 20:30:04 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 20:30:10 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 20:30:16 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 20:30:22 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 20:30:28 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 20:30:33 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 20:30:39 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 20:30:45 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 20:30:50 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 20:30:55 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 20:31:01 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 20:31:07 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 20:31:13 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 20:31:19 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 20:31:25 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 20:31:30 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 20:31:36 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 20:31:41 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 20:31:47 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 20:31:53 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 20:32:00 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 20:32:05 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 20:32:11 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 20:32:17 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 20:32:23 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 20:32:29 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 20:32:34 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 20:32:40 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 20:32:45 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 20:32:51 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 20:32:57 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 20:33:03 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 20:33:08 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 20:33:14 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 20:33:20 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 20:33:26 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 20:33:31 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 20:33:37 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 20:33:43 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 20:33:49 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 20:33:54 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 20:34:00 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 20:34:06 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 20:34:11 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 20:34:17 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 20:34:23 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 20:34:29 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 20:34:34 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 20:34:40 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 20:34:46 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 20:34:52 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 20:34:57 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 20:35:04 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 20:35:07 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 20:35:13 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 20:35:14 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 20:35:15 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 20:35:16 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 20:35:18 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 20:35:20 INFO mapreduce.Job:  map 73% reduce 0%
15/04/09 20:35:21 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 20:35:22 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 20:35:24 INFO mapreduce.Job:  map 77% reduce 8%
15/04/09 20:35:25 INFO mapreduce.Job:  map 81% reduce 10%
15/04/09 20:35:27 INFO mapreduce.Job:  map 81% reduce 13%
15/04/09 20:35:28 INFO mapreduce.Job:  map 85% reduce 15%
15/04/09 20:35:30 INFO mapreduce.Job:  map 85% reduce 18%
15/04/09 20:35:31 INFO mapreduce.Job:  map 86% reduce 19%
15/04/09 20:35:32 INFO mapreduce.Job:  map 87% reduce 19%
15/04/09 20:35:33 INFO mapreduce.Job:  map 90% reduce 21%
15/04/09 20:35:34 INFO mapreduce.Job:  map 90% reduce 23%
15/04/09 20:35:36 INFO mapreduce.Job:  map 92% reduce 24%
15/04/09 20:35:37 INFO mapreduce.Job:  map 93% reduce 25%
15/04/09 20:35:39 INFO mapreduce.Job:  map 95% reduce 26%
15/04/09 20:35:40 INFO mapreduce.Job:  map 95% reduce 28%
15/04/09 20:35:41 INFO mapreduce.Job:  map 96% reduce 28%
15/04/09 20:35:42 INFO mapreduce.Job:  map 96% reduce 29%
15/04/09 20:35:45 INFO mapreduce.Job:  map 96% reduce 30%
15/04/09 20:35:56 INFO mapreduce.Job:  map 97% reduce 30%
15/04/09 20:36:08 INFO mapreduce.Job:  map 97% reduce 31%
15/04/09 20:36:13 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 20:36:21 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 20:36:22 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 20:36:28 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 20:36:34 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 20:36:37 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 20:36:38 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 20:36:39 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 20:36:40 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 20:36:41 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 20:36:42 INFO mapreduce.Job:  map 100% reduce 51%
15/04/09 20:36:43 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 20:36:44 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 20:36:45 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 20:36:46 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 20:36:47 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 20:36:50 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 20:36:52 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 20:36:59 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 20:37:12 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 20:37:28 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 20:38:11 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 20:38:49 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 20:39:26 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 20:39:58 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 20:40:23 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 20:40:56 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 20:41:48 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 20:42:07 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 20:42:49 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 20:43:12 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 20:43:39 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 20:43:54 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 20:44:14 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 20:44:42 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 20:45:01 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 20:45:30 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 20:46:21 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 20:46:39 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 20:47:14 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 20:48:09 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 20:49:07 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 20:51:05 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 20:51:28 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 20:52:05 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 20:53:12 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 20:53:49 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 20:54:46 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 20:54:51 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 20:58:40 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 21:04:00 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 21:07:32 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 21:21:32 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 21:33:53 INFO mapreduce.Job: Job job_1422482982071_4392 completed successfully
15/04/09 21:33:53 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210368
		FILE: Number of bytes written=20771578616
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=225
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Failed map tasks=14
		Killed reduce tasks=1
		Launched map tasks=64
		Launched reduce tasks=26
		Other local map tasks=14
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=40524422
		Total time spent by all reduces in occupied slots (ms)=61769164
		Total time spent by all map tasks (ms)=20262211
		Total time spent by all reduce tasks (ms)=30884582
		Total vcore-seconds taken by all map tasks=20262211
		Total vcore-seconds taken by all reduce tasks=30884582
		Total megabyte-seconds taken by all map tasks=164042860256
		Total megabyte-seconds taken by all reduce tasks=370614984000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382217718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382217718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1250
		Failed Shuffles=0
		Merged Map outputs=1250
		GC time elapsed (ms)=141397
		CPU time spent (ms)=56541910
		Physical memory (bytes) snapshot=112993972224
		Virtual memory (bytes) snapshot=793001959424
		Total committed heap usage (bytes)=191112265728
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 21:33:53 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	65m21.911s
user	0m26.803s
sys	0m2.907s
15/04/09 21:33:56 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 25
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-25-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3284807899537935628.jar tmpDir=null
15/04/09 21:33:59 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 21:33:59 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 21:34:00 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 21:34:00 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 21:34:00 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 21:34:01 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4396
15/04/09 21:34:01 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4396
15/04/09 21:34:01 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4396/
15/04/09 21:34:01 INFO mapreduce.Job: Running job: job_1422482982071_4396
15/04/09 21:34:07 INFO mapreduce.Job: Job job_1422482982071_4396 running in uber mode : false
15/04/09 21:34:07 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 21:34:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4396_m_000009_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 21:34:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4396_m_000034_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 21:34:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4396_m_000042_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 21:34:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4396_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 21:34:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4396_m_000039_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 21:34:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4396_m_000011_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 21:34:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4396_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 21:34:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4396_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 21:34:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4396_m_000042_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 21:34:20 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 21:34:26 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 21:34:31 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 21:34:36 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 21:34:42 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 21:34:48 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 21:34:54 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 21:34:59 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 21:35:05 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 21:35:10 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 21:35:16 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 21:35:21 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 21:35:27 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 21:35:33 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 21:35:39 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 21:35:44 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 21:35:50 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 21:35:55 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 21:36:01 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 21:36:07 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 21:36:13 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 21:36:19 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 21:36:24 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 21:36:29 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 21:36:35 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 21:36:40 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 21:36:46 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 21:36:52 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 21:36:59 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 21:37:05 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 21:37:11 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 21:37:16 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 21:37:21 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 21:37:27 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 21:37:33 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 21:37:39 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 21:37:44 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 21:37:50 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 21:37:56 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 21:38:01 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 21:38:07 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 21:38:12 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 21:38:18 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 21:38:24 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 21:38:30 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 21:38:36 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 21:38:41 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 21:38:47 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 21:38:52 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 21:38:58 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 21:39:04 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 21:39:09 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 21:39:15 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 21:39:21 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 21:39:27 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 21:39:32 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 21:39:38 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 21:39:43 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 21:39:49 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 21:39:55 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 21:40:01 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 21:40:07 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 21:40:13 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 21:40:19 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 21:40:25 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 21:40:32 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 21:40:34 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 21:40:37 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 21:40:38 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 21:40:40 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 21:40:42 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 21:40:44 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 21:40:45 INFO mapreduce.Job:  map 76% reduce 0%
15/04/09 21:40:47 INFO mapreduce.Job:  map 78% reduce 2%
15/04/09 21:40:48 INFO mapreduce.Job:  map 79% reduce 9%
15/04/09 21:40:49 INFO mapreduce.Job:  map 81% reduce 11%
15/04/09 21:40:50 INFO mapreduce.Job:  map 83% reduce 11%
15/04/09 21:40:51 INFO mapreduce.Job:  map 83% reduce 14%
15/04/09 21:40:52 INFO mapreduce.Job:  map 85% reduce 16%
15/04/09 21:40:53 INFO mapreduce.Job:  map 87% reduce 16%
15/04/09 21:40:54 INFO mapreduce.Job:  map 88% reduce 18%
15/04/09 21:40:55 INFO mapreduce.Job:  map 88% reduce 20%
15/04/09 21:40:56 INFO mapreduce.Job:  map 90% reduce 20%
15/04/09 21:40:57 INFO mapreduce.Job:  map 91% reduce 22%
15/04/09 21:40:58 INFO mapreduce.Job:  map 91% reduce 23%
15/04/09 21:40:59 INFO mapreduce.Job:  map 92% reduce 23%
15/04/09 21:41:00 INFO mapreduce.Job:  map 94% reduce 25%
15/04/09 21:41:01 INFO mapreduce.Job:  map 95% reduce 26%
15/04/09 21:41:03 INFO mapreduce.Job:  map 95% reduce 28%
15/04/09 21:41:05 INFO mapreduce.Job:  map 96% reduce 28%
15/04/09 21:41:06 INFO mapreduce.Job:  map 97% reduce 29%
15/04/09 21:41:07 INFO mapreduce.Job:  map 98% reduce 29%
15/04/09 21:41:08 INFO mapreduce.Job:  map 99% reduce 30%
15/04/09 21:41:09 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 21:41:10 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 21:41:12 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 21:41:13 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 21:41:14 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 21:41:15 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 21:41:16 INFO mapreduce.Job:  map 100% reduce 47%
15/04/09 21:41:17 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 21:41:18 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 21:41:19 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 21:41:20 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 21:41:21 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 21:41:22 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 21:41:24 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 21:41:25 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 21:41:28 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 21:41:34 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 21:41:46 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 21:42:04 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 21:42:43 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 21:43:25 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 21:44:07 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 21:44:32 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 21:44:58 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 21:45:35 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 21:46:22 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 21:46:53 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 21:47:23 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 21:47:52 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 21:48:07 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 21:48:28 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 21:48:51 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 21:49:11 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 21:49:40 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 21:50:06 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 21:50:57 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 21:51:17 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 21:51:56 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 21:52:37 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 21:53:31 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 21:55:12 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 21:55:48 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 21:56:15 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 21:57:18 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 21:57:47 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 21:58:23 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 21:58:40 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 22:02:53 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 22:08:43 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 22:12:16 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 22:27:31 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 22:40:14 INFO mapreduce.Job: Job job_1422482982071_4396 completed successfully
15/04/09 22:40:14 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210368
		FILE: Number of bytes written=20771578616
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=225
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Failed map tasks=9
		Killed reduce tasks=1
		Launched map tasks=59
		Launched reduce tasks=26
		Other local map tasks=9
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=40108450
		Total time spent by all reduces in occupied slots (ms)=59305956
		Total time spent by all map tasks (ms)=20054225
		Total time spent by all reduce tasks (ms)=29652978
		Total vcore-seconds taken by all map tasks=20054225
		Total vcore-seconds taken by all reduce tasks=29652978
		Total megabyte-seconds taken by all map tasks=162359005600
		Total megabyte-seconds taken by all reduce tasks=355835736000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382217718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382217718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1250
		Failed Shuffles=0
		Merged Map outputs=1250
		GC time elapsed (ms)=150477
		CPU time spent (ms)=56129540
		Physical memory (bytes) snapshot=112735629312
		Virtual memory (bytes) snapshot=792996696064
		Total committed heap usage (bytes)=191113007104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 22:40:14 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	66m21.042s
user	0m28.304s
sys	0m3.281s
15/04/09 22:40:17 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 15
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-15-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5818472837757996230.jar tmpDir=null
15/04/09 22:40:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 22:40:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 22:40:21 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 22:40:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 22:40:21 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 22:40:22 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4401
15/04/09 22:40:22 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4401
15/04/09 22:40:22 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4401/
15/04/09 22:40:22 INFO mapreduce.Job: Running job: job_1422482982071_4401
15/04/09 22:40:28 INFO mapreduce.Job: Job job_1422482982071_4401 running in uber mode : false
15/04/09 22:40:28 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 22:40:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4401_m_000015_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 22:40:34 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 22:40:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4401_m_000038_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 22:40:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4401_m_000045_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 22:40:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4401_m_000037_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 22:40:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4401_m_000010_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 22:40:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4401_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 22:40:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4401_m_000026_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 22:40:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4401_m_000014_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 22:40:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4401_m_000042_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 22:40:35 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 22:40:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4401_m_000045_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 22:40:41 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 22:40:46 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 22:40:52 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 22:40:57 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 22:41:03 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 22:41:09 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 22:41:15 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 22:41:20 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 22:41:26 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 22:41:31 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 22:41:36 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 22:41:42 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 22:41:48 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 22:41:54 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 22:41:59 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 22:42:05 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 22:42:10 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 22:42:16 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 22:42:22 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 22:42:28 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 22:42:33 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 22:42:39 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 22:42:44 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 22:42:50 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 22:42:55 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 22:43:02 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 22:43:08 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 22:43:14 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 22:43:20 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 22:43:26 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 22:43:31 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 22:43:36 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 22:43:42 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 22:43:48 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 22:43:53 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 22:43:59 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 22:44:05 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 22:44:11 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 22:44:17 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 22:44:22 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 22:44:27 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 22:44:33 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 22:44:39 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 22:44:45 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 22:44:51 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 22:44:56 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 22:45:02 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 22:45:07 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 22:45:13 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 22:45:18 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 22:45:24 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 22:45:30 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 22:45:37 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 22:45:43 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 22:45:49 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 22:45:54 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 22:46:00 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 22:46:05 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 22:46:11 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 22:46:17 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 22:46:22 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 22:46:28 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 22:46:34 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 22:46:40 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 22:46:46 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 22:46:48 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 22:46:53 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 22:46:56 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 22:46:57 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 22:47:00 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 22:47:01 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 22:47:03 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 22:47:04 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 22:47:06 INFO mapreduce.Job:  map 75% reduce 2%
15/04/09 22:47:07 INFO mapreduce.Job:  map 76% reduce 8%
15/04/09 22:47:08 INFO mapreduce.Job:  map 78% reduce 9%
15/04/09 22:47:09 INFO mapreduce.Job:  map 79% reduce 9%
15/04/09 22:47:10 INFO mapreduce.Job:  map 81% reduce 13%
15/04/09 22:47:12 INFO mapreduce.Job:  map 84% reduce 13%
15/04/09 22:47:13 INFO mapreduce.Job:  map 85% reduce 17%
15/04/09 22:47:14 INFO mapreduce.Job:  map 89% reduce 18%
15/04/09 22:47:15 INFO mapreduce.Job:  map 90% reduce 18%
15/04/09 22:47:16 INFO mapreduce.Job:  map 90% reduce 23%
15/04/09 22:47:17 INFO mapreduce.Job:  map 90% reduce 24%
15/04/09 22:47:18 INFO mapreduce.Job:  map 92% reduce 24%
15/04/09 22:47:19 INFO mapreduce.Job:  map 94% reduce 26%
15/04/09 22:47:20 INFO mapreduce.Job:  map 95% reduce 26%
15/04/09 22:47:21 INFO mapreduce.Job:  map 96% reduce 26%
15/04/09 22:47:22 INFO mapreduce.Job:  map 96% reduce 29%
15/04/09 22:47:25 INFO mapreduce.Job:  map 96% reduce 30%
15/04/09 22:47:26 INFO mapreduce.Job:  map 97% reduce 30%
15/04/09 22:47:29 INFO mapreduce.Job:  map 97% reduce 31%
15/04/09 22:47:31 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 22:47:33 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 22:47:34 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 22:47:59 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 22:48:22 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 22:48:26 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 22:48:27 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 22:48:28 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 22:48:30 INFO mapreduce.Job:  map 100% reduce 47%
15/04/09 22:48:31 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 22:48:33 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 22:48:34 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 22:48:35 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 22:48:36 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 22:48:37 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 22:48:39 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 22:48:40 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 22:48:41 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 22:48:43 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 22:48:50 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 22:49:43 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 22:50:56 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 22:52:21 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 22:53:19 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 22:54:27 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 22:55:12 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 22:56:00 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 22:56:26 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 22:57:14 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 22:58:00 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 22:58:51 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 22:59:21 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 23:00:06 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 23:00:51 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 23:01:42 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 23:02:39 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 23:03:17 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 23:04:25 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 23:05:40 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 23:06:37 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 23:07:11 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 23:07:52 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 23:09:32 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 23:11:25 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 23:12:09 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 23:14:27 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 23:16:46 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 23:23:48 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 23:27:26 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 23:34:13 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 23:34:41 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 23:36:29 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 23:43:32 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 23:51:36 INFO mapreduce.Job: Job job_1422482982071_4401 completed successfully
15/04/09 23:51:37 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10382210326
		FILE: Number of bytes written=20770614374
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=195
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Failed map tasks=10
		Launched map tasks=60
		Launched reduce tasks=15
		Other local map tasks=10
		Data-local map tasks=30
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=40202192
		Total time spent by all reduces in occupied slots (ms)=57494894
		Total time spent by all map tasks (ms)=20101096
		Total time spent by all reduce tasks (ms)=28747447
		Total vcore-seconds taken by all map tasks=20101096
		Total vcore-seconds taken by all reduce tasks=28747447
		Total megabyte-seconds taken by all map tasks=162738473216
		Total megabyte-seconds taken by all reduce tasks=344969364000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382214718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382214718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=132920
		CPU time spent (ms)=56337530
		Physical memory (bytes) snapshot=111295451136
		Virtual memory (bytes) snapshot=659373060096
		Total committed heap usage (bytes)=170062184448
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 23:51:37 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	71m22.380s
user	0m27.945s
sys	0m3.158s
15/04/09 23:51:39 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 15
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-15-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob9219382734531886605.jar tmpDir=null
15/04/09 23:51:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 23:51:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 23:51:43 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 23:51:43 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 23:51:43 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 23:51:44 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4408
15/04/09 23:51:44 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4408
15/04/09 23:51:44 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4408/
15/04/09 23:51:44 INFO mapreduce.Job: Running job: job_1422482982071_4408
15/04/09 23:51:51 INFO mapreduce.Job: Job job_1422482982071_4408 running in uber mode : false
15/04/09 23:51:51 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 23:51:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:51:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000000_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:51:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000039_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:51:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:51:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:51:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:51:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000048_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:51:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000017_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:51:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000046_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:51:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:51:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000018_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:51:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000014_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:51:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000028_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:52:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000048_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:52:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000002_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:52:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000018_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:52:02 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 23:52:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4408_m_000002_2, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:52:08 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 23:52:14 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 23:52:20 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 23:52:26 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 23:52:31 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 23:52:36 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 23:52:42 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 23:52:48 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 23:52:54 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 23:53:00 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 23:53:05 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 23:53:10 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 23:53:16 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 23:53:22 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 23:53:28 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 23:53:35 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 23:53:40 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 23:53:46 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 23:53:51 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 23:53:57 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 23:54:02 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 23:54:08 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 23:54:14 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 23:54:20 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 23:54:26 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 23:54:31 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 23:54:36 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 23:54:42 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 23:54:48 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 23:54:53 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 23:54:59 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 23:55:05 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 23:55:11 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 23:55:16 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 23:55:22 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 23:55:27 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 23:55:33 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 23:55:39 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 23:55:45 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 23:55:51 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 23:55:57 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 23:56:03 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 23:56:09 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 23:56:14 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 23:56:20 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 23:56:26 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 23:56:32 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 23:56:39 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 23:56:46 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 23:56:52 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 23:56:58 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 23:57:04 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 23:57:10 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 23:57:17 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 23:57:23 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 23:57:30 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 23:57:37 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 23:57:43 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 23:57:49 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 23:57:55 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 23:58:02 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 23:58:08 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 23:58:14 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 23:58:21 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 23:58:26 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 23:58:31 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 23:58:32 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 23:58:36 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 23:58:38 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 23:58:40 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 23:58:41 INFO mapreduce.Job:  map 76% reduce 0%
15/04/09 23:58:42 INFO mapreduce.Job:  map 77% reduce 1%
15/04/09 23:58:43 INFO mapreduce.Job:  map 79% reduce 9%
15/04/09 23:58:44 INFO mapreduce.Job:  map 82% reduce 10%
15/04/09 23:58:45 INFO mapreduce.Job:  map 84% reduce 10%
15/04/09 23:58:46 INFO mapreduce.Job:  map 86% reduce 16%
15/04/09 23:58:47 INFO mapreduce.Job:  map 89% reduce 16%
15/04/09 23:58:49 INFO mapreduce.Job:  map 90% reduce 22%
15/04/09 23:58:50 INFO mapreduce.Job:  map 90% reduce 23%
15/04/09 23:58:51 INFO mapreduce.Job:  map 91% reduce 23%
15/04/09 23:58:52 INFO mapreduce.Job:  map 92% reduce 24%
15/04/09 23:58:53 INFO mapreduce.Job:  map 93% reduce 25%
15/04/09 23:58:54 INFO mapreduce.Job:  map 94% reduce 25%
15/04/09 23:58:55 INFO mapreduce.Job:  map 94% reduce 27%
15/04/09 23:58:58 INFO mapreduce.Job:  map 94% reduce 28%
15/04/09 23:59:00 INFO mapreduce.Job:  map 95% reduce 28%
15/04/09 23:59:02 INFO mapreduce.Job:  map 95% reduce 29%
15/04/09 23:59:06 INFO mapreduce.Job:  map 97% reduce 29%
15/04/09 23:59:08 INFO mapreduce.Job:  map 97% reduce 30%
15/04/09 23:59:17 INFO mapreduce.Job:  map 97% reduce 31%
15/04/09 23:59:22 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 23:59:33 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 23:59:35 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 23:59:38 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 23:59:40 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 23:59:42 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 23:59:44 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 23:59:45 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 23:59:47 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 23:59:49 INFO mapreduce.Job:  map 100% reduce 51%
15/04/09 23:59:50 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 23:59:52 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 23:59:53 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 23:59:56 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 23:59:59 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 00:00:05 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 00:00:59 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 00:02:10 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 00:03:27 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 00:04:14 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 00:05:26 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 00:06:11 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 00:07:23 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 00:07:41 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 00:08:35 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 00:09:14 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 00:10:09 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 00:10:45 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 00:11:25 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 00:12:09 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 00:13:03 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 00:13:57 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 00:14:47 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 00:16:08 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 00:17:03 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 00:17:43 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 00:18:34 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 00:19:42 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 00:21:11 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 00:23:21 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 00:23:24 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 00:26:41 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 00:28:11 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 00:35:32 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 00:39:35 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 00:48:19 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 00:50:09 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 00:58:58 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 01:07:51 INFO mapreduce.Job: Job job_1422482982071_4408 completed successfully
15/04/10 01:07:51 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210326
		FILE: Number of bytes written=20770614374
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=195
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Failed map tasks=17
		Killed reduce tasks=1
		Launched map tasks=67
		Launched reduce tasks=16
		Other local map tasks=17
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=41646306
		Total time spent by all reduces in occupied slots (ms)=60346712
		Total time spent by all map tasks (ms)=20823153
		Total time spent by all reduce tasks (ms)=30173356
		Total vcore-seconds taken by all map tasks=20823153
		Total vcore-seconds taken by all reduce tasks=30173356
		Total megabyte-seconds taken by all map tasks=168584246688
		Total megabyte-seconds taken by all reduce tasks=362080272000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382214718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382214718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=115828
		CPU time spent (ms)=57747050
		Physical memory (bytes) snapshot=111488360448
		Virtual memory (bytes) snapshot=659369951232
		Total committed heap usage (bytes)=170061705216
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/10 01:07:51 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	76m14.151s
user	0m30.422s
sys	0m3.286s
15/04/10 01:07:53 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 15
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-15-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1324720757048247690.jar tmpDir=null
15/04/10 01:07:56 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 01:07:56 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 01:07:57 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/10 01:07:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/10 01:07:57 INFO mapreduce.JobSubmitter: number of splits:50
15/04/10 01:07:58 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4417
15/04/10 01:07:58 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4417
15/04/10 01:07:58 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4417/
15/04/10 01:07:58 INFO mapreduce.Job: Running job: job_1422482982071_4417
15/04/10 01:08:04 INFO mapreduce.Job: Job job_1422482982071_4417 running in uber mode : false
15/04/10 01:08:04 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 01:08:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4417_m_000026_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:08:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4417_m_000010_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:08:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4417_m_000041_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:08:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4417_m_000017_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:08:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4417_m_000024_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:08:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4417_m_000003_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:08:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4417_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:08:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4417_m_000033_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:08:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4417_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:08:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4417_m_000027_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:08:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4417_m_000018_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:08:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4417_m_000039_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:08:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4417_m_000042_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:08:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4417_m_000031_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:08:17 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 01:08:23 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 01:08:28 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 01:08:34 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 01:08:40 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 01:08:45 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 01:08:51 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 01:08:56 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 01:09:02 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 01:09:08 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 01:09:14 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 01:09:19 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 01:09:25 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 01:09:31 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 01:09:36 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 01:09:42 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 01:09:48 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 01:09:54 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 01:09:59 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 01:10:04 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 01:10:10 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 01:10:16 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 01:10:22 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 01:10:27 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 01:10:33 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 01:10:39 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 01:10:44 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 01:10:50 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 01:10:55 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 01:11:01 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 01:11:08 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 01:11:14 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 01:11:19 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 01:11:25 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 01:11:31 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 01:11:36 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 01:11:42 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 01:11:48 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 01:11:54 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 01:11:59 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 01:12:05 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 01:12:11 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 01:12:17 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 01:12:22 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 01:12:27 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 01:12:33 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 01:12:39 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 01:12:45 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 01:12:50 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 01:12:56 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 01:13:02 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 01:13:08 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 01:13:14 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 01:13:19 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 01:13:25 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 01:13:31 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 01:13:36 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 01:13:42 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 01:13:48 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 01:13:54 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 01:13:59 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 01:14:05 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 01:14:11 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 01:14:17 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 01:14:23 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 01:14:31 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 01:14:34 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 01:14:37 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 01:14:38 INFO mapreduce.Job:  map 69% reduce 0%
15/04/10 01:14:39 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 01:14:40 INFO mapreduce.Job:  map 71% reduce 0%
15/04/10 01:14:43 INFO mapreduce.Job:  map 74% reduce 0%
15/04/10 01:14:44 INFO mapreduce.Job:  map 76% reduce 0%
15/04/10 01:14:45 INFO mapreduce.Job:  map 77% reduce 0%
15/04/10 01:14:46 INFO mapreduce.Job:  map 79% reduce 0%
15/04/10 01:14:47 INFO mapreduce.Job:  map 82% reduce 5%
15/04/10 01:14:48 INFO mapreduce.Job:  map 82% reduce 13%
15/04/10 01:14:49 INFO mapreduce.Job:  map 84% reduce 13%
15/04/10 01:14:50 INFO mapreduce.Job:  map 86% reduce 15%
15/04/10 01:14:51 INFO mapreduce.Job:  map 86% reduce 18%
15/04/10 01:14:52 INFO mapreduce.Job:  map 88% reduce 18%
15/04/10 01:14:53 INFO mapreduce.Job:  map 88% reduce 20%
15/04/10 01:14:54 INFO mapreduce.Job:  map 90% reduce 21%
15/04/10 01:14:55 INFO mapreduce.Job:  map 91% reduce 22%
15/04/10 01:14:56 INFO mapreduce.Job:  map 91% reduce 23%
15/04/10 01:14:57 INFO mapreduce.Job:  map 91% reduce 24%
15/04/10 01:14:58 INFO mapreduce.Job:  map 92% reduce 25%
15/04/10 01:14:59 INFO mapreduce.Job:  map 94% reduce 26%
15/04/10 01:15:00 INFO mapreduce.Job:  map 96% reduce 27%
15/04/10 01:15:01 INFO mapreduce.Job:  map 97% reduce 28%
15/04/10 01:15:03 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 01:15:05 INFO mapreduce.Job:  map 97% reduce 31%
15/04/10 01:15:06 INFO mapreduce.Job:  map 98% reduce 31%
15/04/10 01:15:24 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 01:15:33 INFO mapreduce.Job:  map 99% reduce 33%
15/04/10 01:15:34 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 01:15:36 INFO mapreduce.Job:  map 100% reduce 35%
15/04/10 01:15:37 INFO mapreduce.Job:  map 100% reduce 39%
15/04/10 01:15:38 INFO mapreduce.Job:  map 100% reduce 40%
15/04/10 01:15:39 INFO mapreduce.Job:  map 100% reduce 43%
15/04/10 01:15:40 INFO mapreduce.Job:  map 100% reduce 47%
15/04/10 01:15:41 INFO mapreduce.Job:  map 100% reduce 49%
15/04/10 01:15:42 INFO mapreduce.Job:  map 100% reduce 51%
15/04/10 01:15:43 INFO mapreduce.Job:  map 100% reduce 54%
15/04/10 01:15:44 INFO mapreduce.Job:  map 100% reduce 55%
15/04/10 01:15:45 INFO mapreduce.Job:  map 100% reduce 57%
15/04/10 01:15:46 INFO mapreduce.Job:  map 100% reduce 60%
15/04/10 01:15:47 INFO mapreduce.Job:  map 100% reduce 61%
15/04/10 01:15:48 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 01:15:49 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 01:15:52 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 01:15:53 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 01:15:59 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 01:16:55 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 01:18:04 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 01:19:17 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 01:20:13 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 01:21:25 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 01:22:08 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 01:23:00 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 01:23:27 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 01:24:22 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 01:25:29 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 01:25:57 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 01:26:41 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 01:27:23 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 01:28:07 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 01:29:13 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 01:30:11 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 01:30:59 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 01:32:21 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 01:33:08 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 01:33:47 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 01:34:14 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 01:35:18 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 01:36:55 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 01:38:54 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 01:39:38 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 01:41:27 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 01:43:32 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 01:50:21 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 01:53:41 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 02:01:10 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 02:04:14 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 02:12:32 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 02:21:19 INFO mapreduce.Job: Job job_1422482982071_4417 completed successfully
15/04/10 02:21:19 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10382210326
		FILE: Number of bytes written=20770614374
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=195
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Failed map tasks=14
		Launched map tasks=64
		Launched reduce tasks=15
		Other local map tasks=14
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=40400098
		Total time spent by all reduces in occupied slots (ms)=56722014
		Total time spent by all map tasks (ms)=20200049
		Total time spent by all reduce tasks (ms)=28361007
		Total vcore-seconds taken by all map tasks=20200049
		Total vcore-seconds taken by all reduce tasks=28361007
		Total megabyte-seconds taken by all map tasks=163539596704
		Total megabyte-seconds taken by all reduce tasks=340332084000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382214718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382214718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=125765
		CPU time spent (ms)=56452540
		Physical memory (bytes) snapshot=111349452800
		Virtual memory (bytes) snapshot=660150996992
		Total committed heap usage (bytes)=170061856768
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/10 02:21:19 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	73m28.394s
user	0m28.002s
sys	0m3.354s
15/04/10 02:21:22 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 35
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-35-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3780833001839906116.jar tmpDir=null
15/04/10 02:21:25 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 02:21:25 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 02:21:26 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 02:21:26 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 02:21:27 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4420
15/04/10 02:21:27 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4420
15/04/10 02:21:27 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4420/
15/04/10 02:21:27 INFO mapreduce.Job: Running job: job_1422482982071_4420
15/04/10 02:21:33 INFO mapreduce.Job: Job job_1422482982071_4420 running in uber mode : false
15/04/10 02:21:33 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 02:21:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000048_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000056_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000050_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000064_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000053_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000020_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000021_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000060_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000023_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000049_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000006_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000038_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000006_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000036_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000053_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:45 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 02:21:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000049_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000053_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:21:52 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 02:21:58 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 02:22:04 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 02:22:10 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 02:22:16 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 02:22:22 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 02:22:28 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 02:22:34 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 02:22:40 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 02:22:46 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 02:22:52 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 02:22:58 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 02:23:05 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 02:23:11 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 02:23:17 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 02:23:23 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 02:23:29 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 02:23:35 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 02:23:41 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 02:23:47 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 02:23:54 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 02:24:01 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 02:24:07 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 02:24:13 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 02:24:19 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 02:24:25 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 02:24:31 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 02:24:37 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 02:24:43 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 02:24:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000065_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:24:45 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 02:24:46 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 02:24:52 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 02:24:58 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 02:25:04 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 02:25:10 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 02:25:16 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 02:25:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:25:25 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 02:25:31 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 02:25:37 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 02:25:43 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 02:25:50 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 02:25:56 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 02:26:02 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 02:26:08 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 02:26:14 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 02:26:20 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 02:26:26 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 02:26:32 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 02:26:38 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 02:26:44 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 02:26:50 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 02:26:56 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 02:27:04 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 02:27:10 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 02:27:14 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 02:27:20 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 02:27:26 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 02:27:33 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 02:27:39 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 02:27:45 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 02:27:51 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 02:27:57 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 02:28:03 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 02:28:11 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 02:28:15 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 02:28:19 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 02:28:20 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 02:28:23 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 02:28:26 INFO mapreduce.Job:  map 69% reduce 0%
15/04/10 02:28:28 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 02:28:29 INFO mapreduce.Job:  map 70% reduce 3%
15/04/10 02:28:30 INFO mapreduce.Job:  map 71% reduce 6%
15/04/10 02:28:31 INFO mapreduce.Job:  map 72% reduce 7%
15/04/10 02:28:32 INFO mapreduce.Job:  map 74% reduce 7%
15/04/10 02:28:33 INFO mapreduce.Job:  map 75% reduce 8%
15/04/10 02:28:34 INFO mapreduce.Job:  map 75% reduce 9%
15/04/10 02:28:35 INFO mapreduce.Job:  map 76% reduce 10%
15/04/10 02:28:36 INFO mapreduce.Job:  map 77% reduce 11%
15/04/10 02:28:37 INFO mapreduce.Job:  map 79% reduce 12%
15/04/10 02:28:38 INFO mapreduce.Job:  map 80% reduce 13%
15/04/10 02:28:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4420_m_000002_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:28:39 INFO mapreduce.Job:  map 81% reduce 15%
15/04/10 02:28:40 INFO mapreduce.Job:  map 82% reduce 16%
15/04/10 02:28:41 INFO mapreduce.Job:  map 83% reduce 16%
15/04/10 02:28:42 INFO mapreduce.Job:  map 84% reduce 18%
15/04/10 02:28:43 INFO mapreduce.Job:  map 85% reduce 19%
15/04/10 02:28:45 INFO mapreduce.Job:  map 86% reduce 21%
15/04/10 02:28:48 INFO mapreduce.Job:  map 86% reduce 22%
15/04/10 02:28:49 INFO mapreduce.Job:  map 87% reduce 22%
15/04/10 02:28:50 INFO mapreduce.Job:  map 88% reduce 22%
15/04/10 02:28:51 INFO mapreduce.Job:  map 88% reduce 23%
15/04/10 02:28:57 INFO mapreduce.Job:  map 89% reduce 23%
15/04/10 02:29:01 INFO mapreduce.Job:  map 89% reduce 24%
15/04/10 02:29:12 INFO mapreduce.Job:  map 90% reduce 24%
15/04/10 02:29:17 INFO mapreduce.Job:  map 91% reduce 24%
15/04/10 02:29:19 INFO mapreduce.Job:  map 91% reduce 25%
15/04/10 02:29:24 INFO mapreduce.Job:  map 92% reduce 25%
15/04/10 02:29:26 INFO mapreduce.Job:  map 92% reduce 26%
15/04/10 02:29:27 INFO mapreduce.Job:  map 93% reduce 26%
15/04/10 02:29:29 INFO mapreduce.Job:  map 94% reduce 27%
15/04/10 02:29:31 INFO mapreduce.Job:  map 96% reduce 28%
15/04/10 02:29:32 INFO mapreduce.Job:  map 96% reduce 29%
15/04/10 02:29:34 INFO mapreduce.Job:  map 96% reduce 30%
15/04/10 02:29:36 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 02:29:39 INFO mapreduce.Job:  map 97% reduce 31%
15/04/10 02:29:47 INFO mapreduce.Job:  map 98% reduce 31%
15/04/10 02:29:55 INFO mapreduce.Job:  map 98% reduce 32%
15/04/10 02:29:58 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 02:32:22 INFO mapreduce.Job:  map 100% reduce 32%
15/04/10 02:32:23 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 02:32:28 INFO mapreduce.Job:  map 100% reduce 35%
15/04/10 02:32:29 INFO mapreduce.Job:  map 100% reduce 37%
15/04/10 02:32:30 INFO mapreduce.Job:  map 100% reduce 39%
15/04/10 02:32:31 INFO mapreduce.Job:  map 100% reduce 44%
15/04/10 02:32:32 INFO mapreduce.Job:  map 100% reduce 47%
15/04/10 02:32:33 INFO mapreduce.Job:  map 100% reduce 49%
15/04/10 02:32:34 INFO mapreduce.Job:  map 100% reduce 55%
15/04/10 02:32:35 INFO mapreduce.Job:  map 100% reduce 56%
15/04/10 02:32:36 INFO mapreduce.Job:  map 100% reduce 57%
15/04/10 02:32:37 INFO mapreduce.Job:  map 100% reduce 60%
15/04/10 02:32:38 INFO mapreduce.Job:  map 100% reduce 61%
15/04/10 02:32:39 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 02:32:40 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 02:32:41 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 02:32:43 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 02:32:44 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 02:32:52 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 02:33:25 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 02:34:04 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 02:34:42 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 02:35:13 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 02:35:46 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 02:36:18 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 02:36:54 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 02:37:23 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 02:37:54 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 02:38:23 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 02:38:55 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 02:39:09 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 02:39:38 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 02:40:03 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 02:40:33 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 02:41:03 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 02:41:41 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 02:42:10 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 02:42:49 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 02:43:20 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 02:44:43 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 02:45:16 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 02:45:45 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 02:46:53 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 02:48:04 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 02:49:39 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 02:52:15 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 02:53:39 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 02:57:34 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 02:59:34 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 03:00:39 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 03:16:55 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 03:41:47 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 03:50:05 INFO mapreduce.Job: Job job_1422482982071_4420 completed successfully
15/04/10 03:50:05 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=16787700639
		FILE: Number of bytes written=33585923317
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=330
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Failed map tasks=22
		Killed map tasks=2
		Killed reduce tasks=1
		Launched map tasks=99
		Launched reduce tasks=36
		Other local map tasks=24
		Data-local map tasks=54
		Rack-local map tasks=21
		Total time spent by all maps in occupied slots (ms)=66634656
		Total time spent by all reduces in occupied slots (ms)=106283710
		Total time spent by all map tasks (ms)=33317328
		Total time spent by all reduce tasks (ms)=53141855
		Total vcore-seconds taken by all map tasks=33317328
		Total vcore-seconds taken by all reduce tasks=53141855
		Total megabyte-seconds taken by all map tasks=269737087488
		Total megabyte-seconds taken by all reduce tasks=637702260000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787716173
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787716173
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =2625
		Failed Shuffles=0
		Merged Map outputs=2625
		GC time elapsed (ms)=238879
		CPU time spent (ms)=88624800
		Physical memory (bytes) snapshot=171093032960
		Virtual memory (bytes) snapshot=1156198158336
		Total committed heap usage (bytes)=281404776448
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/10 03:50:05 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	88m45.599s
user	0m31.484s
sys	0m3.987s
15/04/10 03:50:08 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 35
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-35-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2279341996080491848.jar tmpDir=null
15/04/10 03:50:11 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 03:50:11 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 03:50:12 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 03:50:12 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 03:50:13 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4422
15/04/10 03:50:13 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4422
15/04/10 03:50:13 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4422/
15/04/10 03:50:13 INFO mapreduce.Job: Running job: job_1422482982071_4422
15/04/10 03:50:20 INFO mapreduce.Job: Job job_1422482982071_4422 running in uber mode : false
15/04/10 03:50:20 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 03:50:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000035_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000015_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000020_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000066_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000013_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000021_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000052_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000046_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000062_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 03:50:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000073_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000050_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000038_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000050_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000052_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000002_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:32 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 03:50:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4422_m_000002_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:50:37 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 03:50:44 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 03:50:50 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 03:50:56 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 03:51:02 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 03:51:08 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 03:51:14 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 03:51:20 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 03:51:26 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 03:51:32 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 03:51:38 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 03:51:44 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 03:51:50 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 03:51:56 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 03:52:02 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 03:52:08 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 03:52:13 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 03:52:19 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 03:52:25 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 03:52:31 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 03:52:37 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 03:52:44 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 03:52:50 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 03:52:56 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 03:53:02 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 03:53:08 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 03:53:14 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 03:53:20 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 03:53:26 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 03:53:32 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 03:53:38 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 03:53:44 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 03:53:50 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 03:53:55 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 03:54:01 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 03:54:07 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 03:54:13 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 03:54:19 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 03:54:25 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 03:54:31 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 03:54:37 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 03:54:43 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 03:54:48 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 03:54:54 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 03:55:00 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 03:55:06 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 03:55:12 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 03:55:18 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 03:55:24 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 03:55:30 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 03:55:36 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 03:55:43 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 03:55:49 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 03:55:55 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 03:55:58 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 03:56:05 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 03:56:11 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 03:56:17 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 03:56:23 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 03:56:29 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 03:56:35 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 03:56:41 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 03:56:47 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 03:56:54 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 03:57:01 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 03:57:03 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 03:57:07 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 03:57:09 INFO mapreduce.Job:  map 69% reduce 0%
15/04/10 03:57:10 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 03:57:11 INFO mapreduce.Job:  map 71% reduce 0%
15/04/10 03:57:12 INFO mapreduce.Job:  map 72% reduce 0%
15/04/10 03:57:13 INFO mapreduce.Job:  map 74% reduce 4%
15/04/10 03:57:14 INFO mapreduce.Job:  map 75% reduce 7%
15/04/10 03:57:15 INFO mapreduce.Job:  map 76% reduce 7%
15/04/10 03:57:16 INFO mapreduce.Job:  map 79% reduce 8%
15/04/10 03:57:17 INFO mapreduce.Job:  map 81% reduce 11%
15/04/10 03:57:19 INFO mapreduce.Job:  map 84% reduce 14%
15/04/10 03:57:20 INFO mapreduce.Job:  map 85% reduce 16%
15/04/10 03:57:21 INFO mapreduce.Job:  map 85% reduce 17%
15/04/10 03:57:22 INFO mapreduce.Job:  map 87% reduce 19%
15/04/10 03:57:23 INFO mapreduce.Job:  map 87% reduce 20%
15/04/10 03:57:24 INFO mapreduce.Job:  map 88% reduce 20%
15/04/10 03:57:25 INFO mapreduce.Job:  map 89% reduce 21%
15/04/10 03:57:26 INFO mapreduce.Job:  map 90% reduce 22%
15/04/10 03:57:27 INFO mapreduce.Job:  map 91% reduce 23%
15/04/10 03:57:28 INFO mapreduce.Job:  map 91% reduce 24%
15/04/10 03:57:29 INFO mapreduce.Job:  map 92% reduce 25%
15/04/10 03:57:31 INFO mapreduce.Job:  map 94% reduce 26%
15/04/10 03:57:32 INFO mapreduce.Job:  map 95% reduce 27%
15/04/10 03:57:33 INFO mapreduce.Job:  map 95% reduce 28%
15/04/10 03:57:35 INFO mapreduce.Job:  map 95% reduce 29%
15/04/10 03:57:59 INFO mapreduce.Job:  map 96% reduce 29%
15/04/10 03:58:03 INFO mapreduce.Job:  map 97% reduce 29%
15/04/10 03:58:05 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 03:58:08 INFO mapreduce.Job:  map 97% reduce 31%
15/04/10 03:58:11 INFO mapreduce.Job:  map 98% reduce 31%
15/04/10 03:58:18 INFO mapreduce.Job:  map 98% reduce 32%
15/04/10 03:58:20 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 03:58:26 INFO mapreduce.Job:  map 100% reduce 32%
15/04/10 03:58:28 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 03:58:30 INFO mapreduce.Job:  map 100% reduce 36%
15/04/10 03:58:31 INFO mapreduce.Job:  map 100% reduce 38%
15/04/10 03:58:32 INFO mapreduce.Job:  map 100% reduce 40%
15/04/10 03:58:33 INFO mapreduce.Job:  map 100% reduce 45%
15/04/10 03:58:34 INFO mapreduce.Job:  map 100% reduce 49%
15/04/10 03:58:35 INFO mapreduce.Job:  map 100% reduce 50%
15/04/10 03:58:36 INFO mapreduce.Job:  map 100% reduce 54%
15/04/10 03:58:37 INFO mapreduce.Job:  map 100% reduce 57%
15/04/10 03:58:38 INFO mapreduce.Job:  map 100% reduce 58%
15/04/10 03:58:39 INFO mapreduce.Job:  map 100% reduce 60%
15/04/10 03:58:40 INFO mapreduce.Job:  map 100% reduce 61%
15/04/10 03:58:41 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 03:58:42 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 03:58:43 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 03:58:45 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 03:58:48 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 03:58:56 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 03:59:26 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 04:00:16 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 04:01:02 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 04:01:40 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 04:02:15 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 04:02:46 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 04:03:21 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 04:03:45 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 04:04:20 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 04:04:46 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 04:05:25 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 04:05:41 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 04:06:06 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 04:06:36 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 04:07:00 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 04:07:26 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 04:08:07 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 04:08:37 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 04:09:08 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 04:10:03 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 04:11:11 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 04:11:45 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 04:12:09 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 04:13:21 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 04:14:43 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 04:16:32 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 04:18:20 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 04:20:14 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 04:23:28 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 04:25:35 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 04:26:55 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 04:42:09 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 05:06:04 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 05:13:56 INFO mapreduce.Job: Job job_1422482982071_4422 completed successfully
15/04/10 05:13:56 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16787700639
		FILE: Number of bytes written=33585923317
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=330
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Failed map tasks=18
		Killed reduce tasks=2
		Launched map tasks=93
		Launched reduce tasks=37
		Other local map tasks=18
		Data-local map tasks=50
		Rack-local map tasks=25
		Total time spent by all maps in occupied slots (ms)=63355986
		Total time spent by all reduces in occupied slots (ms)=96758342
		Total time spent by all map tasks (ms)=31677993
		Total time spent by all reduce tasks (ms)=48379171
		Total vcore-seconds taken by all map tasks=31677993
		Total vcore-seconds taken by all reduce tasks=48379171
		Total megabyte-seconds taken by all map tasks=256465031328
		Total megabyte-seconds taken by all reduce tasks=580550052000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787716173
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787716173
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =2625
		Failed Shuffles=0
		Merged Map outputs=2625
		GC time elapsed (ms)=213520
		CPU time spent (ms)=88077220
		Physical memory (bytes) snapshot=170724982784
		Virtual memory (bytes) snapshot=1156387758080
		Total committed heap usage (bytes)=281406390272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/10 05:13:56 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	83m51.536s
user	0m31.423s
sys	0m3.908s
15/04/10 05:13:59 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 35
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-35-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob351487181476152560.jar tmpDir=null
15/04/10 05:14:02 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 05:14:02 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 05:14:03 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 05:14:03 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 05:14:04 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4425
15/04/10 05:14:04 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4425
15/04/10 05:14:04 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4425/
15/04/10 05:14:04 INFO mapreduce.Job: Running job: job_1422482982071_4425
15/04/10 05:14:11 INFO mapreduce.Job: Job job_1422482982071_4425 running in uber mode : false
15/04/10 05:14:11 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 05:14:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000062_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:14:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000014_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:14:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000074_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:14:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000001_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:14:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000057_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:14:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000055_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 05:14:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000021_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:14:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:14:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000068_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:14:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000053_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:14:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000054_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 05:14:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000052_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 05:14:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000008_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 05:14:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000012_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 05:14:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000038_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 05:14:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000022_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 05:14:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000045_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 05:14:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000045_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:14:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000053_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:14:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_m_000021_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:14:22 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 05:14:28 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 05:14:34 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 05:14:41 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 05:14:47 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 05:14:53 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 05:14:59 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 05:15:05 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 05:15:11 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 05:15:17 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 05:15:23 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 05:15:30 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 05:15:37 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 05:15:43 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 05:15:49 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 05:15:55 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 05:16:01 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 05:16:07 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 05:16:13 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 05:16:19 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 05:16:25 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 05:16:31 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 05:16:37 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 05:16:43 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 05:16:49 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 05:16:55 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 05:17:01 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 05:17:07 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 05:17:14 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 05:17:20 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 05:17:26 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 05:17:32 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 05:17:38 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 05:17:44 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 05:17:50 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 05:17:56 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 05:18:02 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 05:18:08 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 05:18:14 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 05:18:20 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 05:18:27 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 05:18:33 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 05:18:40 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 05:18:46 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 05:18:52 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 05:18:58 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 05:19:04 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 05:19:10 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 05:19:16 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 05:19:22 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 05:19:28 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 05:19:34 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 05:19:40 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 05:19:46 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 05:19:52 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 05:19:58 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 05:20:04 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 05:20:10 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 05:20:16 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 05:20:22 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 05:20:28 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 05:20:36 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 05:20:43 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 05:20:50 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 05:20:55 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 05:21:00 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 05:21:01 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 05:21:05 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 05:21:06 INFO mapreduce.Job:  map 69% reduce 0%
15/04/10 05:21:07 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 05:21:09 INFO mapreduce.Job:  map 71% reduce 0%
15/04/10 05:21:10 INFO mapreduce.Job:  map 72% reduce 1%
15/04/10 05:21:11 INFO mapreduce.Job:  map 73% reduce 6%
15/04/10 05:21:12 INFO mapreduce.Job:  map 74% reduce 6%
15/04/10 05:21:13 INFO mapreduce.Job:  map 75% reduce 6%
15/04/10 05:21:14 INFO mapreduce.Job:  map 75% reduce 8%
15/04/10 05:21:15 INFO mapreduce.Job:  map 77% reduce 8%
15/04/10 05:21:17 INFO mapreduce.Job:  map 78% reduce 11%
15/04/10 05:21:18 INFO mapreduce.Job:  map 79% reduce 11%
15/04/10 05:21:19 INFO mapreduce.Job:  map 80% reduce 11%
15/04/10 05:21:20 INFO mapreduce.Job:  map 81% reduce 14%
15/04/10 05:21:21 INFO mapreduce.Job:  map 82% reduce 14%
15/04/10 05:21:23 INFO mapreduce.Job:  map 83% reduce 17%
15/04/10 05:21:24 INFO mapreduce.Job:  map 85% reduce 17%
15/04/10 05:21:25 INFO mapreduce.Job:  map 86% reduce 17%
15/04/10 05:21:26 INFO mapreduce.Job:  map 87% reduce 20%
15/04/10 05:21:29 INFO mapreduce.Job:  map 88% reduce 21%
15/04/10 05:21:32 INFO mapreduce.Job:  map 89% reduce 22%
15/04/10 05:21:34 INFO mapreduce.Job:  map 90% reduce 22%
15/04/10 05:21:35 INFO mapreduce.Job:  map 90% reduce 24%
15/04/10 05:21:37 INFO mapreduce.Job:  map 91% reduce 24%
15/04/10 05:21:41 INFO mapreduce.Job:  map 92% reduce 24%
15/04/10 05:21:42 INFO mapreduce.Job:  map 92% reduce 25%
15/04/10 05:21:45 INFO mapreduce.Job:  map 92% reduce 26%
15/04/10 05:21:59 INFO mapreduce.Job:  map 93% reduce 26%
15/04/10 05:22:01 INFO mapreduce.Job:  map 94% reduce 26%
15/04/10 05:22:03 INFO mapreduce.Job:  map 94% reduce 27%
15/04/10 05:22:04 INFO mapreduce.Job:  map 95% reduce 27%
15/04/10 05:22:06 INFO mapreduce.Job:  map 95% reduce 28%
15/04/10 05:22:09 INFO mapreduce.Job:  map 96% reduce 28%
15/04/10 05:22:12 INFO mapreduce.Job:  map 96% reduce 30%
15/04/10 05:22:13 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 05:22:14 INFO mapreduce.Job:  map 98% reduce 30%
15/04/10 05:22:15 INFO mapreduce.Job:  map 99% reduce 31%
15/04/10 05:22:18 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 05:22:21 INFO mapreduce.Job:  map 100% reduce 32%
15/04/10 05:22:24 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 05:22:48 INFO mapreduce.Job:  map 100% reduce 36%
15/04/10 05:22:49 INFO mapreduce.Job:  map 100% reduce 37%
15/04/10 05:22:51 INFO mapreduce.Job:  map 100% reduce 46%
15/04/10 05:22:52 INFO mapreduce.Job:  map 100% reduce 47%
15/04/10 05:22:54 INFO mapreduce.Job:  map 100% reduce 55%
15/04/10 05:22:55 INFO mapreduce.Job:  map 100% reduce 56%
15/04/10 05:22:57 INFO mapreduce.Job:  map 100% reduce 60%
15/04/10 05:22:58 INFO mapreduce.Job:  map 100% reduce 61%
15/04/10 05:23:00 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 05:23:01 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 05:23:03 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 05:23:06 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 05:23:13 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 05:23:49 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 05:24:28 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 05:25:10 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:25:44 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 05:26:14 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 05:26:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000021_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:26:46 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:26:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000020_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:26:47 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 05:26:56 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 05:26:57 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 05:27:02 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 05:27:26 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 05:27:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000022_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:27:40 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 05:27:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000006_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:27:45 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 05:27:50 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:27:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000002_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:27:51 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 05:27:55 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 05:27:56 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:28:01 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 05:28:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000003_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:28:05 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:28:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000009_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:28:09 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 05:28:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000000_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:28:10 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 05:28:15 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 05:28:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000024_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:28:17 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 05:28:19 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 05:28:20 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 05:28:23 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 05:28:27 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:28:29 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 05:28:42 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 05:29:17 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 05:29:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000008_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:29:26 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:29:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000033_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:29:32 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 05:29:37 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:29:42 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 05:29:45 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 05:30:00 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 05:30:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000029_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:30:06 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:30:13 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 05:30:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000034_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:30:16 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 05:30:17 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:30:23 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 05:30:26 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 05:30:27 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000032_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:30:28 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:30:36 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 05:30:38 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 05:30:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000016_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:30:41 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:30:48 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 05:30:53 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 05:30:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000027_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:30:55 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:31:02 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 05:31:06 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 05:31:14 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 05:31:29 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 05:31:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000030_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:31:35 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 05:31:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000004_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:31:36 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 05:31:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000019_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:31:43 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 05:31:46 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 05:31:49 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:31:53 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 05:31:59 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 05:32:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000025_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:32:19 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 05:32:29 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 05:32:32 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 05:32:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000017_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:32:53 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 05:33:05 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 05:33:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000007_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:33:06 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:33:08 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 05:33:16 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 05:33:19 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 05:33:31 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 05:33:42 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 05:34:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000018_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:34:03 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 05:34:14 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 05:34:16 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 05:34:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000028_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:34:19 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 05:34:29 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 05:34:34 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 05:34:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000001_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:34:43 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 05:34:54 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 05:34:55 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 05:35:03 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 05:35:25 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 05:35:48 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 05:35:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000015_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:35:55 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 05:36:07 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 05:36:17 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 05:36:23 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 05:36:50 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 05:36:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000023_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:36:55 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 05:37:07 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 05:37:16 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 05:37:55 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 05:38:28 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 05:39:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000014_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:39:06 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 05:39:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000031_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:39:10 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 05:39:17 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 05:39:21 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 05:39:23 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 05:39:34 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 05:39:45 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 05:40:11 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 05:40:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000005_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:40:55 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 05:41:06 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 05:41:15 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 05:41:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000013_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:41:19 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 05:41:29 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 05:41:44 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 05:42:36 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 05:42:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000026_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:42:52 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 05:43:03 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 05:43:20 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 05:44:10 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 05:45:37 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 05:45:56 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 05:47:34 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 05:48:57 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 05:50:05 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 05:52:05 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 05:54:14 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 05:56:40 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 06:00:30 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 06:02:41 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 06:03:36 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 06:06:33 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 06:08:03 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 06:33:22 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 06:37:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4425_r_000010_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 06:37:27 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 06:48:45 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 06:57:10 INFO mapreduce.Job: Job job_1422482982071_4425 completed successfully
15/04/10 06:57:10 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=16787700639
		FILE: Number of bytes written=33585923317
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=330
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Failed map tasks=20
		Failed reduce tasks=33
		Killed reduce tasks=7
		Launched map tasks=95
		Launched reduce tasks=75
		Other local map tasks=20
		Data-local map tasks=49
		Rack-local map tasks=26
		Total time spent by all maps in occupied slots (ms)=65541376
		Total time spent by all reduces in occupied slots (ms)=164677478
		Total time spent by all map tasks (ms)=32770688
		Total time spent by all reduce tasks (ms)=82338739
		Total vcore-seconds taken by all map tasks=32770688
		Total vcore-seconds taken by all reduce tasks=82338739
		Total megabyte-seconds taken by all map tasks=265311490048
		Total megabyte-seconds taken by all reduce tasks=988064868000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787716173
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787716173
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =2625
		Failed Shuffles=0
		Merged Map outputs=2625
		GC time elapsed (ms)=174893
		CPU time spent (ms)=90965340
		Physical memory (bytes) snapshot=169985556480
		Virtual memory (bytes) snapshot=1157782986752
		Total committed heap usage (bytes)=281405857792
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/10 06:57:10 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	103m14.024s
user	0m32.282s
sys	0m4.719s
15/04/10 06:57:14 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 25
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-25-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4006527357453058571.jar tmpDir=null
15/04/10 06:57:17 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 06:57:17 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 06:57:18 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 06:57:18 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 06:57:18 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4430
15/04/10 06:57:19 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4430
15/04/10 06:57:19 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4430/
15/04/10 06:57:19 INFO mapreduce.Job: Running job: job_1422482982071_4430
15/04/10 06:57:25 INFO mapreduce.Job: Job job_1422482982071_4430 running in uber mode : false
15/04/10 06:57:25 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 06:57:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4430_m_000030_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 06:57:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4430_m_000026_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 06:57:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4430_m_000047_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 06:57:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4430_m_000005_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 06:57:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4430_m_000072_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 06:57:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4430_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 06:57:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4430_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 06:57:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4430_m_000067_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 06:57:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4430_m_000042_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 06:57:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4430_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 06:57:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4430_m_000033_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 06:57:36 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 06:57:42 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 06:57:49 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 06:57:55 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 06:58:01 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 06:58:07 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 06:58:13 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 06:58:19 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 06:58:25 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 06:58:31 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 06:58:37 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 06:58:43 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 06:58:49 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 06:58:55 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 06:59:01 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 06:59:07 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 06:59:13 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 06:59:18 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 06:59:24 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 06:59:30 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 06:59:36 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 06:59:42 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 06:59:48 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 06:59:54 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 07:00:00 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 07:00:06 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 07:00:13 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 07:00:19 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 07:00:25 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 07:00:31 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 07:00:37 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 07:00:43 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 07:00:49 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 07:00:55 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 07:01:00 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 07:01:06 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 07:01:12 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 07:01:18 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 07:01:24 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 07:01:30 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 07:01:36 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 07:01:42 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 07:01:48 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 07:01:54 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 07:02:00 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 07:02:06 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 07:02:12 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 07:02:18 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 07:02:24 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 07:02:30 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 07:02:36 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 07:02:42 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 07:02:48 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 07:02:52 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 07:02:58 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 07:03:04 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 07:03:10 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 07:03:16 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 07:03:22 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 07:03:28 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 07:03:34 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 07:03:40 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 07:03:46 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 07:03:52 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 07:03:59 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 07:04:06 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 07:04:13 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 07:04:15 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 07:04:16 INFO mapreduce.Job:  map 69% reduce 0%
15/04/10 07:04:17 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 07:04:18 INFO mapreduce.Job:  map 72% reduce 0%
15/04/10 07:04:19 INFO mapreduce.Job:  map 73% reduce 0%
15/04/10 07:04:20 INFO mapreduce.Job:  map 75% reduce 0%
15/04/10 07:04:21 INFO mapreduce.Job:  map 77% reduce 0%
15/04/10 07:04:22 INFO mapreduce.Job:  map 78% reduce 0%
15/04/10 07:04:23 INFO mapreduce.Job:  map 80% reduce 0%
15/04/10 07:04:24 INFO mapreduce.Job:  map 82% reduce 0%
15/04/10 07:04:26 INFO mapreduce.Job:  map 83% reduce 11%
15/04/10 07:04:27 INFO mapreduce.Job:  map 83% reduce 16%
15/04/10 07:04:28 INFO mapreduce.Job:  map 85% reduce 16%
15/04/10 07:04:29 INFO mapreduce.Job:  map 86% reduce 18%
15/04/10 07:04:30 INFO mapreduce.Job:  map 87% reduce 19%
15/04/10 07:04:31 INFO mapreduce.Job:  map 88% reduce 19%
15/04/10 07:04:32 INFO mapreduce.Job:  map 89% reduce 21%
15/04/10 07:04:33 INFO mapreduce.Job:  map 91% reduce 23%
15/04/10 07:04:34 INFO mapreduce.Job:  map 92% reduce 23%
15/04/10 07:04:35 INFO mapreduce.Job:  map 92% reduce 25%
15/04/10 07:04:36 INFO mapreduce.Job:  map 93% reduce 25%
15/04/10 07:04:37 INFO mapreduce.Job:  map 94% reduce 25%
15/04/10 07:04:38 INFO mapreduce.Job:  map 95% reduce 27%
15/04/10 07:04:39 INFO mapreduce.Job:  map 95% reduce 28%
15/04/10 07:04:41 INFO mapreduce.Job:  map 95% reduce 29%
15/04/10 07:04:43 INFO mapreduce.Job:  map 96% reduce 29%
15/04/10 07:04:52 INFO mapreduce.Job:  map 96% reduce 30%
15/04/10 07:05:09 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 07:05:12 INFO mapreduce.Job:  map 97% reduce 31%
15/04/10 07:05:13 INFO mapreduce.Job:  map 98% reduce 31%
15/04/10 07:05:14 INFO mapreduce.Job:  map 99% reduce 31%
15/04/10 07:05:16 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 07:05:20 INFO mapreduce.Job:  map 100% reduce 32%
15/04/10 07:05:21 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 07:05:28 INFO mapreduce.Job:  map 100% reduce 34%
15/04/10 07:05:29 INFO mapreduce.Job:  map 100% reduce 35%
15/04/10 07:05:30 INFO mapreduce.Job:  map 100% reduce 38%
15/04/10 07:05:31 INFO mapreduce.Job:  map 100% reduce 40%
15/04/10 07:05:32 INFO mapreduce.Job:  map 100% reduce 41%
15/04/10 07:05:33 INFO mapreduce.Job:  map 100% reduce 44%
15/04/10 07:05:34 INFO mapreduce.Job:  map 100% reduce 46%
15/04/10 07:05:35 INFO mapreduce.Job:  map 100% reduce 48%
15/04/10 07:05:36 INFO mapreduce.Job:  map 100% reduce 51%
15/04/10 07:05:38 INFO mapreduce.Job:  map 100% reduce 53%
15/04/10 07:05:39 INFO mapreduce.Job:  map 100% reduce 55%
15/04/10 07:05:40 INFO mapreduce.Job:  map 100% reduce 58%
15/04/10 07:05:41 INFO mapreduce.Job:  map 100% reduce 60%
15/04/10 07:05:43 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 07:05:45 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 07:05:46 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 07:05:47 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 07:05:55 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 07:06:55 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 07:08:16 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 07:09:18 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 07:10:13 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 07:11:04 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 07:11:55 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 07:12:51 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 07:13:59 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 07:14:58 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 07:15:31 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 07:16:07 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 07:16:36 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 07:17:20 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 07:17:50 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 07:18:25 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 07:19:05 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 07:19:36 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 07:20:49 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 07:21:59 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 07:22:42 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 07:23:13 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 07:24:37 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 07:26:00 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 07:28:13 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 07:29:53 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 07:31:08 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 07:31:28 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 07:33:33 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 07:35:41 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 07:38:28 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 07:47:47 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 07:55:53 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 08:14:28 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 08:28:43 INFO mapreduce.Job: Job job_1422482982071_4430 completed successfully
15/04/10 08:28:43 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16787700591
		FILE: Number of bytes written=33584951569
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=300
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Failed map tasks=11
		Killed reduce tasks=1
		Launched map tasks=86
		Launched reduce tasks=26
		Other local map tasks=11
		Data-local map tasks=53
		Rack-local map tasks=22
		Total time spent by all maps in occupied slots (ms)=63354438
		Total time spent by all reduces in occupied slots (ms)=92032868
		Total time spent by all map tasks (ms)=31677219
		Total time spent by all reduce tasks (ms)=46016434
		Total vcore-seconds taken by all map tasks=31677219
		Total vcore-seconds taken by all reduce tasks=46016434
		Total megabyte-seconds taken by all map tasks=256458765024
		Total megabyte-seconds taken by all reduce tasks=552197208000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787711673
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787711673
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1875
		Failed Shuffles=0
		Merged Map outputs=1875
		GC time elapsed (ms)=186739
		CPU time spent (ms)=87686550
		Physical memory (bytes) snapshot=168873693184
		Virtual memory (bytes) snapshot=1022157742080
		Total committed heap usage (bytes)=260355813376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/10 08:28:43 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	91m33.103s
user	0m32.535s
sys	0m4.146s
15/04/10 08:28:46 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 25
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-25-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob402407464583489886.jar tmpDir=null
15/04/10 08:28:48 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 08:28:49 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 08:28:50 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 08:28:50 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 08:28:50 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4435
15/04/10 08:28:51 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4435
15/04/10 08:28:51 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4435/
15/04/10 08:28:51 INFO mapreduce.Job: Running job: job_1422482982071_4435
15/04/10 08:28:56 INFO mapreduce.Job: Job job_1422482982071_4435 running in uber mode : false
15/04/10 08:28:56 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 08:29:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4435_m_000004_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 08:29:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4435_m_000068_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 08:29:06 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 08:29:12 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 08:29:18 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 08:29:27 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 08:29:33 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 08:29:39 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 08:29:46 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 08:29:54 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 08:30:00 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 08:30:06 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 08:30:14 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 08:30:22 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 08:30:28 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 08:30:34 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 08:30:41 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 08:30:47 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 08:30:53 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 08:30:59 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 08:31:05 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 08:31:11 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 08:31:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4435_m_000054_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 08:31:19 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 08:31:25 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 08:31:31 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 08:31:37 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 08:31:42 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 08:31:48 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 08:31:53 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 08:31:59 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 08:32:05 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 08:32:11 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 08:32:17 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 08:32:23 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 08:32:29 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 08:32:35 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 08:32:41 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 08:32:47 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 08:32:53 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 08:32:59 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 08:33:06 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 08:33:11 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 08:33:17 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 08:33:23 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 08:33:29 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 08:33:35 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 08:33:41 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 08:33:47 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 08:33:53 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 08:33:59 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 08:34:05 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 08:34:11 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 08:34:17 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 08:34:23 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 08:34:29 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 08:34:35 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 08:34:41 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 08:34:44 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 08:34:50 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 08:34:56 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 08:35:02 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 08:35:08 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 08:35:14 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 08:35:20 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 08:35:26 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 08:35:32 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 08:35:38 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 08:35:45 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 08:35:50 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 08:35:53 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 08:35:56 INFO mapreduce.Job:  map 69% reduce 0%
15/04/10 08:35:57 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 08:35:58 INFO mapreduce.Job:  map 71% reduce 0%
15/04/10 08:35:59 INFO mapreduce.Job:  map 73% reduce 0%
15/04/10 08:36:00 INFO mapreduce.Job:  map 74% reduce 0%
15/04/10 08:36:01 INFO mapreduce.Job:  map 76% reduce 0%
15/04/10 08:36:02 INFO mapreduce.Job:  map 78% reduce 0%
15/04/10 08:36:03 INFO mapreduce.Job:  map 79% reduce 10%
15/04/10 08:36:04 INFO mapreduce.Job:  map 80% reduce 11%
15/04/10 08:36:05 INFO mapreduce.Job:  map 81% reduce 11%
15/04/10 08:36:06 INFO mapreduce.Job:  map 83% reduce 15%
15/04/10 08:36:07 INFO mapreduce.Job:  map 84% reduce 15%
15/04/10 08:36:08 INFO mapreduce.Job:  map 86% reduce 15%
15/04/10 08:36:09 INFO mapreduce.Job:  map 86% reduce 19%
15/04/10 08:36:10 INFO mapreduce.Job:  map 89% reduce 19%
15/04/10 08:36:11 INFO mapreduce.Job:  map 90% reduce 20%
15/04/10 08:36:12 INFO mapreduce.Job:  map 91% reduce 23%
15/04/10 08:36:13 INFO mapreduce.Job:  map 91% reduce 24%
15/04/10 08:36:15 INFO mapreduce.Job:  map 92% reduce 24%
15/04/10 08:36:16 INFO mapreduce.Job:  map 93% reduce 26%
15/04/10 08:36:18 INFO mapreduce.Job:  map 94% reduce 26%
15/04/10 08:36:19 INFO mapreduce.Job:  map 94% reduce 27%
15/04/10 08:36:20 INFO mapreduce.Job:  map 95% reduce 28%
15/04/10 08:36:21 INFO mapreduce.Job:  map 96% reduce 28%
15/04/10 08:36:22 INFO mapreduce.Job:  map 96% reduce 29%
15/04/10 08:36:23 INFO mapreduce.Job:  map 97% reduce 29%
15/04/10 08:36:25 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 08:36:28 INFO mapreduce.Job:  map 98% reduce 30%
15/04/10 08:36:29 INFO mapreduce.Job:  map 98% reduce 31%
15/04/10 08:36:43 INFO mapreduce.Job:  map 99% reduce 31%
15/04/10 08:36:44 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 08:36:56 INFO mapreduce.Job:  map 99% reduce 33%
15/04/10 08:37:30 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 08:38:15 INFO mapreduce.Job:  map 100% reduce 34%
15/04/10 08:38:16 INFO mapreduce.Job:  map 100% reduce 35%
15/04/10 08:38:17 INFO mapreduce.Job:  map 100% reduce 36%
15/04/10 08:38:18 INFO mapreduce.Job:  map 100% reduce 40%
15/04/10 08:38:19 INFO mapreduce.Job:  map 100% reduce 42%
15/04/10 08:38:20 INFO mapreduce.Job:  map 100% reduce 43%
15/04/10 08:38:21 INFO mapreduce.Job:  map 100% reduce 47%
15/04/10 08:38:22 INFO mapreduce.Job:  map 100% reduce 48%
15/04/10 08:38:23 INFO mapreduce.Job:  map 100% reduce 50%
15/04/10 08:38:24 INFO mapreduce.Job:  map 100% reduce 54%
15/04/10 08:38:25 INFO mapreduce.Job:  map 100% reduce 55%
15/04/10 08:38:26 INFO mapreduce.Job:  map 100% reduce 56%
15/04/10 08:38:27 INFO mapreduce.Job:  map 100% reduce 59%
15/04/10 08:38:28 INFO mapreduce.Job:  map 100% reduce 61%
15/04/10 08:38:30 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 08:38:31 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 08:38:33 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 08:38:34 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 08:38:37 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 08:39:35 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 08:40:41 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 08:41:50 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 08:42:40 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 08:43:31 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 08:44:17 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 08:45:14 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 08:46:23 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 08:47:29 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 08:47:52 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 08:48:22 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 08:49:02 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 08:49:35 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 08:50:20 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 08:50:54 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 08:51:08 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 08:52:00 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 08:53:01 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 08:54:16 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 08:55:01 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 08:55:22 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 08:57:16 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 08:58:32 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 09:01:31 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 09:02:57 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 09:04:14 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 09:05:36 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 09:06:27 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 09:07:31 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 09:11:10 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 09:19:46 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 09:27:49 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 09:46:51 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 10:01:16 INFO mapreduce.Job: Job job_1422482982071_4435 completed successfully
15/04/10 10:01:17 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16787700591
		FILE: Number of bytes written=33584951569
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=300
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Failed map tasks=3
		Killed reduce tasks=1
		Launched map tasks=78
		Launched reduce tasks=26
		Other local map tasks=3
		Data-local map tasks=54
		Rack-local map tasks=21
		Total time spent by all maps in occupied slots (ms)=64728264
		Total time spent by all reduces in occupied slots (ms)=95105442
		Total time spent by all map tasks (ms)=32364132
		Total time spent by all reduce tasks (ms)=47552721
		Total vcore-seconds taken by all map tasks=32364132
		Total vcore-seconds taken by all reduce tasks=47552721
		Total megabyte-seconds taken by all map tasks=262020012672
		Total megabyte-seconds taken by all reduce tasks=570632652000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787711673
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787711673
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1875
		Failed Shuffles=0
		Merged Map outputs=1875
		GC time elapsed (ms)=197445
		CPU time spent (ms)=88522270
		Physical memory (bytes) snapshot=168419090432
		Virtual memory (bytes) snapshot=1022964662272
		Total committed heap usage (bytes)=260355436544
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/10 10:01:17 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	92m33.160s
user	0m30.663s
sys	0m4.092s
15/04/10 10:01:19 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 25
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-25-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7537911859504188493.jar tmpDir=null
15/04/10 10:01:22 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 10:01:22 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 10:01:23 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 10:01:23 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 10:01:24 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4441
15/04/10 10:01:24 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4441
15/04/10 10:01:24 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4441/
15/04/10 10:01:24 INFO mapreduce.Job: Running job: job_1422482982071_4441
15/04/10 10:01:31 INFO mapreduce.Job: Job job_1422482982071_4441 running in uber mode : false
15/04/10 10:01:31 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 10:01:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_m_000023_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:01:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_m_000058_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:01:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_m_000010_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:01:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_m_000044_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:01:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_m_000004_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:01:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_m_000048_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:01:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_m_000067_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:01:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:01:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_m_000038_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:01:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_m_000001_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:01:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_m_000038_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:01:43 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 10:01:49 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 10:01:55 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 10:02:01 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 10:02:07 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 10:02:13 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 10:02:19 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 10:02:25 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 10:02:31 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 10:02:37 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 10:02:43 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 10:02:49 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 10:02:55 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 10:03:02 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 10:03:08 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 10:03:14 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 10:03:20 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 10:03:26 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 10:03:32 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 10:03:38 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 10:03:45 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 10:03:51 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 10:03:57 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 10:04:03 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 10:04:09 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 10:04:15 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 10:04:21 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 10:04:27 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 10:04:33 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 10:04:40 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 10:04:45 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 10:04:52 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 10:04:58 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 10:05:04 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 10:05:10 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 10:05:16 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 10:05:22 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 10:05:28 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 10:05:34 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 10:05:40 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 10:05:46 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 10:05:53 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 10:05:59 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 10:06:06 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 10:06:14 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 10:06:20 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 10:06:28 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 10:06:35 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 10:06:42 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 10:06:49 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 10:06:56 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 10:07:03 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 10:07:10 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 10:07:17 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 10:07:23 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 10:07:28 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 10:07:35 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 10:07:42 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 10:07:48 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 10:07:55 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 10:08:01 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 10:08:08 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 10:08:15 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 10:08:21 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 10:08:28 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 10:08:33 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 10:08:36 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 10:08:39 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 10:08:41 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 10:08:42 INFO mapreduce.Job:  map 71% reduce 0%
15/04/10 10:08:43 INFO mapreduce.Job:  map 72% reduce 0%
15/04/10 10:08:44 INFO mapreduce.Job:  map 73% reduce 0%
15/04/10 10:08:46 INFO mapreduce.Job:  map 75% reduce 0%
15/04/10 10:08:47 INFO mapreduce.Job:  map 76% reduce 7%
15/04/10 10:08:48 INFO mapreduce.Job:  map 76% reduce 9%
15/04/10 10:08:49 INFO mapreduce.Job:  map 77% reduce 9%
15/04/10 10:08:50 INFO mapreduce.Job:  map 79% reduce 11%
15/04/10 10:08:51 INFO mapreduce.Job:  map 81% reduce 11%
15/04/10 10:08:52 INFO mapreduce.Job:  map 82% reduce 11%
15/04/10 10:08:53 INFO mapreduce.Job:  map 84% reduce 16%
15/04/10 10:08:54 INFO mapreduce.Job:  map 85% reduce 17%
15/04/10 10:08:56 INFO mapreduce.Job:  map 85% reduce 18%
15/04/10 10:08:57 INFO mapreduce.Job:  map 85% reduce 19%
15/04/10 10:08:58 INFO mapreduce.Job:  map 86% reduce 19%
15/04/10 10:08:59 INFO mapreduce.Job:  map 87% reduce 20%
15/04/10 10:09:00 INFO mapreduce.Job:  map 88% reduce 20%
15/04/10 10:09:02 INFO mapreduce.Job:  map 88% reduce 21%
15/04/10 10:09:05 INFO mapreduce.Job:  map 89% reduce 22%
15/04/10 10:09:07 INFO mapreduce.Job:  map 90% reduce 22%
15/04/10 10:09:08 INFO mapreduce.Job:  map 90% reduce 23%
15/04/10 10:09:09 INFO mapreduce.Job:  map 90% reduce 24%
15/04/10 10:09:11 INFO mapreduce.Job:  map 91% reduce 24%
15/04/10 10:09:15 INFO mapreduce.Job:  map 91% reduce 25%
15/04/10 10:09:17 INFO mapreduce.Job:  map 92% reduce 25%
15/04/10 10:09:20 INFO mapreduce.Job:  map 93% reduce 26%
15/04/10 10:09:23 INFO mapreduce.Job:  map 94% reduce 26%
15/04/10 10:09:24 INFO mapreduce.Job:  map 94% reduce 27%
15/04/10 10:09:26 INFO mapreduce.Job:  map 96% reduce 27%
15/04/10 10:09:27 INFO mapreduce.Job:  map 96% reduce 28%
15/04/10 10:09:29 INFO mapreduce.Job:  map 96% reduce 29%
15/04/10 10:09:30 INFO mapreduce.Job:  map 96% reduce 30%
15/04/10 10:09:31 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 10:09:34 INFO mapreduce.Job:  map 98% reduce 30%
15/04/10 10:09:35 INFO mapreduce.Job:  map 99% reduce 31%
15/04/10 10:09:38 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 10:09:49 INFO mapreduce.Job:  map 100% reduce 32%
15/04/10 10:09:50 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 10:09:56 INFO mapreduce.Job:  map 100% reduce 34%
15/04/10 10:09:58 INFO mapreduce.Job:  map 100% reduce 37%
15/04/10 10:09:59 INFO mapreduce.Job:  map 100% reduce 39%
15/04/10 10:10:00 INFO mapreduce.Job:  map 100% reduce 40%
15/04/10 10:10:01 INFO mapreduce.Job:  map 100% reduce 43%
15/04/10 10:10:02 INFO mapreduce.Job:  map 100% reduce 45%
15/04/10 10:10:03 INFO mapreduce.Job:  map 100% reduce 46%
15/04/10 10:10:04 INFO mapreduce.Job:  map 100% reduce 51%
15/04/10 10:10:05 INFO mapreduce.Job:  map 100% reduce 54%
15/04/10 10:10:07 INFO mapreduce.Job:  map 100% reduce 57%
15/04/10 10:10:08 INFO mapreduce.Job:  map 100% reduce 59%
15/04/10 10:10:10 INFO mapreduce.Job:  map 100% reduce 60%
15/04/10 10:10:11 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 10:10:13 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 10:10:14 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 10:10:16 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 10:10:22 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 10:10:25 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 10:11:17 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 10:12:22 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 10:13:24 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 10:14:27 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 10:14:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000021_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:14:34 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 10:14:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000020_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:14:42 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 10:14:44 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 10:14:53 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 10:14:59 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 10:15:03 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 10:15:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000023_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:15:10 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 10:15:20 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 10:15:32 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 10:15:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000022_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:15:39 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 10:15:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000017_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:15:46 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 10:15:49 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 10:15:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000003_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:15:52 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 10:15:56 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 10:16:01 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 10:16:02 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 10:16:09 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 10:16:17 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 10:16:27 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 10:16:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000024_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:16:29 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 10:16:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000004_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:16:34 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 10:16:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000019_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:16:37 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 10:16:41 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 10:16:44 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 10:16:47 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 10:16:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000018_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:16:49 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 10:16:54 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 10:17:00 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 10:17:10 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 10:17:28 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 10:18:46 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 10:19:50 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 10:19:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000014_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:19:55 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 10:20:06 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 10:20:09 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 10:20:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000015_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:20:16 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 10:20:21 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 10:20:23 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000011_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:20:24 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 10:20:27 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 10:20:33 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 10:20:35 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 10:20:39 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 10:20:45 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 10:21:00 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 10:21:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000001_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:21:03 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 10:21:14 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 10:21:17 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 10:21:27 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 10:21:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000002_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:21:34 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 10:21:44 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 10:21:51 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 10:21:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000009_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:22:00 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 10:22:08 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 10:22:11 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 10:22:18 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 10:22:27 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 10:22:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000010_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:22:32 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 10:22:38 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 10:22:43 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 10:22:52 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 10:23:01 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 10:23:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000012_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:23:26 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 10:23:36 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 10:23:45 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 10:23:59 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 10:24:39 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 10:24:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000013_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:24:50 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 10:25:01 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 10:25:04 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 10:25:17 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 10:26:04 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 10:27:00 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 10:27:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000008_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:27:34 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 10:27:45 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 10:28:06 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 10:28:09 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 10:28:48 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 10:29:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000000_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:29:29 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 10:29:39 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 10:29:51 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 10:30:07 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 10:30:55 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 10:31:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000016_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:31:07 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 10:31:18 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 10:31:19 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 10:31:31 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 10:31:46 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 10:32:44 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 10:33:38 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 10:34:34 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 10:36:14 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 10:37:21 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 10:38:00 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 10:38:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000007_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:38:18 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 10:38:29 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 10:38:35 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 10:38:48 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 10:40:01 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 10:41:28 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 10:44:03 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 10:45:21 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 10:46:31 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 10:47:46 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 10:48:29 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 10:49:36 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 10:52:12 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 10:53:26 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 10:53:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000006_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:53:27 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 10:53:38 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 10:54:09 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 10:55:29 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 10:59:29 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 11:07:48 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 11:19:45 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 11:23:02 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 11:25:27 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000005_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 11:25:28 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 11:35:04 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 11:43:09 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 12:02:46 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 12:08:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000005_1, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 12:08:49 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 12:56:25 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 13:02:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4441_r_000005_2, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:02:14 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 13:50:57 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 13:56:37 INFO mapreduce.Job: Job job_1422482982071_4441 failed with state FAILED due to: Task failed task_1422482982071_4441_r_000005
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/10 13:56:37 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=15366078100
		FILE: Number of bytes written=32163234159
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3607058
		HDFS: Number of read operations=297
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=48
	Job Counters 
		Failed map tasks=11
		Failed reduce tasks=28
		Killed reduce tasks=4
		Launched map tasks=86
		Launched reduce tasks=56
		Other local map tasks=11
		Data-local map tasks=50
		Rack-local map tasks=25
		Total time spent by all maps in occupied slots (ms)=66849586
		Total time spent by all reduces in occupied slots (ms)=175208552
		Total time spent by all map tasks (ms)=33424793
		Total time spent by all reduce tasks (ms)=87604276
		Total vcore-seconds taken by all map tasks=33424793
		Total vcore-seconds taken by all reduce tasks=87604276
		Total megabyte-seconds taken by all map tasks=270607124128
		Total megabyte-seconds taken by all reduce tasks=1051251312000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787711673
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=248601
		Reduce shuffle bytes=15366088744
		Reduce input records=1480599498
		Reduce output records=248601
		Spilled Records=3167464306
		Shuffled Maps =1800
		Failed Shuffles=0
		Merged Map outputs=1800
		GC time elapsed (ms)=150329
		CPU time spent (ms)=88054450
		Physical memory (bytes) snapshot=166584172544
		Virtual memory (bytes) snapshot=1010226954240
		Total committed heap usage (bytes)=258250461184
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3607058
15/04/10 13:56:37 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	235m20.100s
user	0m42.536s
sys	0m9.747s
15/04/10 13:56:40 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 15
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-15-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2600819306398590896.jar tmpDir=null
15/04/10 13:56:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 13:56:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 13:56:43 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 13:56:44 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 13:56:44 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4450
15/04/10 13:56:45 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4450
15/04/10 13:56:45 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4450/
15/04/10 13:56:45 INFO mapreduce.Job: Running job: job_1422482982071_4450
15/04/10 13:56:51 INFO mapreduce.Job: Job job_1422482982071_4450 running in uber mode : false
15/04/10 13:56:51 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 13:56:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4450_m_000018_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:56:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4450_m_000055_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:56:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4450_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:56:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4450_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:56:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4450_m_000005_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 13:56:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4450_m_000074_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:56:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4450_m_000052_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:56:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4450_m_000003_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:56:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4450_m_000061_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:56:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4450_m_000024_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:56:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4450_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:57:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4450_m_000024_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:57:03 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 13:57:09 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 13:57:15 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 13:57:21 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 13:57:27 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 13:57:33 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 13:57:39 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 13:57:45 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 13:57:51 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 13:57:58 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 13:58:04 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 13:58:09 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 13:58:16 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 13:58:22 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 13:58:28 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 13:58:34 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 13:58:41 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 13:58:47 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 13:58:53 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 13:58:59 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 13:59:06 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 13:59:11 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 13:59:18 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 13:59:24 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 13:59:30 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 13:59:36 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 13:59:42 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 13:59:48 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 13:59:54 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 14:00:00 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 14:00:06 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 14:00:12 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 14:00:18 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 14:00:24 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 14:00:30 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 14:00:36 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 14:00:43 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 14:00:49 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 14:00:55 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 14:01:01 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 14:01:07 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 14:01:13 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 14:01:20 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 14:01:26 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 14:01:32 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 14:01:38 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 14:01:44 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 14:01:50 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 14:01:56 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 14:02:02 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 14:02:08 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 14:02:14 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 14:02:20 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 14:02:26 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 14:02:32 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 14:02:38 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 14:02:45 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 14:02:48 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 14:02:54 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 14:03:00 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 14:03:06 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 14:03:12 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 14:03:19 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 14:03:25 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 14:03:32 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 14:03:38 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 14:03:40 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 14:03:42 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 14:03:43 INFO mapreduce.Job:  map 69% reduce 0%
15/04/10 14:03:44 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 14:03:45 INFO mapreduce.Job:  map 72% reduce 0%
15/04/10 14:03:47 INFO mapreduce.Job:  map 74% reduce 0%
15/04/10 14:03:49 INFO mapreduce.Job:  map 75% reduce 4%
15/04/10 14:03:50 INFO mapreduce.Job:  map 77% reduce 8%
15/04/10 14:03:51 INFO mapreduce.Job:  map 80% reduce 9%
15/04/10 14:03:52 INFO mapreduce.Job:  map 80% reduce 11%
15/04/10 14:03:53 INFO mapreduce.Job:  map 81% reduce 14%
15/04/10 14:03:54 INFO mapreduce.Job:  map 84% reduce 15%
15/04/10 14:03:55 INFO mapreduce.Job:  map 86% reduce 16%
15/04/10 14:03:56 INFO mapreduce.Job:  map 86% reduce 19%
15/04/10 14:03:57 INFO mapreduce.Job:  map 87% reduce 20%
15/04/10 14:03:58 INFO mapreduce.Job:  map 87% reduce 21%
15/04/10 14:04:00 INFO mapreduce.Job:  map 88% reduce 22%
15/04/10 14:04:04 INFO mapreduce.Job:  map 89% reduce 22%
15/04/10 14:04:06 INFO mapreduce.Job:  map 89% reduce 23%
15/04/10 14:04:10 INFO mapreduce.Job:  map 90% reduce 23%
15/04/10 14:04:21 INFO mapreduce.Job:  map 91% reduce 23%
15/04/10 14:04:22 INFO mapreduce.Job:  map 91% reduce 24%
15/04/10 14:04:25 INFO mapreduce.Job:  map 92% reduce 24%
15/04/10 14:04:27 INFO mapreduce.Job:  map 92% reduce 25%
15/04/10 14:04:31 INFO mapreduce.Job:  map 92% reduce 26%
15/04/10 14:04:33 INFO mapreduce.Job:  map 93% reduce 26%
15/04/10 14:04:34 INFO mapreduce.Job:  map 94% reduce 26%
15/04/10 14:04:36 INFO mapreduce.Job:  map 94% reduce 27%
15/04/10 14:04:38 INFO mapreduce.Job:  map 94% reduce 28%
15/04/10 14:04:40 INFO mapreduce.Job:  map 95% reduce 28%
15/04/10 14:04:41 INFO mapreduce.Job:  map 96% reduce 28%
15/04/10 14:04:43 INFO mapreduce.Job:  map 97% reduce 29%
15/04/10 14:04:45 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 14:04:47 INFO mapreduce.Job:  map 98% reduce 30%
15/04/10 14:04:48 INFO mapreduce.Job:  map 98% reduce 31%
15/04/10 14:04:49 INFO mapreduce.Job:  map 99% reduce 31%
15/04/10 14:04:50 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 14:04:51 INFO mapreduce.Job:  map 100% reduce 32%
15/04/10 14:04:54 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 14:05:09 INFO mapreduce.Job:  map 100% reduce 35%
15/04/10 14:05:11 INFO mapreduce.Job:  map 100% reduce 36%
15/04/10 14:05:12 INFO mapreduce.Job:  map 100% reduce 39%
15/04/10 14:05:13 INFO mapreduce.Job:  map 100% reduce 41%
15/04/10 14:05:14 INFO mapreduce.Job:  map 100% reduce 47%
15/04/10 14:05:15 INFO mapreduce.Job:  map 100% reduce 49%
15/04/10 14:05:16 INFO mapreduce.Job:  map 100% reduce 50%
15/04/10 14:05:17 INFO mapreduce.Job:  map 100% reduce 51%
15/04/10 14:05:18 INFO mapreduce.Job:  map 100% reduce 53%
15/04/10 14:05:19 INFO mapreduce.Job:  map 100% reduce 54%
15/04/10 14:05:20 INFO mapreduce.Job:  map 100% reduce 55%
15/04/10 14:05:21 INFO mapreduce.Job:  map 100% reduce 57%
15/04/10 14:05:22 INFO mapreduce.Job:  map 100% reduce 58%
15/04/10 14:05:23 INFO mapreduce.Job:  map 100% reduce 59%
15/04/10 14:05:24 INFO mapreduce.Job:  map 100% reduce 61%
15/04/10 14:05:25 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 14:05:26 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 14:05:27 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 14:05:29 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 14:05:32 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 14:07:22 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 14:09:11 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 14:11:02 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 14:12:39 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 14:14:28 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 14:16:04 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 14:17:19 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 14:18:16 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 14:19:23 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 14:20:17 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 14:21:28 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 14:22:47 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 14:24:17 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 14:25:04 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 14:25:53 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 14:27:06 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 14:28:26 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 14:29:58 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 14:31:33 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 14:32:45 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 14:33:32 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 14:35:04 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 14:36:31 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 14:37:53 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 14:42:23 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 14:43:42 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 14:48:26 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 14:59:09 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 15:03:24 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 15:14:18 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 15:17:45 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 15:30:34 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 15:42:28 INFO mapreduce.Job: Job job_1422482982071_4450 completed successfully
15/04/10 15:42:28 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=16787700561
		FILE: Number of bytes written=33583979839
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Failed map tasks=12
		Launched map tasks=87
		Launched reduce tasks=15
		Other local map tasks=12
		Data-local map tasks=52
		Rack-local map tasks=23
		Total time spent by all maps in occupied slots (ms)=64469308
		Total time spent by all reduces in occupied slots (ms)=86706748
		Total time spent by all map tasks (ms)=32234654
		Total time spent by all reduce tasks (ms)=43353374
		Total vcore-seconds taken by all map tasks=32234654
		Total vcore-seconds taken by all reduce tasks=43353374
		Total megabyte-seconds taken by all map tasks=260971758784
		Total megabyte-seconds taken by all reduce tasks=520240488000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787707173
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787707173
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1125
		Failed Shuffles=0
		Merged Map outputs=1125
		GC time elapsed (ms)=173568
		CPU time spent (ms)=88122780
		Physical memory (bytes) snapshot=167556222976
		Virtual memory (bytes) snapshot=889727393792
		Total committed heap usage (bytes)=239304491008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/10 15:42:28 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	105m50.975s
user	0m31.526s
sys	0m4.724s
15/04/10 15:42:31 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 15
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-15-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3808384213647452432.jar tmpDir=null
15/04/10 15:42:34 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 15:42:34 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 15:42:34 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 15:42:35 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 15:42:35 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4451
15/04/10 15:42:36 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4451
15/04/10 15:42:36 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4451/
15/04/10 15:42:36 INFO mapreduce.Job: Running job: job_1422482982071_4451
15/04/10 15:42:42 INFO mapreduce.Job: Job job_1422482982071_4451 running in uber mode : false
15/04/10 15:42:42 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 15:42:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4451_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 15:42:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4451_m_000004_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 15:42:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4451_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 15:42:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4451_m_000021_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 15:42:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4451_m_000008_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 15:42:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4451_m_000063_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 15:42:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4451_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 15:42:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4451_m_000022_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 15:42:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4451_m_000058_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 15:42:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4451_m_000009_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 15:42:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_4451_m_000063_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 15:42:53 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 15:42:59 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 15:43:05 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 15:43:11 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 15:43:17 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 15:43:23 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 15:43:29 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 15:43:35 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 15:43:41 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 15:43:47 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 15:43:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4451_m_000008_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 15:43:54 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 15:44:01 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 15:44:07 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 15:44:14 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 15:44:20 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 15:44:26 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 15:44:32 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 15:44:38 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 15:44:44 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 15:44:50 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 15:44:56 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 15:45:02 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 15:45:08 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 15:45:14 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 15:45:20 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 15:45:26 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 15:45:32 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 15:45:38 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 15:45:44 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 15:45:51 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 15:45:57 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 15:46:03 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 15:46:09 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 15:46:15 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 15:46:21 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 15:46:27 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 15:46:33 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 15:46:39 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 15:46:45 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 15:46:51 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 15:46:58 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 15:47:04 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 15:47:10 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 15:47:16 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 15:47:23 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 15:47:29 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 15:47:35 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 15:47:41 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 15:47:47 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 15:47:53 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 15:47:59 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 15:48:05 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 15:48:11 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 15:48:17 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 15:48:23 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 15:48:29 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 15:48:35 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 15:48:41 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 15:48:47 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 15:48:53 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 15:48:59 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 15:49:03 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 15:49:09 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 15:49:16 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 15:49:20 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 15:49:25 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 15:49:28 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 15:49:29 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 15:49:31 INFO mapreduce.Job:  map 69% reduce 0%
15/04/10 15:49:33 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 15:49:34 INFO mapreduce.Job:  map 71% reduce 0%
15/04/10 15:49:35 INFO mapreduce.Job:  map 72% reduce 0%
15/04/10 15:49:37 INFO mapreduce.Job:  map 73% reduce 0%
15/04/10 15:49:38 INFO mapreduce.Job:  map 75% reduce 5%
15/04/10 15:49:39 INFO mapreduce.Job:  map 76% reduce 8%
15/04/10 15:49:40 INFO mapreduce.Job:  map 77% reduce 9%
15/04/10 15:49:41 INFO mapreduce.Job:  map 79% reduce 11%
15/04/10 15:49:42 INFO mapreduce.Job:  map 80% reduce 13%
15/04/10 15:49:43 INFO mapreduce.Job:  map 82% reduce 13%
15/04/10 15:49:44 INFO mapreduce.Job:  map 83% reduce 15%
15/04/10 15:49:45 INFO mapreduce.Job:  map 83% reduce 17%
15/04/10 15:49:46 INFO mapreduce.Job:  map 84% reduce 17%
15/04/10 15:49:47 INFO mapreduce.Job:  map 85% reduce 17%
15/04/10 15:49:48 INFO mapreduce.Job:  map 85% reduce 19%
15/04/10 15:49:49 INFO mapreduce.Job:  map 86% reduce 20%
15/04/10 15:49:50 INFO mapreduce.Job:  map 87% reduce 20%
15/04/10 15:49:51 INFO mapreduce.Job:  map 88% reduce 21%
15/04/10 15:49:53 INFO mapreduce.Job:  map 88% reduce 22%
15/04/10 15:49:54 INFO mapreduce.Job:  map 90% reduce 22%
15/04/10 15:49:56 INFO mapreduce.Job:  map 90% reduce 23%
15/04/10 15:49:57 INFO mapreduce.Job:  map 91% reduce 24%
15/04/10 15:50:13 INFO mapreduce.Job:  map 92% reduce 24%
15/04/10 15:50:14 INFO mapreduce.Job:  map 92% reduce 25%
15/04/10 15:50:19 INFO mapreduce.Job:  map 92% reduce 26%
15/04/10 15:50:21 INFO mapreduce.Job:  map 93% reduce 26%
15/04/10 15:50:26 INFO mapreduce.Job:  map 93% reduce 27%
15/04/10 15:50:28 INFO mapreduce.Job:  map 94% reduce 27%
15/04/10 15:50:32 INFO mapreduce.Job:  map 95% reduce 28%
15/04/10 15:50:37 INFO mapreduce.Job:  map 95% reduce 29%
15/04/10 15:50:40 INFO mapreduce.Job:  map 96% reduce 29%
15/04/10 15:50:42 INFO mapreduce.Job:  map 96% reduce 30%
15/04/10 15:50:44 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 15:50:50 INFO mapreduce.Job:  map 98% reduce 31%
15/04/10 15:50:57 INFO mapreduce.Job:  map 98% reduce 32%
15/04/10 15:51:00 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 15:51:08 INFO mapreduce.Job:  map 99% reduce 33%
15/04/10 15:51:14 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 15:51:59 INFO mapreduce.Job:  map 100% reduce 35%
15/04/10 15:52:00 INFO mapreduce.Job:  map 100% reduce 42%
15/04/10 15:52:02 INFO mapreduce.Job:  map 100% reduce 43%
15/04/10 15:52:03 INFO mapreduce.Job:  map 100% reduce 46%
15/04/10 15:52:05 INFO mapreduce.Job:  map 100% reduce 47%
15/04/10 15:52:06 INFO mapreduce.Job:  map 100% reduce 50%
15/04/10 15:52:08 INFO mapreduce.Job:  map 100% reduce 51%
15/04/10 15:52:09 INFO mapreduce.Job:  map 100% reduce 54%
15/04/10 15:52:11 INFO mapreduce.Job:  map 100% reduce 55%
15/04/10 15:52:12 INFO mapreduce.Job:  map 100% reduce 58%
15/04/10 15:52:14 INFO mapreduce.Job:  map 100% reduce 59%
15/04/10 15:52:15 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 15:52:17 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 15:52:18 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 15:52:20 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 15:52:24 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 15:54:07 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 15:55:58 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 15:57:47 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 15:59:23 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 16:01:17 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 16:02:40 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 16:03:58 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 16:05:09 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 16:05:58 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 16:07:03 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 16:08:06 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 16:09:28 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 16:10:35 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 16:11:26 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 16:12:25 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 16:13:37 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 16:14:57 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 16:16:34 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 16:17:54 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 16:18:36 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 16:20:05 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 16:21:03 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 16:22:36 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 16:24:23 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 16:28:03 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 16:30:36 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 16:34:42 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 16:44:18 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 16:50:03 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 16:59:05 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 17:01:53 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 17:03:00 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 17:14:04 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 17:25:25 INFO mapreduce.Job: Job job_1422482982071_4451 completed successfully
15/04/10 17:25:25 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=16787700561
		FILE: Number of bytes written=33583979839
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Failed map tasks=12
		Launched map tasks=87
		Launched reduce tasks=15
		Other local map tasks=12
		Data-local map tasks=49
		Rack-local map tasks=26
		Total time spent by all maps in occupied slots (ms)=64681656
		Total time spent by all reduces in occupied slots (ms)=87010206
		Total time spent by all map tasks (ms)=32340828
		Total time spent by all reduce tasks (ms)=43505103
		Total vcore-seconds taken by all map tasks=32340828
		Total vcore-seconds taken by all reduce tasks=43505103
		Total megabyte-seconds taken by all map tasks=261831343488
		Total megabyte-seconds taken by all reduce tasks=522061236000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787707173
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787707173
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1125
		Failed Shuffles=0
		Merged Map outputs=1125
		GC time elapsed (ms)=210712
		CPU time spent (ms)=87564370
		Physical memory (bytes) snapshot=167215476736
		Virtual memory (bytes) snapshot=889122906112
		Total committed heap usage (bytes)=239304359936
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/10 17:25:25 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	102m56.916s
user	0m32.527s
sys	0m4.622s
15/04/10 17:25:27 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 15
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-15-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7207016951346335924.jar tmpDir=null
15/04/10 17:25:30 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 17:25:31 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 17:25:31 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 17:25:32 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 17:25:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4452
15/04/10 17:25:33 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4452
15/04/10 17:25:33 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4452/
15/04/10 17:25:33 INFO mapreduce.Job: Running job: job_1422482982071_4452
15/04/10 17:25:39 INFO mapreduce.Job: Job job_1422482982071_4452 running in uber mode : false
15/04/10 17:25:39 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 17:25:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4452_m_000020_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:25:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4452_m_000057_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:25:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4452_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:25:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4452_m_000044_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:25:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4452_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:25:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4452_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:25:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4452_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:25:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4452_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:25:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4452_m_000056_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:25:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4452_m_000070_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:25:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4452_m_000034_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:25:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4452_m_000041_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:25:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4452_m_000068_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:25:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4452_m_000068_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:25:50 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 17:25:56 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 17:25:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4452_m_000067_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:26:02 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 17:26:09 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 17:26:15 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 17:26:21 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 17:26:27 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 17:26:34 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 17:26:40 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 17:26:46 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 17:26:52 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 17:26:58 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 17:27:04 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 17:27:10 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 17:27:16 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 17:27:23 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 17:27:29 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 17:27:35 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 17:27:41 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 17:27:47 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 17:27:53 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 17:27:59 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 17:28:05 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 17:28:11 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 17:28:17 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 17:28:23 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 17:28:30 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 17:28:36 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 17:28:42 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 17:28:48 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 17:28:54 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 17:29:00 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 17:29:07 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 17:29:13 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 17:29:19 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 17:29:25 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 17:29:31 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 17:29:37 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 17:29:43 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 17:29:49 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 17:29:55 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 17:30:01 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 17:30:07 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 17:30:14 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 17:30:20 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 17:30:26 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 17:30:32 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 17:30:38 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 17:30:44 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 17:30:50 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 17:30:56 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 17:31:02 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 17:31:08 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 17:31:14 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 17:31:17 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 17:31:23 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 17:31:30 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 17:31:36 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 17:31:42 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 17:31:49 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 17:31:56 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 17:32:02 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 17:32:08 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 17:32:15 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 17:32:23 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 17:32:24 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 17:32:27 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 17:32:29 INFO mapreduce.Job:  map 69% reduce 0%
15/04/10 17:32:30 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 17:32:31 INFO mapreduce.Job:  map 71% reduce 0%
15/04/10 17:32:33 INFO mapreduce.Job:  map 73% reduce 0%
15/04/10 17:32:36 INFO mapreduce.Job:  map 74% reduce 0%
15/04/10 17:32:37 INFO mapreduce.Job:  map 75% reduce 0%
15/04/10 17:32:38 INFO mapreduce.Job:  map 76% reduce 8%
15/04/10 17:32:39 INFO mapreduce.Job:  map 77% reduce 10%
15/04/10 17:32:40 INFO mapreduce.Job:  map 78% reduce 10%
15/04/10 17:32:41 INFO mapreduce.Job:  map 81% reduce 12%
15/04/10 17:32:42 INFO mapreduce.Job:  map 81% reduce 13%
15/04/10 17:32:43 INFO mapreduce.Job:  map 82% reduce 13%
15/04/10 17:32:44 INFO mapreduce.Job:  map 83% reduce 16%
15/04/10 17:32:45 INFO mapreduce.Job:  map 85% reduce 17%
15/04/10 17:32:46 INFO mapreduce.Job:  map 86% reduce 17%
15/04/10 17:32:47 INFO mapreduce.Job:  map 87% reduce 19%
15/04/10 17:32:48 INFO mapreduce.Job:  map 87% reduce 21%
15/04/10 17:32:49 INFO mapreduce.Job:  map 88% reduce 21%
15/04/10 17:32:50 INFO mapreduce.Job:  map 89% reduce 22%
15/04/10 17:32:52 INFO mapreduce.Job:  map 89% reduce 23%
15/04/10 17:32:59 INFO mapreduce.Job:  map 90% reduce 23%
15/04/10 17:33:05 INFO mapreduce.Job:  map 91% reduce 23%
15/04/10 17:33:07 INFO mapreduce.Job:  map 91% reduce 24%
15/04/10 17:33:18 INFO mapreduce.Job:  map 91% reduce 25%
15/04/10 17:33:19 INFO mapreduce.Job:  map 92% reduce 25%
15/04/10 17:33:23 INFO mapreduce.Job:  map 93% reduce 25%
15/04/10 17:33:24 INFO mapreduce.Job:  map 93% reduce 26%
15/04/10 17:33:25 INFO mapreduce.Job:  map 94% reduce 26%
15/04/10 17:33:27 INFO mapreduce.Job:  map 94% reduce 27%
15/04/10 17:33:28 INFO mapreduce.Job:  map 95% reduce 27%
15/04/10 17:33:30 INFO mapreduce.Job:  map 95% reduce 28%
15/04/10 17:33:31 INFO mapreduce.Job:  map 96% reduce 28%
15/04/10 17:33:32 INFO mapreduce.Job:  map 97% reduce 29%
15/04/10 17:33:34 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 17:33:49 INFO mapreduce.Job:  map 97% reduce 31%
15/04/10 17:33:51 INFO mapreduce.Job:  map 99% reduce 31%
15/04/10 17:33:52 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 17:33:56 INFO mapreduce.Job:  map 100% reduce 32%
15/04/10 17:33:57 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 17:34:10 INFO mapreduce.Job:  map 100% reduce 35%
15/04/10 17:34:11 INFO mapreduce.Job:  map 100% reduce 38%
15/04/10 17:34:13 INFO mapreduce.Job:  map 100% reduce 41%
15/04/10 17:34:14 INFO mapreduce.Job:  map 100% reduce 42%
15/04/10 17:34:16 INFO mapreduce.Job:  map 100% reduce 48%
15/04/10 17:34:17 INFO mapreduce.Job:  map 100% reduce 49%
15/04/10 17:34:19 INFO mapreduce.Job:  map 100% reduce 53%
15/04/10 17:34:20 INFO mapreduce.Job:  map 100% reduce 54%
15/04/10 17:34:22 INFO mapreduce.Job:  map 100% reduce 57%
15/04/10 17:34:23 INFO mapreduce.Job:  map 100% reduce 58%
15/04/10 17:34:25 INFO mapreduce.Job:  map 100% reduce 61%
15/04/10 17:34:26 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 17:34:28 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 17:34:29 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 17:34:30 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 17:34:33 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 17:36:16 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 17:38:11 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 17:40:13 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 17:41:32 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 17:43:41 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 17:45:03 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 17:46:28 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 17:47:14 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 17:48:18 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 17:49:18 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 17:50:21 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 17:51:46 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 17:53:09 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 17:54:07 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 17:54:55 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 17:56:08 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 17:57:23 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 17:58:57 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 18:00:10 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 18:01:26 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 18:02:21 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 18:03:16 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 18:05:27 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 18:06:39 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 18:10:07 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 18:13:06 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 18:16:28 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 18:26:01 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 18:31:59 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 18:40:31 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 18:43:48 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 18:44:52 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 18:56:02 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 19:07:23 INFO mapreduce.Job: Job job_1422482982071_4452 completed successfully
15/04/10 19:07:23 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=16787700561
		FILE: Number of bytes written=33583979839
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Failed map tasks=15
		Launched map tasks=90
		Launched reduce tasks=15
		Other local map tasks=15
		Data-local map tasks=53
		Rack-local map tasks=22
		Total time spent by all maps in occupied slots (ms)=64697640
		Total time spent by all reduces in occupied slots (ms)=85905762
		Total time spent by all map tasks (ms)=32348820
		Total time spent by all reduce tasks (ms)=42952881
		Total vcore-seconds taken by all map tasks=32348820
		Total vcore-seconds taken by all reduce tasks=42952881
		Total megabyte-seconds taken by all map tasks=261896046720
		Total megabyte-seconds taken by all reduce tasks=515434572000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787707173
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787707173
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1125
		Failed Shuffles=0
		Merged Map outputs=1125
		GC time elapsed (ms)=189907
		CPU time spent (ms)=87697160
		Physical memory (bytes) snapshot=167302565888
		Virtual memory (bytes) snapshot=888728338432
		Total committed heap usage (bytes)=239304151040
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/10 19:07:23 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	101m58.257s
user	0m33.225s
sys	0m4.644s
50 35
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-35-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4765782978039716439.jar tmpDir=null
15/04/10 19:07:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 19:07:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 19:07:29 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 19:07:29 INFO mapreduce.JobSubmitter: number of splits:134
15/04/10 19:07:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4458
15/04/10 19:07:30 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4458
15/04/10 19:07:30 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4458/
15/04/10 19:07:30 INFO mapreduce.Job: Running job: job_1422482982071_4458
15/04/10 19:07:36 INFO mapreduce.Job: Job job_1422482982071_4458 running in uber mode : false
15/04/10 19:07:36 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 19:07:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000038_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000006_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000031_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000011_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000082_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000020_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000073_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000014_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000058_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000088_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 19:07:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000091_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000071_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000084_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000101_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000085_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000083_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000116_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000122_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000115_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 19:07:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000119_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000114_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4458_m_000082_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:07:49 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 19:07:55 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 19:08:02 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 19:08:09 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 19:08:15 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 19:08:22 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 19:08:28 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 19:08:34 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 19:08:41 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 19:08:48 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 19:08:54 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 19:09:01 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 19:09:07 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 19:09:13 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 19:09:20 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 19:09:27 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 19:09:34 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 19:09:40 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 19:09:46 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 19:09:53 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 19:10:00 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 19:10:08 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 19:10:14 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 19:10:20 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 19:10:26 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 19:10:32 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 19:10:38 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 19:10:45 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 19:10:52 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 19:10:59 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 19:11:05 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 19:11:12 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 19:11:19 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 19:11:26 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 19:11:32 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 19:11:38 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 19:11:45 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 19:11:53 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 19:11:59 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 19:12:07 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 19:12:14 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 19:12:21 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 19:12:28 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 19:12:35 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 19:12:42 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 19:12:49 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 19:12:56 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 19:13:03 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 19:13:10 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 19:13:17 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 19:13:25 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 19:13:32 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 19:13:39 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 19:13:46 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 19:13:53 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 19:14:00 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 19:14:07 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 19:14:14 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 19:14:21 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 19:14:28 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 19:14:36 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 19:14:42 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 19:14:44 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 19:14:48 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 19:14:51 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 19:14:54 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 19:14:56 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 19:14:57 INFO mapreduce.Job:  map 67% reduce 4%
15/04/10 19:15:02 INFO mapreduce.Job:  map 68% reduce 4%
15/04/10 19:15:03 INFO mapreduce.Job:  map 68% reduce 5%
15/04/10 19:15:04 INFO mapreduce.Job:  map 69% reduce 5%
15/04/10 19:15:06 INFO mapreduce.Job:  map 70% reduce 5%
15/04/10 19:15:07 INFO mapreduce.Job:  map 70% reduce 6%
15/04/10 19:15:09 INFO mapreduce.Job:  map 71% reduce 6%
15/04/10 19:15:12 INFO mapreduce.Job:  map 72% reduce 7%
15/04/10 19:15:14 INFO mapreduce.Job:  map 73% reduce 7%
15/04/10 19:15:15 INFO mapreduce.Job:  map 74% reduce 9%
15/04/10 19:15:17 INFO mapreduce.Job:  map 75% reduce 9%
15/04/10 19:15:18 INFO mapreduce.Job:  map 75% reduce 10%
15/04/10 19:15:19 INFO mapreduce.Job:  map 76% reduce 10%
15/04/10 19:15:20 INFO mapreduce.Job:  map 77% reduce 10%
15/04/10 19:15:21 INFO mapreduce.Job:  map 77% reduce 12%
15/04/10 19:15:23 INFO mapreduce.Job:  map 78% reduce 12%
15/04/10 19:15:27 INFO mapreduce.Job:  map 78% reduce 13%
15/04/10 19:15:29 INFO mapreduce.Job:  map 79% reduce 13%
15/04/10 19:15:34 INFO mapreduce.Job:  map 80% reduce 13%
15/04/10 19:15:37 INFO mapreduce.Job:  map 80% reduce 14%
15/04/10 19:15:39 INFO mapreduce.Job:  map 81% reduce 14%
15/04/10 19:15:42 INFO mapreduce.Job:  map 81% reduce 15%
15/04/10 19:15:46 INFO mapreduce.Job:  map 82% reduce 15%
15/04/10 19:15:48 INFO mapreduce.Job:  map 83% reduce 15%
15/04/10 19:15:49 INFO mapreduce.Job:  map 83% reduce 16%
15/04/10 19:15:50 INFO mapreduce.Job:  map 85% reduce 16%
15/04/10 19:15:52 INFO mapreduce.Job:  map 87% reduce 18%
15/04/10 19:15:54 INFO mapreduce.Job:  map 87% reduce 19%
15/04/10 19:15:55 INFO mapreduce.Job:  map 88% reduce 20%
15/04/10 19:15:57 INFO mapreduce.Job:  map 89% reduce 20%
15/04/10 19:15:58 INFO mapreduce.Job:  map 89% reduce 21%
15/04/10 19:15:59 INFO mapreduce.Job:  map 90% reduce 21%
15/04/10 19:16:00 INFO mapreduce.Job:  map 90% reduce 22%
15/04/10 19:16:01 INFO mapreduce.Job:  map 92% reduce 23%
15/04/10 19:16:04 INFO mapreduce.Job:  map 93% reduce 25%
15/04/10 19:16:06 INFO mapreduce.Job:  map 94% reduce 25%
15/04/10 19:16:07 INFO mapreduce.Job:  map 95% reduce 26%
15/04/10 19:16:09 INFO mapreduce.Job:  map 96% reduce 27%
15/04/10 19:16:10 INFO mapreduce.Job:  map 96% reduce 28%
15/04/10 19:16:11 INFO mapreduce.Job:  map 97% reduce 28%
15/04/10 19:16:13 INFO mapreduce.Job:  map 97% reduce 29%
15/04/10 19:16:14 INFO mapreduce.Job:  map 98% reduce 29%
15/04/10 19:16:15 INFO mapreduce.Job:  map 99% reduce 29%
15/04/10 19:16:16 INFO mapreduce.Job:  map 99% reduce 30%
15/04/10 19:16:19 INFO mapreduce.Job:  map 99% reduce 31%
15/04/10 19:16:20 INFO mapreduce.Job:  map 100% reduce 31%
15/04/10 19:16:22 INFO mapreduce.Job:  map 100% reduce 32%
15/04/10 19:16:31 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 19:16:39 INFO mapreduce.Job:  map 100% reduce 34%
15/04/10 19:16:40 INFO mapreduce.Job:  map 100% reduce 37%
15/04/10 19:16:41 INFO mapreduce.Job:  map 100% reduce 38%
15/04/10 19:16:42 INFO mapreduce.Job:  map 100% reduce 39%
15/04/10 19:16:43 INFO mapreduce.Job:  map 100% reduce 43%
15/04/10 19:16:44 INFO mapreduce.Job:  map 100% reduce 44%
15/04/10 19:16:45 INFO mapreduce.Job:  map 100% reduce 45%
15/04/10 19:16:47 INFO mapreduce.Job:  map 100% reduce 49%
15/04/10 19:16:48 INFO mapreduce.Job:  map 100% reduce 50%
15/04/10 19:16:49 INFO mapreduce.Job:  map 100% reduce 51%
15/04/10 19:16:50 INFO mapreduce.Job:  map 100% reduce 55%
15/04/10 19:16:51 INFO mapreduce.Job:  map 100% reduce 56%
15/04/10 19:16:53 INFO mapreduce.Job:  map 100% reduce 59%
15/04/10 19:16:54 INFO mapreduce.Job:  map 100% reduce 60%
15/04/10 19:16:56 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 19:16:59 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 19:17:02 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 19:17:05 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 19:18:23 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 19:19:31 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 19:20:55 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 19:21:51 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 19:22:54 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 19:24:02 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 19:24:59 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 19:25:53 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 19:26:53 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 19:27:44 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 19:28:38 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 19:29:26 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 19:30:27 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 19:31:11 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 19:32:17 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 19:33:15 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 19:34:10 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 19:35:34 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 19:36:27 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 19:37:25 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 19:38:58 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 19:39:59 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 19:41:13 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 19:43:03 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 19:44:40 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 19:46:05 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 19:50:50 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 19:55:19 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 19:59:25 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 20:04:04 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 20:09:31 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 20:30:47 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 21:25:43 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 21:45:57 INFO mapreduce.Job: Job job_1422482982071_4458 completed successfully
15/04/10 21:45:57 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=30424174096
		FILE: Number of bytes written=60864534433
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=507
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Failed map tasks=24
		Killed reduce tasks=2
		Launched map tasks=158
		Launched reduce tasks=37
		Other local map tasks=24
		Data-local map tasks=63
		Rack-local map tasks=71
		Total time spent by all maps in occupied slots (ms)=127842280
		Total time spent by all reduces in occupied slots (ms)=174167782
		Total time spent by all map tasks (ms)=63921140
		Total time spent by all reduce tasks (ms)=87083891
		Total vcore-seconds taken by all map tasks=63921140
		Total vcore-seconds taken by all reduce tasks=87083891
		Total megabyte-seconds taken by all map tasks=517505549440
		Total megabyte-seconds taken by all reduce tasks=1045006692000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130838272
		Map output bytes=24162497276
		Map output materialized bytes=30424201960
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424201960
		Reduce input records=3130838272
		Reduce output records=325361
		Spilled Records=6261676544
		Shuffled Maps =4690
		Failed Shuffles=0
		Merged Map outputs=4690
		GC time elapsed (ms)=312278
		CPU time spent (ms)=167935370
		Physical memory (bytes) snapshot=299273080832
		Virtual memory (bytes) snapshot=1697198166016
		Total committed heap usage (bytes)=444819435520
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/10 21:45:57 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st

real	158m33.869s
user	0m35.741s
sys	0m6.732s
15/04/10 21:45:59 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 35
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-35-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3242712052424262621.jar tmpDir=null
15/04/10 21:46:02 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 21:46:02 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 21:46:03 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 21:46:03 INFO mapreduce.JobSubmitter: number of splits:134
15/04/10 21:46:04 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4461
15/04/10 21:46:04 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4461
15/04/10 21:46:04 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4461/
15/04/10 21:46:04 INFO mapreduce.Job: Running job: job_1422482982071_4461
15/04/10 21:46:11 INFO mapreduce.Job: Job job_1422482982071_4461 running in uber mode : false
15/04/10 21:46:11 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 21:46:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000022_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000009_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000008_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000051_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000055_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000042_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000004_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000034_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000026_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000065_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000093_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000044_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000114_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000133_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000121_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000059_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000115_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000074_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000131_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000124_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000042_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000059_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:46:22 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 21:46:29 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 21:46:35 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 21:46:43 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 21:46:49 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 21:46:55 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 21:47:02 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 21:47:08 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 21:47:15 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 21:47:22 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 21:47:28 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 21:47:35 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 21:47:41 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 21:47:47 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 21:47:54 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 21:48:02 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 21:48:08 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 21:48:15 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 21:48:21 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 21:48:27 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 21:48:34 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 21:48:41 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 21:48:47 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 21:48:54 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 21:49:00 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 21:49:06 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 21:49:13 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 21:49:20 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 21:49:25 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 21:49:32 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 21:49:38 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 21:49:45 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 21:49:51 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 21:49:58 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 21:50:05 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 21:50:12 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 21:50:18 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 21:50:24 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 21:50:31 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 21:50:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4461_m_000024_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:50:39 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 21:50:46 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 21:50:53 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 21:51:00 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 21:51:06 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 21:51:14 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 21:51:21 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 21:51:28 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 21:51:34 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 21:51:40 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 21:51:47 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 21:51:54 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 21:52:01 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 21:52:07 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 21:52:14 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 21:52:20 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 21:52:28 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 21:52:34 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 21:52:41 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 21:52:47 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 21:52:54 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 21:53:01 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 21:53:08 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 21:53:13 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 21:53:14 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 21:53:17 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 21:53:19 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 21:53:20 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 21:53:23 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 21:53:24 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 21:53:25 INFO mapreduce.Job:  map 70% reduce 5%
15/04/10 21:53:26 INFO mapreduce.Job:  map 71% reduce 7%
15/04/10 21:53:28 INFO mapreduce.Job:  map 72% reduce 8%
15/04/10 21:53:30 INFO mapreduce.Job:  map 73% reduce 8%
15/04/10 21:53:31 INFO mapreduce.Job:  map 73% reduce 9%
15/04/10 21:53:32 INFO mapreduce.Job:  map 74% reduce 10%
15/04/10 21:53:33 INFO mapreduce.Job:  map 75% reduce 10%
15/04/10 21:53:34 INFO mapreduce.Job:  map 76% reduce 11%
15/04/10 21:53:35 INFO mapreduce.Job:  map 76% reduce 12%
15/04/10 21:53:36 INFO mapreduce.Job:  map 77% reduce 12%
15/04/10 21:53:37 INFO mapreduce.Job:  map 77% reduce 13%
15/04/10 21:53:40 INFO mapreduce.Job:  map 78% reduce 13%
15/04/10 21:53:43 INFO mapreduce.Job:  map 78% reduce 14%
15/04/10 21:53:45 INFO mapreduce.Job:  map 79% reduce 14%
15/04/10 21:53:55 INFO mapreduce.Job:  map 80% reduce 14%
15/04/10 21:53:59 INFO mapreduce.Job:  map 81% reduce 14%
15/04/10 21:54:00 INFO mapreduce.Job:  map 81% reduce 15%
15/04/10 21:54:04 INFO mapreduce.Job:  map 82% reduce 15%
15/04/10 21:54:07 INFO mapreduce.Job:  map 83% reduce 16%
15/04/10 21:54:08 INFO mapreduce.Job:  map 83% reduce 17%
15/04/10 21:54:09 INFO mapreduce.Job:  map 84% reduce 17%
15/04/10 21:54:11 INFO mapreduce.Job:  map 85% reduce 18%
15/04/10 21:54:13 INFO mapreduce.Job:  map 86% reduce 19%
15/04/10 21:54:15 INFO mapreduce.Job:  map 87% reduce 20%
15/04/10 21:54:17 INFO mapreduce.Job:  map 89% reduce 21%
15/04/10 21:54:19 INFO mapreduce.Job:  map 89% reduce 22%
15/04/10 21:54:20 INFO mapreduce.Job:  map 90% reduce 23%
15/04/10 21:54:22 INFO mapreduce.Job:  map 91% reduce 23%
15/04/10 21:54:23 INFO mapreduce.Job:  map 91% reduce 24%
15/04/10 21:54:24 INFO mapreduce.Job:  map 92% reduce 25%
15/04/10 21:54:27 INFO mapreduce.Job:  map 92% reduce 26%
15/04/10 21:54:28 INFO mapreduce.Job:  map 93% reduce 26%
15/04/10 21:54:32 INFO mapreduce.Job:  map 94% reduce 27%
15/04/10 21:54:33 INFO mapreduce.Job:  map 95% reduce 27%
15/04/10 21:54:35 INFO mapreduce.Job:  map 95% reduce 28%
15/04/10 21:54:36 INFO mapreduce.Job:  map 96% reduce 28%
15/04/10 21:54:38 INFO mapreduce.Job:  map 96% reduce 29%
15/04/10 21:54:40 INFO mapreduce.Job:  map 97% reduce 29%
15/04/10 21:54:44 INFO mapreduce.Job:  map 98% reduce 30%
15/04/10 21:54:47 INFO mapreduce.Job:  map 98% reduce 31%
15/04/10 21:54:48 INFO mapreduce.Job:  map 99% reduce 31%
15/04/10 21:54:51 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 21:55:00 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 21:58:26 INFO mapreduce.Job:  map 100% reduce 34%
15/04/10 21:58:27 INFO mapreduce.Job:  map 100% reduce 37%
15/04/10 21:58:28 INFO mapreduce.Job:  map 100% reduce 38%
15/04/10 21:58:29 INFO mapreduce.Job:  map 100% reduce 40%
15/04/10 21:58:30 INFO mapreduce.Job:  map 100% reduce 43%
15/04/10 21:58:31 INFO mapreduce.Job:  map 100% reduce 45%
15/04/10 21:58:32 INFO mapreduce.Job:  map 100% reduce 46%
15/04/10 21:58:33 INFO mapreduce.Job:  map 100% reduce 49%
15/04/10 21:58:34 INFO mapreduce.Job:  map 100% reduce 52%
15/04/10 21:58:36 INFO mapreduce.Job:  map 100% reduce 55%
15/04/10 21:58:37 INFO mapreduce.Job:  map 100% reduce 57%
15/04/10 21:58:38 INFO mapreduce.Job:  map 100% reduce 58%
15/04/10 21:58:39 INFO mapreduce.Job:  map 100% reduce 60%
15/04/10 21:58:40 INFO mapreduce.Job:  map 100% reduce 61%
15/04/10 21:58:41 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 21:58:42 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 21:58:43 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 21:58:46 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 21:58:48 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 21:58:54 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 22:00:06 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 22:01:10 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 22:02:34 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 22:03:33 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 22:04:31 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 22:05:46 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 22:06:43 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 22:07:36 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 22:08:29 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 22:09:33 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 22:10:14 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 22:10:51 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 22:12:02 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 22:12:44 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 22:13:50 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 22:14:45 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 22:15:36 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 22:16:57 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 22:18:00 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 22:18:35 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 22:20:25 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 22:21:37 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 22:22:51 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 22:24:33 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 22:26:06 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 22:27:18 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 22:33:01 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 22:36:16 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 22:42:19 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 22:46:05 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 22:51:27 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 23:12:45 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 00:10:20 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 00:30:39 INFO mapreduce.Job: Job job_1422482982071_4461 completed successfully
15/04/11 00:30:39 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=30424216069
		FILE: Number of bytes written=60864618379
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=507
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Failed map tasks=24
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=159
		Launched reduce tasks=36
		Other local map tasks=25
		Data-local map tasks=62
		Rack-local map tasks=72
		Total time spent by all maps in occupied slots (ms)=125323206
		Total time spent by all reduces in occupied slots (ms)=186148584
		Total time spent by all map tasks (ms)=62661603
		Total time spent by all reduce tasks (ms)=93074292
		Total vcore-seconds taken by all map tasks=62661603
		Total vcore-seconds taken by all reduce tasks=93074292
		Total megabyte-seconds taken by all map tasks=507308337888
		Total megabyte-seconds taken by all reduce tasks=1116891504000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424243933
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424243933
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =4690
		Failed Shuffles=0
		Merged Map outputs=4690
		GC time elapsed (ms)=349841
		CPU time spent (ms)=165804560
		Physical memory (bytes) snapshot=300478881792
		Virtual memory (bytes) snapshot=1697006145536
		Total committed heap usage (bytes)=444817969152
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/11 00:30:39 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st

real	164m42.210s
user	0m36.553s
sys	0m6.863s
15/04/11 00:30:42 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 35
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-35-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=35 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6290386108820367868.jar tmpDir=null
15/04/11 00:30:44 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 00:30:45 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 00:30:46 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/11 00:30:46 INFO mapreduce.JobSubmitter: number of splits:134
15/04/11 00:30:46 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4463
15/04/11 00:30:47 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4463
15/04/11 00:30:47 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4463/
15/04/11 00:30:47 INFO mapreduce.Job: Running job: job_1422482982071_4463
15/04/11 00:30:53 INFO mapreduce.Job: Job job_1422482982071_4463 running in uber mode : false
15/04/11 00:30:53 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 00:30:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4463_m_000008_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 00:30:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4463_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 00:30:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4463_m_000023_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 00:30:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4463_m_000031_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 00:30:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4463_m_000021_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 00:30:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4463_m_000037_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 00:30:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4463_m_000007_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 00:30:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4463_m_000004_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 00:30:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4463_m_000075_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 00:30:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4463_m_000094_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 00:30:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4463_m_000095_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 00:30:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4463_m_000028_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 00:30:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4463_m_000113_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 00:31:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4463_m_000037_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 00:31:04 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 00:31:10 INFO mapreduce.Job:  map 2% reduce 0%
15/04/11 00:31:17 INFO mapreduce.Job:  map 3% reduce 0%
15/04/11 00:31:25 INFO mapreduce.Job:  map 4% reduce 0%
15/04/11 00:31:32 INFO mapreduce.Job:  map 5% reduce 0%
15/04/11 00:31:38 INFO mapreduce.Job:  map 6% reduce 0%
15/04/11 00:31:44 INFO mapreduce.Job:  map 7% reduce 0%
15/04/11 00:31:51 INFO mapreduce.Job:  map 8% reduce 0%
15/04/11 00:31:57 INFO mapreduce.Job:  map 9% reduce 0%
15/04/11 00:32:03 INFO mapreduce.Job:  map 10% reduce 0%
15/04/11 00:32:10 INFO mapreduce.Job:  map 11% reduce 0%
15/04/11 00:32:17 INFO mapreduce.Job:  map 12% reduce 0%
15/04/11 00:32:23 INFO mapreduce.Job:  map 13% reduce 0%
15/04/11 00:32:29 INFO mapreduce.Job:  map 14% reduce 0%
15/04/11 00:32:36 INFO mapreduce.Job:  map 15% reduce 0%
15/04/11 00:32:42 INFO mapreduce.Job:  map 16% reduce 0%
15/04/11 00:32:49 INFO mapreduce.Job:  map 17% reduce 0%
15/04/11 00:32:56 INFO mapreduce.Job:  map 18% reduce 0%
15/04/11 00:33:02 INFO mapreduce.Job:  map 19% reduce 0%
15/04/11 00:33:08 INFO mapreduce.Job:  map 20% reduce 0%
15/04/11 00:33:15 INFO mapreduce.Job:  map 21% reduce 0%
15/04/11 00:33:21 INFO mapreduce.Job:  map 22% reduce 0%
15/04/11 00:33:27 INFO mapreduce.Job:  map 23% reduce 0%
15/04/11 00:33:34 INFO mapreduce.Job:  map 24% reduce 0%
15/04/11 00:33:39 INFO mapreduce.Job:  map 25% reduce 0%
15/04/11 00:33:45 INFO mapreduce.Job:  map 26% reduce 0%
15/04/11 00:33:53 INFO mapreduce.Job:  map 27% reduce 0%
15/04/11 00:33:59 INFO mapreduce.Job:  map 28% reduce 0%
15/04/11 00:34:06 INFO mapreduce.Job:  map 29% reduce 0%
15/04/11 00:34:12 INFO mapreduce.Job:  map 30% reduce 0%
15/04/11 00:34:18 INFO mapreduce.Job:  map 31% reduce 0%
15/04/11 00:34:27 INFO mapreduce.Job:  map 32% reduce 0%
15/04/11 00:34:33 INFO mapreduce.Job:  map 33% reduce 0%
15/04/11 00:34:40 INFO mapreduce.Job:  map 34% reduce 0%
15/04/11 00:34:46 INFO mapreduce.Job:  map 35% reduce 0%
15/04/11 00:34:52 INFO mapreduce.Job:  map 36% reduce 0%
15/04/11 00:34:59 INFO mapreduce.Job:  map 37% reduce 0%
15/04/11 00:35:06 INFO mapreduce.Job:  map 38% reduce 0%
15/04/11 00:35:13 INFO mapreduce.Job:  map 39% reduce 0%
15/04/11 00:35:19 INFO mapreduce.Job:  map 40% reduce 0%
15/04/11 00:35:25 INFO mapreduce.Job:  map 41% reduce 0%
15/04/11 00:35:32 INFO mapreduce.Job:  map 42% reduce 0%
15/04/11 00:35:39 INFO mapreduce.Job:  map 43% reduce 0%
15/04/11 00:35:46 INFO mapreduce.Job:  map 44% reduce 0%
15/04/11 00:35:52 INFO mapreduce.Job:  map 45% reduce 0%
15/04/11 00:35:58 INFO mapreduce.Job:  map 46% reduce 0%
15/04/11 00:36:05 INFO mapreduce.Job:  map 47% reduce 0%
15/04/11 00:36:12 INFO mapreduce.Job:  map 48% reduce 0%
15/04/11 00:36:19 INFO mapreduce.Job:  map 49% reduce 0%
15/04/11 00:36:25 INFO mapreduce.Job:  map 50% reduce 0%
15/04/11 00:36:31 INFO mapreduce.Job:  map 51% reduce 0%
15/04/11 00:36:38 INFO mapreduce.Job:  map 52% reduce 0%
15/04/11 00:36:45 INFO mapreduce.Job:  map 53% reduce 0%
15/04/11 00:36:52 INFO mapreduce.Job:  map 54% reduce 0%
15/04/11 00:36:58 INFO mapreduce.Job:  map 55% reduce 0%
15/04/11 00:37:04 INFO mapreduce.Job:  map 56% reduce 0%
15/04/11 00:37:11 INFO mapreduce.Job:  map 57% reduce 0%
15/04/11 00:37:19 INFO mapreduce.Job:  map 58% reduce 0%
15/04/11 00:37:25 INFO mapreduce.Job:  map 59% reduce 0%
15/04/11 00:37:31 INFO mapreduce.Job:  map 60% reduce 0%
15/04/11 00:37:37 INFO mapreduce.Job:  map 61% reduce 0%
15/04/11 00:37:45 INFO mapreduce.Job:  map 62% reduce 0%
15/04/11 00:37:52 INFO mapreduce.Job:  map 63% reduce 0%
15/04/11 00:37:56 INFO mapreduce.Job:  map 64% reduce 0%
15/04/11 00:38:00 INFO mapreduce.Job:  map 65% reduce 0%
15/04/11 00:38:02 INFO mapreduce.Job:  map 66% reduce 0%
15/04/11 00:38:03 INFO mapreduce.Job:  map 67% reduce 0%
15/04/11 00:38:04 INFO mapreduce.Job:  map 68% reduce 0%
15/04/11 00:38:05 INFO mapreduce.Job:  map 70% reduce 0%
15/04/11 00:38:06 INFO mapreduce.Job:  map 72% reduce 0%
15/04/11 00:38:09 INFO mapreduce.Job:  map 73% reduce 0%
15/04/11 00:38:10 INFO mapreduce.Job:  map 74% reduce 8%
15/04/11 00:38:11 INFO mapreduce.Job:  map 74% reduce 9%
15/04/11 00:38:12 INFO mapreduce.Job:  map 75% reduce 9%
15/04/11 00:38:13 INFO mapreduce.Job:  map 76% reduce 11%
15/04/11 00:38:15 INFO mapreduce.Job:  map 77% reduce 11%
15/04/11 00:38:16 INFO mapreduce.Job:  map 78% reduce 13%
15/04/11 00:38:18 INFO mapreduce.Job:  map 79% reduce 13%
15/04/11 00:38:19 INFO mapreduce.Job:  map 79% reduce 14%
15/04/11 00:38:21 INFO mapreduce.Job:  map 80% reduce 14%
15/04/11 00:38:22 INFO mapreduce.Job:  map 80% reduce 15%
15/04/11 00:38:28 INFO mapreduce.Job:  map 81% reduce 15%
15/04/11 00:38:40 INFO mapreduce.Job:  map 82% reduce 15%
15/04/11 00:38:43 INFO mapreduce.Job:  map 82% reduce 16%
15/04/11 00:38:48 INFO mapreduce.Job:  map 83% reduce 16%
15/04/11 00:38:51 INFO mapreduce.Job:  map 84% reduce 17%
15/04/11 00:38:53 INFO mapreduce.Job:  map 85% reduce 17%
15/04/11 00:38:55 INFO mapreduce.Job:  map 86% reduce 18%
15/04/11 00:38:57 INFO mapreduce.Job:  map 87% reduce 19%
15/04/11 00:38:58 INFO mapreduce.Job:  map 89% reduce 20%
15/04/11 00:38:59 INFO mapreduce.Job:  map 90% reduce 21%
15/04/11 00:39:01 INFO mapreduce.Job:  map 91% reduce 23%
15/04/11 00:39:02 INFO mapreduce.Job:  map 91% reduce 24%
15/04/11 00:39:03 INFO mapreduce.Job:  map 93% reduce 24%
15/04/11 00:39:04 INFO mapreduce.Job:  map 93% reduce 25%
15/04/11 00:39:05 INFO mapreduce.Job:  map 93% reduce 26%
15/04/11 00:39:08 INFO mapreduce.Job:  map 94% reduce 26%
15/04/11 00:39:09 INFO mapreduce.Job:  map 95% reduce 27%
15/04/11 00:39:11 INFO mapreduce.Job:  map 95% reduce 28%
15/04/11 00:39:12 INFO mapreduce.Job:  map 96% reduce 28%
15/04/11 00:39:13 INFO mapreduce.Job:  map 97% reduce 28%
15/04/11 00:39:14 INFO mapreduce.Job:  map 97% reduce 29%
15/04/11 00:39:16 INFO mapreduce.Job:  map 98% reduce 29%
15/04/11 00:39:17 INFO mapreduce.Job:  map 98% reduce 30%
15/04/11 00:39:26 INFO mapreduce.Job:  map 99% reduce 31%
15/04/11 00:39:29 INFO mapreduce.Job:  map 99% reduce 32%
15/04/11 00:39:30 INFO mapreduce.Job:  map 100% reduce 32%
15/04/11 00:39:35 INFO mapreduce.Job:  map 100% reduce 34%
15/04/11 00:39:36 INFO mapreduce.Job:  map 100% reduce 36%
15/04/11 00:39:38 INFO mapreduce.Job:  map 100% reduce 39%
15/04/11 00:39:39 INFO mapreduce.Job:  map 100% reduce 42%
15/04/11 00:39:41 INFO mapreduce.Job:  map 100% reduce 46%
15/04/11 00:39:42 INFO mapreduce.Job:  map 100% reduce 48%
15/04/11 00:39:44 INFO mapreduce.Job:  map 100% reduce 52%
15/04/11 00:39:45 INFO mapreduce.Job:  map 100% reduce 53%
15/04/11 00:39:46 INFO mapreduce.Job:  map 100% reduce 54%
15/04/11 00:39:47 INFO mapreduce.Job:  map 100% reduce 56%
15/04/11 00:39:48 INFO mapreduce.Job:  map 100% reduce 57%
15/04/11 00:39:49 INFO mapreduce.Job:  map 100% reduce 58%
15/04/11 00:39:50 INFO mapreduce.Job:  map 100% reduce 59%
15/04/11 00:39:51 INFO mapreduce.Job:  map 100% reduce 60%
15/04/11 00:39:53 INFO mapreduce.Job:  map 100% reduce 61%
15/04/11 00:39:56 INFO mapreduce.Job:  map 100% reduce 62%
15/04/11 00:39:57 INFO mapreduce.Job:  map 100% reduce 63%
15/04/11 00:39:59 INFO mapreduce.Job:  map 100% reduce 64%
15/04/11 00:40:01 INFO mapreduce.Job:  map 100% reduce 65%
15/04/11 00:40:04 INFO mapreduce.Job:  map 100% reduce 66%
15/04/11 00:40:05 INFO mapreduce.Job:  map 100% reduce 67%
15/04/11 00:41:18 INFO mapreduce.Job:  map 100% reduce 68%
15/04/11 00:42:19 INFO mapreduce.Job:  map 100% reduce 69%
15/04/11 00:43:47 INFO mapreduce.Job:  map 100% reduce 70%
15/04/11 00:44:44 INFO mapreduce.Job:  map 100% reduce 71%
15/04/11 00:45:48 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 00:46:57 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 00:47:54 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 00:48:39 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 00:49:41 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 00:50:37 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 00:51:24 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 00:52:10 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 00:53:15 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 00:53:58 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 00:55:02 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 00:55:55 INFO mapreduce.Job:  map 100% reduce 83%
15/04/11 00:56:57 INFO mapreduce.Job:  map 100% reduce 84%
15/04/11 00:57:53 INFO mapreduce.Job:  map 100% reduce 85%
15/04/11 00:59:21 INFO mapreduce.Job:  map 100% reduce 86%
15/04/11 00:59:55 INFO mapreduce.Job:  map 100% reduce 87%
15/04/11 01:01:45 INFO mapreduce.Job:  map 100% reduce 88%
15/04/11 01:02:38 INFO mapreduce.Job:  map 100% reduce 89%
15/04/11 01:04:10 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 01:05:57 INFO mapreduce.Job:  map 100% reduce 91%
15/04/11 01:07:23 INFO mapreduce.Job:  map 100% reduce 92%
15/04/11 01:08:32 INFO mapreduce.Job:  map 100% reduce 93%
15/04/11 01:13:35 INFO mapreduce.Job:  map 100% reduce 94%
15/04/11 01:17:28 INFO mapreduce.Job:  map 100% reduce 95%
15/04/11 01:24:14 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 01:26:18 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 01:32:17 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 01:54:09 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 02:52:43 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 03:13:27 INFO mapreduce.Job: Job job_1422482982071_4463 completed successfully
15/04/11 03:13:27 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=30424216069
		FILE: Number of bytes written=60864618379
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=507
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Failed map tasks=14
		Killed reduce tasks=2
		Launched map tasks=148
		Launched reduce tasks=37
		Other local map tasks=14
		Data-local map tasks=63
		Rack-local map tasks=71
		Total time spent by all maps in occupied slots (ms)=123337270
		Total time spent by all reduces in occupied slots (ms)=173603682
		Total time spent by all map tasks (ms)=61668635
		Total time spent by all reduce tasks (ms)=86801841
		Total vcore-seconds taken by all map tasks=61668635
		Total vcore-seconds taken by all reduce tasks=86801841
		Total megabyte-seconds taken by all map tasks=499269268960
		Total megabyte-seconds taken by all reduce tasks=1041622092000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424243933
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424243933
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =4690
		Failed Shuffles=0
		Merged Map outputs=4690
		GC time elapsed (ms)=315013
		CPU time spent (ms)=165151060
		Physical memory (bytes) snapshot=300122742784
		Virtual memory (bytes) snapshot=1697392795648
		Total committed heap usage (bytes)=444818616320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/11 03:13:27 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st

real	162m48.030s
user	0m35.714s
sys	0m6.973s
15/04/11 03:13:30 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 25
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-25-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5667796043008698731.jar tmpDir=null
15/04/11 03:13:32 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 03:13:33 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 03:13:34 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/11 03:13:34 INFO mapreduce.JobSubmitter: number of splits:134
15/04/11 03:13:34 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4465
15/04/11 03:13:35 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4465
15/04/11 03:13:35 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4465/
15/04/11 03:13:35 INFO mapreduce.Job: Running job: job_1422482982071_4465
15/04/11 03:13:40 INFO mapreduce.Job: Job job_1422482982071_4465 running in uber mode : false
15/04/11 03:13:40 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 03:13:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000024_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000033_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000004_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000050_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000030_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000003_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000025_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000017_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000000_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000018_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000032_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000070_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000105_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000083_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000089_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000079_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000122_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000121_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000127_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/11 03:13:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000118_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000083_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:13:52 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 03:13:58 INFO mapreduce.Job:  map 2% reduce 0%
15/04/11 03:14:05 INFO mapreduce.Job:  map 3% reduce 0%
15/04/11 03:14:12 INFO mapreduce.Job:  map 4% reduce 0%
15/04/11 03:14:18 INFO mapreduce.Job:  map 5% reduce 0%
15/04/11 03:14:25 INFO mapreduce.Job:  map 6% reduce 0%
15/04/11 03:14:32 INFO mapreduce.Job:  map 7% reduce 0%
15/04/11 03:14:38 INFO mapreduce.Job:  map 8% reduce 0%
15/04/11 03:14:45 INFO mapreduce.Job:  map 9% reduce 0%
15/04/11 03:14:52 INFO mapreduce.Job:  map 10% reduce 0%
15/04/11 03:14:58 INFO mapreduce.Job:  map 11% reduce 0%
15/04/11 03:15:05 INFO mapreduce.Job:  map 12% reduce 0%
15/04/11 03:15:11 INFO mapreduce.Job:  map 13% reduce 0%
15/04/11 03:15:17 INFO mapreduce.Job:  map 14% reduce 0%
15/04/11 03:15:24 INFO mapreduce.Job:  map 15% reduce 0%
15/04/11 03:15:31 INFO mapreduce.Job:  map 16% reduce 0%
15/04/11 03:15:37 INFO mapreduce.Job:  map 17% reduce 0%
15/04/11 03:15:44 INFO mapreduce.Job:  map 18% reduce 0%
15/04/11 03:15:50 INFO mapreduce.Job:  map 19% reduce 0%
15/04/11 03:15:56 INFO mapreduce.Job:  map 20% reduce 0%
15/04/11 03:16:03 INFO mapreduce.Job:  map 21% reduce 0%
15/04/11 03:16:10 INFO mapreduce.Job:  map 22% reduce 0%
15/04/11 03:16:16 INFO mapreduce.Job:  map 23% reduce 0%
15/04/11 03:16:23 INFO mapreduce.Job:  map 24% reduce 0%
15/04/11 03:16:28 INFO mapreduce.Job:  map 25% reduce 0%
15/04/11 03:16:34 INFO mapreduce.Job:  map 26% reduce 0%
15/04/11 03:16:41 INFO mapreduce.Job:  map 27% reduce 0%
15/04/11 03:16:47 INFO mapreduce.Job:  map 28% reduce 0%
15/04/11 03:16:54 INFO mapreduce.Job:  map 29% reduce 0%
15/04/11 03:17:01 INFO mapreduce.Job:  map 30% reduce 0%
15/04/11 03:17:08 INFO mapreduce.Job:  map 31% reduce 0%
15/04/11 03:17:14 INFO mapreduce.Job:  map 32% reduce 0%
15/04/11 03:17:20 INFO mapreduce.Job:  map 33% reduce 0%
15/04/11 03:17:27 INFO mapreduce.Job:  map 34% reduce 0%
15/04/11 03:17:35 INFO mapreduce.Job:  map 35% reduce 0%
15/04/11 03:17:42 INFO mapreduce.Job:  map 36% reduce 0%
15/04/11 03:17:48 INFO mapreduce.Job:  map 37% reduce 0%
15/04/11 03:17:54 INFO mapreduce.Job:  map 38% reduce 0%
15/04/11 03:18:01 INFO mapreduce.Job:  map 39% reduce 0%
15/04/11 03:18:08 INFO mapreduce.Job:  map 40% reduce 0%
15/04/11 03:18:15 INFO mapreduce.Job:  map 41% reduce 0%
15/04/11 03:18:21 INFO mapreduce.Job:  map 42% reduce 0%
15/04/11 03:18:28 INFO mapreduce.Job:  map 43% reduce 0%
15/04/11 03:18:35 INFO mapreduce.Job:  map 44% reduce 0%
15/04/11 03:18:42 INFO mapreduce.Job:  map 45% reduce 0%
15/04/11 03:18:48 INFO mapreduce.Job:  map 46% reduce 0%
15/04/11 03:18:53 INFO mapreduce.Job: Task Id : attempt_1422482982071_4465_m_000118_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 03:18:57 INFO mapreduce.Job:  map 47% reduce 0%
15/04/11 03:19:03 INFO mapreduce.Job:  map 48% reduce 0%
15/04/11 03:19:10 INFO mapreduce.Job:  map 49% reduce 0%
15/04/11 03:19:17 INFO mapreduce.Job:  map 50% reduce 0%
15/04/11 03:19:24 INFO mapreduce.Job:  map 51% reduce 0%
15/04/11 03:19:30 INFO mapreduce.Job:  map 52% reduce 0%
15/04/11 03:19:37 INFO mapreduce.Job:  map 53% reduce 0%
15/04/11 03:19:43 INFO mapreduce.Job:  map 54% reduce 0%
15/04/11 03:19:50 INFO mapreduce.Job:  map 55% reduce 0%
15/04/11 03:19:57 INFO mapreduce.Job:  map 56% reduce 0%
15/04/11 03:20:03 INFO mapreduce.Job:  map 57% reduce 0%
15/04/11 03:20:10 INFO mapreduce.Job:  map 58% reduce 0%
15/04/11 03:20:17 INFO mapreduce.Job:  map 59% reduce 0%
15/04/11 03:20:24 INFO mapreduce.Job:  map 60% reduce 0%
15/04/11 03:20:30 INFO mapreduce.Job:  map 61% reduce 0%
15/04/11 03:20:37 INFO mapreduce.Job:  map 62% reduce 0%
15/04/11 03:20:42 INFO mapreduce.Job:  map 63% reduce 0%
15/04/11 03:20:46 INFO mapreduce.Job:  map 64% reduce 0%
15/04/11 03:20:47 INFO mapreduce.Job:  map 65% reduce 0%
15/04/11 03:20:49 INFO mapreduce.Job:  map 66% reduce 0%
15/04/11 03:20:51 INFO mapreduce.Job:  map 67% reduce 0%
15/04/11 03:20:54 INFO mapreduce.Job:  map 68% reduce 0%
15/04/11 03:20:56 INFO mapreduce.Job:  map 69% reduce 0%
15/04/11 03:20:57 INFO mapreduce.Job:  map 69% reduce 4%
15/04/11 03:20:58 INFO mapreduce.Job:  map 71% reduce 6%
15/04/11 03:21:00 INFO mapreduce.Job:  map 72% reduce 7%
15/04/11 03:21:01 INFO mapreduce.Job:  map 73% reduce 8%
15/04/11 03:21:02 INFO mapreduce.Job:  map 74% reduce 8%
15/04/11 03:21:03 INFO mapreduce.Job:  map 75% reduce 11%
15/04/11 03:21:04 INFO mapreduce.Job:  map 76% reduce 11%
15/04/11 03:21:06 INFO mapreduce.Job:  map 77% reduce 12%
15/04/11 03:21:07 INFO mapreduce.Job:  map 77% reduce 13%
15/04/11 03:21:08 INFO mapreduce.Job:  map 78% reduce 13%
15/04/11 03:21:09 INFO mapreduce.Job:  map 79% reduce 14%
15/04/11 03:21:12 INFO mapreduce.Job:  map 80% reduce 15%
15/04/11 03:21:18 INFO mapreduce.Job:  map 80% reduce 16%
15/04/11 03:21:21 INFO mapreduce.Job:  map 81% reduce 16%
15/04/11 03:21:33 INFO mapreduce.Job:  map 82% reduce 16%
15/04/11 03:21:38 INFO mapreduce.Job:  map 83% reduce 16%
15/04/11 03:21:39 INFO mapreduce.Job:  map 84% reduce 16%
15/04/11 03:21:40 INFO mapreduce.Job:  map 84% reduce 17%
15/04/11 03:21:41 INFO mapreduce.Job:  map 84% reduce 18%
15/04/11 03:21:42 INFO mapreduce.Job:  map 85% reduce 18%
15/04/11 03:21:44 INFO mapreduce.Job:  map 86% reduce 18%
15/04/11 03:21:45 INFO mapreduce.Job:  map 87% reduce 19%
15/04/11 03:21:46 INFO mapreduce.Job:  map 87% reduce 20%
15/04/11 03:21:47 INFO mapreduce.Job:  map 88% reduce 20%
15/04/11 03:21:48 INFO mapreduce.Job:  map 88% reduce 21%
15/04/11 03:21:50 INFO mapreduce.Job:  map 88% reduce 22%
15/04/11 03:21:51 INFO mapreduce.Job:  map 89% reduce 22%
15/04/11 03:21:55 INFO mapreduce.Job:  map 90% reduce 23%
15/04/11 03:21:58 INFO mapreduce.Job:  map 91% reduce 23%
15/04/11 03:21:59 INFO mapreduce.Job:  map 91% reduce 24%
15/04/11 03:22:00 INFO mapreduce.Job:  map 92% reduce 24%
15/04/11 03:22:01 INFO mapreduce.Job:  map 93% reduce 24%
15/04/11 03:22:02 INFO mapreduce.Job:  map 93% reduce 25%
15/04/11 03:22:03 INFO mapreduce.Job:  map 94% reduce 25%
15/04/11 03:22:04 INFO mapreduce.Job:  map 94% reduce 26%
15/04/11 03:22:05 INFO mapreduce.Job:  map 95% reduce 26%
15/04/11 03:22:06 INFO mapreduce.Job:  map 95% reduce 27%
15/04/11 03:22:08 INFO mapreduce.Job:  map 96% reduce 27%
15/04/11 03:22:09 INFO mapreduce.Job:  map 97% reduce 27%
15/04/11 03:22:10 INFO mapreduce.Job:  map 97% reduce 28%
15/04/11 03:22:14 INFO mapreduce.Job:  map 97% reduce 29%
15/04/11 03:22:15 INFO mapreduce.Job:  map 98% reduce 29%
15/04/11 03:22:17 INFO mapreduce.Job:  map 98% reduce 30%
15/04/11 03:22:19 INFO mapreduce.Job:  map 99% reduce 30%
15/04/11 03:22:22 INFO mapreduce.Job:  map 99% reduce 31%
15/04/11 03:22:28 INFO mapreduce.Job:  map 99% reduce 32%
15/04/11 03:22:31 INFO mapreduce.Job:  map 99% reduce 33%
15/04/11 03:22:48 INFO mapreduce.Job:  map 100% reduce 33%
15/04/11 03:26:31 INFO mapreduce.Job:  map 100% reduce 34%
15/04/11 03:26:32 INFO mapreduce.Job:  map 100% reduce 38%
15/04/11 03:26:33 INFO mapreduce.Job:  map 100% reduce 41%
15/04/11 03:26:34 INFO mapreduce.Job:  map 100% reduce 43%
15/04/11 03:26:35 INFO mapreduce.Job:  map 100% reduce 47%
15/04/11 03:26:36 INFO mapreduce.Job:  map 100% reduce 48%
15/04/11 03:26:37 INFO mapreduce.Job:  map 100% reduce 49%
15/04/11 03:26:38 INFO mapreduce.Job:  map 100% reduce 52%
15/04/11 03:26:39 INFO mapreduce.Job:  map 100% reduce 53%
15/04/11 03:26:40 INFO mapreduce.Job:  map 100% reduce 54%
15/04/11 03:26:41 INFO mapreduce.Job:  map 100% reduce 56%
15/04/11 03:26:42 INFO mapreduce.Job:  map 100% reduce 57%
15/04/11 03:26:43 INFO mapreduce.Job:  map 100% reduce 58%
15/04/11 03:26:44 INFO mapreduce.Job:  map 100% reduce 59%
15/04/11 03:26:45 INFO mapreduce.Job:  map 100% reduce 60%
15/04/11 03:26:46 INFO mapreduce.Job:  map 100% reduce 61%
15/04/11 03:26:47 INFO mapreduce.Job:  map 100% reduce 62%
15/04/11 03:26:48 INFO mapreduce.Job:  map 100% reduce 63%
15/04/11 03:26:49 INFO mapreduce.Job:  map 100% reduce 64%
15/04/11 03:26:51 INFO mapreduce.Job:  map 100% reduce 65%
15/04/11 03:26:53 INFO mapreduce.Job:  map 100% reduce 66%
15/04/11 03:26:59 INFO mapreduce.Job:  map 100% reduce 67%
15/04/11 03:28:52 INFO mapreduce.Job:  map 100% reduce 68%
15/04/11 03:30:26 INFO mapreduce.Job:  map 100% reduce 69%
15/04/11 03:32:52 INFO mapreduce.Job:  map 100% reduce 70%
15/04/11 03:34:39 INFO mapreduce.Job:  map 100% reduce 71%
15/04/11 03:36:01 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 03:37:12 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 03:39:25 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 03:40:46 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 03:42:04 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 03:43:41 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 03:45:24 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 03:46:10 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 03:47:36 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 03:49:05 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 03:50:48 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 03:52:15 INFO mapreduce.Job:  map 100% reduce 83%
15/04/11 03:53:28 INFO mapreduce.Job:  map 100% reduce 84%
15/04/11 03:54:12 INFO mapreduce.Job:  map 100% reduce 85%
15/04/11 03:54:55 INFO mapreduce.Job:  map 100% reduce 86%
15/04/11 03:56:22 INFO mapreduce.Job:  map 100% reduce 87%
15/04/11 03:58:17 INFO mapreduce.Job:  map 100% reduce 88%
15/04/11 04:00:45 INFO mapreduce.Job:  map 100% reduce 89%
15/04/11 04:03:53 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 04:06:30 INFO mapreduce.Job:  map 100% reduce 91%
15/04/11 04:10:30 INFO mapreduce.Job:  map 100% reduce 92%
15/04/11 04:12:31 INFO mapreduce.Job:  map 100% reduce 93%
15/04/11 04:12:55 INFO mapreduce.Job:  map 100% reduce 94%
15/04/11 04:15:46 INFO mapreduce.Job:  map 100% reduce 95%
15/04/11 04:18:12 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 04:24:34 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 04:43:11 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 04:56:10 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 05:36:50 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 06:11:45 INFO mapreduce.Job: Job job_1422482982071_4465 completed successfully
15/04/11 06:11:46 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=30424216039
		FILE: Number of bytes written=60863628939
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=477
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Failed map tasks=25
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=160
		Launched reduce tasks=26
		Other local map tasks=26
		Data-local map tasks=63
		Rack-local map tasks=71
		Total time spent by all maps in occupied slots (ms)=125459300
		Total time spent by all reduces in occupied slots (ms)=178999626
		Total time spent by all map tasks (ms)=62729650
		Total time spent by all reduce tasks (ms)=89499813
		Total vcore-seconds taken by all map tasks=62729650
		Total vcore-seconds taken by all reduce tasks=89499813
		Total megabyte-seconds taken by all map tasks=507859246400
		Total megabyte-seconds taken by all reduce tasks=1073997756000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424235893
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424235893
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =3350
		Failed Shuffles=0
		Merged Map outputs=3350
		GC time elapsed (ms)=368457
		CPU time spent (ms)=165351350
		Physical memory (bytes) snapshot=297603158016
		Virtual memory (bytes) snapshot=1565163229184
		Total committed heap usage (bytes)=423767748608
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/11 06:11:46 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st

real	178m18.453s
user	0m38.989s
sys	0m7.386s
15/04/11 06:11:48 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 25
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-25-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob124566671746693611.jar tmpDir=null
15/04/11 06:11:51 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 06:11:51 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 06:11:52 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/11 06:11:52 INFO mapreduce.JobSubmitter: number of splits:134
15/04/11 06:11:53 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4467
15/04/11 06:11:53 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4467
15/04/11 06:11:53 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4467/
15/04/11 06:11:53 INFO mapreduce.Job: Running job: job_1422482982071_4467
15/04/11 06:11:59 INFO mapreduce.Job: Job job_1422482982071_4467 running in uber mode : false
15/04/11 06:11:59 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 06:12:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000041_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000034_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000077_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000084_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000033_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000046_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000010_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000074_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000035_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000069_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000087_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000039_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000119_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000122_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000089_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000104_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000114_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_m_000089_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 06:12:11 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 06:12:17 INFO mapreduce.Job:  map 2% reduce 0%
15/04/11 06:12:24 INFO mapreduce.Job:  map 3% reduce 0%
15/04/11 06:12:32 INFO mapreduce.Job:  map 4% reduce 0%
15/04/11 06:12:38 INFO mapreduce.Job:  map 5% reduce 0%
15/04/11 06:12:44 INFO mapreduce.Job:  map 6% reduce 0%
15/04/11 06:12:51 INFO mapreduce.Job:  map 7% reduce 0%
15/04/11 06:12:57 INFO mapreduce.Job:  map 8% reduce 0%
15/04/11 06:13:04 INFO mapreduce.Job:  map 9% reduce 0%
15/04/11 06:13:11 INFO mapreduce.Job:  map 10% reduce 0%
15/04/11 06:13:17 INFO mapreduce.Job:  map 11% reduce 0%
15/04/11 06:13:23 INFO mapreduce.Job:  map 12% reduce 0%
15/04/11 06:13:30 INFO mapreduce.Job:  map 13% reduce 0%
15/04/11 06:13:36 INFO mapreduce.Job:  map 14% reduce 0%
15/04/11 06:13:42 INFO mapreduce.Job:  map 15% reduce 0%
15/04/11 06:13:50 INFO mapreduce.Job:  map 16% reduce 0%
15/04/11 06:13:56 INFO mapreduce.Job:  map 17% reduce 0%
15/04/11 06:14:03 INFO mapreduce.Job:  map 18% reduce 0%
15/04/11 06:14:09 INFO mapreduce.Job:  map 19% reduce 0%
15/04/11 06:14:15 INFO mapreduce.Job:  map 20% reduce 0%
15/04/11 06:14:22 INFO mapreduce.Job:  map 21% reduce 0%
15/04/11 06:14:29 INFO mapreduce.Job:  map 22% reduce 0%
15/04/11 06:14:35 INFO mapreduce.Job:  map 23% reduce 0%
15/04/11 06:14:43 INFO mapreduce.Job:  map 24% reduce 0%
15/04/11 06:14:49 INFO mapreduce.Job:  map 25% reduce 0%
15/04/11 06:14:54 INFO mapreduce.Job:  map 26% reduce 0%
15/04/11 06:15:01 INFO mapreduce.Job:  map 27% reduce 0%
15/04/11 06:15:07 INFO mapreduce.Job:  map 28% reduce 0%
15/04/11 06:15:14 INFO mapreduce.Job:  map 29% reduce 0%
15/04/11 06:15:21 INFO mapreduce.Job:  map 30% reduce 0%
15/04/11 06:15:28 INFO mapreduce.Job:  map 31% reduce 0%
15/04/11 06:15:34 INFO mapreduce.Job:  map 32% reduce 0%
15/04/11 06:15:40 INFO mapreduce.Job:  map 33% reduce 0%
15/04/11 06:15:48 INFO mapreduce.Job:  map 34% reduce 0%
15/04/11 06:15:54 INFO mapreduce.Job:  map 35% reduce 0%
15/04/11 06:16:01 INFO mapreduce.Job:  map 36% reduce 0%
15/04/11 06:16:07 INFO mapreduce.Job:  map 37% reduce 0%
15/04/11 06:16:14 INFO mapreduce.Job:  map 38% reduce 0%
15/04/11 06:16:21 INFO mapreduce.Job:  map 39% reduce 0%
15/04/11 06:16:28 INFO mapreduce.Job:  map 40% reduce 0%
15/04/11 06:16:34 INFO mapreduce.Job:  map 41% reduce 0%
15/04/11 06:16:40 INFO mapreduce.Job:  map 42% reduce 0%
15/04/11 06:16:47 INFO mapreduce.Job:  map 43% reduce 0%
15/04/11 06:16:55 INFO mapreduce.Job:  map 44% reduce 0%
15/04/11 06:17:01 INFO mapreduce.Job:  map 45% reduce 0%
15/04/11 06:17:07 INFO mapreduce.Job:  map 46% reduce 0%
15/04/11 06:17:14 INFO mapreduce.Job:  map 47% reduce 0%
15/04/11 06:17:21 INFO mapreduce.Job:  map 48% reduce 0%
15/04/11 06:17:28 INFO mapreduce.Job:  map 49% reduce 0%
15/04/11 06:17:34 INFO mapreduce.Job:  map 50% reduce 0%
15/04/11 06:17:40 INFO mapreduce.Job:  map 51% reduce 0%
15/04/11 06:17:47 INFO mapreduce.Job:  map 52% reduce 0%
15/04/11 06:17:55 INFO mapreduce.Job:  map 53% reduce 0%
15/04/11 06:18:01 INFO mapreduce.Job:  map 54% reduce 0%
15/04/11 06:18:08 INFO mapreduce.Job:  map 55% reduce 0%
15/04/11 06:18:15 INFO mapreduce.Job:  map 56% reduce 0%
15/04/11 06:18:22 INFO mapreduce.Job:  map 57% reduce 0%
15/04/11 06:18:29 INFO mapreduce.Job:  map 58% reduce 0%
15/04/11 06:18:35 INFO mapreduce.Job:  map 59% reduce 0%
15/04/11 06:18:41 INFO mapreduce.Job:  map 60% reduce 0%
15/04/11 06:18:48 INFO mapreduce.Job:  map 61% reduce 0%
15/04/11 06:18:56 INFO mapreduce.Job:  map 62% reduce 0%
15/04/11 06:19:00 INFO mapreduce.Job:  map 63% reduce 0%
15/04/11 06:19:02 INFO mapreduce.Job:  map 64% reduce 0%
15/04/11 06:19:05 INFO mapreduce.Job:  map 65% reduce 0%
15/04/11 06:19:06 INFO mapreduce.Job:  map 66% reduce 0%
15/04/11 06:19:10 INFO mapreduce.Job:  map 67% reduce 0%
15/04/11 06:19:11 INFO mapreduce.Job:  map 68% reduce 0%
15/04/11 06:19:14 INFO mapreduce.Job:  map 69% reduce 4%
15/04/11 06:19:15 INFO mapreduce.Job:  map 70% reduce 6%
15/04/11 06:19:16 INFO mapreduce.Job:  map 71% reduce 6%
15/04/11 06:19:17 INFO mapreduce.Job:  map 72% reduce 7%
15/04/11 06:19:18 INFO mapreduce.Job:  map 73% reduce 7%
15/04/11 06:19:19 INFO mapreduce.Job:  map 73% reduce 8%
15/04/11 06:19:20 INFO mapreduce.Job:  map 74% reduce 9%
15/04/11 06:19:21 INFO mapreduce.Job:  map 75% reduce 10%
15/04/11 06:19:23 INFO mapreduce.Job:  map 76% reduce 11%
15/04/11 06:19:24 INFO mapreduce.Job:  map 76% reduce 12%
15/04/11 06:19:26 INFO mapreduce.Job:  map 77% reduce 12%
15/04/11 06:19:27 INFO mapreduce.Job:  map 78% reduce 13%
15/04/11 06:19:29 INFO mapreduce.Job:  map 78% reduce 14%
15/04/11 06:19:31 INFO mapreduce.Job:  map 79% reduce 14%
15/04/11 06:19:42 INFO mapreduce.Job:  map 80% reduce 14%
15/04/11 06:19:49 INFO mapreduce.Job:  map 80% reduce 15%
15/04/11 06:19:50 INFO mapreduce.Job:  map 81% reduce 15%
15/04/11 06:19:54 INFO mapreduce.Job:  map 82% reduce 15%
15/04/11 06:19:57 INFO mapreduce.Job:  map 82% reduce 16%
15/04/11 06:20:00 INFO mapreduce.Job:  map 83% reduce 16%
15/04/11 06:20:01 INFO mapreduce.Job:  map 84% reduce 16%
15/04/11 06:20:02 INFO mapreduce.Job:  map 85% reduce 17%
15/04/11 06:20:04 INFO mapreduce.Job:  map 85% reduce 18%
15/04/11 06:20:05 INFO mapreduce.Job:  map 86% reduce 18%
15/04/11 06:20:06 INFO mapreduce.Job:  map 86% reduce 19%
15/04/11 06:20:07 INFO mapreduce.Job:  map 87% reduce 19%
15/04/11 06:20:08 INFO mapreduce.Job:  map 87% reduce 20%
15/04/11 06:20:10 INFO mapreduce.Job:  map 88% reduce 21%
15/04/11 06:20:11 INFO mapreduce.Job:  map 89% reduce 21%
15/04/11 06:20:13 INFO mapreduce.Job:  map 91% reduce 22%
15/04/11 06:20:15 INFO mapreduce.Job:  map 91% reduce 23%
15/04/11 06:20:16 INFO mapreduce.Job:  map 91% reduce 24%
15/04/11 06:20:17 INFO mapreduce.Job:  map 93% reduce 24%
15/04/11 06:20:19 INFO mapreduce.Job:  map 93% reduce 25%
15/04/11 06:20:20 INFO mapreduce.Job:  map 94% reduce 25%
15/04/11 06:20:22 INFO mapreduce.Job:  map 94% reduce 26%
15/04/11 06:20:24 INFO mapreduce.Job:  map 95% reduce 26%
15/04/11 06:20:25 INFO mapreduce.Job:  map 96% reduce 26%
15/04/11 06:20:27 INFO mapreduce.Job:  map 96% reduce 27%
15/04/11 06:20:29 INFO mapreduce.Job:  map 98% reduce 28%
15/04/11 06:20:33 INFO mapreduce.Job:  map 99% reduce 29%
15/04/11 06:20:37 INFO mapreduce.Job:  map 99% reduce 30%
15/04/11 06:20:38 INFO mapreduce.Job:  map 100% reduce 30%
15/04/11 06:20:40 INFO mapreduce.Job:  map 100% reduce 31%
15/04/11 06:20:42 INFO mapreduce.Job:  map 100% reduce 32%
15/04/11 06:20:44 INFO mapreduce.Job:  map 100% reduce 33%
15/04/11 06:20:45 INFO mapreduce.Job:  map 100% reduce 34%
15/04/11 06:20:46 INFO mapreduce.Job:  map 100% reduce 36%
15/04/11 06:20:47 INFO mapreduce.Job:  map 100% reduce 38%
15/04/11 06:20:48 INFO mapreduce.Job:  map 100% reduce 39%
15/04/11 06:20:49 INFO mapreduce.Job:  map 100% reduce 41%
15/04/11 06:20:50 INFO mapreduce.Job:  map 100% reduce 45%
15/04/11 06:20:51 INFO mapreduce.Job:  map 100% reduce 46%
15/04/11 06:20:52 INFO mapreduce.Job:  map 100% reduce 48%
15/04/11 06:20:53 INFO mapreduce.Job:  map 100% reduce 51%
15/04/11 06:20:54 INFO mapreduce.Job:  map 100% reduce 52%
15/04/11 06:20:55 INFO mapreduce.Job:  map 100% reduce 54%
15/04/11 06:20:56 INFO mapreduce.Job:  map 100% reduce 56%
15/04/11 06:20:57 INFO mapreduce.Job:  map 100% reduce 57%
15/04/11 06:20:58 INFO mapreduce.Job:  map 100% reduce 59%
15/04/11 06:20:59 INFO mapreduce.Job:  map 100% reduce 60%
15/04/11 06:21:00 INFO mapreduce.Job:  map 100% reduce 62%
15/04/11 06:21:01 INFO mapreduce.Job:  map 100% reduce 63%
15/04/11 06:21:02 INFO mapreduce.Job:  map 100% reduce 64%
15/04/11 06:21:04 INFO mapreduce.Job:  map 100% reduce 65%
15/04/11 06:21:05 INFO mapreduce.Job:  map 100% reduce 66%
15/04/11 06:21:17 INFO mapreduce.Job:  map 100% reduce 67%
15/04/11 06:23:06 INFO mapreduce.Job:  map 100% reduce 68%
15/04/11 06:24:56 INFO mapreduce.Job:  map 100% reduce 69%
15/04/11 06:27:06 INFO mapreduce.Job:  map 100% reduce 70%
15/04/11 06:28:54 INFO mapreduce.Job:  map 100% reduce 71%
15/04/11 06:30:15 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 06:31:31 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 06:33:41 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 06:35:04 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 06:36:31 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 06:38:18 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 06:39:33 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 06:40:14 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 06:41:55 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 06:43:21 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 06:45:09 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 06:46:15 INFO mapreduce.Job:  map 100% reduce 83%
15/04/11 06:47:45 INFO mapreduce.Job:  map 100% reduce 84%
15/04/11 06:48:34 INFO mapreduce.Job:  map 100% reduce 85%
15/04/11 06:48:53 INFO mapreduce.Job:  map 100% reduce 86%
15/04/11 06:50:37 INFO mapreduce.Job:  map 100% reduce 87%
15/04/11 06:53:07 INFO mapreduce.Job:  map 100% reduce 88%
15/04/11 06:54:45 INFO mapreduce.Job:  map 100% reduce 89%
15/04/11 06:57:34 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 07:00:48 INFO mapreduce.Job:  map 100% reduce 91%
15/04/11 07:03:23 INFO mapreduce.Job:  map 100% reduce 92%
15/04/11 07:06:50 INFO mapreduce.Job:  map 100% reduce 93%
15/04/11 07:08:41 INFO mapreduce.Job:  map 100% reduce 94%
15/04/11 07:10:03 INFO mapreduce.Job:  map 100% reduce 95%
15/04/11 07:12:07 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 07:17:59 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 07:38:53 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 07:52:33 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 07:59:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_r_000006_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4467_r_000006_0/part-00006 (inode 3605073): File does not exist. Holder DFSClient_attempt_1422482982071_4467_r_000006_0_140363875_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:59:42 INFO mapreduce.Job:  map 100% reduce 95%
15/04/11 08:00:26 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 08:00:41 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 08:34:38 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 08:44:23 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_r_000005_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 08:44:24 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 09:18:39 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 09:31:53 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 10:00:33 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 10:36:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_r_000005_1, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4467_r_000005_1/part-00005 (inode 3605150): File does not exist. Holder DFSClient_attempt_1422482982071_4467_r_000005_1_-1713797666_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 10:36:34 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 11:33:29 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 11:42:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4467_r_000005_2, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 11:42:42 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 13:14:38 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 13:24:13 INFO mapreduce.Job: Job job_1422482982071_4467 failed with state FAILED due to: Task failed task_1422482982071_4467_r_000005
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/11 13:24:13 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=27551502117
		FILE: Number of bytes written=57990820097
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4542987
		HDFS: Number of read operations=474
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=48
	Job Counters 
		Failed map tasks=22
		Failed reduce tasks=5
		Killed reduce tasks=1
		Launched map tasks=156
		Launched reduce tasks=30
		Other local map tasks=22
		Data-local map tasks=62
		Rack-local map tasks=72
		Total time spent by all maps in occupied slots (ms)=124576732
		Total time spent by all reduces in occupied slots (ms)=227887636
		Total time spent by all map tasks (ms)=62288366
		Total time spent by all reduce tasks (ms)=113943818
		Total vcore-seconds taken by all map tasks=62288366
		Total vcore-seconds taken by all reduce tasks=113943818
		Total megabyte-seconds taken by all map tasks=504286611136
		Total megabyte-seconds taken by all reduce tasks=1367325816000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424235893
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=312254
		Reduce shuffle bytes=27551521185
		Reduce input records=2725839885
		Reduce output records=312254
		Spilled Records=5856682645
		Shuffled Maps =3216
		Failed Shuffles=0
		Merged Map outputs=3216
		GC time elapsed (ms)=330878
		CPU time spent (ms)=155117910
		Physical memory (bytes) snapshot=295435554816
		Virtual memory (bytes) snapshot=1550853558272
		Total committed heap usage (bytes)=421662601216
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4542987
15/04/11 13:24:13 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	432m27.183s
user	0m56.675s
sys	0m17.325s
15/04/11 13:24:16 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 25
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-25-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=25 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5207413121210676676.jar tmpDir=null
15/04/11 13:24:18 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 13:24:18 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 13:24:19 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/11 13:24:19 INFO mapreduce.JobSubmitter: number of splits:134
15/04/11 13:24:20 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4471
15/04/11 13:24:20 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4471
15/04/11 13:24:20 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4471/
15/04/11 13:24:20 INFO mapreduce.Job: Running job: job_1422482982071_4471
15/04/11 13:24:25 INFO mapreduce.Job: Job job_1422482982071_4471 running in uber mode : false
15/04/11 13:24:25 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 13:24:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000039_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000045_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000048_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:30 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 13:24:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000076_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000083_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/11 13:24:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000024_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000050_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000056_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000023_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000053_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000074_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000009_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:31 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 13:24:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000119_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000113_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_m_000104_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:36 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 13:24:44 INFO mapreduce.Job:  map 2% reduce 0%
15/04/11 13:24:50 INFO mapreduce.Job:  map 3% reduce 0%
15/04/11 13:24:58 INFO mapreduce.Job:  map 4% reduce 0%
15/04/11 13:25:04 INFO mapreduce.Job:  map 5% reduce 0%
15/04/11 13:25:11 INFO mapreduce.Job:  map 6% reduce 0%
15/04/11 13:25:17 INFO mapreduce.Job:  map 7% reduce 0%
15/04/11 13:25:25 INFO mapreduce.Job:  map 8% reduce 0%
15/04/11 13:25:31 INFO mapreduce.Job:  map 9% reduce 0%
15/04/11 13:25:37 INFO mapreduce.Job:  map 10% reduce 0%
15/04/11 13:25:44 INFO mapreduce.Job:  map 11% reduce 0%
15/04/11 13:25:51 INFO mapreduce.Job:  map 12% reduce 0%
15/04/11 13:25:58 INFO mapreduce.Job:  map 13% reduce 0%
15/04/11 13:26:04 INFO mapreduce.Job:  map 14% reduce 0%
15/04/11 13:26:11 INFO mapreduce.Job:  map 15% reduce 0%
15/04/11 13:26:18 INFO mapreduce.Job:  map 16% reduce 0%
15/04/11 13:26:25 INFO mapreduce.Job:  map 17% reduce 0%
15/04/11 13:26:31 INFO mapreduce.Job:  map 18% reduce 0%
15/04/11 13:26:38 INFO mapreduce.Job:  map 19% reduce 0%
15/04/11 13:26:45 INFO mapreduce.Job:  map 20% reduce 0%
15/04/11 13:26:52 INFO mapreduce.Job:  map 21% reduce 0%
15/04/11 13:26:58 INFO mapreduce.Job:  map 22% reduce 0%
15/04/11 13:27:05 INFO mapreduce.Job:  map 23% reduce 0%
15/04/11 13:27:11 INFO mapreduce.Job:  map 24% reduce 0%
15/04/11 13:27:19 INFO mapreduce.Job:  map 25% reduce 0%
15/04/11 13:27:25 INFO mapreduce.Job:  map 26% reduce 0%
15/04/11 13:27:31 INFO mapreduce.Job:  map 27% reduce 0%
15/04/11 13:27:38 INFO mapreduce.Job:  map 28% reduce 0%
15/04/11 13:27:44 INFO mapreduce.Job:  map 29% reduce 0%
15/04/11 13:27:51 INFO mapreduce.Job:  map 30% reduce 0%
15/04/11 13:27:59 INFO mapreduce.Job:  map 31% reduce 0%
15/04/11 13:28:05 INFO mapreduce.Job:  map 32% reduce 0%
15/04/11 13:28:12 INFO mapreduce.Job:  map 33% reduce 0%
15/04/11 13:28:18 INFO mapreduce.Job:  map 34% reduce 0%
15/04/11 13:28:26 INFO mapreduce.Job:  map 35% reduce 0%
15/04/11 13:28:32 INFO mapreduce.Job:  map 36% reduce 0%
15/04/11 13:28:39 INFO mapreduce.Job:  map 37% reduce 0%
15/04/11 13:28:46 INFO mapreduce.Job:  map 38% reduce 0%
15/04/11 13:28:53 INFO mapreduce.Job:  map 39% reduce 0%
15/04/11 13:28:59 INFO mapreduce.Job:  map 40% reduce 0%
15/04/11 13:29:06 INFO mapreduce.Job:  map 41% reduce 0%
15/04/11 13:29:13 INFO mapreduce.Job:  map 42% reduce 0%
15/04/11 13:29:20 INFO mapreduce.Job:  map 43% reduce 0%
15/04/11 13:29:27 INFO mapreduce.Job:  map 44% reduce 0%
15/04/11 13:29:33 INFO mapreduce.Job:  map 45% reduce 0%
15/04/11 13:29:40 INFO mapreduce.Job:  map 46% reduce 0%
15/04/11 13:29:47 INFO mapreduce.Job:  map 47% reduce 0%
15/04/11 13:29:54 INFO mapreduce.Job:  map 48% reduce 0%
15/04/11 13:30:00 INFO mapreduce.Job:  map 49% reduce 0%
15/04/11 13:30:08 INFO mapreduce.Job:  map 50% reduce 0%
15/04/11 13:30:14 INFO mapreduce.Job:  map 51% reduce 0%
15/04/11 13:30:21 INFO mapreduce.Job:  map 52% reduce 0%
15/04/11 13:30:28 INFO mapreduce.Job:  map 53% reduce 0%
15/04/11 13:30:35 INFO mapreduce.Job:  map 54% reduce 0%
15/04/11 13:30:42 INFO mapreduce.Job:  map 55% reduce 0%
15/04/11 13:30:48 INFO mapreduce.Job:  map 56% reduce 0%
15/04/11 13:30:55 INFO mapreduce.Job:  map 57% reduce 0%
15/04/11 13:31:03 INFO mapreduce.Job:  map 58% reduce 0%
15/04/11 13:31:10 INFO mapreduce.Job:  map 59% reduce 0%
15/04/11 13:31:16 INFO mapreduce.Job:  map 60% reduce 0%
15/04/11 13:31:24 INFO mapreduce.Job:  map 61% reduce 0%
15/04/11 13:31:30 INFO mapreduce.Job:  map 62% reduce 0%
15/04/11 13:31:32 INFO mapreduce.Job:  map 63% reduce 0%
15/04/11 13:31:34 INFO mapreduce.Job:  map 64% reduce 0%
15/04/11 13:31:36 INFO mapreduce.Job:  map 65% reduce 0%
15/04/11 13:31:38 INFO mapreduce.Job:  map 66% reduce 0%
15/04/11 13:31:40 INFO mapreduce.Job:  map 67% reduce 0%
15/04/11 13:31:42 INFO mapreduce.Job:  map 68% reduce 0%
15/04/11 13:31:44 INFO mapreduce.Job:  map 69% reduce 5%
15/04/11 13:31:45 INFO mapreduce.Job:  map 69% reduce 6%
15/04/11 13:31:47 INFO mapreduce.Job:  map 70% reduce 6%
15/04/11 13:31:48 INFO mapreduce.Job:  map 70% reduce 7%
15/04/11 13:31:49 INFO mapreduce.Job:  map 71% reduce 7%
15/04/11 13:31:51 INFO mapreduce.Job:  map 71% reduce 8%
15/04/11 13:31:55 INFO mapreduce.Job:  map 72% reduce 8%
15/04/11 13:31:56 INFO mapreduce.Job:  map 73% reduce 9%
15/04/11 13:32:00 INFO mapreduce.Job:  map 74% reduce 9%
15/04/11 13:32:02 INFO mapreduce.Job:  map 74% reduce 10%
15/04/11 13:32:03 INFO mapreduce.Job:  map 75% reduce 10%
15/04/11 13:32:09 INFO mapreduce.Job:  map 76% reduce 10%
15/04/11 13:32:11 INFO mapreduce.Job:  map 76% reduce 11%
15/04/11 13:32:16 INFO mapreduce.Job:  map 77% reduce 11%
15/04/11 13:32:22 INFO mapreduce.Job:  map 78% reduce 11%
15/04/11 13:32:23 INFO mapreduce.Job:  map 78% reduce 12%
15/04/11 13:32:24 INFO mapreduce.Job:  map 79% reduce 12%
15/04/11 13:32:26 INFO mapreduce.Job:  map 79% reduce 13%
15/04/11 13:32:27 INFO mapreduce.Job:  map 80% reduce 13%
15/04/11 13:32:29 INFO mapreduce.Job:  map 80% reduce 14%
15/04/11 13:32:30 INFO mapreduce.Job:  map 81% reduce 14%
15/04/11 13:32:32 INFO mapreduce.Job:  map 83% reduce 15%
15/04/11 13:32:34 INFO mapreduce.Job:  map 84% reduce 16%
15/04/11 13:32:35 INFO mapreduce.Job:  map 84% reduce 17%
15/04/11 13:32:36 INFO mapreduce.Job:  map 86% reduce 18%
15/04/11 13:32:38 INFO mapreduce.Job:  map 87% reduce 19%
15/04/11 13:32:39 INFO mapreduce.Job:  map 88% reduce 20%
15/04/11 13:32:41 INFO mapreduce.Job:  map 89% reduce 21%
15/04/11 13:32:42 INFO mapreduce.Job:  map 90% reduce 21%
15/04/11 13:32:44 INFO mapreduce.Job:  map 90% reduce 22%
15/04/11 13:32:46 INFO mapreduce.Job:  map 91% reduce 22%
15/04/11 13:32:47 INFO mapreduce.Job:  map 91% reduce 23%
15/04/11 13:32:49 INFO mapreduce.Job:  map 92% reduce 23%
15/04/11 13:32:50 INFO mapreduce.Job:  map 92% reduce 24%
15/04/11 13:32:52 INFO mapreduce.Job:  map 93% reduce 24%
15/04/11 13:32:54 INFO mapreduce.Job:  map 94% reduce 25%
15/04/11 13:32:55 INFO mapreduce.Job:  map 95% reduce 25%
15/04/11 13:32:57 INFO mapreduce.Job:  map 95% reduce 26%
15/04/11 13:32:58 INFO mapreduce.Job:  map 96% reduce 26%
15/04/11 13:33:00 INFO mapreduce.Job:  map 97% reduce 27%
15/04/11 13:33:02 INFO mapreduce.Job:  map 98% reduce 28%
15/04/11 13:33:04 INFO mapreduce.Job:  map 99% reduce 28%
15/04/11 13:33:05 INFO mapreduce.Job:  map 99% reduce 29%
15/04/11 13:33:06 INFO mapreduce.Job:  map 99% reduce 30%
15/04/11 13:33:08 INFO mapreduce.Job:  map 100% reduce 30%
15/04/11 13:33:12 INFO mapreduce.Job:  map 100% reduce 31%
15/04/11 13:33:15 INFO mapreduce.Job:  map 100% reduce 33%
15/04/11 13:33:17 INFO mapreduce.Job:  map 100% reduce 34%
15/04/11 13:33:18 INFO mapreduce.Job:  map 100% reduce 37%
15/04/11 13:33:20 INFO mapreduce.Job:  map 100% reduce 38%
15/04/11 13:33:21 INFO mapreduce.Job:  map 100% reduce 41%
15/04/11 13:33:22 INFO mapreduce.Job:  map 100% reduce 42%
15/04/11 13:33:23 INFO mapreduce.Job:  map 100% reduce 43%
15/04/11 13:33:24 INFO mapreduce.Job:  map 100% reduce 48%
15/04/11 13:33:25 INFO mapreduce.Job:  map 100% reduce 49%
15/04/11 13:33:26 INFO mapreduce.Job:  map 100% reduce 50%
15/04/11 13:33:27 INFO mapreduce.Job:  map 100% reduce 55%
15/04/11 13:33:29 INFO mapreduce.Job:  map 100% reduce 56%
15/04/11 13:33:30 INFO mapreduce.Job:  map 100% reduce 59%
15/04/11 13:33:32 INFO mapreduce.Job:  map 100% reduce 60%
15/04/11 13:33:33 INFO mapreduce.Job:  map 100% reduce 62%
15/04/11 13:33:35 INFO mapreduce.Job:  map 100% reduce 64%
15/04/11 13:33:36 INFO mapreduce.Job:  map 100% reduce 65%
15/04/11 13:33:42 INFO mapreduce.Job:  map 100% reduce 66%
15/04/11 13:34:00 INFO mapreduce.Job:  map 100% reduce 67%
15/04/11 13:35:34 INFO mapreduce.Job:  map 100% reduce 68%
15/04/11 13:37:31 INFO mapreduce.Job:  map 100% reduce 69%
15/04/11 13:39:42 INFO mapreduce.Job:  map 100% reduce 70%
15/04/11 13:41:33 INFO mapreduce.Job:  map 100% reduce 71%
15/04/11 13:42:57 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 13:44:52 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 13:46:35 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 13:47:29 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 13:49:04 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 13:50:56 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:52:19 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 13:53:15 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 13:54:41 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 13:56:34 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 13:58:15 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 14:00:01 INFO mapreduce.Job:  map 100% reduce 83%
15/04/11 14:01:10 INFO mapreduce.Job:  map 100% reduce 84%
15/04/11 14:02:21 INFO mapreduce.Job:  map 100% reduce 85%
15/04/11 14:02:36 INFO mapreduce.Job:  map 100% reduce 86%
15/04/11 14:04:45 INFO mapreduce.Job:  map 100% reduce 87%
15/04/11 14:06:08 INFO mapreduce.Job:  map 100% reduce 88%
15/04/11 14:08:24 INFO mapreduce.Job:  map 100% reduce 89%
15/04/11 14:11:52 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 14:16:14 INFO mapreduce.Job:  map 100% reduce 91%
15/04/11 14:18:38 INFO mapreduce.Job:  map 100% reduce 92%
15/04/11 14:20:32 INFO mapreduce.Job:  map 100% reduce 93%
15/04/11 14:22:12 INFO mapreduce.Job:  map 100% reduce 94%
15/04/11 14:24:24 INFO mapreduce.Job:  map 100% reduce 95%
15/04/11 14:26:40 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 14:33:18 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 14:51:41 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 15:04:48 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 15:38:22 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 16:12:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_r_000005_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4471_r_000005_0/part-00005 (inode 3605718): File does not exist. Holder DFSClient_attempt_1422482982071_4471_r_000005_0_1441672322_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:03 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 17:15:39 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 17:24:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_r_000005_1, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 17:24:52 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 18:55:10 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 19:05:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4471_r_000005_2, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 19:05:43 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 20:37:59 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 20:47:31 INFO mapreduce.Job: Job job_1422482982071_4471 failed with state FAILED due to: Task failed task_1422482982071_4471_r_000005
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/11 20:47:31 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=27551502117
		FILE: Number of bytes written=57990820097
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4542987
		HDFS: Number of read operations=474
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=48
	Job Counters 
		Failed map tasks=16
		Failed reduce tasks=4
		Killed reduce tasks=1
		Launched map tasks=150
		Launched reduce tasks=29
		Other local map tasks=16
		Data-local map tasks=62
		Rack-local map tasks=72
		Total time spent by all maps in occupied slots (ms)=127178130
		Total time spent by all reduces in occupied slots (ms)=217652312
		Total time spent by all map tasks (ms)=63589065
		Total time spent by all reduce tasks (ms)=108826156
		Total vcore-seconds taken by all map tasks=63589065
		Total vcore-seconds taken by all reduce tasks=108826156
		Total megabyte-seconds taken by all map tasks=514817070240
		Total megabyte-seconds taken by all reduce tasks=1305913872000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424235893
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=312254
		Reduce shuffle bytes=27551521185
		Reduce input records=2725839885
		Reduce output records=312254
		Spilled Records=5856682645
		Shuffled Maps =3216
		Failed Shuffles=0
		Merged Map outputs=3216
		GC time elapsed (ms)=273302
		CPU time spent (ms)=158323810
		Physical memory (bytes) snapshot=295502299136
		Virtual memory (bytes) snapshot=1551452000256
		Total committed heap usage (bytes)=421661499392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4542987
15/04/11 20:47:31 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	443m18.713s
user	0m57.327s
sys	0m17.920s
15/04/11 20:47:34 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 15
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-15-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2080809747984684285.jar tmpDir=null
15/04/11 20:47:37 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 20:47:37 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 20:47:38 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/11 20:47:38 INFO mapreduce.JobSubmitter: number of splits:134
15/04/11 20:47:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4475
15/04/11 20:47:39 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4475
15/04/11 20:47:39 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4475/
15/04/11 20:47:39 INFO mapreduce.Job: Running job: job_1422482982071_4475
15/04/11 20:47:45 INFO mapreduce.Job: Job job_1422482982071_4475 running in uber mode : false
15/04/11 20:47:45 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 20:47:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000037_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/11 20:47:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000042_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000033_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000089_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000090_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000065_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000066_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/11 20:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000056_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000082_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000093_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000057_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000021_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000114_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000126_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000037_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000066_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:57 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 20:48:03 INFO mapreduce.Job:  map 2% reduce 0%
15/04/11 20:48:10 INFO mapreduce.Job:  map 3% reduce 0%
15/04/11 20:48:17 INFO mapreduce.Job:  map 4% reduce 0%
15/04/11 20:48:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:48:24 INFO mapreduce.Job:  map 5% reduce 0%
15/04/11 20:48:30 INFO mapreduce.Job:  map 6% reduce 0%
15/04/11 20:48:36 INFO mapreduce.Job:  map 7% reduce 0%
15/04/11 20:48:43 INFO mapreduce.Job:  map 8% reduce 0%
15/04/11 20:48:49 INFO mapreduce.Job:  map 9% reduce 0%
15/04/11 20:48:55 INFO mapreduce.Job:  map 10% reduce 0%
15/04/11 20:49:01 INFO mapreduce.Job:  map 11% reduce 0%
15/04/11 20:49:10 INFO mapreduce.Job:  map 12% reduce 0%
15/04/11 20:49:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:49:16 INFO mapreduce.Job:  map 13% reduce 0%
15/04/11 20:49:22 INFO mapreduce.Job:  map 14% reduce 0%
15/04/11 20:49:28 INFO mapreduce.Job:  map 15% reduce 0%
15/04/11 20:49:35 INFO mapreduce.Job:  map 16% reduce 0%
15/04/11 20:49:43 INFO mapreduce.Job:  map 17% reduce 0%
15/04/11 20:49:49 INFO mapreduce.Job:  map 18% reduce 0%
15/04/11 20:49:55 INFO mapreduce.Job:  map 19% reduce 0%
15/04/11 20:50:01 INFO mapreduce.Job:  map 20% reduce 0%
15/04/11 20:50:08 INFO mapreduce.Job:  map 21% reduce 0%
15/04/11 20:50:14 INFO mapreduce.Job:  map 22% reduce 0%
15/04/11 20:50:21 INFO mapreduce.Job:  map 23% reduce 0%
15/04/11 20:50:29 INFO mapreduce.Job:  map 24% reduce 0%
15/04/11 20:50:35 INFO mapreduce.Job:  map 25% reduce 0%
15/04/11 20:50:40 INFO mapreduce.Job:  map 26% reduce 0%
15/04/11 20:50:47 INFO mapreduce.Job:  map 27% reduce 0%
15/04/11 20:50:53 INFO mapreduce.Job:  map 28% reduce 0%
15/04/11 20:50:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4475_m_000083_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:51:02 INFO mapreduce.Job:  map 29% reduce 0%
15/04/11 20:51:08 INFO mapreduce.Job:  map 30% reduce 0%
15/04/11 20:51:14 INFO mapreduce.Job:  map 31% reduce 0%
15/04/11 20:51:20 INFO mapreduce.Job:  map 32% reduce 0%
15/04/11 20:51:27 INFO mapreduce.Job:  map 33% reduce 0%
15/04/11 20:51:35 INFO mapreduce.Job:  map 34% reduce 0%
15/04/11 20:51:41 INFO mapreduce.Job:  map 35% reduce 0%
15/04/11 20:51:47 INFO mapreduce.Job:  map 36% reduce 0%
15/04/11 20:51:53 INFO mapreduce.Job:  map 37% reduce 0%
15/04/11 20:52:00 INFO mapreduce.Job:  map 38% reduce 0%
15/04/11 20:52:08 INFO mapreduce.Job:  map 39% reduce 0%
15/04/11 20:52:14 INFO mapreduce.Job:  map 40% reduce 0%
15/04/11 20:52:20 INFO mapreduce.Job:  map 41% reduce 0%
15/04/11 20:52:26 INFO mapreduce.Job:  map 42% reduce 0%
15/04/11 20:52:33 INFO mapreduce.Job:  map 43% reduce 0%
15/04/11 20:52:41 INFO mapreduce.Job:  map 44% reduce 0%
15/04/11 20:52:47 INFO mapreduce.Job:  map 45% reduce 0%
15/04/11 20:52:53 INFO mapreduce.Job:  map 46% reduce 0%
15/04/11 20:52:59 INFO mapreduce.Job:  map 47% reduce 0%
15/04/11 20:53:06 INFO mapreduce.Job:  map 48% reduce 0%
15/04/11 20:53:14 INFO mapreduce.Job:  map 49% reduce 0%
15/04/11 20:53:21 INFO mapreduce.Job:  map 50% reduce 0%
15/04/11 20:53:27 INFO mapreduce.Job:  map 51% reduce 0%
15/04/11 20:53:34 INFO mapreduce.Job:  map 52% reduce 0%
15/04/11 20:53:40 INFO mapreduce.Job:  map 53% reduce 0%
15/04/11 20:53:48 INFO mapreduce.Job:  map 54% reduce 0%
15/04/11 20:53:54 INFO mapreduce.Job:  map 55% reduce 0%
15/04/11 20:54:01 INFO mapreduce.Job:  map 56% reduce 0%
15/04/11 20:54:07 INFO mapreduce.Job:  map 57% reduce 0%
15/04/11 20:54:14 INFO mapreduce.Job:  map 58% reduce 0%
15/04/11 20:54:22 INFO mapreduce.Job:  map 59% reduce 0%
15/04/11 20:54:28 INFO mapreduce.Job:  map 60% reduce 0%
15/04/11 20:54:34 INFO mapreduce.Job:  map 61% reduce 0%
15/04/11 20:54:43 INFO mapreduce.Job:  map 62% reduce 0%
15/04/11 20:54:48 INFO mapreduce.Job:  map 63% reduce 0%
15/04/11 20:54:51 INFO mapreduce.Job:  map 64% reduce 0%
15/04/11 20:54:52 INFO mapreduce.Job:  map 65% reduce 0%
15/04/11 20:54:53 INFO mapreduce.Job:  map 66% reduce 0%
15/04/11 20:54:54 INFO mapreduce.Job:  map 67% reduce 0%
15/04/11 20:54:55 INFO mapreduce.Job:  map 68% reduce 0%
15/04/11 20:54:57 INFO mapreduce.Job:  map 69% reduce 0%
15/04/11 20:54:58 INFO mapreduce.Job:  map 70% reduce 0%
15/04/11 20:55:00 INFO mapreduce.Job:  map 71% reduce 0%
15/04/11 20:55:01 INFO mapreduce.Job:  map 72% reduce 0%
15/04/11 20:55:02 INFO mapreduce.Job:  map 73% reduce 8%
15/04/11 20:55:04 INFO mapreduce.Job:  map 74% reduce 8%
15/04/11 20:55:05 INFO mapreduce.Job:  map 75% reduce 10%
15/04/11 20:55:06 INFO mapreduce.Job:  map 76% reduce 10%
15/04/11 20:55:07 INFO mapreduce.Job:  map 77% reduce 10%
15/04/11 20:55:08 INFO mapreduce.Job:  map 77% reduce 13%
15/04/11 20:55:10 INFO mapreduce.Job:  map 78% reduce 13%
15/04/11 20:55:12 INFO mapreduce.Job:  map 79% reduce 14%
15/04/11 20:55:13 INFO mapreduce.Job:  map 80% reduce 14%
15/04/11 20:55:14 INFO mapreduce.Job:  map 80% reduce 15%
15/04/11 20:55:19 INFO mapreduce.Job:  map 81% reduce 15%
15/04/11 20:55:33 INFO mapreduce.Job:  map 82% reduce 15%
15/04/11 20:55:35 INFO mapreduce.Job:  map 82% reduce 16%
15/04/11 20:55:43 INFO mapreduce.Job:  map 83% reduce 16%
15/04/11 20:55:44 INFO mapreduce.Job:  map 83% reduce 17%
15/04/11 20:55:46 INFO mapreduce.Job:  map 84% reduce 17%
15/04/11 20:55:47 INFO mapreduce.Job:  map 85% reduce 17%
15/04/11 20:55:48 INFO mapreduce.Job:  map 85% reduce 18%
15/04/11 20:55:50 INFO mapreduce.Job:  map 86% reduce 19%
15/04/11 20:55:51 INFO mapreduce.Job:  map 87% reduce 19%
15/04/11 20:55:52 INFO mapreduce.Job:  map 88% reduce 19%
15/04/11 20:55:53 INFO mapreduce.Job:  map 88% reduce 20%
15/04/11 20:55:54 INFO mapreduce.Job:  map 88% reduce 22%
15/04/11 20:55:56 INFO mapreduce.Job:  map 89% reduce 22%
15/04/11 20:55:57 INFO mapreduce.Job:  map 90% reduce 22%
15/04/11 20:55:58 INFO mapreduce.Job:  map 91% reduce 22%
15/04/11 20:56:00 INFO mapreduce.Job:  map 91% reduce 23%
15/04/11 20:56:05 INFO mapreduce.Job:  map 92% reduce 23%
15/04/11 20:56:08 INFO mapreduce.Job:  map 93% reduce 23%
15/04/11 20:56:12 INFO mapreduce.Job:  map 94% reduce 24%
15/04/11 20:56:15 INFO mapreduce.Job:  map 95% reduce 25%
15/04/11 20:56:18 INFO mapreduce.Job:  map 95% reduce 26%
15/04/11 20:56:19 INFO mapreduce.Job:  map 96% reduce 26%
15/04/11 20:56:21 INFO mapreduce.Job:  map 97% reduce 27%
15/04/11 20:56:23 INFO mapreduce.Job:  map 97% reduce 28%
15/04/11 20:56:24 INFO mapreduce.Job:  map 97% reduce 29%
15/04/11 20:56:27 INFO mapreduce.Job:  map 97% reduce 30%
15/04/11 20:56:28 INFO mapreduce.Job:  map 98% reduce 31%
15/04/11 20:56:31 INFO mapreduce.Job:  map 99% reduce 31%
15/04/11 20:56:34 INFO mapreduce.Job:  map 99% reduce 32%
15/04/11 20:56:53 INFO mapreduce.Job:  map 99% reduce 33%
15/04/11 20:57:10 INFO mapreduce.Job:  map 100% reduce 33%
15/04/11 20:58:48 INFO mapreduce.Job:  map 100% reduce 38%
15/04/11 20:58:50 INFO mapreduce.Job:  map 100% reduce 40%
15/04/11 20:58:51 INFO mapreduce.Job:  map 100% reduce 46%
15/04/11 20:58:53 INFO mapreduce.Job:  map 100% reduce 48%
15/04/11 20:58:54 INFO mapreduce.Job:  map 100% reduce 53%
15/04/11 20:58:55 INFO mapreduce.Job:  map 100% reduce 54%
15/04/11 20:58:56 INFO mapreduce.Job:  map 100% reduce 55%
15/04/11 20:58:57 INFO mapreduce.Job:  map 100% reduce 58%
15/04/11 20:58:58 INFO mapreduce.Job:  map 100% reduce 59%
15/04/11 20:58:59 INFO mapreduce.Job:  map 100% reduce 60%
15/04/11 20:59:00 INFO mapreduce.Job:  map 100% reduce 62%
15/04/11 20:59:01 INFO mapreduce.Job:  map 100% reduce 63%
15/04/11 20:59:03 INFO mapreduce.Job:  map 100% reduce 65%
15/04/11 20:59:05 INFO mapreduce.Job:  map 100% reduce 66%
15/04/11 20:59:12 INFO mapreduce.Job:  map 100% reduce 67%
15/04/11 21:02:18 INFO mapreduce.Job:  map 100% reduce 68%
15/04/11 21:05:51 INFO mapreduce.Job:  map 100% reduce 69%
15/04/11 21:09:29 INFO mapreduce.Job:  map 100% reduce 70%
15/04/11 21:11:52 INFO mapreduce.Job:  map 100% reduce 71%
15/04/11 21:15:12 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 21:17:41 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 21:19:58 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 21:23:07 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 21:25:21 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 21:26:37 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 21:27:59 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 21:31:40 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 21:33:06 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 21:34:02 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 21:36:12 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 21:38:07 INFO mapreduce.Job:  map 100% reduce 83%
15/04/11 21:40:32 INFO mapreduce.Job:  map 100% reduce 84%
15/04/11 21:42:27 INFO mapreduce.Job:  map 100% reduce 85%
15/04/11 21:44:41 INFO mapreduce.Job:  map 100% reduce 86%
15/04/11 21:47:28 INFO mapreduce.Job:  map 100% reduce 87%
15/04/11 21:49:18 INFO mapreduce.Job:  map 100% reduce 88%
15/04/11 21:52:05 INFO mapreduce.Job:  map 100% reduce 89%
15/04/11 21:54:20 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 21:56:10 INFO mapreduce.Job:  map 100% reduce 91%
15/04/11 22:00:35 INFO mapreduce.Job:  map 100% reduce 92%
15/04/11 22:06:47 INFO mapreduce.Job:  map 100% reduce 93%
15/04/11 22:15:19 INFO mapreduce.Job:  map 100% reduce 94%
15/04/11 22:26:57 INFO mapreduce.Job:  map 100% reduce 95%
15/04/11 22:44:14 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 23:02:39 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 23:10:22 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 23:13:43 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 23:38:19 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 23:55:22 INFO mapreduce.Job: Job job_1422482982071_4475 completed successfully
15/04/11 23:55:22 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=30424216021
		FILE: Number of bytes written=60862639511
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=447
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Failed map tasks=22
		Killed map tasks=1
		Launched map tasks=157
		Launched reduce tasks=15
		Other local map tasks=23
		Data-local map tasks=65
		Rack-local map tasks=69
		Total time spent by all maps in occupied slots (ms)=125220920
		Total time spent by all reduces in occupied slots (ms)=158711526
		Total time spent by all map tasks (ms)=62610460
		Total time spent by all reduce tasks (ms)=79355763
		Total vcore-seconds taken by all map tasks=62610460
		Total vcore-seconds taken by all reduce tasks=79355763
		Total megabyte-seconds taken by all map tasks=506894284160
		Total megabyte-seconds taken by all reduce tasks=952269156000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424227853
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424227853
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =2010
		Failed Shuffles=0
		Merged Map outputs=2010
		GC time elapsed (ms)=350402
		CPU time spent (ms)=164535100
		Physical memory (bytes) snapshot=290700369920
		Virtual memory (bytes) snapshot=1431343706112
		Total committed heap usage (bytes)=402717478912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/11 23:55:22 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st

real	187m50.424s
user	0m38.014s
sys	0m7.718s
15/04/11 23:55:25 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 15
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-15-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4385214053273177172.jar tmpDir=null
15/04/11 23:55:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 23:55:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 23:55:28 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/11 23:55:29 INFO mapreduce.JobSubmitter: number of splits:134
15/04/11 23:55:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4476
15/04/11 23:55:30 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4476
15/04/11 23:55:30 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4476/
15/04/11 23:55:30 INFO mapreduce.Job: Running job: job_1422482982071_4476
15/04/11 23:55:35 INFO mapreduce.Job: Job job_1422482982071_4476 running in uber mode : false
15/04/11 23:55:35 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 23:55:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000035_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000039_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000071_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000065_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/11 23:55:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000024_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000031_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000118_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000064_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000097_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000096_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000119_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000114_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/11 23:55:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000129_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000101_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000128_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000114_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000101_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:55:47 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 23:55:53 INFO mapreduce.Job:  map 2% reduce 0%
15/04/11 23:56:00 INFO mapreduce.Job:  map 3% reduce 0%
15/04/11 23:56:07 INFO mapreduce.Job:  map 4% reduce 0%
15/04/11 23:56:13 INFO mapreduce.Job:  map 5% reduce 0%
15/04/11 23:56:20 INFO mapreduce.Job:  map 6% reduce 0%
15/04/11 23:56:26 INFO mapreduce.Job:  map 7% reduce 0%
15/04/11 23:56:32 INFO mapreduce.Job:  map 8% reduce 0%
15/04/11 23:56:39 INFO mapreduce.Job:  map 9% reduce 0%
15/04/11 23:56:46 INFO mapreduce.Job:  map 10% reduce 0%
15/04/11 23:56:54 INFO mapreduce.Job:  map 11% reduce 0%
15/04/11 23:57:00 INFO mapreduce.Job:  map 12% reduce 0%
15/04/11 23:57:06 INFO mapreduce.Job:  map 13% reduce 0%
15/04/11 23:57:12 INFO mapreduce.Job:  map 14% reduce 0%
15/04/11 23:57:19 INFO mapreduce.Job:  map 15% reduce 0%
15/04/11 23:57:25 INFO mapreduce.Job:  map 16% reduce 0%
15/04/11 23:57:33 INFO mapreduce.Job:  map 17% reduce 0%
15/04/11 23:57:39 INFO mapreduce.Job:  map 18% reduce 0%
15/04/11 23:57:45 INFO mapreduce.Job:  map 19% reduce 0%
15/04/11 23:57:51 INFO mapreduce.Job:  map 20% reduce 0%
15/04/11 23:57:58 INFO mapreduce.Job:  map 21% reduce 0%
15/04/11 23:58:04 INFO mapreduce.Job:  map 22% reduce 0%
15/04/11 23:58:12 INFO mapreduce.Job:  map 23% reduce 0%
15/04/11 23:58:18 INFO mapreduce.Job:  map 24% reduce 0%
15/04/11 23:58:22 INFO mapreduce.Job:  map 25% reduce 0%
15/04/11 23:58:30 INFO mapreduce.Job:  map 26% reduce 0%
15/04/11 23:58:36 INFO mapreduce.Job:  map 27% reduce 0%
15/04/11 23:58:42 INFO mapreduce.Job:  map 28% reduce 0%
15/04/11 23:58:49 INFO mapreduce.Job:  map 29% reduce 0%
15/04/11 23:58:56 INFO mapreduce.Job:  map 30% reduce 0%
15/04/11 23:59:03 INFO mapreduce.Job:  map 31% reduce 0%
15/04/11 23:59:09 INFO mapreduce.Job:  map 32% reduce 0%
15/04/11 23:59:15 INFO mapreduce.Job:  map 33% reduce 0%
15/04/11 23:59:22 INFO mapreduce.Job:  map 34% reduce 0%
15/04/11 23:59:30 INFO mapreduce.Job:  map 35% reduce 0%
15/04/11 23:59:36 INFO mapreduce.Job:  map 36% reduce 0%
15/04/11 23:59:42 INFO mapreduce.Job:  map 37% reduce 0%
15/04/11 23:59:49 INFO mapreduce.Job:  map 38% reduce 0%
15/04/11 23:59:56 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 00:00:04 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 00:00:10 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 00:00:16 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 00:00:23 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 00:00:30 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 00:00:37 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 00:00:43 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 00:00:49 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 00:00:56 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 00:01:03 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 00:01:10 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 00:01:16 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 00:01:23 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 00:01:29 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 00:01:36 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 00:01:43 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 00:01:49 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 00:01:56 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 00:02:02 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 00:02:10 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 00:02:16 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 00:02:23 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 00:02:29 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 00:02:36 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 00:02:40 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 00:02:42 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 00:02:45 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 00:02:47 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 00:02:49 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 00:02:51 INFO mapreduce.Job:  map 71% reduce 4%
15/04/12 00:02:52 INFO mapreduce.Job:  map 72% reduce 7%
15/04/12 00:02:53 INFO mapreduce.Job:  map 73% reduce 7%
15/04/12 00:02:56 INFO mapreduce.Job:  map 74% reduce 9%
15/04/12 00:02:57 INFO mapreduce.Job:  map 75% reduce 9%
15/04/12 00:02:59 INFO mapreduce.Job:  map 76% reduce 11%
15/04/12 00:03:01 INFO mapreduce.Job:  map 77% reduce 11%
15/04/12 00:03:02 INFO mapreduce.Job:  map 78% reduce 13%
15/04/12 00:03:04 INFO mapreduce.Job:  map 79% reduce 13%
15/04/12 00:03:05 INFO mapreduce.Job:  map 79% reduce 14%
15/04/12 00:03:10 INFO mapreduce.Job:  map 80% reduce 14%
15/04/12 00:03:18 INFO mapreduce.Job:  map 81% reduce 14%
15/04/12 00:03:25 INFO mapreduce.Job:  map 81% reduce 15%
15/04/12 00:03:30 INFO mapreduce.Job:  map 82% reduce 15%
15/04/12 00:03:33 INFO mapreduce.Job:  map 82% reduce 16%
15/04/12 00:03:34 INFO mapreduce.Job:  map 83% reduce 16%
15/04/12 00:03:37 INFO mapreduce.Job:  map 85% reduce 17%
15/04/12 00:03:39 INFO mapreduce.Job:  map 86% reduce 18%
15/04/12 00:03:40 INFO mapreduce.Job:  map 86% reduce 19%
15/04/12 00:03:42 INFO mapreduce.Job:  map 87% reduce 19%
15/04/12 00:03:43 INFO mapreduce.Job:  map 88% reduce 20%
15/04/12 00:03:45 INFO mapreduce.Job:  map 89% reduce 20%
15/04/12 00:03:46 INFO mapreduce.Job:  map 90% reduce 21%
15/04/12 00:03:48 INFO mapreduce.Job:  map 91% reduce 21%
15/04/12 00:03:49 INFO mapreduce.Job:  map 91% reduce 22%
15/04/12 00:03:50 INFO mapreduce.Job:  map 92% reduce 22%
15/04/12 00:03:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000079_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 00:03:52 INFO mapreduce.Job:  map 93% reduce 22%
15/04/12 00:03:53 INFO mapreduce.Job:  map 94% reduce 23%
15/04/12 00:03:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000079_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 00:03:57 INFO mapreduce.Job:  map 95% reduce 23%
15/04/12 00:03:58 INFO mapreduce.Job:  map 95% reduce 24%
15/04/12 00:04:01 INFO mapreduce.Job:  map 96% reduce 24%
15/04/12 00:04:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_m_000079_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 00:04:04 INFO mapreduce.Job:  map 96% reduce 25%
15/04/12 00:04:07 INFO mapreduce.Job:  map 96% reduce 26%
15/04/12 00:04:09 INFO mapreduce.Job:  map 97% reduce 26%
15/04/12 00:04:10 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 00:04:12 INFO mapreduce.Job:  map 98% reduce 28%
15/04/12 00:04:13 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 00:04:14 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 00:04:16 INFO mapreduce.Job:  map 98% reduce 31%
15/04/12 00:04:17 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 00:04:19 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 00:04:28 INFO mapreduce.Job:  map 99% reduce 33%
15/04/12 00:07:27 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 00:11:12 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 00:11:13 INFO mapreduce.Job:  map 100% reduce 39%
15/04/12 00:11:14 INFO mapreduce.Job:  map 100% reduce 40%
15/04/12 00:11:15 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 00:11:16 INFO mapreduce.Job:  map 100% reduce 46%
15/04/12 00:11:17 INFO mapreduce.Job:  map 100% reduce 48%
15/04/12 00:11:18 INFO mapreduce.Job:  map 100% reduce 50%
15/04/12 00:11:19 INFO mapreduce.Job:  map 100% reduce 54%
15/04/12 00:11:20 INFO mapreduce.Job:  map 100% reduce 56%
15/04/12 00:11:22 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 00:11:23 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 00:11:25 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 00:11:26 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 00:11:29 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 00:11:37 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 00:14:44 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 00:18:22 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 00:22:05 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 00:24:20 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 00:27:41 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 00:29:51 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 00:32:11 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 00:35:23 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 00:37:43 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 00:39:31 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 00:40:39 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 00:43:09 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 00:44:34 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 00:46:46 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 00:48:07 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 00:50:17 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 00:52:45 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 00:54:34 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 00:57:07 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 00:59:42 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 01:01:30 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 01:05:54 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 01:07:49 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 01:08:35 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 01:08:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000007_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:36 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 01:08:46 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 01:09:13 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 01:09:43 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 01:09:54 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 01:10:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000009_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4476_r_000009_0/part-00009 (inode 3606318): File does not exist. Holder DFSClient_attempt_1422482982071_4476_r_000009_0_352115345_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:01 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 01:10:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000010_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4476_r_000010_0/part-00010 (inode 3606316): File does not exist. Holder DFSClient_attempt_1422482982071_4476_r_000010_0_-1836943677_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:09 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 01:10:12 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 01:10:19 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 01:10:59 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 01:11:02 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 01:11:09 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 01:11:12 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 01:11:16 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 01:11:29 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 01:13:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000003_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4476_r_000003_0/part-00003 (inode 3606320): File does not exist. Holder DFSClient_attempt_1422482982071_4476_r_000003_0_1553761860_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:34 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 01:13:48 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 01:14:13 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 01:14:23 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 01:14:29 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 01:17:11 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 01:17:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000001_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4476_r_000001_0/part-00001 (inode 3606326): File does not exist. Holder DFSClient_attempt_1422482982071_4476_r_000001_0_140420247_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:17:37 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 01:17:49 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 01:18:16 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 01:18:20 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 01:18:29 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 01:18:51 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 01:19:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000002_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4476_r_000002_0/part-00002 (inode 3606324): File does not exist. Holder DFSClient_attempt_1422482982071_4476_r_000002_0_1301810658_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:19:50 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 01:20:00 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 01:20:02 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 01:20:28 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 01:20:37 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 01:20:43 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 01:23:53 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 01:23:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000013_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(java.io.IOException): BP-1272212113-129.114.57.132-1408108439175:blk_1077936609_4195950 does not exist or is not under Constructionnull
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkUCBlock(FSNamesystem.java:5956)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updateBlockForPipeline(FSNamesystem.java:6023)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updateBlockForPipeline(NameNodeRpcServer.java:645)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:874)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:826)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:924)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:486)

15/04/12 01:23:59 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 01:24:09 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 01:24:21 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 01:24:48 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 01:24:52 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 01:24:55 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 01:27:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000000_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(java.io.IOException): BP-1272212113-129.114.57.132-1408108439175:blk_1077936618_4195959 does not exist or is not under Constructionnull
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkUCBlock(FSNamesystem.java:5956)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updateBlockForPipeline(FSNamesystem.java:6023)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updateBlockForPipeline(NameNodeRpcServer.java:645)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:874)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:826)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:924)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:486)

15/04/12 01:27:21 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 01:27:33 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 01:27:58 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 01:28:10 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 01:28:16 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 01:30:50 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 01:33:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000003_2, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:33:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000003_1, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:33:08 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 01:33:19 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 01:33:40 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 01:33:49 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 01:33:55 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 01:33:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000010_1, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:33:56 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 01:34:08 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 01:34:26 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 01:34:36 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 01:34:42 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 01:35:48 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 01:38:37 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 01:41:05 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 01:41:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000009_1, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:41:06 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 01:41:16 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 01:41:40 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 01:41:49 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 01:41:52 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 01:42:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000004_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(java.io.IOException): BP-1272212113-129.114.57.132-1408108439175:blk_1077936611_4195952 does not exist or is not under Constructionnull
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkUCBlock(FSNamesystem.java:5956)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updateBlockForPipeline(FSNamesystem.java:6023)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updateBlockForPipeline(NameNodeRpcServer.java:645)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:874)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:826)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:924)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:486)

15/04/12 01:42:31 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 01:42:43 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 01:43:08 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 01:43:32 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 01:43:38 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 01:43:41 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 01:48:36 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 01:52:18 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 01:56:04 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 01:57:33 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 02:00:28 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 02:02:21 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 02:05:28 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 02:05:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000006_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 02:05:42 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 02:05:53 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 02:06:23 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 02:06:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000007_1, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 02:06:29 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 02:06:40 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 02:07:08 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 02:07:31 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 02:07:37 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 02:07:40 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 02:07:43 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 02:07:53 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 02:08:05 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 02:09:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000008_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(java.io.IOException): BP-1272212113-129.114.57.132-1408108439175:blk_1077936619_4195960 does not exist or is not under Constructionnull
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkUCBlock(FSNamesystem.java:5956)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updateBlockForPipeline(FSNamesystem.java:6023)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updateBlockForPipeline(NameNodeRpcServer.java:645)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:874)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:826)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:924)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:486)

15/04/12 02:09:21 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 02:09:32 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 02:09:56 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 02:10:18 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 02:10:30 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 02:10:39 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 02:10:54 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 02:13:48 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 02:17:18 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 02:20:06 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 02:22:27 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 02:25:42 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 02:30:27 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 02:30:31 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 02:33:49 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 02:36:31 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 02:41:29 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 02:47:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4476_r_000005_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 02:47:09 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 03:00:30 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 03:06:17 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 03:17:33 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 03:44:42 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 03:55:13 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 04:09:00 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 04:20:03 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 04:42:32 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 04:53:14 INFO mapreduce.Job: Job job_1422482982071_4476 completed successfully
15/04/12 04:53:14 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=30424216021
		FILE: Number of bytes written=60862639511
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=447
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Failed map tasks=23
		Failed reduce tasks=17
		Killed map tasks=1
		Launched map tasks=158
		Launched reduce tasks=32
		Other local map tasks=24
		Data-local map tasks=64
		Rack-local map tasks=70
		Total time spent by all maps in occupied slots (ms)=125994990
		Total time spent by all reduces in occupied slots (ms)=310387906
		Total time spent by all map tasks (ms)=62997495
		Total time spent by all reduce tasks (ms)=155193953
		Total vcore-seconds taken by all map tasks=62997495
		Total vcore-seconds taken by all reduce tasks=155193953
		Total megabyte-seconds taken by all map tasks=510027719520
		Total megabyte-seconds taken by all reduce tasks=1862327436000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424227853
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424227853
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =2010
		Failed Shuffles=0
		Merged Map outputs=2010
		GC time elapsed (ms)=297551
		CPU time spent (ms)=166062690
		Physical memory (bytes) snapshot=292432666624
		Virtual memory (bytes) snapshot=1432326660096
		Total committed heap usage (bytes)=402743144448
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/12 04:53:14 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st

real	297m52.400s
user	0m47.615s
sys	0m11.309s
15/04/12 04:53:17 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 15
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-15-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=15 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1986393634723665459.jar tmpDir=null
15/04/12 04:53:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 04:53:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 04:53:21 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 04:53:21 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 04:53:21 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4501
15/04/12 04:53:22 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4501
15/04/12 04:53:22 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4501/
15/04/12 04:53:22 INFO mapreduce.Job: Running job: job_1422482982071_4501
15/04/12 04:53:28 INFO mapreduce.Job: Job job_1422482982071_4501 running in uber mode : false
15/04/12 04:53:28 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 04:53:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000035_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000025_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000011_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000051_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000008_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000057_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000101_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000113_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000069_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000104_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000065_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000131_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000022_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000120_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000073_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000078_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000087_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:38 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 04:53:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000131_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4501_m_000057_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 04:53:45 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 04:53:52 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 04:54:00 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 04:54:07 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 04:54:13 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 04:54:20 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 04:54:26 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 04:54:33 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 04:54:39 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 04:54:46 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 04:54:52 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 04:54:58 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 04:55:05 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 04:55:11 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 04:55:18 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 04:55:25 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 04:55:31 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 04:55:38 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 04:55:44 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 04:55:50 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 04:55:57 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 04:56:04 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 04:56:10 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 04:56:16 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 04:56:23 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 04:56:29 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 04:56:35 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 04:56:41 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 04:56:47 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 04:56:54 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 04:57:01 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 04:57:09 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 04:57:15 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 04:57:21 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 04:57:28 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 04:57:35 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 04:57:42 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 04:57:48 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 04:57:54 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 04:58:01 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 04:58:08 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 04:58:15 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 04:58:21 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 04:58:27 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 04:58:34 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 04:58:41 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 04:58:48 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 04:58:54 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 04:59:00 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 04:59:07 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 04:59:14 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 04:59:21 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 04:59:27 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 04:59:33 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 04:59:40 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 04:59:47 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 04:59:54 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 05:00:00 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 05:00:06 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 05:00:13 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 05:00:20 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 05:00:28 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 05:00:32 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 05:00:34 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 05:00:36 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 05:00:40 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 05:00:42 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 05:00:43 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 05:00:44 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 05:00:45 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 05:00:46 INFO mapreduce.Job:  map 73% reduce 7%
15/04/12 05:00:47 INFO mapreduce.Job:  map 73% reduce 8%
15/04/12 05:00:48 INFO mapreduce.Job:  map 74% reduce 8%
15/04/12 05:00:49 INFO mapreduce.Job:  map 75% reduce 10%
15/04/12 05:00:50 INFO mapreduce.Job:  map 76% reduce 10%
15/04/12 05:00:51 INFO mapreduce.Job:  map 77% reduce 10%
15/04/12 05:00:52 INFO mapreduce.Job:  map 77% reduce 12%
15/04/12 05:00:55 INFO mapreduce.Job:  map 78% reduce 13%
15/04/12 05:00:57 INFO mapreduce.Job:  map 79% reduce 13%
15/04/12 05:00:59 INFO mapreduce.Job:  map 79% reduce 14%
15/04/12 05:01:01 INFO mapreduce.Job:  map 80% reduce 14%
15/04/12 05:01:05 INFO mapreduce.Job:  map 81% reduce 14%
15/04/12 05:01:17 INFO mapreduce.Job:  map 82% reduce 14%
15/04/12 05:01:19 INFO mapreduce.Job:  map 82% reduce 15%
15/04/12 05:01:24 INFO mapreduce.Job:  map 82% reduce 16%
15/04/12 05:01:25 INFO mapreduce.Job:  map 83% reduce 16%
15/04/12 05:01:26 INFO mapreduce.Job:  map 84% reduce 16%
15/04/12 05:01:28 INFO mapreduce.Job:  map 85% reduce 17%
15/04/12 05:01:29 INFO mapreduce.Job:  map 85% reduce 18%
15/04/12 05:01:30 INFO mapreduce.Job:  map 86% reduce 18%
15/04/12 05:01:31 INFO mapreduce.Job:  map 87% reduce 19%
15/04/12 05:01:32 INFO mapreduce.Job:  map 88% reduce 20%
15/04/12 05:01:34 INFO mapreduce.Job:  map 89% reduce 21%
15/04/12 05:01:35 INFO mapreduce.Job:  map 91% reduce 21%
15/04/12 05:01:36 INFO mapreduce.Job:  map 92% reduce 21%
15/04/12 05:01:37 INFO mapreduce.Job:  map 93% reduce 22%
15/04/12 05:01:38 INFO mapreduce.Job:  map 94% reduce 23%
15/04/12 05:01:40 INFO mapreduce.Job:  map 95% reduce 23%
15/04/12 05:01:42 INFO mapreduce.Job:  map 96% reduce 23%
15/04/12 05:01:46 INFO mapreduce.Job:  map 97% reduce 23%
15/04/12 05:01:48 INFO mapreduce.Job:  map 97% reduce 24%
15/04/12 05:01:50 INFO mapreduce.Job:  map 98% reduce 24%
15/04/12 05:01:55 INFO mapreduce.Job:  map 98% reduce 25%
15/04/12 05:01:56 INFO mapreduce.Job:  map 98% reduce 26%
15/04/12 05:01:57 INFO mapreduce.Job:  map 98% reduce 27%
15/04/12 05:02:00 INFO mapreduce.Job:  map 99% reduce 27%
15/04/12 05:02:01 INFO mapreduce.Job:  map 99% reduce 29%
15/04/12 05:02:02 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 05:02:04 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 05:02:05 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 05:02:09 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 05:02:28 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 05:02:29 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 05:02:30 INFO mapreduce.Job:  map 100% reduce 38%
15/04/12 05:02:31 INFO mapreduce.Job:  map 100% reduce 41%
15/04/12 05:02:32 INFO mapreduce.Job:  map 100% reduce 44%
15/04/12 05:02:33 INFO mapreduce.Job:  map 100% reduce 45%
15/04/12 05:02:34 INFO mapreduce.Job:  map 100% reduce 46%
15/04/12 05:02:35 INFO mapreduce.Job:  map 100% reduce 50%
15/04/12 05:02:36 INFO mapreduce.Job:  map 100% reduce 51%
15/04/12 05:02:37 INFO mapreduce.Job:  map 100% reduce 53%
15/04/12 05:02:38 INFO mapreduce.Job:  map 100% reduce 56%
15/04/12 05:02:40 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 05:02:41 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 05:02:42 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 05:02:44 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 05:02:45 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 05:02:48 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 05:02:54 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 05:06:04 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 05:09:38 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 05:13:31 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 05:15:32 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 05:19:14 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 05:21:28 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 05:24:04 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 05:27:14 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 05:29:27 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 05:30:41 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 05:32:06 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 05:35:20 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 05:37:04 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 05:38:18 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 05:40:06 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 05:42:07 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 05:44:28 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 05:46:31 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 05:48:47 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 05:51:53 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 05:53:38 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 05:56:18 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 05:58:44 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 06:00:51 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 06:04:51 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 06:11:25 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 06:18:06 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 06:32:54 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 06:48:55 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 07:07:49 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 07:12:48 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 07:17:03 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 07:41:46 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 07:57:07 INFO mapreduce.Job: Job job_1422482982071_4501 completed successfully
15/04/12 07:57:07 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=30424216021
		FILE: Number of bytes written=60862639511
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=447
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Failed map tasks=23
		Launched map tasks=157
		Launched reduce tasks=15
		Other local map tasks=23
		Data-local map tasks=66
		Rack-local map tasks=68
		Total time spent by all maps in occupied slots (ms)=123572204
		Total time spent by all reduces in occupied slots (ms)=155974890
		Total time spent by all map tasks (ms)=61786102
		Total time spent by all reduce tasks (ms)=77987445
		Total vcore-seconds taken by all map tasks=61786102
		Total vcore-seconds taken by all reduce tasks=77987445
		Total megabyte-seconds taken by all map tasks=500220281792
		Total megabyte-seconds taken by all reduce tasks=935849340000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424227853
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424227853
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =2010
		Failed Shuffles=0
		Merged Map outputs=2010
		GC time elapsed (ms)=296078
		CPU time spent (ms)=164296060
		Physical memory (bytes) snapshot=291544973312
		Virtual memory (bytes) snapshot=1431145320448
		Total committed heap usage (bytes)=402717851648
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/12 07:57:07 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st

real	183m52.329s
user	0m36.206s
sys	0m6.991s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-35-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=35"


15/04/12 07:57:12 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 07:57:12 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5454475816601732628.jar tmpDir=null
15/04/12 07:57:13 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 07:57:13 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 07:57:13 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 07:57:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 07:57:14 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 07:57:14 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4510
15/04/12 07:57:15 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4510
15/04/12 07:57:15 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4510/
15/04/12 07:57:15 INFO mapreduce.Job: Running job: job_1422482982071_4510
15/04/12 07:57:21 INFO mapreduce.Job: Job job_1422482982071_4510 running in uber mode : false
15/04/12 07:57:21 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 07:57:31 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 07:57:32 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 07:57:34 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 07:57:35 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 07:57:36 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 07:57:38 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 07:57:39 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 07:57:40 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 07:57:41 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 07:57:42 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 07:57:43 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 07:57:44 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 07:57:45 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 07:57:47 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 07:57:48 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 07:57:49 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 07:57:50 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 07:57:51 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 07:57:52 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 07:57:53 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 07:57:54 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 07:57:56 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 07:57:57 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 07:57:59 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 07:58:00 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 07:58:02 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 07:58:03 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 07:58:04 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 07:58:05 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 07:58:06 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 07:58:07 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 07:58:08 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 07:58:09 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 07:58:10 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 07:58:11 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 07:58:12 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 07:58:13 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 07:58:14 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 07:58:15 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 07:58:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4510_m_000038_0, Status : FAILED
Error: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:334)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRawBytes(TypedBytesInput.java:218)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRaw(TypedBytesInput.java:152)
	at org.apache.hadoop.streaming.io.TypedBytesOutputReader.readKeyValue(TypedBytesOutputReader.java:56)
	at org.apache.hadoop.streaming.PipeMapRed$MROutputThread.run(PipeMapRed.java:376)

15/04/12 07:58:19 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 07:58:21 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 07:58:23 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 07:58:26 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 07:58:27 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 07:58:28 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 07:58:29 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 07:58:30 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 07:58:31 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 07:58:32 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 07:58:33 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 07:58:34 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 07:58:35 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 07:58:36 INFO mapreduce.Job:  map 88% reduce 0%
15/04/12 07:58:37 INFO mapreduce.Job:  map 88% reduce 13%
15/04/12 07:58:38 INFO mapreduce.Job:  map 89% reduce 23%
15/04/12 07:58:39 INFO mapreduce.Job:  map 90% reduce 25%
15/04/12 07:58:41 INFO mapreduce.Job:  map 90% reduce 26%
15/04/12 07:58:42 INFO mapreduce.Job:  map 91% reduce 26%
15/04/12 07:58:48 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 07:58:53 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 07:58:56 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 07:58:57 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 07:58:59 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 07:59:00 INFO mapreduce.Job:  map 96% reduce 29%
15/04/12 07:59:01 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 07:59:02 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 07:59:03 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 07:59:06 INFO mapreduce.Job:  map 99% reduce 33%
15/04/12 07:59:33 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 07:59:34 INFO mapreduce.Job:  map 100% reduce 36%
15/04/12 07:59:35 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 07:59:36 INFO mapreduce.Job:  map 100% reduce 58%
15/04/12 07:59:37 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 07:59:38 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 07:59:39 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 07:59:40 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 07:59:42 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 07:59:45 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 07:59:47 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 07:59:48 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 07:59:51 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 07:59:52 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 07:59:54 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 07:59:55 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 07:59:57 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 08:00:00 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 08:00:03 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 08:00:06 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 08:00:07 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 08:00:12 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 08:00:16 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 08:00:19 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 08:00:24 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 08:00:29 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 08:00:33 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 08:00:36 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 08:00:41 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 08:00:46 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 08:00:51 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 08:00:56 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 08:01:03 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 08:01:11 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 08:01:22 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 08:01:31 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 08:01:53 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 08:04:58 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 08:07:13 INFO mapreduce.Job: Job job_1422482982071_4510 completed successfully
15/04/12 08:07:13 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=10607076759
		FILE: Number of bytes written=21222395473
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109478906
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Failed map tasks=1
		Killed map tasks=1
		Launched map tasks=52
		Launched reduce tasks=35
		Other local map tasks=2
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=7579000
		Total time spent by all reduces in occupied slots (ms)=15200190
		Total time spent by all map tasks (ms)=3789500
		Total time spent by all reduce tasks (ms)=7600095
		Total vcore-seconds taken by all map tasks=3789500
		Total vcore-seconds taken by all reduce tasks=7600095
		Total megabyte-seconds taken by all map tasks=30679792000
		Total megabyte-seconds taken by all reduce tasks=91201140000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985387
		Map output bytes=10355527761
		Map output materialized bytes=10607087049
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623830
		Reduce shuffle bytes=10607087049
		Reduce input records=121985387
		Reduce output records=18701000
		Spilled Records=243970774
		Shuffled Maps =1750
		Failed Shuffles=0
		Merged Map outputs=1750
		GC time elapsed (ms)=62029
		CPU time spent (ms)=9115980
		Physical memory (bytes) snapshot=114980839424
		Virtual memory (bytes) snapshot=926693109760
		Total committed heap usage (bytes)=212163989504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109478906
	rmr
		reduce calls=18623830
15/04/12 08:07:13 INFO streaming.StreamJob: Output directory: /tmp/file871c44a0384
function () 
{
    fname
}
<bytecode: 0x1c95080>
<environment: 0x1c94448>
15/04/12 08:07:18 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file871c44a0384

real	10m11.826s
user	0m20.853s
sys	0m1.538s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-35-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=35"


15/04/12 08:07:23 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 08:07:23 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1382799195026154854.jar tmpDir=null
15/04/12 08:07:24 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 08:07:24 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 08:07:25 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 08:07:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 08:07:25 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 08:07:25 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4511
15/04/12 08:07:26 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4511
15/04/12 08:07:26 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4511/
15/04/12 08:07:26 INFO mapreduce.Job: Running job: job_1422482982071_4511
15/04/12 08:07:32 INFO mapreduce.Job: Job job_1422482982071_4511 running in uber mode : false
15/04/12 08:07:32 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 08:07:43 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 08:07:44 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 08:07:47 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 08:07:49 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 08:07:50 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 08:07:53 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 08:07:54 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 08:07:56 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 08:07:57 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 08:07:59 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 08:08:00 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 08:08:02 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 08:08:03 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 08:08:05 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 08:08:06 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 08:08:08 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 08:08:09 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 08:08:11 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 08:08:12 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 08:08:14 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 08:08:15 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 08:08:17 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 08:08:18 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 08:08:21 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 08:08:24 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 08:08:27 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 08:08:29 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 08:08:30 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 08:08:33 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 08:08:37 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 08:08:38 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 08:08:39 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 08:08:40 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 08:08:41 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 08:08:42 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 08:08:43 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 08:08:44 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 08:08:46 INFO mapreduce.Job:  map 88% reduce 0%
15/04/12 08:08:47 INFO mapreduce.Job:  map 90% reduce 0%
15/04/12 08:08:48 INFO mapreduce.Job:  map 91% reduce 14%
15/04/12 08:08:49 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 08:08:50 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 08:08:51 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 08:08:52 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 08:08:55 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 08:09:04 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 08:09:08 INFO mapreduce.Job:  map 97% reduce 27%
15/04/12 08:09:09 INFO mapreduce.Job:  map 98% reduce 28%
15/04/12 08:09:10 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 08:09:11 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 08:09:13 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 08:09:16 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 08:09:17 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 08:09:18 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 08:09:19 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 08:09:20 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 08:09:21 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 08:09:22 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 08:09:23 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 08:09:25 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 08:09:26 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 08:09:28 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 08:09:29 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 08:09:31 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 08:09:32 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 08:09:34 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 08:09:35 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 08:09:37 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 08:09:38 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 08:09:40 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 08:09:43 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 08:09:46 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 08:09:49 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 08:09:52 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 08:09:55 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 08:10:00 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 08:10:04 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 08:10:08 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 08:10:11 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 08:10:17 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 08:10:20 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 08:10:25 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 08:10:29 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 08:10:35 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 08:10:41 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 08:10:47 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 08:10:55 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 08:11:06 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 08:11:17 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 08:11:40 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 08:14:42 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 08:16:56 INFO mapreduce.Job: Job job_1422482982071_4511 completed successfully
15/04/12 08:16:56 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607080233
		FILE: Number of bytes written=21222402166
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109480922
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=35
		Data-local map tasks=32
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=7329750
		Total time spent by all reduces in occupied slots (ms)=13450192
		Total time spent by all map tasks (ms)=3664875
		Total time spent by all reduce tasks (ms)=6725096
		Total vcore-seconds taken by all map tasks=3664875
		Total vcore-seconds taken by all reduce tasks=6725096
		Total megabyte-seconds taken by all map tasks=29670828000
		Total megabyte-seconds taken by all reduce tasks=80701152000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985462
		Map output bytes=10355531079
		Map output materialized bytes=10607090523
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623887
		Reduce shuffle bytes=10607090523
		Reduce input records=121985462
		Reduce output records=18701048
		Spilled Records=243970924
		Shuffled Maps =1750
		Failed Shuffles=0
		Merged Map outputs=1750
		GC time elapsed (ms)=68711
		CPU time spent (ms)=9195840
		Physical memory (bytes) snapshot=114930069504
		Virtual memory (bytes) snapshot=926884196352
		Total committed heap usage (bytes)=212164100096
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109480922
	rmr
		reduce calls=18623887
15/04/12 08:16:56 INFO streaming.StreamJob: Output directory: /tmp/file88b22c5521dc
function () 
{
    fname
}
<bytecode: 0x1ef6080>
<environment: 0x1ef5448>
15/04/12 08:17:01 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file88b22c5521dc

real	9m42.813s
user	0m19.957s
sys	0m1.344s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-35-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=35"


15/04/12 08:17:06 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 08:17:06 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4504539478113980407.jar tmpDir=null
15/04/12 08:17:07 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 08:17:07 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 08:17:07 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 08:17:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 08:17:08 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 08:17:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4512
15/04/12 08:17:08 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4512
15/04/12 08:17:09 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4512/
15/04/12 08:17:09 INFO mapreduce.Job: Running job: job_1422482982071_4512
15/04/12 08:17:14 INFO mapreduce.Job: Job job_1422482982071_4512 running in uber mode : false
15/04/12 08:17:14 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 08:17:25 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 08:17:26 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 08:17:28 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 08:17:29 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 08:17:31 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 08:17:32 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 08:17:34 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 08:17:35 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 08:17:38 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 08:17:41 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 08:17:44 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 08:17:47 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 08:17:48 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 08:17:50 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 08:17:51 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 08:17:53 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 08:17:54 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 08:17:56 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 08:17:57 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 08:17:58 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 08:17:59 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 08:18:00 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 08:18:01 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 08:18:02 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 08:18:03 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 08:18:05 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 08:18:06 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 08:18:08 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 08:18:09 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 08:18:11 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 08:18:12 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 08:18:14 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 08:18:17 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 08:18:19 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 08:18:20 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 08:18:21 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 08:18:22 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 08:18:23 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 08:18:24 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 08:18:25 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 08:18:27 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 08:18:28 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 08:18:30 INFO mapreduce.Job:  map 91% reduce 1%
15/04/12 08:18:31 INFO mapreduce.Job:  map 92% reduce 3%
15/04/12 08:18:32 INFO mapreduce.Job:  map 92% reduce 20%
15/04/12 08:18:33 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 08:18:34 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 08:18:35 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 08:18:36 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 08:18:43 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 08:18:47 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 08:18:48 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 08:18:49 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 08:18:51 INFO mapreduce.Job:  map 97% reduce 30%
15/04/12 08:18:52 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 08:18:53 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 08:18:54 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 08:18:59 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 08:19:00 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 08:19:01 INFO mapreduce.Job:  map 100% reduce 38%
15/04/12 08:19:02 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 08:19:03 INFO mapreduce.Job:  map 100% reduce 47%
15/04/12 08:19:04 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 08:19:05 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 08:19:06 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 08:19:07 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 08:19:08 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 08:19:10 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 08:19:12 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 08:19:13 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 08:19:15 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 08:19:16 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 08:19:17 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 08:19:20 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 08:19:21 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 08:19:22 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 08:19:25 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 08:19:26 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 08:19:29 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 08:19:33 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 08:19:35 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 08:19:40 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 08:19:43 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 08:19:48 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 08:19:54 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 08:19:56 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 08:20:01 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 08:20:04 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 08:20:08 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 08:20:13 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 08:20:19 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 08:20:24 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 08:20:31 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 08:20:39 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 08:20:51 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 08:21:01 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 08:21:23 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 08:24:28 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 08:26:49 INFO mapreduce.Job: Job job_1422482982071_4512 completed successfully
15/04/12 08:26:50 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607083984
		FILE: Number of bytes written=21222409328
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109479428
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=35
		Data-local map tasks=32
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=7378278
		Total time spent by all reduces in occupied slots (ms)=13540512
		Total time spent by all map tasks (ms)=3689139
		Total time spent by all reduce tasks (ms)=6770256
		Total vcore-seconds taken by all map tasks=3689139
		Total vcore-seconds taken by all reduce tasks=6770256
		Total megabyte-seconds taken by all map tasks=29867269344
		Total megabyte-seconds taken by all reduce tasks=81243072000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985447
		Map output bytes=10355534867
		Map output materialized bytes=10607094274
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623854
		Reduce shuffle bytes=10607094274
		Reduce input records=121985447
		Reduce output records=18701018
		Spilled Records=243970894
		Shuffled Maps =1750
		Failed Shuffles=0
		Merged Map outputs=1750
		GC time elapsed (ms)=66596
		CPU time spent (ms)=9249390
		Physical memory (bytes) snapshot=115006648320
		Virtual memory (bytes) snapshot=926890348544
		Total committed heap usage (bytes)=212164018176
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109479428
	rmr
		reduce calls=18623854
15/04/12 08:26:50 INFO streaming.StreamJob: Output directory: /tmp/file8a6a3086d156
function () 
{
    fname
}
<bytecode: 0x2517080>
<environment: 0x2516448>
15/04/12 08:26:55 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file8a6a3086d156

real	9m53.535s
user	0m20.914s
sys	0m1.509s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-25-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=25"


15/04/12 08:27:00 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 08:27:00 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1652417252464156297.jar tmpDir=null
15/04/12 08:27:00 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 08:27:00 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 08:27:01 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 08:27:01 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 08:27:01 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 08:27:02 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4514
15/04/12 08:27:02 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4514
15/04/12 08:27:02 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4514/
15/04/12 08:27:02 INFO mapreduce.Job: Running job: job_1422482982071_4514
15/04/12 08:27:07 INFO mapreduce.Job: Job job_1422482982071_4514 running in uber mode : false
15/04/12 08:27:07 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 08:27:19 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 08:27:20 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 08:27:22 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 08:27:23 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 08:27:25 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 08:27:26 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 08:27:28 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 08:27:29 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 08:27:30 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 08:27:31 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 08:27:32 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 08:27:33 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 08:27:34 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 08:27:35 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 08:27:36 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 08:27:37 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 08:27:38 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 08:27:39 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 08:27:40 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 08:27:41 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 08:27:42 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 08:27:43 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 08:27:44 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 08:27:45 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 08:27:46 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 08:27:47 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 08:27:48 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 08:27:49 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 08:27:50 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 08:27:51 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 08:27:53 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 08:27:54 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 08:27:56 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 08:27:57 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 08:27:59 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 08:28:00 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 08:28:01 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 08:28:02 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 08:28:03 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 08:28:05 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 08:28:06 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 08:28:08 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 08:28:09 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 08:28:12 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 08:28:13 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 08:28:14 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 08:28:15 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 08:28:16 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 08:28:17 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 08:28:18 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 08:28:19 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 08:28:20 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 08:28:21 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 08:28:22 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 08:28:23 INFO mapreduce.Job:  map 88% reduce 0%
15/04/12 08:28:24 INFO mapreduce.Job:  map 88% reduce 12%
15/04/12 08:28:25 INFO mapreduce.Job:  map 91% reduce 23%
15/04/12 08:28:27 INFO mapreduce.Job:  map 92% reduce 24%
15/04/12 08:28:28 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 08:28:30 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 08:28:31 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 08:28:39 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 08:28:40 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 08:28:43 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 08:28:44 INFO mapreduce.Job:  map 98% reduce 28%
15/04/12 08:28:45 INFO mapreduce.Job:  map 99% reduce 29%
15/04/12 08:28:46 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 08:28:47 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 08:28:49 INFO mapreduce.Job:  map 100% reduce 38%
15/04/12 08:28:50 INFO mapreduce.Job:  map 100% reduce 41%
15/04/12 08:28:51 INFO mapreduce.Job:  map 100% reduce 45%
15/04/12 08:28:52 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 08:28:53 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 08:28:54 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 08:28:55 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 08:28:57 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 08:28:59 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 08:29:01 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 08:29:04 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 08:29:05 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 08:29:08 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 08:29:11 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 08:29:14 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 08:29:15 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 08:29:18 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 08:29:20 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 08:29:24 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 08:29:29 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 08:29:32 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 08:29:38 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 08:29:44 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 08:29:51 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 08:29:54 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 08:29:57 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 08:30:02 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 08:30:08 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 08:30:15 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 08:30:18 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 08:30:27 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 08:30:32 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 08:30:39 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 08:30:47 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 08:30:58 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 08:31:11 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 08:31:26 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 08:31:46 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 08:32:31 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 08:34:54 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 08:37:20 INFO mapreduce.Job: Job job_1422482982071_4514 completed successfully
15/04/12 08:37:20 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607083294
		FILE: Number of bytes written=21221430368
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109185353
		HDFS: Number of read operations=225
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=25
		Data-local map tasks=32
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=7378148
		Total time spent by all reduces in occupied slots (ms)=12682386
		Total time spent by all map tasks (ms)=3689074
		Total time spent by all reduce tasks (ms)=6341193
		Total vcore-seconds taken by all map tasks=3689074
		Total vcore-seconds taken by all reduce tasks=6341193
		Total megabyte-seconds taken by all map tasks=29866743104
		Total megabyte-seconds taken by all reduce tasks=76094316000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985415
		Map output bytes=10355534297
		Map output materialized bytes=10607090644
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623891
		Reduce shuffle bytes=10607090644
		Reduce input records=121985415
		Reduce output records=18699002
		Spilled Records=243970830
		Shuffled Maps =1250
		Failed Shuffles=0
		Merged Map outputs=1250
		GC time elapsed (ms)=59645
		CPU time spent (ms)=9288820
		Physical memory (bytes) snapshot=113020137472
		Virtual memory (bytes) snapshot=793241989120
		Total committed heap usage (bytes)=191113424896
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109185353
	rmr
		reduce calls=18623891
15/04/12 08:37:20 INFO streaming.StreamJob: Output directory: /tmp/file8d21755a1277
function () 
{
    fname
}
<bytecode: 0x2bf3080>
<environment: 0x2bf2448>
15/04/12 08:37:26 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file8d21755a1277

real	10m30.998s
user	0m22.120s
sys	0m1.762s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-25-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=25"


15/04/12 08:37:31 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 08:37:31 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7252276250120390670.jar tmpDir=null
15/04/12 08:37:31 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 08:37:31 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 08:37:32 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 08:37:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 08:37:33 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 08:37:34 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4515
15/04/12 08:37:34 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4515
15/04/12 08:37:34 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4515/
15/04/12 08:37:34 INFO mapreduce.Job: Running job: job_1422482982071_4515
15/04/12 08:37:39 INFO mapreduce.Job: Job job_1422482982071_4515 running in uber mode : false
15/04/12 08:37:39 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 08:37:50 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 08:37:51 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 08:37:53 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 08:37:54 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 08:37:57 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 08:37:59 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 08:38:00 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 08:38:03 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 08:38:04 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 08:38:06 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 08:38:07 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 08:38:09 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 08:38:10 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 08:38:12 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 08:38:13 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 08:38:15 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 08:38:16 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 08:38:19 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 08:38:20 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 08:38:21 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 08:38:22 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 08:38:23 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 08:38:25 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 08:38:26 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 08:38:28 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 08:38:29 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 08:38:31 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 08:38:32 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 08:38:34 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 08:38:35 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 08:38:37 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 08:38:38 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 08:38:41 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 08:38:43 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 08:38:44 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 08:38:45 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 08:38:46 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 08:38:47 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 08:38:48 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 08:38:49 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 08:38:50 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 08:38:51 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 08:38:52 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 08:38:53 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 08:38:54 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 08:38:55 INFO mapreduce.Job:  map 90% reduce 13%
15/04/12 08:38:56 INFO mapreduce.Job:  map 92% reduce 24%
15/04/12 08:38:58 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 08:38:59 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 08:39:05 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 08:39:11 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 08:39:14 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 08:39:15 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 08:39:17 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 08:39:19 INFO mapreduce.Job:  map 97% reduce 30%
15/04/12 08:39:20 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 08:39:23 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 08:39:24 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 08:39:25 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 08:39:26 INFO mapreduce.Job:  map 100% reduce 49%
15/04/12 08:39:27 INFO mapreduce.Job:  map 100% reduce 56%
15/04/12 08:39:29 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 08:39:30 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 08:39:32 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 08:39:35 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 08:39:36 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 08:39:39 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 08:39:41 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 08:39:43 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 08:39:45 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 08:39:48 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 08:39:50 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 08:39:53 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 08:39:54 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 08:39:59 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 08:40:03 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 08:40:06 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 08:40:14 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 08:40:20 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 08:40:24 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 08:40:27 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 08:40:32 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 08:40:36 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 08:40:42 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 08:40:48 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 08:40:55 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 08:41:01 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 08:41:07 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 08:41:14 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 08:41:22 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 08:41:34 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 08:41:46 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 08:41:58 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 08:42:19 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 08:43:02 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 08:45:34 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 08:48:39 INFO mapreduce.Job: Job job_1422482982071_4515 completed successfully
15/04/12 08:48:39 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607075934
		FILE: Number of bytes written=21221415648
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109181171
		HDFS: Number of read operations=225
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=25
		Data-local map tasks=31
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=7377468
		Total time spent by all reduces in occupied slots (ms)=12904804
		Total time spent by all map tasks (ms)=3688734
		Total time spent by all reduce tasks (ms)=6452402
		Total vcore-seconds taken by all map tasks=3688734
		Total vcore-seconds taken by all reduce tasks=6452402
		Total megabyte-seconds taken by all map tasks=29863990464
		Total megabyte-seconds taken by all reduce tasks=77428824000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985389
		Map output bytes=10355526991
		Map output materialized bytes=10607083284
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623818
		Reduce shuffle bytes=10607083284
		Reduce input records=121985389
		Reduce output records=18698928
		Spilled Records=243970778
		Shuffled Maps =1250
		Failed Shuffles=0
		Merged Map outputs=1250
		GC time elapsed (ms)=68782
		CPU time spent (ms)=9316030
		Physical memory (bytes) snapshot=112972795904
		Virtual memory (bytes) snapshot=793044942848
		Total committed heap usage (bytes)=191113760768
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109181171
	rmr
		reduce calls=18623818
15/04/12 08:48:39 INFO streaming.StreamJob: Output directory: /tmp/file8ea1324b4947
function () 
{
    fname
}
<bytecode: 0x2234080>
<environment: 0x2233448>
15/04/12 08:48:46 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file8ea1324b4947

real	11m20.337s
user	0m23.086s
sys	0m1.657s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-25-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=25"


15/04/12 08:48:52 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 08:48:52 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4694892751633455683.jar tmpDir=null
15/04/12 08:48:52 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 08:48:52 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 08:48:53 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 08:48:53 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 08:48:53 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 08:48:54 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4517
15/04/12 08:48:54 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4517
15/04/12 08:48:54 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4517/
15/04/12 08:48:54 INFO mapreduce.Job: Running job: job_1422482982071_4517
15/04/12 08:49:01 INFO mapreduce.Job: Job job_1422482982071_4517 running in uber mode : false
15/04/12 08:49:01 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 08:49:11 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 08:49:12 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 08:49:13 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 08:49:15 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 08:49:16 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 08:49:17 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 08:49:18 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 08:49:19 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 08:49:21 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 08:49:22 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 08:49:24 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 08:49:25 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 08:49:27 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 08:49:28 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 08:49:30 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 08:49:31 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 08:49:33 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 08:49:34 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 08:49:36 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 08:49:37 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 08:49:38 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 08:49:40 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 08:49:41 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 08:49:43 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 08:49:44 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 08:49:46 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 08:49:47 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 08:49:49 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 08:49:50 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 08:49:51 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 08:49:52 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 08:49:53 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 08:49:54 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 08:49:55 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 08:49:57 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 08:49:58 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 08:49:59 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 08:50:01 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 08:50:04 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 08:50:05 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 08:50:06 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 08:50:07 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 08:50:08 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 08:50:09 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 08:50:10 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 08:50:11 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 08:50:13 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 08:50:14 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 08:50:15 INFO mapreduce.Job:  map 88% reduce 10%
15/04/12 08:50:16 INFO mapreduce.Job:  map 89% reduce 21%
15/04/12 08:50:17 INFO mapreduce.Job:  map 90% reduce 23%
15/04/12 08:50:19 INFO mapreduce.Job:  map 90% reduce 25%
15/04/12 08:50:20 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 08:50:21 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 08:50:22 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 08:50:23 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 08:50:34 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 08:50:35 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 08:50:37 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 08:50:38 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 08:50:39 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 08:50:40 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 08:50:41 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 08:50:43 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 08:50:44 INFO mapreduce.Job:  map 99% reduce 33%
15/04/12 08:50:46 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 08:50:48 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 08:50:49 INFO mapreduce.Job:  map 100% reduce 44%
15/04/12 08:50:50 INFO mapreduce.Job:  map 100% reduce 53%
15/04/12 08:50:51 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 08:50:52 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 08:50:53 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 08:50:54 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 08:50:56 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 08:50:58 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 08:51:00 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 08:51:03 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 08:51:05 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 08:51:08 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 08:51:09 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 08:51:12 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 08:51:15 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 08:51:17 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 08:51:19 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 08:51:22 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 08:51:27 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 08:51:32 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 08:51:38 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 08:51:42 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 08:51:47 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 08:51:52 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 08:51:56 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 08:52:01 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 08:52:06 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 08:52:12 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 08:52:18 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 08:52:25 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 08:52:30 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 08:52:38 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 08:52:43 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 08:52:55 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 08:53:07 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 08:53:22 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 08:53:41 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 08:54:40 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 08:56:58 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 08:59:54 INFO mapreduce.Job: Job job_1422482982071_4517 completed successfully
15/04/12 08:59:54 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607082353
		FILE: Number of bytes written=21221428486
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109180220
		HDFS: Number of read operations=225
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=25
		Data-local map tasks=32
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=7448926
		Total time spent by all reduces in occupied slots (ms)=12885814
		Total time spent by all map tasks (ms)=3724463
		Total time spent by all reduce tasks (ms)=6442907
		Total vcore-seconds taken by all map tasks=3724463
		Total vcore-seconds taken by all reduce tasks=6442907
		Total megabyte-seconds taken by all map tasks=30153252448
		Total megabyte-seconds taken by all reduce tasks=77314884000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985407
		Map output bytes=10355533366
		Map output materialized bytes=10607089703
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623828
		Reduce shuffle bytes=10607089703
		Reduce input records=121985407
		Reduce output records=18698928
		Spilled Records=243970814
		Shuffled Maps =1250
		Failed Shuffles=0
		Merged Map outputs=1250
		GC time elapsed (ms)=61961
		CPU time spent (ms)=9252540
		Physical memory (bytes) snapshot=112954208256
		Virtual memory (bytes) snapshot=793830039552
		Total committed heap usage (bytes)=191113015296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109180220
	rmr
		reduce calls=18623828
15/04/12 08:59:54 INFO streaming.StreamJob: Output directory: /tmp/file916224026917
function () 
{
    fname
}
<bytecode: 0x1d5f080>
<environment: 0x1d5e448>
15/04/12 09:00:01 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file916224026917

real	11m14.511s
user	0m25.122s
sys	0m1.730s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-15-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=15"


15/04/12 09:00:06 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 09:00:06 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8054420603609820715.jar tmpDir=null
15/04/12 09:00:06 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 09:00:06 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 09:00:07 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 09:00:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 09:00:07 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 09:00:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4518
15/04/12 09:00:08 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4518
15/04/12 09:00:08 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4518/
15/04/12 09:00:08 INFO mapreduce.Job: Running job: job_1422482982071_4518
15/04/12 09:00:15 INFO mapreduce.Job: Job job_1422482982071_4518 running in uber mode : false
15/04/12 09:00:15 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 09:00:26 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 09:00:27 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 09:00:29 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 09:00:30 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 09:00:32 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 09:00:33 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 09:00:36 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 09:00:38 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 09:00:39 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 09:00:40 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 09:00:42 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 09:00:44 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 09:00:45 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 09:00:46 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 09:00:47 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 09:00:48 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 09:00:49 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 09:00:50 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 09:00:51 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 09:00:52 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 09:00:53 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 09:00:54 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 09:00:55 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 09:00:56 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 09:00:57 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 09:00:58 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 09:00:59 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 09:01:00 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 09:01:01 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 09:01:02 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 09:01:03 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 09:01:04 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 09:01:05 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 09:01:06 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 09:01:07 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 09:01:09 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 09:01:10 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 09:01:12 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 09:01:13 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 09:01:14 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 09:01:16 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 09:01:18 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 09:01:19 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 09:01:20 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 09:01:21 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 09:01:22 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 09:01:23 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 09:01:24 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 09:01:25 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 09:01:26 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 09:01:27 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 09:01:28 INFO mapreduce.Job:  map 88% reduce 1%
15/04/12 09:01:29 INFO mapreduce.Job:  map 90% reduce 6%
15/04/12 09:01:30 INFO mapreduce.Job:  map 92% reduce 22%
15/04/12 09:01:31 INFO mapreduce.Job:  map 92% reduce 24%
15/04/12 09:01:32 INFO mapreduce.Job:  map 93% reduce 25%
15/04/12 09:01:33 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 09:01:37 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 09:01:43 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 09:01:45 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 09:01:50 INFO mapreduce.Job:  map 96% reduce 29%
15/04/12 09:01:51 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 09:01:52 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 09:01:53 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 09:01:54 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 09:01:55 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 09:01:56 INFO mapreduce.Job:  map 100% reduce 38%
15/04/12 09:01:57 INFO mapreduce.Job:  map 100% reduce 40%
15/04/12 09:01:58 INFO mapreduce.Job:  map 100% reduce 46%
15/04/12 09:01:59 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 09:02:01 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 09:02:02 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 09:02:04 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 09:02:07 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 09:02:11 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 09:02:16 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 09:02:20 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 09:02:23 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 09:02:27 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 09:02:31 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 09:02:35 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 09:02:39 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 09:02:42 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 09:02:48 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 09:02:53 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 09:02:59 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 09:03:06 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 09:03:11 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 09:03:20 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 09:03:26 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 09:03:35 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 09:03:42 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 09:03:53 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 09:04:04 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 09:04:11 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 09:04:22 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 09:04:33 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 09:04:45 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 09:05:00 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 09:05:19 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 09:05:40 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 09:06:01 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 09:06:35 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 09:07:18 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 09:08:00 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 09:10:05 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 09:13:50 INFO mapreduce.Job: Job job_1422482982071_4518 completed successfully
15/04/12 09:13:50 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607076185
		FILE: Number of bytes written=21220437559
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1108997966
		HDFS: Number of read operations=195
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=15
		Data-local map tasks=32
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=7254774
		Total time spent by all reduces in occupied slots (ms)=11826204
		Total time spent by all map tasks (ms)=3627387
		Total time spent by all reduce tasks (ms)=5913102
		Total vcore-seconds taken by all map tasks=3627387
		Total vcore-seconds taken by all reduce tasks=5913102
		Total megabyte-seconds taken by all map tasks=29367325152
		Total megabyte-seconds taken by all reduce tasks=70957224000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985387
		Map output bytes=10355527303
		Map output materialized bytes=10607080589
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623813
		Reduce shuffle bytes=10607080589
		Reduce input records=121985387
		Reduce output records=18697711
		Spilled Records=243970774
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=58715
		CPU time spent (ms)=9225890
		Physical memory (bytes) snapshot=111077122048
		Virtual memory (bytes) snapshot=658985627648
		Total committed heap usage (bytes)=170062340096
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1108997966
	rmr
		reduce calls=18623813
15/04/12 09:13:50 INFO streaming.StreamJob: Output directory: /tmp/file92e44457cfba
function () 
{
    fname
}
<bytecode: 0x20ed080>
<environment: 0x20ec448>
15/04/12 09:13:57 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file92e44457cfba

real	13m56.211s
user	0m24.634s
sys	0m1.727s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-15-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=15"


15/04/12 09:14:02 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 09:14:02 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob941072021259124694.jar tmpDir=null
15/04/12 09:14:03 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 09:14:03 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 09:14:04 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 09:14:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 09:14:04 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 09:14:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4519
15/04/12 09:14:05 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4519
15/04/12 09:14:05 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4519/
15/04/12 09:14:05 INFO mapreduce.Job: Running job: job_1422482982071_4519
15/04/12 09:14:12 INFO mapreduce.Job: Job job_1422482982071_4519 running in uber mode : false
15/04/12 09:14:12 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 09:14:23 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 09:14:24 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 09:14:26 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 09:14:27 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 09:14:29 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 09:14:30 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 09:14:32 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 09:14:33 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 09:14:36 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 09:14:39 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 09:14:41 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 09:14:42 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 09:14:44 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 09:14:45 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 09:14:47 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 09:14:48 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 09:14:50 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 09:14:51 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 09:14:53 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 09:14:54 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 09:14:55 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 09:14:57 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 09:14:58 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 09:15:00 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 09:15:01 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 09:15:02 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 09:15:03 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 09:15:04 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 09:15:05 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 09:15:06 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 09:15:07 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 09:15:09 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 09:15:12 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 09:15:14 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 09:15:15 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 09:15:16 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 09:15:17 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 09:15:18 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 09:15:19 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 09:15:20 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 09:15:21 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 09:15:22 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 09:15:23 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 09:15:24 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 09:15:25 INFO mapreduce.Job:  map 89% reduce 1%
15/04/12 09:15:26 INFO mapreduce.Job:  map 90% reduce 11%
15/04/12 09:15:27 INFO mapreduce.Job:  map 90% reduce 22%
15/04/12 09:15:28 INFO mapreduce.Job:  map 91% reduce 24%
15/04/12 09:15:29 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 09:15:30 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 09:15:32 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 09:15:33 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 09:15:41 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 09:15:42 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 09:15:44 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 09:15:46 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 09:15:47 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 09:15:48 INFO mapreduce.Job:  map 97% reduce 30%
15/04/12 09:15:49 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 09:15:50 INFO mapreduce.Job:  map 98% reduce 31%
15/04/12 09:15:52 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 09:15:54 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 09:15:56 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 09:15:57 INFO mapreduce.Job:  map 100% reduce 36%
15/04/12 09:15:58 INFO mapreduce.Job:  map 100% reduce 40%
15/04/12 09:15:59 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 09:16:00 INFO mapreduce.Job:  map 100% reduce 50%
15/04/12 09:16:01 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 09:16:03 INFO mapreduce.Job:  map 100% reduce 58%
15/04/12 09:16:04 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 09:16:05 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 09:16:06 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 09:16:07 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 09:16:10 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 09:16:14 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 09:16:17 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 09:16:22 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 09:16:26 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 09:16:29 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 09:16:34 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 09:16:38 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 09:16:41 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 09:16:46 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 09:16:51 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 09:16:57 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 09:17:04 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 09:17:08 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 09:17:13 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 09:17:19 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 09:17:29 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 09:17:34 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 09:17:43 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 09:17:52 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 09:18:04 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 09:18:11 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 09:18:23 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 09:18:33 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 09:18:47 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 09:19:00 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 09:19:18 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 09:19:40 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 09:20:07 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 09:20:36 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 09:21:23 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 09:22:08 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 09:24:07 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 09:28:11 INFO mapreduce.Job: Job job_1422482982071_4519 completed successfully
15/04/12 09:28:11 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607081616
		FILE: Number of bytes written=21220448746
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1108999853
		HDFS: Number of read operations=195
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=15
		Data-local map tasks=32
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=7325444
		Total time spent by all reduces in occupied slots (ms)=11923264
		Total time spent by all map tasks (ms)=3662722
		Total time spent by all reduce tasks (ms)=5961632
		Total vcore-seconds taken by all map tasks=3662722
		Total vcore-seconds taken by all reduce tasks=5961632
		Total megabyte-seconds taken by all map tasks=29653397312
		Total megabyte-seconds taken by all reduce tasks=71539584000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985390
		Map output bytes=10355532724
		Map output materialized bytes=10607086020
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623861
		Reduce shuffle bytes=10607086020
		Reduce input records=121985390
		Reduce output records=18697752
		Spilled Records=243970780
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=59704
		CPU time spent (ms)=9213460
		Physical memory (bytes) snapshot=111052242944
		Virtual memory (bytes) snapshot=659589763072
		Total committed heap usage (bytes)=170062249984
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1108999853
	rmr
		reduce calls=18623861
15/04/12 09:28:11 INFO streaming.StreamJob: Output directory: /tmp/file94914067c47e
function () 
{
    fname
}
<bytecode: 0x3530080>
<environment: 0x352f448>
15/04/12 09:28:17 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file94914067c47e

real	14m20.245s
user	0m25.254s
sys	0m1.867s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-15-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=15"


15/04/12 09:28:23 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 09:28:23 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6079224075660750764.jar tmpDir=null
15/04/12 09:28:24 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 09:28:24 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 09:28:25 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 09:28:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 09:28:25 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 09:28:25 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4523
15/04/12 09:28:26 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4523
15/04/12 09:28:26 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4523/
15/04/12 09:28:26 INFO mapreduce.Job: Running job: job_1422482982071_4523
15/04/12 09:28:31 INFO mapreduce.Job: Job job_1422482982071_4523 running in uber mode : false
15/04/12 09:28:31 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 09:28:42 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 09:28:43 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 09:28:45 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 09:28:46 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 09:28:47 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 09:28:48 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 09:28:49 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 09:28:51 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 09:28:52 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 09:28:53 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 09:28:54 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 09:28:55 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 09:28:57 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 09:28:58 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 09:29:00 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 09:29:01 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 09:29:03 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 09:29:04 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 09:29:05 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 09:29:06 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 09:29:07 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 09:29:08 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 09:29:10 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 09:29:13 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 09:29:14 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 09:29:15 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 09:29:16 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 09:29:17 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 09:29:18 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 09:29:19 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 09:29:20 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 09:29:21 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 09:29:22 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 09:29:23 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 09:29:24 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 09:29:26 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 09:29:27 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 09:29:28 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 09:29:29 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 09:29:30 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 09:29:32 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 09:29:33 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 09:29:36 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 09:29:37 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 09:29:38 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 09:29:40 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 09:29:41 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 09:29:42 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 09:29:43 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 09:29:44 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 09:29:45 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 09:29:46 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 09:29:47 INFO mapreduce.Job:  map 90% reduce 0%
15/04/12 09:29:48 INFO mapreduce.Job:  map 91% reduce 0%
15/04/12 09:29:49 INFO mapreduce.Job:  map 91% reduce 3%
15/04/12 09:29:50 INFO mapreduce.Job:  map 92% reduce 21%
15/04/12 09:29:51 INFO mapreduce.Job:  map 92% reduce 24%
15/04/12 09:29:52 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 09:29:53 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 09:29:56 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 09:30:01 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 09:30:06 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 09:30:08 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 09:30:11 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 09:30:13 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 09:30:14 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 09:30:17 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 09:30:18 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 09:30:19 INFO mapreduce.Job:  map 100% reduce 37%
15/04/12 09:30:20 INFO mapreduce.Job:  map 100% reduce 46%
15/04/12 09:30:21 INFO mapreduce.Job:  map 100% reduce 53%
15/04/12 09:30:22 INFO mapreduce.Job:  map 100% reduce 56%
15/04/12 09:30:23 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 09:30:24 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 09:30:25 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 09:30:26 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 09:30:27 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 09:30:30 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 09:30:34 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 09:30:39 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 09:30:43 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 09:30:46 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 09:30:50 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 09:30:53 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 09:30:57 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 09:31:02 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 09:31:06 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 09:31:10 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 09:31:18 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 09:31:24 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 09:31:29 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 09:31:35 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 09:31:44 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 09:31:51 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 09:31:56 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 09:32:05 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 09:32:17 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 09:32:26 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 09:32:35 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 09:32:45 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 09:32:54 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 09:33:09 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 09:33:24 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 09:33:42 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 09:34:04 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 09:34:30 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 09:34:57 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 09:35:42 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 09:36:22 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 09:38:22 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 09:42:45 INFO mapreduce.Job: Job job_1422482982071_4523 completed successfully
15/04/12 09:42:45 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607078399
		FILE: Number of bytes written=21220441987
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1108997106
		HDFS: Number of read operations=195
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=15
		Data-local map tasks=31
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=7549952
		Total time spent by all reduces in occupied slots (ms)=11922368
		Total time spent by all map tasks (ms)=3774976
		Total time spent by all reduce tasks (ms)=5961184
		Total vcore-seconds taken by all map tasks=3774976
		Total vcore-seconds taken by all reduce tasks=5961184
		Total megabyte-seconds taken by all map tasks=30562205696
		Total megabyte-seconds taken by all reduce tasks=71534208000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985401
		Map output bytes=10355529483
		Map output materialized bytes=10607082803
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623852
		Reduce shuffle bytes=10607082803
		Reduce input records=121985401
		Reduce output records=18697726
		Spilled Records=243970802
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=53345
		CPU time spent (ms)=9352330
		Physical memory (bytes) snapshot=111159902208
		Virtual memory (bytes) snapshot=659004264448
		Total committed heap usage (bytes)=170062356480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1108997106
	rmr
		reduce calls=18623852
15/04/12 09:42:45 INFO streaming.StreamJob: Output directory: /tmp/file98774adf203a
function () 
{
    fname
}
<bytecode: 0x1927080>
<environment: 0x1926448>
15/04/12 09:42:51 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file98774adf203a

real	14m33.781s
user	0m25.490s
sys	0m1.886s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-35-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=35"


15/04/12 09:42:56 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 09:42:56 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6364792387068483848.jar tmpDir=null
15/04/12 09:42:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 09:42:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 09:42:59 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 09:42:59 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 09:43:00 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4526
15/04/12 09:43:00 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4526
15/04/12 09:43:00 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4526/
15/04/12 09:43:00 INFO mapreduce.Job: Running job: job_1422482982071_4526
15/04/12 09:43:05 INFO mapreduce.Job: Job job_1422482982071_4526 running in uber mode : false
15/04/12 09:43:05 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 09:43:17 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 09:43:18 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 09:43:20 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 09:43:23 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 09:43:24 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 09:43:26 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 09:43:29 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 09:43:30 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 09:43:32 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 09:43:33 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 09:43:35 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 09:43:36 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 09:43:38 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 09:43:39 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 09:43:40 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 09:43:41 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 09:43:42 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 09:43:44 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 09:43:45 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 09:43:47 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 09:43:48 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 09:43:50 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 09:43:51 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 09:43:53 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 09:43:54 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 09:43:55 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 09:43:56 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 09:43:57 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 09:43:59 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 09:44:00 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 09:44:01 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 09:44:02 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 09:44:03 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 09:44:05 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 09:44:06 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 09:44:08 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 09:44:10 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 09:44:11 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 09:44:13 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 09:44:14 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 09:44:15 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 09:44:16 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 09:44:17 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 09:44:18 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 09:44:19 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 09:44:20 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 09:44:21 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 09:44:22 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 09:44:23 INFO mapreduce.Job:  map 89% reduce 15%
15/04/12 09:44:24 INFO mapreduce.Job:  map 90% reduce 23%
15/04/12 09:44:25 INFO mapreduce.Job:  map 91% reduce 23%
15/04/12 09:44:26 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 09:44:27 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 09:44:30 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 09:44:33 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 09:44:46 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 09:44:47 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 09:44:48 INFO mapreduce.Job:  map 96% reduce 27%
15/04/12 09:44:49 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 09:44:50 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 09:44:51 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 09:44:52 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 09:44:54 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 09:44:56 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 09:44:57 INFO mapreduce.Job:  map 100% reduce 40%
15/04/12 09:44:58 INFO mapreduce.Job:  map 100% reduce 45%
15/04/12 09:44:59 INFO mapreduce.Job:  map 100% reduce 48%
15/04/12 09:45:00 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 09:45:01 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 09:45:02 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 09:45:03 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 09:45:04 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 09:45:07 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 09:45:09 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 09:45:12 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 09:45:13 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 09:45:17 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 09:45:20 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 09:45:22 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 09:45:25 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 09:45:28 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 09:45:31 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 09:45:35 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 09:45:40 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 09:45:44 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 09:45:50 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 09:45:55 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 09:46:02 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 09:46:09 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 09:46:14 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 09:46:20 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 09:46:28 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 09:46:35 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 09:46:42 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 09:46:50 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 09:46:59 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 09:47:10 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 09:47:21 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 09:47:34 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 09:47:49 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 09:48:05 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 09:48:37 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 09:49:29 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 10:01:18 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 10:05:44 INFO mapreduce.Job: Job job_1422482982071_4526 completed successfully
15/04/12 10:05:45 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559783853
		FILE: Number of bytes written=33130244955
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1697315100
		HDFS: Number of read operations=330
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=36
		Data-local map tasks=55
		Rack-local map tasks=21
		Total time spent by all maps in occupied slots (ms)=11539920
		Total time spent by all reduces in occupied slots (ms)=22514228
		Total time spent by all map tasks (ms)=5769960
		Total time spent by all reduce tasks (ms)=11257114
		Total vcore-seconds taken by all map tasks=5769960
		Total vcore-seconds taken by all reduce tasks=11257114
		Total megabyte-seconds taken by all map tasks=46713596160
		Total megabyte-seconds taken by all reduce tasks=135085368000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167235
		Map output bytes=16164699397
		Map output materialized bytes=16559799387
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462442
		Reduce shuffle bytes=16559799387
		Reduce input records=191167235
		Reduce output records=28581230
		Spilled Records=382334470
		Shuffled Maps =2625
		Failed Shuffles=0
		Merged Map outputs=2625
		GC time elapsed (ms)=78371
		CPU time spent (ms)=15006960
		Physical memory (bytes) snapshot=169751093248
		Virtual memory (bytes) snapshot=1156458811392
		Total committed heap usage (bytes)=281406595072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1697315100
	rmr
		reduce calls=28462442
15/04/12 10:05:45 INFO streaming.StreamJob: Output directory: /tmp/file9afc37cfb4d
function () 
{
    fname
}
<bytecode: 0x326b080>
<environment: 0x326a448>
15/04/12 10:05:51 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file9afc37cfb4d

real	22m59.795s
user	0m28.557s
sys	0m2.154s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-35-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=35"


15/04/12 10:05:56 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 10:05:56 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1567594462169257479.jar tmpDir=null
15/04/12 10:05:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 10:05:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 10:05:58 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 10:05:58 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 10:05:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4532
15/04/12 10:05:59 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4532
15/04/12 10:05:59 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4532/
15/04/12 10:05:59 INFO mapreduce.Job: Running job: job_1422482982071_4532
15/04/12 10:06:04 INFO mapreduce.Job: Job job_1422482982071_4532 running in uber mode : false
15/04/12 10:06:04 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 10:06:14 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 10:06:15 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 10:06:17 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 10:06:18 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 10:06:21 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 10:06:24 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 10:06:25 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 10:06:27 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 10:06:30 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 10:06:31 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 10:06:33 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 10:06:36 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 10:06:37 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 10:06:39 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 10:06:41 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 10:06:42 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 10:06:46 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 10:06:48 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 10:06:49 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 10:06:52 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 10:06:53 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 10:06:55 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 10:06:56 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 10:06:58 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 10:06:59 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 10:07:01 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 10:07:04 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 10:07:05 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 10:07:07 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 10:07:10 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 10:07:11 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 10:07:13 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 10:07:14 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 10:07:15 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 10:07:16 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 10:07:17 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 10:07:18 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 10:07:19 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 10:07:20 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 10:07:21 INFO mapreduce.Job:  map 86% reduce 1%
15/04/12 10:07:22 INFO mapreduce.Job:  map 89% reduce 9%
15/04/12 10:07:23 INFO mapreduce.Job:  map 90% reduce 21%
15/04/12 10:07:24 INFO mapreduce.Job:  map 91% reduce 23%
15/04/12 10:07:25 INFO mapreduce.Job:  map 91% reduce 24%
15/04/12 10:07:26 INFO mapreduce.Job:  map 91% reduce 26%
15/04/12 10:07:27 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 10:07:28 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 10:07:29 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 10:07:37 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 10:07:47 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 10:07:48 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 10:07:49 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 10:07:50 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 10:07:51 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 10:07:52 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 10:07:53 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 10:07:54 INFO mapreduce.Job:  map 100% reduce 36%
15/04/12 10:07:55 INFO mapreduce.Job:  map 100% reduce 38%
15/04/12 10:07:56 INFO mapreduce.Job:  map 100% reduce 50%
15/04/12 10:07:57 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 10:07:58 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 10:07:59 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 10:08:00 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 10:08:02 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 10:08:05 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 10:08:06 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 10:08:09 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 10:08:11 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 10:08:14 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 10:08:17 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 10:08:19 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 10:08:21 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 10:08:24 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 10:08:27 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 10:08:32 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 10:08:36 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 10:08:40 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 10:08:46 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 10:08:51 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 10:08:56 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 10:09:04 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 10:09:09 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 10:09:16 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 10:09:23 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 10:09:31 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 10:09:37 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 10:09:45 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 10:09:54 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 10:10:04 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 10:10:16 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 10:10:28 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 10:10:43 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 10:10:57 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 10:11:31 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 10:12:21 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 10:24:17 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 10:28:37 INFO mapreduce.Job: Job job_1422482982071_4532 completed successfully
15/04/12 10:28:38 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559777303
		FILE: Number of bytes written=33130231855
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1697308532
		HDFS: Number of read operations=330
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=36
		Data-local map tasks=52
		Rack-local map tasks=24
		Total time spent by all maps in occupied slots (ms)=11564750
		Total time spent by all reduces in occupied slots (ms)=22206764
		Total time spent by all map tasks (ms)=5782375
		Total time spent by all reduce tasks (ms)=11103382
		Total vcore-seconds taken by all map tasks=5782375
		Total vcore-seconds taken by all reduce tasks=11103382
		Total megabyte-seconds taken by all map tasks=46814108000
		Total megabyte-seconds taken by all reduce tasks=133240584000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167248
		Map output bytes=16164692814
		Map output materialized bytes=16559792837
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462399
		Reduce shuffle bytes=16559792837
		Reduce input records=191167248
		Reduce output records=28581173
		Spilled Records=382334496
		Shuffled Maps =2625
		Failed Shuffles=0
		Merged Map outputs=2625
		GC time elapsed (ms)=73002
		CPU time spent (ms)=14913330
		Physical memory (bytes) snapshot=169754456064
		Virtual memory (bytes) snapshot=1156047409152
		Total committed heap usage (bytes)=281405906944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1697308532
	rmr
		reduce calls=28462399
15/04/12 10:28:38 INFO streaming.StreamJob: Output directory: /tmp/file9ffcfe14365
function () 
{
    fname
}
<bytecode: 0x233a080>
<environment: 0x2339448>
15/04/12 10:28:45 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file9ffcfe14365

real	22m54.280s
user	0m29.474s
sys	0m2.204s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-35-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=35"


15/04/12 10:28:51 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 10:28:51 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8193717785047676475.jar tmpDir=null
15/04/12 10:28:51 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 10:28:51 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 10:28:52 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 10:28:53 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 10:28:53 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4538
15/04/12 10:28:54 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4538
15/04/12 10:28:54 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4538/
15/04/12 10:28:54 INFO mapreduce.Job: Running job: job_1422482982071_4538
15/04/12 10:28:58 INFO mapreduce.Job: Job job_1422482982071_4538 running in uber mode : false
15/04/12 10:28:58 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 10:29:09 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 10:29:10 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 10:29:12 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 10:29:13 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 10:29:15 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 10:29:16 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 10:29:18 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 10:29:19 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 10:29:21 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 10:29:22 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 10:29:24 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 10:29:25 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 10:29:27 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 10:29:28 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 10:29:30 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 10:29:31 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 10:29:33 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 10:29:34 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 10:29:36 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 10:29:37 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 10:29:39 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 10:29:40 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 10:29:42 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 10:29:43 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 10:29:45 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 10:29:46 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 10:29:48 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 10:29:49 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 10:29:51 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 10:29:52 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 10:29:54 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 10:29:55 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 10:29:57 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 10:29:58 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 10:30:00 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 10:30:02 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 10:30:05 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 10:30:06 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 10:30:07 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 10:30:08 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 10:30:09 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 10:30:10 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 10:30:11 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 10:30:12 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 10:30:13 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 10:30:14 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 10:30:15 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 10:30:16 INFO mapreduce.Job:  map 90% reduce 1%
15/04/12 10:30:17 INFO mapreduce.Job:  map 90% reduce 16%
15/04/12 10:30:18 INFO mapreduce.Job:  map 91% reduce 24%
15/04/12 10:30:19 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 10:30:20 INFO mapreduce.Job:  map 91% reduce 26%
15/04/12 10:30:22 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 10:30:23 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 10:30:24 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 10:30:30 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 10:30:39 INFO mapreduce.Job:  map 96% reduce 27%
15/04/12 10:30:40 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 10:30:42 INFO mapreduce.Job:  map 96% reduce 29%
15/04/12 10:30:43 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 10:30:44 INFO mapreduce.Job:  map 97% reduce 30%
15/04/12 10:30:45 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 10:30:46 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 10:30:48 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 10:30:49 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 10:30:50 INFO mapreduce.Job:  map 100% reduce 36%
15/04/12 10:30:51 INFO mapreduce.Job:  map 100% reduce 41%
15/04/12 10:30:52 INFO mapreduce.Job:  map 100% reduce 53%
15/04/12 10:30:53 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 10:30:54 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 10:30:55 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 10:30:56 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 10:30:58 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 10:31:01 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 10:31:02 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 10:31:04 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 10:31:07 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 10:31:10 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 10:31:13 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 10:31:16 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 10:31:17 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 10:31:20 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 10:31:25 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 10:31:28 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 10:31:32 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 10:31:36 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 10:31:41 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 10:31:47 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 10:31:52 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 10:31:58 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 10:32:04 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 10:32:10 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 10:32:16 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 10:32:25 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 10:32:31 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 10:32:37 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 10:32:46 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 10:32:56 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 10:33:10 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 10:33:24 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 10:33:35 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 10:33:50 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 10:34:23 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 10:35:17 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 10:47:04 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 10:51:03 INFO mapreduce.Job: Job job_1422482982071_4538 completed successfully
15/04/12 10:51:03 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559765085
		FILE: Number of bytes written=33130206979
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1697297271
		HDFS: Number of read operations=330
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=70
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=36
		Data-local map tasks=50
		Rack-local map tasks=26
		Total time spent by all maps in occupied slots (ms)=11580836
		Total time spent by all reduces in occupied slots (ms)=21966842
		Total time spent by all map tasks (ms)=5790418
		Total time spent by all reduce tasks (ms)=10983421
		Total vcore-seconds taken by all map tasks=5790418
		Total vcore-seconds taken by all reduce tasks=10983421
		Total megabyte-seconds taken by all map tasks=46879224128
		Total megabyte-seconds taken by all reduce tasks=131801052000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167197
		Map output bytes=16164680705
		Map output materialized bytes=16559780619
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462176
		Reduce shuffle bytes=16559780619
		Reduce input records=191167197
		Reduce output records=28580952
		Spilled Records=382334394
		Shuffled Maps =2625
		Failed Shuffles=0
		Merged Map outputs=2625
		GC time elapsed (ms)=76741
		CPU time spent (ms)=14833490
		Physical memory (bytes) snapshot=169788301312
		Virtual memory (bytes) snapshot=1156050493440
		Total committed heap usage (bytes)=281406775296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1697297271
	rmr
		reduce calls=28462176
15/04/12 10:51:03 INFO streaming.StreamJob: Output directory: /tmp/filea4e05deeaec6
function () 
{
    fname
}
<bytecode: 0x1e48080>
<environment: 0x1e47448>
15/04/12 10:51:08 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/filea4e05deeaec6

real	22m23.634s
user	0m26.803s
sys	0m2.174s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-25-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=25"


15/04/12 10:51:15 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 10:51:15 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob434694179245781780.jar tmpDir=null
15/04/12 10:51:16 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 10:51:16 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 10:51:17 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 10:51:17 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 10:51:18 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4544
15/04/12 10:51:18 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4544
15/04/12 10:51:18 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4544/
15/04/12 10:51:18 INFO mapreduce.Job: Running job: job_1422482982071_4544
15/04/12 10:51:23 INFO mapreduce.Job: Job job_1422482982071_4544 running in uber mode : false
15/04/12 10:51:23 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 10:51:34 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 10:51:35 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 10:51:37 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 10:51:40 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 10:51:42 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 10:51:43 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 10:51:44 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 10:51:46 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 10:51:47 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 10:51:49 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 10:51:52 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 10:51:53 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 10:51:55 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 10:51:59 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 10:52:00 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 10:52:02 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 10:52:05 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 10:52:06 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 10:52:08 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 10:52:09 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 10:52:11 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 10:52:12 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 10:52:14 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 10:52:15 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 10:52:17 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 10:52:18 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 10:52:20 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 10:52:21 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 10:52:23 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 10:52:24 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 10:52:26 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 10:52:28 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 10:52:29 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 10:52:31 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 10:52:33 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 10:52:34 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 10:52:35 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 10:52:36 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 10:52:37 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 10:52:38 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 10:52:39 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 10:52:40 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 10:52:41 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 10:52:42 INFO mapreduce.Job:  map 86% reduce 3%
15/04/12 10:52:43 INFO mapreduce.Job:  map 88% reduce 19%
15/04/12 10:52:44 INFO mapreduce.Job:  map 89% reduce 22%
15/04/12 10:52:46 INFO mapreduce.Job:  map 90% reduce 24%
15/04/12 10:52:47 INFO mapreduce.Job:  map 90% reduce 25%
15/04/12 10:52:50 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 10:52:59 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 10:53:04 INFO mapreduce.Job:  map 93% reduce 25%
15/04/12 10:53:05 INFO mapreduce.Job:  map 94% reduce 26%
15/04/12 10:53:07 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 10:53:08 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 10:53:10 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 10:53:11 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 10:53:13 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 10:53:14 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 10:53:15 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 10:53:16 INFO mapreduce.Job:  map 100% reduce 36%
15/04/12 10:53:17 INFO mapreduce.Job:  map 100% reduce 47%
15/04/12 10:53:18 INFO mapreduce.Job:  map 100% reduce 49%
15/04/12 10:53:19 INFO mapreduce.Job:  map 100% reduce 53%
15/04/12 10:53:20 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 10:53:22 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 10:53:23 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 10:53:26 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 10:53:29 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 10:53:32 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 10:53:37 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 10:53:40 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 10:53:44 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 10:53:47 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 10:53:51 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 10:53:55 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 10:53:59 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 10:54:02 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 10:54:08 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 10:54:17 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 10:54:23 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 10:54:30 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 10:54:38 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 10:54:46 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 10:54:54 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 10:55:03 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 10:55:12 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 10:55:23 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 10:55:33 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 10:55:45 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 10:56:00 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 10:56:09 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 10:56:29 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 10:56:42 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 10:57:07 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 10:57:20 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 10:57:38 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 10:58:10 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 11:00:14 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 11:10:40 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 11:15:10 INFO mapreduce.Job: Job job_1422482982071_4544 completed successfully
15/04/12 11:15:11 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559776753
		FILE: Number of bytes written=33129245105
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1697110431
		HDFS: Number of read operations=300
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=26
		Data-local map tasks=50
		Rack-local map tasks=26
		Total time spent by all maps in occupied slots (ms)=11955106
		Total time spent by all reduces in occupied slots (ms)=21288794
		Total time spent by all map tasks (ms)=5977553
		Total time spent by all reduce tasks (ms)=10644397
		Total vcore-seconds taken by all map tasks=5977553
		Total vcore-seconds taken by all reduce tasks=10644397
		Total megabyte-seconds taken by all map tasks=48394269088
		Total megabyte-seconds taken by all reduce tasks=127732764000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167391
		Map output bytes=16164692023
		Map output materialized bytes=16559787847
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462719
		Reduce shuffle bytes=16559787847
		Reduce input records=191167391
		Reduce output records=28580042
		Spilled Records=382334782
		Shuffled Maps =1875
		Failed Shuffles=0
		Merged Map outputs=1875
		GC time elapsed (ms)=72822
		CPU time spent (ms)=15157630
		Physical memory (bytes) snapshot=167743086592
		Virtual memory (bytes) snapshot=1023206002688
		Total committed heap usage (bytes)=260355772416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1697110431
	rmr
		reduce calls=28462719
15/04/12 11:15:11 INFO streaming.StreamJob: Output directory: /tmp/filea8fc64f6164d
function () 
{
    fname
}
<bytecode: 0x2455080>
<environment: 0x2454448>
15/04/12 11:15:16 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/filea8fc64f6164d

real	24m7.711s
user	0m29.224s
sys	0m2.236s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-25-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=25"


15/04/12 11:15:22 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 11:15:22 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4067234708244109652.jar tmpDir=null
15/04/12 11:15:22 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 11:15:22 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 11:15:23 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 11:15:24 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 11:15:24 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4551
15/04/12 11:15:25 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4551
15/04/12 11:15:25 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4551/
15/04/12 11:15:25 INFO mapreduce.Job: Running job: job_1422482982071_4551
15/04/12 11:15:30 INFO mapreduce.Job: Job job_1422482982071_4551 running in uber mode : false
15/04/12 11:15:30 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 11:15:41 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 11:15:42 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 11:15:44 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 11:15:45 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 11:15:47 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 11:15:48 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 11:15:50 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 11:15:51 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 11:15:53 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 11:15:54 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 11:15:56 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 11:15:57 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 11:15:59 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 11:16:00 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 11:16:02 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 11:16:03 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 11:16:05 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 11:16:06 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 11:16:07 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 11:16:08 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 11:16:09 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 11:16:11 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 11:16:13 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 11:16:15 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 11:16:16 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 11:16:18 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 11:16:19 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 11:16:21 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 11:16:22 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 11:16:23 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 11:16:25 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 11:16:27 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 11:16:28 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 11:16:29 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 11:16:31 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 11:16:34 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 11:16:35 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 11:16:37 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 11:16:40 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 11:16:41 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 11:16:42 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 11:16:43 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 11:16:44 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 11:16:45 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 11:16:46 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 11:16:47 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 11:16:48 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 11:16:49 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 11:16:50 INFO mapreduce.Job:  map 90% reduce 0%
15/04/12 11:16:51 INFO mapreduce.Job:  map 91% reduce 16%
15/04/12 11:16:52 INFO mapreduce.Job:  map 92% reduce 24%
15/04/12 11:16:53 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 11:16:54 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 11:16:55 INFO mapreduce.Job:  map 93% reduce 28%
15/04/12 11:17:02 INFO mapreduce.Job:  map 94% reduce 28%
15/04/12 11:17:13 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 11:17:17 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 11:17:18 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 11:17:19 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 11:17:20 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 11:17:22 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 11:17:24 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 11:17:25 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 11:17:26 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 11:17:27 INFO mapreduce.Job:  map 100% reduce 37%
15/04/12 11:17:28 INFO mapreduce.Job:  map 100% reduce 50%
15/04/12 11:17:29 INFO mapreduce.Job:  map 100% reduce 51%
15/04/12 11:17:30 INFO mapreduce.Job:  map 100% reduce 54%
15/04/12 11:17:31 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 11:17:32 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 11:17:33 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 11:17:34 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 11:17:37 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 11:17:40 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 11:17:43 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 11:17:46 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 11:17:52 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 11:17:55 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 11:17:58 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 11:18:04 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 11:18:07 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 11:18:10 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 11:18:16 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 11:18:22 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 11:18:28 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 11:18:37 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 11:18:44 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 11:18:50 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 11:19:02 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 11:19:11 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 11:19:18 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 11:19:26 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 11:19:36 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 11:19:47 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 11:20:02 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 11:20:14 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 11:20:24 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 11:20:42 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 11:20:57 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 11:21:20 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 11:21:32 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 11:21:54 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 11:22:24 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 11:24:28 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 11:35:05 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 11:40:10 INFO mapreduce.Job: Job job_1422482982071_4551 completed successfully
15/04/12 11:40:10 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559775603
		FILE: Number of bytes written=33129242805
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1697080996
		HDFS: Number of read operations=300
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=26
		Data-local map tasks=53
		Rack-local map tasks=23
		Total time spent by all maps in occupied slots (ms)=11747430
		Total time spent by all reduces in occupied slots (ms)=21789210
		Total time spent by all map tasks (ms)=5873715
		Total time spent by all reduce tasks (ms)=10894605
		Total vcore-seconds taken by all map tasks=5873715
		Total vcore-seconds taken by all reduce tasks=10894605
		Total megabyte-seconds taken by all map tasks=47553596640
		Total megabyte-seconds taken by all reduce tasks=130735260000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167271
		Map output bytes=16164691131
		Map output materialized bytes=16559786697
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462318
		Reduce shuffle bytes=16559786697
		Reduce input records=191167271
		Reduce output records=28579622
		Spilled Records=382334542
		Shuffled Maps =1875
		Failed Shuffles=0
		Merged Map outputs=1875
		GC time elapsed (ms)=70919
		CPU time spent (ms)=15187130
		Physical memory (bytes) snapshot=167715536896
		Virtual memory (bytes) snapshot=1022770298880
		Total committed heap usage (bytes)=260355989504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1697080996
	rmr
		reduce calls=28462318
15/04/12 11:40:10 INFO streaming.StreamJob: Output directory: /tmp/fileae8144698591
function () 
{
    fname
}
<bytecode: 0x2d65080>
<environment: 0x2d64448>
15/04/12 11:40:16 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/fileae8144698591

real	25m0.186s
user	0m26.140s
sys	0m2.129s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-25-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=25"


15/04/12 11:40:22 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 11:40:22 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2761080605313712497.jar tmpDir=null
15/04/12 11:40:23 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 11:40:23 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 11:40:24 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 11:40:24 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 11:40:25 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4558
15/04/12 11:40:25 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4558
15/04/12 11:40:25 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4558/
15/04/12 11:40:25 INFO mapreduce.Job: Running job: job_1422482982071_4558
15/04/12 11:40:30 INFO mapreduce.Job: Job job_1422482982071_4558 running in uber mode : false
15/04/12 11:40:30 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 11:40:41 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 11:40:42 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 11:40:44 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 11:40:47 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 11:40:50 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 11:40:51 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 11:40:54 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 11:40:55 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 11:40:57 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 11:41:00 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 11:41:01 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 11:41:03 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 11:41:05 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 11:41:06 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 11:41:09 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 11:41:10 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 11:41:12 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 11:41:15 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 11:41:16 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 11:41:18 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 11:41:21 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 11:41:22 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 11:41:24 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 11:41:26 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 11:41:27 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 11:41:28 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 11:41:30 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 11:41:31 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 11:41:33 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 11:41:35 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 11:41:36 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 11:41:38 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 11:41:41 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 11:41:42 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 11:41:43 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 11:41:44 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 11:41:45 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 11:41:46 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 11:41:47 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 11:41:48 INFO mapreduce.Job:  map 88% reduce 6%
15/04/12 11:41:49 INFO mapreduce.Job:  map 90% reduce 21%
15/04/12 11:41:50 INFO mapreduce.Job:  map 91% reduce 23%
15/04/12 11:41:51 INFO mapreduce.Job:  map 92% reduce 23%
15/04/12 11:41:52 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 11:41:54 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 11:42:03 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 11:42:13 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 11:42:15 INFO mapreduce.Job:  map 96% reduce 27%
15/04/12 11:42:16 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 11:42:17 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 11:42:18 INFO mapreduce.Job:  map 100% reduce 30%
15/04/12 11:42:19 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 11:42:20 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 11:42:21 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 11:42:22 INFO mapreduce.Job:  map 100% reduce 44%
15/04/12 11:42:23 INFO mapreduce.Job:  map 100% reduce 52%
15/04/12 11:42:24 INFO mapreduce.Job:  map 100% reduce 53%
15/04/12 11:42:25 INFO mapreduce.Job:  map 100% reduce 58%
15/04/12 11:42:26 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 11:42:27 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 11:42:28 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 11:42:29 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 11:42:32 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 11:42:35 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 11:42:38 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 11:42:41 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 11:42:46 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 11:42:50 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 11:42:53 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 11:42:57 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 11:43:01 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 11:43:05 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 11:43:08 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 11:43:16 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 11:43:24 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 11:43:31 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 11:43:40 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 11:43:46 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 11:43:54 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 11:44:03 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 11:44:12 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 11:44:20 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 11:44:30 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 11:44:42 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 11:44:55 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 11:45:07 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 11:45:15 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 11:45:33 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 11:45:46 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 11:46:08 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 11:46:19 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 11:46:39 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 11:47:14 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 11:49:19 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 12:00:31 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 12:05:37 INFO mapreduce.Job: Job job_1422482982071_4558 completed successfully
15/04/12 12:05:37 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559766844
		FILE: Number of bytes written=33129225287
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1697087169
		HDFS: Number of read operations=300
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=50
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=26
		Data-local map tasks=51
		Rack-local map tasks=25
		Total time spent by all maps in occupied slots (ms)=11659046
		Total time spent by all reduces in occupied slots (ms)=21316774
		Total time spent by all map tasks (ms)=5829523
		Total time spent by all reduce tasks (ms)=10658387
		Total vcore-seconds taken by all map tasks=5829523
		Total vcore-seconds taken by all reduce tasks=10658387
		Total megabyte-seconds taken by all map tasks=47195818208
		Total megabyte-seconds taken by all reduce tasks=127900644000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167284
		Map output bytes=16164682353
		Map output materialized bytes=16559777938
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462417
		Reduce shuffle bytes=16559777938
		Reduce input records=191167284
		Reduce output records=28579731
		Spilled Records=382334568
		Shuffled Maps =1875
		Failed Shuffles=0
		Merged Map outputs=1875
		GC time elapsed (ms)=71382
		CPU time spent (ms)=14968270
		Physical memory (bytes) snapshot=167781679104
		Virtual memory (bytes) snapshot=1022406316032
		Total committed heap usage (bytes)=260355833856
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1697087169
	rmr
		reduce calls=28462417
15/04/12 12:05:37 INFO streaming.StreamJob: Output directory: /tmp/fileb32612a8c606
function () 
{
    fname
}
<bytecode: 0x220c080>
<environment: 0x220b448>
15/04/12 12:05:42 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/fileb32612a8c606

real	25m25.912s
user	0m27.283s
sys	0m2.234s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-15-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=15"


15/04/12 12:05:47 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 12:05:47 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8733778831058049996.jar tmpDir=null
15/04/12 12:05:48 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 12:05:48 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 12:05:49 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 12:05:49 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 12:05:50 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4565
15/04/12 12:05:50 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4565
15/04/12 12:05:50 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4565/
15/04/12 12:05:50 INFO mapreduce.Job: Running job: job_1422482982071_4565
15/04/12 12:05:55 INFO mapreduce.Job: Job job_1422482982071_4565 running in uber mode : false
15/04/12 12:05:55 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 12:06:07 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 12:06:08 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 12:06:10 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 12:06:11 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 12:06:13 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 12:06:14 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 12:06:16 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 12:06:17 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 12:06:20 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 12:06:21 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 12:06:23 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 12:06:26 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 12:06:27 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 12:06:29 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 12:06:32 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 12:06:33 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 12:06:35 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 12:06:38 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 12:06:39 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 12:06:41 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 12:06:44 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 12:06:45 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 12:06:47 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 12:06:48 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 12:06:49 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 12:06:50 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 12:06:51 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 12:06:53 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 12:06:54 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 12:06:56 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 12:06:57 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 12:06:59 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 12:07:00 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 12:07:02 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 12:07:07 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 12:07:08 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 12:07:09 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 12:07:10 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 12:07:11 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 12:07:12 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 12:07:13 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 12:07:14 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 12:07:15 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 12:07:16 INFO mapreduce.Job:  map 90% reduce 0%
15/04/12 12:07:17 INFO mapreduce.Job:  map 91% reduce 0%
15/04/12 12:07:18 INFO mapreduce.Job:  map 91% reduce 24%
15/04/12 12:07:19 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 12:07:20 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 12:07:21 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 12:07:25 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 12:07:26 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 12:07:41 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 12:07:43 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 12:07:44 INFO mapreduce.Job:  map 98% reduce 28%
15/04/12 12:07:45 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 12:07:46 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 12:07:48 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 12:07:49 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 12:07:51 INFO mapreduce.Job:  map 100% reduce 41%
15/04/12 12:07:54 INFO mapreduce.Job:  map 100% reduce 44%
15/04/12 12:07:55 INFO mapreduce.Job:  map 100% reduce 48%
15/04/12 12:07:57 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 12:07:58 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 12:08:00 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 12:08:01 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 12:08:06 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 12:08:12 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 12:08:18 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 12:08:25 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 12:08:35 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 12:08:44 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 12:08:53 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 12:08:59 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 12:09:05 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 12:09:17 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 12:09:28 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 12:09:35 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 12:09:47 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 12:09:53 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 12:10:08 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 12:10:21 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 12:10:29 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 12:10:42 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 12:10:53 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 12:11:11 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 12:11:24 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 12:11:35 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 12:11:53 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 12:12:13 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 12:12:34 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 12:12:59 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 12:13:27 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 12:14:02 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 12:14:38 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 12:15:22 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 12:16:59 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 12:24:24 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 12:30:18 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 12:36:31 INFO mapreduce.Job: Job job_1422482982071_4565 completed successfully
15/04/12 12:36:31 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=16559771534
		FILE: Number of bytes written=33128248859
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1696882540
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Killed map tasks=1
		Launched map tasks=76
		Launched reduce tasks=15
		Data-local map tasks=55
		Rack-local map tasks=21
		Total time spent by all maps in occupied slots (ms)=12030216
		Total time spent by all reduces in occupied slots (ms)=19448434
		Total time spent by all map tasks (ms)=6015108
		Total time spent by all reduce tasks (ms)=9724217
		Total vcore-seconds taken by all map tasks=6015108
		Total vcore-seconds taken by all reduce tasks=9724217
		Total megabyte-seconds taken by all map tasks=48698314368
		Total megabyte-seconds taken by all reduce tasks=116690604000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167333
		Map output bytes=16164686952
		Map output materialized bytes=16559778140
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462344
		Reduce shuffle bytes=16559778140
		Reduce input records=191167333
		Reduce output records=28578262
		Spilled Records=382334666
		Shuffled Maps =1125
		Failed Shuffles=0
		Merged Map outputs=1125
		GC time elapsed (ms)=65040
		CPU time spent (ms)=15349380
		Physical memory (bytes) snapshot=166787633152
		Virtual memory (bytes) snapshot=889159065600
		Total committed heap usage (bytes)=239306219520
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1696882540
	rmr
		reduce calls=28462344
15/04/12 12:36:31 INFO streaming.StreamJob: Output directory: /tmp/fileb931170a703f
function () 
{
    fname
}
<bytecode: 0x1bb1080>
<environment: 0x1bb0448>
15/04/12 12:36:37 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/fileb931170a703f

real	30m54.455s
user	0m27.452s
sys	0m2.488s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-15-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=15"


15/04/12 12:36:42 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 12:36:42 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8723637083199120857.jar tmpDir=null
15/04/12 12:36:43 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 12:36:43 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 12:36:44 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 12:36:44 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 12:36:45 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4570
15/04/12 12:36:45 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4570
15/04/12 12:36:45 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4570/
15/04/12 12:36:45 INFO mapreduce.Job: Running job: job_1422482982071_4570
15/04/12 12:36:51 INFO mapreduce.Job: Job job_1422482982071_4570 running in uber mode : false
15/04/12 12:36:51 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 12:37:02 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 12:37:03 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 12:37:05 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 12:37:06 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 12:37:08 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 12:37:09 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 12:37:11 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 12:37:12 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 12:37:14 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 12:37:15 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 12:37:17 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 12:37:18 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 12:37:20 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 12:37:21 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 12:37:23 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 12:37:24 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 12:37:25 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 12:37:26 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 12:37:27 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 12:37:30 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 12:37:31 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 12:37:32 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 12:37:33 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 12:37:34 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 12:37:36 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 12:37:37 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 12:37:39 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 12:37:40 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 12:37:41 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 12:37:42 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 12:37:43 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 12:37:45 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 12:37:46 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 12:37:47 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 12:37:48 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 12:37:49 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 12:37:51 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 12:37:52 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 12:37:55 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 12:37:57 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 12:37:59 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 12:38:00 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 12:38:01 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 12:38:02 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 12:38:04 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 12:38:05 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 12:38:06 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 12:38:07 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 12:38:08 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 12:38:09 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 12:38:10 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 12:38:11 INFO mapreduce.Job:  map 88% reduce 1%
15/04/12 12:38:12 INFO mapreduce.Job:  map 89% reduce 19%
15/04/12 12:38:13 INFO mapreduce.Job:  map 90% reduce 23%
15/04/12 12:38:14 INFO mapreduce.Job:  map 91% reduce 23%
15/04/12 12:38:15 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 12:38:16 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 12:38:18 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 12:38:22 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 12:38:33 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 12:38:35 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 12:38:36 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 12:38:38 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 12:38:39 INFO mapreduce.Job:  map 96% reduce 29%
15/04/12 12:38:41 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 12:38:42 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 12:38:43 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 12:38:45 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 12:38:47 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 12:38:48 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 12:38:49 INFO mapreduce.Job:  map 100% reduce 41%
15/04/12 12:38:50 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 12:38:51 INFO mapreduce.Job:  map 100% reduce 47%
15/04/12 12:38:52 INFO mapreduce.Job:  map 100% reduce 51%
15/04/12 12:38:53 INFO mapreduce.Job:  map 100% reduce 52%
15/04/12 12:38:54 INFO mapreduce.Job:  map 100% reduce 56%
15/04/12 12:38:55 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 12:38:56 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 12:38:57 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 12:38:58 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 12:38:59 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 12:39:02 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 12:39:09 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 12:39:16 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 12:39:23 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 12:39:31 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 12:39:40 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 12:39:46 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 12:39:55 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 12:40:01 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 12:40:11 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 12:40:24 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 12:40:33 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 12:40:41 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 12:40:50 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 12:41:02 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 12:41:14 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 12:41:23 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 12:41:36 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 12:41:50 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 12:42:03 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 12:42:14 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 12:42:27 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 12:42:42 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 12:43:06 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 12:43:23 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 12:43:48 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 12:44:15 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 12:44:45 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 12:45:21 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 12:46:04 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 12:47:23 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 12:57:39 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 13:03:44 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 13:09:32 INFO mapreduce.Job: Job job_1422482982071_4570 completed successfully
15/04/12 13:09:32 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559772625
		FILE: Number of bytes written=33128251041
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1696877943
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=16
		Data-local map tasks=53
		Rack-local map tasks=23
		Total time spent by all maps in occupied slots (ms)=12081982
		Total time spent by all reduces in occupied slots (ms)=20672554
		Total time spent by all map tasks (ms)=6040991
		Total time spent by all reduce tasks (ms)=10336277
		Total vcore-seconds taken by all map tasks=6040991
		Total vcore-seconds taken by all reduce tasks=10336277
		Total megabyte-seconds taken by all map tasks=48907863136
		Total megabyte-seconds taken by all reduce tasks=124035324000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167304
		Map output bytes=16164688090
		Map output materialized bytes=16559779231
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462230
		Reduce shuffle bytes=16559779231
		Reduce input records=191167304
		Reduce output records=28578156
		Spilled Records=382334608
		Shuffled Maps =1125
		Failed Shuffles=0
		Merged Map outputs=1125
		GC time elapsed (ms)=69490
		CPU time spent (ms)=15228450
		Physical memory (bytes) snapshot=166803357696
		Virtual memory (bytes) snapshot=889357852672
		Total committed heap usage (bytes)=239305170944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1696877943
	rmr
		reduce calls=28462230
15/04/12 13:09:32 INFO streaming.StreamJob: Output directory: /tmp/filebd4c44f5aa7b
function () 
{
    fname
}
<bytecode: 0x1ac7080>
<environment: 0x1ac6448>
15/04/12 13:09:38 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/filebd4c44f5aa7b

real	33m1.339s
user	0m32.085s
sys	0m2.479s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-15-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=15"


15/04/12 13:09:44 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 13:09:44 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6103494210472034599.jar tmpDir=null
15/04/12 13:09:44 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 13:09:44 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 13:09:45 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 13:09:45 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 13:09:46 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4581
15/04/12 13:09:46 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4581
15/04/12 13:09:46 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4581/
15/04/12 13:09:46 INFO mapreduce.Job: Running job: job_1422482982071_4581
15/04/12 13:09:51 INFO mapreduce.Job: Job job_1422482982071_4581 running in uber mode : false
15/04/12 13:09:51 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 13:10:01 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 13:10:02 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 13:10:04 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 13:10:05 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 13:10:07 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 13:10:08 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 13:10:11 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 13:10:12 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 13:10:14 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 13:10:15 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 13:10:17 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 13:10:18 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 13:10:20 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 13:10:21 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 13:10:23 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 13:10:24 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 13:10:26 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 13:10:27 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 13:10:30 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 13:10:32 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 13:10:33 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 13:10:35 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 13:10:36 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 13:10:39 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 13:10:42 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 13:10:45 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 13:10:46 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 13:10:48 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 13:10:49 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 13:10:51 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 13:10:54 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 13:10:57 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 13:11:00 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 13:11:01 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 13:11:02 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 13:11:03 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 13:11:04 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 13:11:05 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 13:11:06 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 13:11:07 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 13:11:08 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 13:11:09 INFO mapreduce.Job:  map 90% reduce 5%
15/04/12 13:11:10 INFO mapreduce.Job:  map 90% reduce 20%
15/04/12 13:11:11 INFO mapreduce.Job:  map 91% reduce 23%
15/04/12 13:11:12 INFO mapreduce.Job:  map 92% reduce 23%
15/04/12 13:11:13 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 13:11:15 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 13:11:24 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 13:11:33 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 13:11:34 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 13:11:37 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 13:11:38 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 13:11:40 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 13:11:41 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 13:11:43 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 13:11:44 INFO mapreduce.Job:  map 100% reduce 39%
15/04/12 13:11:46 INFO mapreduce.Job:  map 100% reduce 44%
15/04/12 13:11:47 INFO mapreduce.Job:  map 100% reduce 48%
15/04/12 13:11:49 INFO mapreduce.Job:  map 100% reduce 55%
15/04/12 13:11:50 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 13:11:51 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 13:11:52 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 13:11:53 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 13:11:58 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 13:12:05 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 13:12:11 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 13:12:20 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 13:12:28 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 13:12:37 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 13:12:45 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 13:12:53 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 13:13:01 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 13:13:07 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 13:13:21 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 13:13:31 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 13:13:39 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 13:13:48 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 13:14:03 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 13:14:15 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 13:14:22 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 13:14:36 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 13:14:52 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 13:15:06 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 13:15:19 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 13:15:34 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 13:15:48 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 13:16:09 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 13:16:31 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 13:16:55 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 13:17:22 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 13:17:57 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 13:18:36 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 13:19:20 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 13:21:01 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 13:28:13 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 13:33:57 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 13:40:01 INFO mapreduce.Job: Job job_1422482982071_4581 completed successfully
15/04/12 13:40:02 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=16559773113
		FILE: Number of bytes written=33128249587
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1696885197
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
	Job Counters 
		Killed map tasks=1
		Launched map tasks=76
		Launched reduce tasks=15
		Data-local map tasks=51
		Rack-local map tasks=25
		Total time spent by all maps in occupied slots (ms)=11549582
		Total time spent by all reduces in occupied slots (ms)=19548114
		Total time spent by all map tasks (ms)=5774791
		Total time spent by all reduce tasks (ms)=9774057
		Total vcore-seconds taken by all map tasks=5774791
		Total vcore-seconds taken by all reduce tasks=9774057
		Total megabyte-seconds taken by all map tasks=46752707936
		Total megabyte-seconds taken by all reduce tasks=117288684000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167277
		Map output bytes=16164688635
		Map output materialized bytes=16559779719
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462411
		Reduce shuffle bytes=16559779719
		Reduce input records=191167277
		Reduce output records=28578324
		Spilled Records=382334554
		Shuffled Maps =1125
		Failed Shuffles=0
		Merged Map outputs=1125
		GC time elapsed (ms)=71888
		CPU time spent (ms)=15257650
		Physical memory (bytes) snapshot=166623109120
		Virtual memory (bytes) snapshot=888963833856
		Total committed heap usage (bytes)=239303745536
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1696885197
	rmr
		reduce calls=28462411
15/04/12 13:40:02 INFO streaming.StreamJob: Output directory: /tmp/file6316fbfbbd4
function () 
{
    fname
}
<bytecode: 0x2f54080>
<environment: 0x2f53448>
15/04/12 13:40:08 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file6316fbfbbd4

real	30m29.784s
user	0m30.474s
sys	0m2.439s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-35-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=35"


15/04/12 13:40:13 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 13:40:13 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4438875042832669618.jar tmpDir=null
15/04/12 13:40:14 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 13:40:14 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 13:40:15 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 13:40:15 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 13:40:16 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4587
15/04/12 13:40:16 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4587
15/04/12 13:40:16 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4587/
15/04/12 13:40:16 INFO mapreduce.Job: Running job: job_1422482982071_4587
15/04/12 13:40:23 INFO mapreduce.Job: Job job_1422482982071_4587 running in uber mode : false
15/04/12 13:40:23 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 13:40:34 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 13:40:35 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 13:40:36 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 13:40:37 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 13:40:38 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 13:40:40 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 13:40:41 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 13:40:43 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 13:40:44 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 13:40:46 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 13:40:47 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 13:40:49 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 13:40:50 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 13:40:52 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 13:40:53 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 13:40:55 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 13:40:56 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 13:40:58 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 13:40:59 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 13:41:00 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 13:41:01 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 13:41:02 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 13:41:04 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 13:41:05 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 13:41:07 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 13:41:08 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 13:41:10 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 13:41:11 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 13:41:12 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 13:41:13 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 13:41:14 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 13:41:16 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 13:41:17 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 13:41:19 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 13:41:20 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 13:41:22 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 13:41:23 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 13:41:26 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 13:41:29 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 13:41:32 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 13:41:33 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 13:41:34 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 13:41:35 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 13:41:36 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 13:41:37 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 13:41:38 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 13:41:39 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 13:41:40 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 13:41:41 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 13:41:42 INFO mapreduce.Job:  map 90% reduce 11%
15/04/12 13:41:43 INFO mapreduce.Job:  map 91% reduce 23%
15/04/12 13:41:44 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 13:41:46 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 13:41:50 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 13:41:56 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 13:42:07 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 13:42:08 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 13:42:09 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 13:42:10 INFO mapreduce.Job:  map 97% reduce 30%
15/04/12 13:42:11 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 13:42:13 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 13:42:14 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 13:42:16 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 13:42:26 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 13:42:27 INFO mapreduce.Job:  map 100% reduce 45%
15/04/12 13:42:28 INFO mapreduce.Job:  map 100% reduce 46%
15/04/12 13:42:29 INFO mapreduce.Job:  map 100% reduce 55%
15/04/12 13:42:30 INFO mapreduce.Job:  map 100% reduce 56%
15/04/12 13:42:31 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 13:42:32 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 13:42:33 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 13:42:35 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 13:42:39 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 13:42:44 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 13:42:49 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 13:42:53 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 13:42:59 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 13:43:03 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 13:43:06 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 13:43:11 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 13:43:17 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 13:43:21 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 13:43:27 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 13:43:33 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 13:43:41 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 13:43:48 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 13:43:54 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 13:44:02 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 13:44:08 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 13:44:14 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 13:44:23 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 13:44:31 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 13:44:41 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 13:44:50 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 13:45:00 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 13:45:12 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 13:45:27 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 13:45:42 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 13:46:01 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 13:46:23 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 13:46:45 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 13:47:24 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 13:49:01 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 13:52:19 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 14:06:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4587_r_000032_0, Status : FAILED
Container [pid=41393,containerID=container_1422482982071_4587_01_000223] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.9 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4587_01_000223 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 41899 41888 41393 41393 (cat) 0 27 103391232 159 cat 
	|- 41403 41393 41393 41393 (java) 2515 479 13411340288 489269 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4587/container_1422482982071_4587_01_000223/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4587/container_1422482982071_4587_01_000223 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 34202 attempt_1422482982071_4587_r_000032_0 223 
	|- 41901 41888 41393 41393 (cat) 0 0 103391232 151 cat 
	|- 41888 41403 41393 41393 (R) 117961 23208 10892619776 2612162 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reducea554e7b430a 
	|- 41393 3946 41393 41393 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4587/container_1422482982071_4587_01_000223/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4587/container_1422482982071_4587_01_000223 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 34202 attempt_1422482982071_4587_r_000032_0 223 1>/var/log/hadoop-yarn/containers/application_1422482982071_4587/container_1422482982071_4587_01_000223/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4587/container_1422482982071_4587_01_000223/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 14:15:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4587_r_000032_1, Status : FAILED
Container [pid=25621,containerID=container_1422482982071_4587_01_000227] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4587_01_000227 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 25677 25631 25621 25621 (R) 106424 18198 10487984128 2537452 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reducea554e7b430a 
	|- 25690 25677 25621 25621 (cat) 0 0 4231168 134 cat 
	|- 25621 11042 25621 25621 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4587/container_1422482982071_4587_01_000227/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4587/container_1422482982071_4587_01_000227 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 34202 attempt_1422482982071_4587_r_000032_1 227 1>/var/log/hadoop-yarn/containers/application_1422482982071_4587/container_1422482982071_4587_01_000227/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4587/container_1422482982071_4587_01_000227/stderr  
	|- 25631 25621 25621 25621 (java) 3005 598 13312651264 550151 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4587/container_1422482982071_4587_01_000227/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4587/container_1422482982071_4587_01_000227 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 34202 attempt_1422482982071_4587_r_000032_1 227 
	|- 25688 25677 25621 25621 (cat) 0 24 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 14:29:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4587_r_000032_2, Status : FAILED
Container [pid=22848,containerID=container_1422482982071_4587_01_000228] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4587_01_000228 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 22848 9245 22848 22848 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4587/container_1422482982071_4587_01_000228/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4587/container_1422482982071_4587_01_000228 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 34202 attempt_1422482982071_4587_r_000032_2 228 1>/var/log/hadoop-yarn/containers/application_1422482982071_4587/container_1422482982071_4587_01_000228/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4587/container_1422482982071_4587_01_000228/stderr  
	|- 22912 22901 22848 22848 (cat) 1 26 4231168 143 cat 
	|- 22914 22901 22848 22848 (cat) 0 0 4231168 134 cat 
	|- 22901 22858 22848 22848 (R) 106768 18400 10488266752 2537521 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reducea554e7b430a 
	|- 22858 22848 22848 22848 (java) 3325 611 13313773568 554174 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4587/container_1422482982071_4587_01_000228/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4587/container_1422482982071_4587_01_000228 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 34202 attempt_1422482982071_4587_r_000032_2 228 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 14:42:39 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 14:42:40 INFO mapreduce.Job: Job job_1422482982071_4587 failed with state FAILED due to: Task failed task_1422482982071_4587_r_000032
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 14:42:40 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=28570045600
		FILE: Number of bytes written=60424514558
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2118246293
		HDFS: Number of read operations=504
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=69
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Launched map tasks=135
		Launched reduce tasks=39
		Data-local map tasks=66
		Rack-local map tasks=69
		Total time spent by all maps in occupied slots (ms)=20905882
		Total time spent by all reduces in occupied slots (ms)=37639948
		Total time spent by all map tasks (ms)=10452941
		Total time spent by all reduce tasks (ms)=18819974
		Total vcore-seconds taken by all map tasks=10452941
		Total vcore-seconds taken by all reduce tasks=18819974
		Total megabyte-seconds taken by all map tasks=84627010336
		Total megabyte-seconds taken by all reduce tasks=225839688000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141567
		Map output bytes=29491540363
		Map output materialized bytes=30204074667
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=35367853
		Reduce shuffle bytes=30204074667
		Reduce input records=334088004
		Reduce output records=35562637
		Spilled Records=678216717
		Shuffled Maps =4690
		Failed Shuffles=0
		Merged Map outputs=4690
		GC time elapsed (ms)=120204
		CPU time spent (ms)=23205220
		Physical memory (bytes) snapshot=301979095040
		Virtual memory (bytes) snapshot=1701324763136
		Total committed heap usage (bytes)=444820520960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2118246293
	rmr
		reduce calls=35367852
15/04/12 14:42:40 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 14:42:47 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/filea5576750540

real	62m39.252s
user	0m37.771s
sys	0m3.880s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-35-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=35"


15/04/12 14:42:53 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 14:42:53 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1783731143042081084.jar tmpDir=null
15/04/12 14:42:54 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 14:42:54 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 14:42:55 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 14:42:55 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 14:42:55 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4602
15/04/12 14:42:56 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4602
15/04/12 14:42:56 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4602/
15/04/12 14:42:56 INFO mapreduce.Job: Running job: job_1422482982071_4602
15/04/12 14:43:01 INFO mapreduce.Job: Job job_1422482982071_4602 running in uber mode : false
15/04/12 14:43:01 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 14:43:11 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 14:43:12 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 14:43:13 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 14:43:14 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 14:43:15 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 14:43:17 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 14:43:18 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 14:43:20 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 14:43:21 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 14:43:23 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 14:43:24 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 14:43:25 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 14:43:26 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 14:43:27 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 14:43:29 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 14:43:30 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 14:43:31 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 14:43:32 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 14:43:33 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 14:43:34 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 14:43:35 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 14:43:36 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 14:43:37 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 14:43:38 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 14:43:40 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 14:43:41 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 14:43:42 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 14:43:43 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 14:43:44 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 14:43:45 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 14:43:46 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 14:43:47 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 14:43:48 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 14:43:49 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 14:43:50 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 14:43:51 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 14:43:52 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 14:43:53 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 14:43:54 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 14:43:55 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 14:43:56 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 14:43:57 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 14:43:58 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 14:43:59 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 14:44:00 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 14:44:01 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 14:44:02 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 14:44:03 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 14:44:05 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 14:44:07 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 14:44:10 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 14:44:11 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 14:44:12 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 14:44:13 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 14:44:14 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 14:44:15 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 14:44:16 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 14:44:17 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 14:44:18 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 14:44:19 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 14:44:20 INFO mapreduce.Job:  map 91% reduce 0%
15/04/12 14:44:21 INFO mapreduce.Job:  map 92% reduce 6%
15/04/12 14:44:22 INFO mapreduce.Job:  map 93% reduce 21%
15/04/12 14:44:23 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 14:44:24 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 14:44:25 INFO mapreduce.Job:  map 94% reduce 28%
15/04/12 14:44:34 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 14:44:44 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 14:44:46 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 14:44:47 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 14:44:48 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 14:44:49 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 14:44:50 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 14:44:53 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 14:44:54 INFO mapreduce.Job:  map 100% reduce 37%
15/04/12 14:44:55 INFO mapreduce.Job:  map 100% reduce 40%
15/04/12 14:44:56 INFO mapreduce.Job:  map 100% reduce 47%
15/04/12 14:44:57 INFO mapreduce.Job:  map 100% reduce 50%
15/04/12 14:44:58 INFO mapreduce.Job:  map 100% reduce 53%
15/04/12 14:44:59 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 14:45:00 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 14:45:01 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 14:45:02 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 14:45:03 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 14:45:04 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 14:45:08 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 14:45:12 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 14:45:17 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 14:45:22 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 14:45:27 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 14:45:32 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 14:45:36 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 14:45:41 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 14:45:45 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 14:45:51 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 14:45:56 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 14:46:03 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 14:46:09 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 14:46:18 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 14:46:24 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 14:46:32 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 14:46:38 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 14:46:45 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 14:46:52 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 14:47:00 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 14:47:08 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 14:47:19 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 14:47:29 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 14:47:40 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 14:47:54 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 14:48:08 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 14:48:27 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 14:48:49 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 14:49:10 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 14:49:52 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 14:51:28 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 14:54:35 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 15:05:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4602_r_000032_0, Status : FAILED
Container [pid=28249,containerID=container_1422482982071_4602_01_000211] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4602_01_000211 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 28258 28249 28249 28249 (java) 3256 633 13312323584 558102 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4602/container_1422482982071_4602_01_000211/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4602/container_1422482982071_4602_01_000211 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 37842 attempt_1422482982071_4602_r_000032_0 211 
	|- 28303 28258 28249 28249 (R) 107696 18133 10488614912 2537606 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce152caab9ea9 
	|- 28314 28303 28249 28249 (cat) 0 27 4231168 142 cat 
	|- 28317 28303 28249 28249 (cat) 0 0 4231168 134 cat 
	|- 28249 9022 28249 28249 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4602/container_1422482982071_4602_01_000211/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4602/container_1422482982071_4602_01_000211 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 37842 attempt_1422482982071_4602_r_000032_0 211 1>/var/log/hadoop-yarn/containers/application_1422482982071_4602/container_1422482982071_4602_01_000211/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4602/container_1422482982071_4602_01_000211/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 15:17:13 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 15:17:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4602_r_000032_1, Status : FAILED
Container [pid=18275,containerID=container_1422482982071_4602_01_000249] is running beyond physical memory limits. Current usage: 12.1 GB of 11.7 GB physical memory used; 22.4 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4602_01_000249 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 18339 18328 18275 18275 (cat) 0 26 4231168 142 cat 
	|- 18328 18284 18275 18275 (R) 106620 17756 10767589376 2605714 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce152caab9ea9 
	|- 18275 9420 18275 18275 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4602/container_1422482982071_4602_01_000249/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4602/container_1422482982071_4602_01_000249 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 37842 attempt_1422482982071_4602_r_000032_1 249 1>/var/log/hadoop-yarn/containers/application_1422482982071_4602/container_1422482982071_4602_01_000249/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4602/container_1422482982071_4602_01_000249/stderr  
	|- 18284 18275 18275 18275 (java) 2623 416 13311913984 564586 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4602/container_1422482982071_4602_01_000249/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4602/container_1422482982071_4602_01_000249 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 37842 attempt_1422482982071_4602_r_000032_1 249 
	|- 18345 18328 18275 18275 (cat) 0 0 4231168 134 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 15:17:14 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 15:32:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4602_r_000032_2, Status : FAILED
Container [pid=43142,containerID=container_1422482982071_4602_01_000250] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.7 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4602_01_000250 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 43142 9608 43142 43142 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4602/container_1422482982071_4602_01_000250/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4602/container_1422482982071_4602_01_000250 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 37842 attempt_1422482982071_4602_r_000032_2 250 1>/var/log/hadoop-yarn/containers/application_1422482982071_4602/container_1422482982071_4602_01_000250/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4602/container_1422482982071_4602_01_000250/stderr  
	|- 43205 43194 43142 43142 (cat) 1 27 4231168 142 cat 
	|- 43207 43194 43142 43142 (cat) 0 0 4231168 134 cat 
	|- 43194 43152 43142 43142 (R) 117490 23599 11047944192 2674161 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce152caab9ea9 
	|- 43152 43142 43142 43142 (java) 2847 574 13312454656 440446 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4602/container_1422482982071_4602_01_000250/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4602/container_1422482982071_4602_01_000250 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 37842 attempt_1422482982071_4602_r_000032_2 250 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 15:44:22 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 15:44:23 INFO mapreduce.Job: Job job_1422482982071_4602 failed with state FAILED due to: Task failed task_1422482982071_4602_r_000032
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 15:44:24 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=28149550509
		FILE: Number of bytes written=58369930332
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2118244548
		HDFS: Number of read operations=504
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=68
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=135
		Launched reduce tasks=39
		Data-local map tasks=62
		Rack-local map tasks=73
		Total time spent by all maps in occupied slots (ms)=20394926
		Total time spent by all reduces in occupied slots (ms)=37641170
		Total time spent by all map tasks (ms)=10197463
		Total time spent by all reduce tasks (ms)=18820585
		Total vcore-seconds taken by all map tasks=10197463
		Total vcore-seconds taken by all reduce tasks=18820585
		Total megabyte-seconds taken by all map tasks=82558660448
		Total megabyte-seconds taken by all reduce tasks=225847020000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141578
		Map output bytes=29491545666
		Map output materialized bytes=30204079991
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=35367913
		Reduce shuffle bytes=28149577617
		Reduce input records=334074812
		Reduce output records=35562674
		Spilled Records=678216390
		Shuffled Maps =4556
		Failed Shuffles=0
		Merged Map outputs=4556
		GC time elapsed (ms)=113112
		CPU time spent (ms)=22202560
		Physical memory (bytes) snapshot=296274046976
		Virtual memory (bytes) snapshot=1684155244544
		Total committed heap usage (bytes)=442714734592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2118244548
	rmr
		reduce calls=35367913
15/04/12 15:44:24 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 15:44:30 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file152c35abef5b

real	61m42.891s
user	0m38.376s
sys	0m3.521s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-35-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=35"


15/04/12 15:44:36 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 15:44:36 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7698850066998766226.jar tmpDir=null
15/04/12 15:44:37 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 15:44:37 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 15:44:38 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 15:44:38 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 15:44:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4617
15/04/12 15:44:39 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4617
15/04/12 15:44:39 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4617/
15/04/12 15:44:39 INFO mapreduce.Job: Running job: job_1422482982071_4617
15/04/12 15:44:45 INFO mapreduce.Job: Job job_1422482982071_4617 running in uber mode : false
15/04/12 15:44:45 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 15:44:57 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 15:44:58 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 15:44:59 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 15:45:00 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 15:45:01 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 15:45:03 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 15:45:04 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 15:45:06 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 15:45:07 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 15:45:09 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 15:45:10 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 15:45:12 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 15:45:13 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 15:45:15 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 15:45:16 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 15:45:18 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 15:45:19 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 15:45:21 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 15:45:22 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 15:45:24 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 15:45:25 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 15:45:26 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 15:45:27 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 15:45:28 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 15:45:30 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 15:45:31 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 15:45:32 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 15:45:33 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 15:45:34 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 15:45:36 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 15:45:37 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 15:45:38 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 15:45:39 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 15:45:40 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 15:45:42 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 15:45:43 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 15:45:45 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 15:45:46 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 15:45:48 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 15:45:49 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 15:45:51 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 15:45:52 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 15:45:53 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 15:45:55 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 15:45:56 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 15:45:57 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 15:45:58 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 15:45:59 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 15:46:00 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 15:46:01 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 15:46:02 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 15:46:03 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 15:46:04 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 15:46:05 INFO mapreduce.Job:  map 88% reduce 1%
15/04/12 15:46:06 INFO mapreduce.Job:  map 90% reduce 15%
15/04/12 15:46:07 INFO mapreduce.Job:  map 91% reduce 22%
15/04/12 15:46:08 INFO mapreduce.Job:  map 91% reduce 24%
15/04/12 15:46:09 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 15:46:10 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 15:46:16 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 15:46:26 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 15:46:29 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 15:46:31 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 15:46:32 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 15:46:33 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 15:46:34 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 15:46:36 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 15:46:37 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 15:46:40 INFO mapreduce.Job:  map 100% reduce 38%
15/04/12 15:46:41 INFO mapreduce.Job:  map 100% reduce 39%
15/04/12 15:46:42 INFO mapreduce.Job:  map 100% reduce 41%
15/04/12 15:46:43 INFO mapreduce.Job:  map 100% reduce 49%
15/04/12 15:46:44 INFO mapreduce.Job:  map 100% reduce 52%
15/04/12 15:46:45 INFO mapreduce.Job:  map 100% reduce 54%
15/04/12 15:46:46 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 15:46:47 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 15:46:49 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 15:46:50 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 15:46:52 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 15:46:55 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 15:46:59 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 15:47:04 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 15:47:08 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 15:47:14 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 15:47:21 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 15:47:24 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 15:47:29 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 15:47:33 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 15:47:39 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 15:47:45 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 15:47:51 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 15:47:57 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 15:48:06 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 15:48:12 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 15:48:20 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 15:48:27 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 15:48:34 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 15:48:41 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 15:48:50 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 15:48:58 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 15:49:08 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 15:49:19 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 15:49:29 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 15:49:45 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 15:49:59 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 15:50:16 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 15:50:40 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 15:50:59 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 15:51:36 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 15:52:54 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 15:56:20 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 16:09:22 INFO mapreduce.Job: Task Id : attempt_1422482982071_4617_r_000032_0, Status : FAILED
Container [pid=3143,containerID=container_1422482982071_4617_01_000222] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4617_01_000222 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 3224 3213 3143 3143 (cat) 0 26 4231168 142 cat 
	|- 3226 3213 3143 3143 (cat) 0 0 4231168 134 cat 
	|- 3213 3152 3143 3143 (R) 111524 24187 10342617088 2501993 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce1e4b50fc7a2d 
	|- 3143 9971 3143 3143 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4617/container_1422482982071_4617_01_000222/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4617/container_1422482982071_4617_01_000222 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 38115 attempt_1422482982071_4617_r_000032_0 222 1>/var/log/hadoop-yarn/containers/application_1422482982071_4617/container_1422482982071_4617_01_000222/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4617/container_1422482982071_4617_01_000222/stderr  
	|- 3152 3143 3143 3143 (java) 2796 478 13312008192 578900 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4617/container_1422482982071_4617_01_000222/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4617/container_1422482982071_4617_01_000222 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 38115 attempt_1422482982071_4617_r_000032_0 222 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 16:20:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_4617_r_000032_1, Status : FAILED
Container [pid=46134,containerID=container_1422482982071_4617_01_000260] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4617_01_000260 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 46144 46134 46134 46134 (java) 3342 616 13312782336 445774 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4617/container_1422482982071_4617_01_000260/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4617/container_1422482982071_4617_01_000260 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 38115 attempt_1422482982071_4617_r_000032_1 260 
	|- 46186 46144 46134 46134 (R) 112981 20357 10914078720 2641509 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce1e4b50fc7a2d 
	|- 46134 9763 46134 46134 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4617/container_1422482982071_4617_01_000260/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4617/container_1422482982071_4617_01_000260 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 38115 attempt_1422482982071_4617_r_000032_1 260 1>/var/log/hadoop-yarn/containers/application_1422482982071_4617/container_1422482982071_4617_01_000260/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4617/container_1422482982071_4617_01_000260/stderr  
	|- 46199 46186 46134 46134 (cat) 0 0 4231168 134 cat 
	|- 46197 46186 46134 46134 (cat) 0 27 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 16:32:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4617_r_000032_2, Status : FAILED
Container [pid=21775,containerID=container_1422482982071_4617_01_000261] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4617_01_000261 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 21837 21826 21775 21775 (cat) 0 25 4231168 142 cat 
	|- 21775 9420 21775 21775 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4617/container_1422482982071_4617_01_000261/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4617/container_1422482982071_4617_01_000261 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 38115 attempt_1422482982071_4617_r_000032_2 261 1>/var/log/hadoop-yarn/containers/application_1422482982071_4617/container_1422482982071_4617_01_000261/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4617/container_1422482982071_4617_01_000261/stderr  
	|- 21839 21826 21775 21775 (cat) 0 0 4231168 134 cat 
	|- 21826 21784 21775 21775 (R) 107501 19890 10488791040 2537648 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce1e4b50fc7a2d 
	|- 21784 21775 21775 21775 (java) 3139 635 13312065536 550190 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4617/container_1422482982071_4617_01_000261/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4617/container_1422482982071_4617_01_000261 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.200 38115 attempt_1422482982071_4617_r_000032_2 261 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 16:50:03 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 16:50:03 INFO mapreduce.Job: Job job_1422482982071_4617 failed with state FAILED due to: Task failed task_1422482982071_4617_r_000032
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 16:50:03 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=28149564350
		FILE: Number of bytes written=58369943024
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2118233423
		HDFS: Number of read operations=504
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=68
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=135
		Launched reduce tasks=39
		Data-local map tasks=64
		Rack-local map tasks=71
		Total time spent by all maps in occupied slots (ms)=21073988
		Total time spent by all reduces in occupied slots (ms)=38809888
		Total time spent by all map tasks (ms)=10536994
		Total time spent by all reduce tasks (ms)=19404944
		Total vcore-seconds taken by all map tasks=10536994
		Total vcore-seconds taken by all reduce tasks=19404944
		Total megabyte-seconds taken by all map tasks=85307503424
		Total megabyte-seconds taken by all reduce tasks=232859328000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141584
		Map output bytes=29491544502
		Map output materialized bytes=30204078842
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=35367955
		Reduce shuffle bytes=28149591458
		Reduce input records=334074920
		Reduce output records=35562614
		Spilled Records=678216504
		Shuffled Maps =4556
		Failed Shuffles=0
		Merged Map outputs=4556
		GC time elapsed (ms)=118856
		CPU time spent (ms)=22644520
		Physical memory (bytes) snapshot=295966793728
		Virtual memory (bytes) snapshot=1685132247040
		Total committed heap usage (bytes)=442715111424
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2118233423
	rmr
		reduce calls=35367955
15/04/12 16:50:03 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 16:50:10 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file1e4b71956edf

real	65m39.667s
user	0m38.748s
sys	0m3.502s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-25-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=25"


15/04/12 16:50:16 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 16:50:16 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3623819469247561717.jar tmpDir=null
15/04/12 16:50:16 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 16:50:16 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 16:50:17 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 16:50:17 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 16:50:18 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4628
15/04/12 16:50:18 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4628
15/04/12 16:50:18 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4628/
15/04/12 16:50:18 INFO mapreduce.Job: Running job: job_1422482982071_4628
15/04/12 16:50:23 INFO mapreduce.Job: Job job_1422482982071_4628 running in uber mode : false
15/04/12 16:50:23 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 16:50:35 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 16:50:36 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 16:50:37 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 16:50:38 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 16:50:39 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 16:50:41 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 16:50:42 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 16:50:44 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 16:50:45 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 16:50:47 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 16:50:48 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 16:50:49 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 16:50:51 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 16:50:53 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 16:50:54 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 16:50:55 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 16:50:56 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 16:50:57 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 16:50:59 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 16:51:00 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 16:51:02 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 16:51:03 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 16:51:05 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 16:51:06 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 16:51:09 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 16:51:11 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 16:51:12 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 16:51:15 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 16:51:16 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 16:51:18 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 16:51:19 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 16:51:21 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 16:51:23 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 16:51:24 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 16:51:27 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 16:51:30 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 16:51:32 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 16:51:33 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 16:51:34 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 16:51:35 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 16:51:36 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 16:51:37 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 16:51:38 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 16:51:39 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 16:51:40 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 16:51:41 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 16:51:42 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 16:51:43 INFO mapreduce.Job:  map 90% reduce 0%
15/04/12 16:51:44 INFO mapreduce.Job:  map 90% reduce 4%
15/04/12 16:51:45 INFO mapreduce.Job:  map 91% reduce 22%
15/04/12 16:51:46 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 16:51:48 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 16:51:50 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 16:51:51 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 16:51:56 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 16:52:06 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 16:52:09 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 16:52:10 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 16:52:12 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 16:52:13 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 16:52:14 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 16:52:16 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 16:52:18 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 16:52:19 INFO mapreduce.Job:  map 100% reduce 38%
15/04/12 16:52:20 INFO mapreduce.Job:  map 100% reduce 39%
15/04/12 16:52:22 INFO mapreduce.Job:  map 100% reduce 46%
15/04/12 16:52:24 INFO mapreduce.Job:  map 100% reduce 47%
15/04/12 16:52:25 INFO mapreduce.Job:  map 100% reduce 51%
15/04/12 16:52:26 INFO mapreduce.Job:  map 100% reduce 54%
15/04/12 16:52:28 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 16:52:31 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 16:52:37 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 16:52:43 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 16:52:51 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 16:52:59 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 16:53:07 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 16:53:14 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 16:53:20 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 16:53:27 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 16:53:35 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 16:53:42 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 16:53:50 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 16:53:57 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 16:54:05 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 16:54:15 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 16:54:26 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 16:54:36 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 16:54:50 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 16:55:02 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 16:55:14 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 16:55:27 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 16:55:41 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 16:55:58 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 16:56:11 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 16:56:28 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 16:56:50 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 16:57:11 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 16:57:38 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 16:58:05 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 16:58:42 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 17:00:30 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 17:02:31 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 17:06:11 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 17:13:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4628_r_000012_0, Status : FAILED
Container [pid=798,containerID=container_1422482982071_4628_01_000202] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4628_01_000202 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 920 907 798 798 (cat) 0 0 4231168 134 cat 
	|- 807 798 798 798 (java) 3354 745 13312786432 589658 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4628/container_1422482982071_4628_01_000202/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4628/container_1422482982071_4628_01_000202 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.196 42026 attempt_1422482982071_4628_r_000012_0 202 
	|- 907 807 798 798 (R) 108186 19457 10487619584 2537362 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce25d875c955e8 
	|- 918 907 798 798 (cat) 1 26 4231168 142 cat 
	|- 798 9793 798 798 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4628/container_1422482982071_4628_01_000202/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4628/container_1422482982071_4628_01_000202 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.196 42026 attempt_1422482982071_4628_r_000012_0 202 1>/var/log/hadoop-yarn/containers/application_1422482982071_4628/container_1422482982071_4628_01_000202/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4628/container_1422482982071_4628_01_000202/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 17:29:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4628_r_000012_1, Status : FAILED
Container [pid=43212,containerID=container_1422482982071_4628_01_000240] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.4 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4628_01_000240 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 43222 43212 43212 43212 (java) 3600 730 13312655360 590383 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4628/container_1422482982071_4628_01_000240/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4628/container_1422482982071_4628_01_000240 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.196 42026 attempt_1422482982071_4628_r_000012_1 240 
	|- 43275 43264 43212 43212 (cat) 0 25 4231168 142 cat 
	|- 43212 11626 43212 43212 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4628/container_1422482982071_4628_01_000240/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4628/container_1422482982071_4628_01_000240 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.196 42026 attempt_1422482982071_4628_r_000012_1 240 1>/var/log/hadoop-yarn/containers/application_1422482982071_4628/container_1422482982071_4628_01_000240/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4628/container_1422482982071_4628_01_000240/stderr  
	|- 43277 43264 43212 43212 (cat) 0 0 4231168 134 cat 
	|- 43264 43222 43212 43212 (R) 106277 18730 10688061440 2551634 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce25d875c955e8 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 17:49:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4628_r_000012_2, Status : FAILED
Container [pid=24320,containerID=container_1422482982071_4628_01_000241] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4628_01_000241 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 24320 29409 24320 24320 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4628/container_1422482982071_4628_01_000241/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4628/container_1422482982071_4628_01_000241 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.196 42026 attempt_1422482982071_4628_r_000012_2 241 1>/var/log/hadoop-yarn/containers/application_1422482982071_4628/container_1422482982071_4628_01_000241/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4628/container_1422482982071_4628_01_000241/stderr  
	|- 24330 24320 24320 24320 (java) 3508 684 13312577536 455285 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4628/container_1422482982071_4628_01_000241/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4628/container_1422482982071_4628_01_000241 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.196 42026 attempt_1422482982071_4628_r_000012_2 241 
	|- 24382 24371 24320 24320 (cat) 0 28 4231168 142 cat 
	|- 24371 24330 24320 24320 (R) 112984 19628 10924138496 2642169 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce25d875c955e8 
	|- 24384 24371 24320 24320 (cat) 0 0 4231168 134 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 18:05:21 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 18:05:21 INFO mapreduce.Job: Job job_1422482982071_4628 failed with state FAILED due to: Task failed task_1422482982071_4628_r_000012
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 18:05:22 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=27762497166
		FILE: Number of bytes written=57981865458
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2093067060
		HDFS: Number of read operations=474
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=48
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=135
		Launched reduce tasks=29
		Data-local map tasks=65
		Rack-local map tasks=70
		Total time spent by all maps in occupied slots (ms)=20850160
		Total time spent by all reduces in occupied slots (ms)=36233330
		Total time spent by all map tasks (ms)=10425080
		Total time spent by all reduce tasks (ms)=18116665
		Total vcore-seconds taken by all map tasks=10425080
		Total vcore-seconds taken by all reduce tasks=18116665
		Total megabyte-seconds taken by all map tasks=84401447680
		Total megabyte-seconds taken by all reduce tasks=217399980000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141613
		Map output bytes=29491536756
		Map output materialized bytes=30204063110
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=34953396
		Reduce shuffle bytes=27762516198
		Reduce input records=330302840
		Reduce output records=35143408
		Spilled Records=674444453
		Shuffled Maps =3216
		Failed Shuffles=0
		Merged Map outputs=3216
		GC time elapsed (ms)=117721
		CPU time spent (ms)=22700090
		Physical memory (bytes) snapshot=296509612032
		Virtual memory (bytes) snapshot=1550714449920
		Total committed heap usage (bytes)=421672243200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2093067060
	rmr
		reduce calls=34953396
15/04/12 18:05:22 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 18:05:28 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file25d81e5392bf

real	75m18.352s
user	0m39.361s
sys	0m4.146s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-25-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=25"


15/04/12 18:05:33 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 18:05:33 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3485724410240199623.jar tmpDir=null
15/04/12 18:05:34 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 18:05:34 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 18:05:35 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 18:05:35 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 18:05:36 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4643
15/04/12 18:05:36 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4643
15/04/12 18:05:36 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4643/
15/04/12 18:05:36 INFO mapreduce.Job: Running job: job_1422482982071_4643
15/04/12 18:05:40 INFO mapreduce.Job: Job job_1422482982071_4643 running in uber mode : false
15/04/12 18:05:40 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 18:05:51 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 18:05:52 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 18:05:54 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 18:05:55 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 18:05:57 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 18:05:58 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 18:06:01 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 18:06:03 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 18:06:04 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 18:06:05 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 18:06:07 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 18:06:08 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 18:06:09 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 18:06:10 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 18:06:11 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 18:06:12 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 18:06:13 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 18:06:14 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 18:06:15 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 18:06:16 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 18:06:17 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 18:06:18 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 18:06:19 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 18:06:20 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 18:06:21 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 18:06:22 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 18:06:23 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 18:06:24 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 18:06:25 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 18:06:26 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 18:06:27 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 18:06:28 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 18:06:29 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 18:06:30 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 18:06:31 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 18:06:32 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 18:06:34 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 18:06:35 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 18:06:36 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 18:06:37 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 18:06:38 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 18:06:40 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 18:06:41 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 18:06:42 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 18:06:44 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 18:06:45 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 18:06:48 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 18:06:50 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 18:06:51 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 18:06:52 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 18:06:53 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 18:06:54 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 18:06:55 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 18:06:56 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 18:06:57 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 18:06:58 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 18:06:59 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 18:07:00 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 18:07:01 INFO mapreduce.Job:  map 90% reduce 21%
15/04/12 18:07:02 INFO mapreduce.Job:  map 90% reduce 22%
15/04/12 18:07:03 INFO mapreduce.Job:  map 91% reduce 22%
15/04/12 18:07:04 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 18:07:09 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 18:07:10 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 18:07:17 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 18:07:26 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 18:07:27 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 18:07:29 INFO mapreduce.Job:  map 96% reduce 29%
15/04/12 18:07:30 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 18:07:31 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 18:07:32 INFO mapreduce.Job:  map 98% reduce 31%
15/04/12 18:07:33 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 18:07:35 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 18:07:38 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 18:07:43 INFO mapreduce.Job:  map 100% reduce 38%
15/04/12 18:07:44 INFO mapreduce.Job:  map 100% reduce 45%
15/04/12 18:07:46 INFO mapreduce.Job:  map 100% reduce 53%
15/04/12 18:07:47 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 18:07:49 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 18:07:50 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 18:07:52 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 18:07:55 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 18:07:56 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 18:07:59 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 18:08:05 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 18:08:11 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 18:08:17 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 18:08:27 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 18:08:35 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 18:08:42 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 18:08:47 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 18:08:54 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 18:09:02 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 18:09:09 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 18:09:18 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 18:09:26 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 18:09:36 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 18:09:45 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 18:09:56 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 18:10:06 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 18:10:18 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 18:10:29 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 18:10:41 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 18:10:54 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 18:11:09 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 18:11:28 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 18:11:43 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 18:12:01 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 18:12:24 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 18:12:49 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 18:13:15 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 18:13:52 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 18:15:26 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 18:17:29 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 18:21:07 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 18:29:27 INFO mapreduce.Job: Task Id : attempt_1422482982071_4643_r_000012_0, Status : FAILED
Container [pid=4263,containerID=container_1422482982071_4643_01_000199] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4643_01_000199 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 4272 4263 4263 4263 (java) 3277 528 13311815680 591226 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4643/container_1422482982071_4643_01_000199/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4643/container_1422482982071_4643_01_000199 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.196 42072 attempt_1422482982071_4643_r_000012_0 199 
	|- 4263 10599 4263 4263 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4643/container_1422482982071_4643_01_000199/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4643/container_1422482982071_4643_01_000199 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.196 42072 attempt_1422482982071_4643_r_000012_0 199 1>/var/log/hadoop-yarn/containers/application_1422482982071_4643/container_1422482982071_4643_01_000199/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4643/container_1422482982071_4643_01_000199/stderr  
	|- 4358 4272 4263 4263 (R) 109619 20566 10487889920 2537429 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce2f9e6ab791e5 
	|- 4372 4358 4263 4263 (cat) 0 0 4231168 134 cat 
	|- 4370 4358 4263 4263 (cat) 1 26 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 18:46:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4643_r_000012_1, Status : FAILED
Container [pid=4937,containerID=container_1422482982071_4643_01_000213] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4643_01_000213 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 4998 4987 4937 4937 (cat) 0 28 4231168 142 cat 
	|- 4937 9793 4937 4937 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4643/container_1422482982071_4643_01_000213/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4643/container_1422482982071_4643_01_000213 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.196 42072 attempt_1422482982071_4643_r_000012_1 213 1>/var/log/hadoop-yarn/containers/application_1422482982071_4643/container_1422482982071_4643_01_000213/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4643/container_1422482982071_4643_01_000213/stderr  
	|- 5000 4987 4937 4937 (cat) 0 0 4231168 134 cat 
	|- 4987 4946 4937 4937 (R) 113545 19772 10350153728 2483610 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce2f9e6ab791e5 
	|- 4946 4937 4937 4937 (java) 3717 727 13312876544 591736 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4643/container_1422482982071_4643_01_000213/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4643/container_1422482982071_4643_01_000213 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.196 42072 attempt_1422482982071_4643_r_000012_1 213 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 19:02:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4643_r_000012_2, Status : FAILED
Container [pid=44209,containerID=container_1422482982071_4643_01_000214] is running beyond physical memory limits. Current usage: 12.1 GB of 11.7 GB physical memory used; 22.4 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4643_01_000214 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 44271 44260 44209 44209 (cat) 0 25 4231168 142 cat 
	|- 44260 44219 44209 44209 (R) 108654 19855 10684149760 2575544 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce2f9e6ab791e5 
	|- 44273 44260 44209 44209 (cat) 0 0 4231168 134 cat 
	|- 44209 9143 44209 44209 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4643/container_1422482982071_4643_01_000214/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4643/container_1422482982071_4643_01_000214 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.196 42072 attempt_1422482982071_4643_r_000012_2 214 1>/var/log/hadoop-yarn/containers/application_1422482982071_4643/container_1422482982071_4643_01_000214/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4643/container_1422482982071_4643_01_000214/stderr  
	|- 44219 44209 44209 44209 (java) 3583 708 13312978944 590096 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4643/container_1422482982071_4643_01_000214/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4643/container_1422482982071_4643_01_000214 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.196 42072 attempt_1422482982071_4643_r_000012_2 214 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 19:19:25 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 19:19:25 INFO mapreduce.Job: Job job_1422482982071_4643 failed with state FAILED due to: Task failed task_1422482982071_4643_r_000012
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 19:19:25 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=27762373702
		FILE: Number of bytes written=57981737346
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2093073702
		HDFS: Number of read operations=474
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=48
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=135
		Launched reduce tasks=29
		Data-local map tasks=62
		Rack-local map tasks=73
		Total time spent by all maps in occupied slots (ms)=20991936
		Total time spent by all reduces in occupied slots (ms)=35912330
		Total time spent by all map tasks (ms)=10495968
		Total time spent by all reduce tasks (ms)=17956165
		Total vcore-seconds taken by all map tasks=10495968
		Total vcore-seconds taken by all reduce tasks=17956165
		Total megabyte-seconds taken by all map tasks=84975356928
		Total megabyte-seconds taken by all reduce tasks=215473980000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141628
		Map output bytes=29491532707
		Map output materialized bytes=30204059094
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=34953484
		Reduce shuffle bytes=27762392734
		Reduce input records=330301977
		Reduce output records=35143512
		Spilled Records=674443605
		Shuffled Maps =3216
		Failed Shuffles=0
		Merged Map outputs=3216
		GC time elapsed (ms)=96962
		CPU time spent (ms)=22256240
		Physical memory (bytes) snapshot=296274616320
		Virtual memory (bytes) snapshot=1550489710592
		Total committed heap usage (bytes)=421662240768
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2093073702
	rmr
		reduce calls=34953484
15/04/12 19:19:25 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 19:19:32 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file2f9e69b07778

real	74m3.634s
user	0m38.555s
sys	0m4.033s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-25-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=25"


15/04/12 19:19:38 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 19:19:38 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8682865061742420385.jar tmpDir=null
15/04/12 19:19:38 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 19:19:38 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 19:19:39 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 19:19:39 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 19:19:40 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4659
15/04/12 19:19:40 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4659
15/04/12 19:19:40 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4659/
15/04/12 19:19:40 INFO mapreduce.Job: Running job: job_1422482982071_4659
15/04/12 19:19:48 INFO mapreduce.Job: Job job_1422482982071_4659 running in uber mode : false
15/04/12 19:19:48 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 19:19:59 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 19:20:00 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 19:20:02 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 19:20:03 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 19:20:05 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 19:20:06 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 19:20:07 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 19:20:08 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 19:20:09 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 19:20:11 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 19:20:12 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 19:20:13 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 19:20:14 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 19:20:15 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 19:20:17 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 19:20:18 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 19:20:19 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 19:20:20 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 19:20:21 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 19:20:23 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 19:20:24 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 19:20:26 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 19:20:27 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 19:20:29 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 19:20:30 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 19:20:32 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 19:20:33 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 19:20:35 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 19:20:36 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 19:20:38 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 19:20:39 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 19:20:41 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 19:20:42 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 19:20:44 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 19:20:45 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 19:20:47 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 19:20:48 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 19:20:50 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 19:20:52 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 19:20:54 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 19:20:56 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 19:20:57 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 19:20:58 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 19:20:59 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 19:21:00 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 19:21:01 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 19:21:02 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 19:21:03 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 19:21:04 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 19:21:05 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 19:21:06 INFO mapreduce.Job:  map 88% reduce 0%
15/04/12 19:21:07 INFO mapreduce.Job:  map 89% reduce 4%
15/04/12 19:21:08 INFO mapreduce.Job:  map 89% reduce 13%
15/04/12 19:21:09 INFO mapreduce.Job:  map 91% reduce 24%
15/04/12 19:21:11 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 19:21:12 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 19:21:14 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 19:21:17 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 19:21:18 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 19:21:30 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 19:21:32 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 19:21:33 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 19:21:34 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 19:21:35 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 19:21:36 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 19:21:37 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 19:21:38 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 19:21:39 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 19:21:41 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 19:21:43 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 19:21:44 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 19:21:45 INFO mapreduce.Job:  map 100% reduce 40%
15/04/12 19:21:47 INFO mapreduce.Job:  map 100% reduce 41%
15/04/12 19:21:48 INFO mapreduce.Job:  map 100% reduce 44%
15/04/12 19:21:49 INFO mapreduce.Job:  map 100% reduce 48%
15/04/12 19:21:50 INFO mapreduce.Job:  map 100% reduce 50%
15/04/12 19:21:51 INFO mapreduce.Job:  map 100% reduce 54%
15/04/12 19:21:52 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 19:21:53 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 19:21:54 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 19:21:55 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 19:21:57 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 19:21:58 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 19:21:59 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 19:22:07 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 19:22:14 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 19:22:22 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 19:22:29 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 19:22:37 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 19:22:44 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 19:22:49 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 19:22:57 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 19:23:04 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 19:23:13 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 19:23:21 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 19:23:28 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 19:23:39 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 19:23:49 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 19:24:01 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 19:24:10 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 19:24:22 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 19:24:34 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 19:24:49 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 19:24:59 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 19:25:14 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 19:25:33 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 19:25:47 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 19:26:08 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 19:26:29 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 19:26:54 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 19:27:27 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 19:27:55 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 19:29:43 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 19:31:43 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 19:35:20 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 19:42:58 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 19:42:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4659_r_000012_0, Status : FAILED
Container [pid=29362,containerID=container_1422482982071_4659_01_000203] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4659_01_000203 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 29570 29371 29362 29362 (R) 108028 18632 10349387776 2503646 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3d597f6b0473 
	|- 29580 29570 29362 29362 (cat) 0 26 4231168 142 cat 
	|- 29362 10176 29362 29362 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4659/container_1422482982071_4659_01_000203/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4659/container_1422482982071_4659_01_000203 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 37792 attempt_1422482982071_4659_r_000012_0 203 1>/var/log/hadoop-yarn/containers/application_1422482982071_4659/container_1422482982071_4659_01_000203/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4659/container_1422482982071_4659_01_000203/stderr  
	|- 29584 29570 29362 29362 (cat) 0 0 4231168 134 cat 
	|- 29371 29362 29362 29362 (java) 2846 559 13312045056 589369 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4659/container_1422482982071_4659_01_000203/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4659/container_1422482982071_4659_01_000203 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 37792 attempt_1422482982071_4659_r_000012_0 203 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 19:42:59 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 20:01:04 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 20:01:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4659_r_000012_1, Status : FAILED
Container [pid=5804,containerID=container_1422482982071_4659_01_000241] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4659_01_000241 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 5871 5858 5804 5804 (cat) 0 0 4231168 134 cat 
	|- 5804 9608 5804 5804 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4659/container_1422482982071_4659_01_000241/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4659/container_1422482982071_4659_01_000241 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 37792 attempt_1422482982071_4659_r_000012_1 241 1>/var/log/hadoop-yarn/containers/application_1422482982071_4659/container_1422482982071_4659_01_000241/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4659/container_1422482982071_4659_01_000241/stderr  
	|- 5814 5804 5804 5804 (java) 3542 727 13312126976 590447 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4659/container_1422482982071_4659_01_000241/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4659/container_1422482982071_4659_01_000241 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 37792 attempt_1422482982071_4659_r_000012_1 241 
	|- 5869 5858 5804 5804 (cat) 0 27 4231168 142 cat 
	|- 5858 5814 5804 5804 (R) 117080 20870 10832699392 2558373 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3d597f6b0473 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 20:01:05 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 20:16:31 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 20:16:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4659_r_000012_2, Status : FAILED
Container [pid=16107,containerID=container_1422482982071_4659_01_000242] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4659_01_000242 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 16198 16117 16107 16107 (R) 107542 19003 10573148160 2558276 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3d597f6b0473 
	|- 16209 16198 16107 16107 (cat) 1 26 4231168 142 cat 
	|- 16107 6181 16107 16107 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4659/container_1422482982071_4659_01_000242/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4659/container_1422482982071_4659_01_000242 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 37792 attempt_1422482982071_4659_r_000012_2 242 1>/var/log/hadoop-yarn/containers/application_1422482982071_4659/container_1422482982071_4659_01_000242/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4659/container_1422482982071_4659_01_000242/stderr  
	|- 16117 16107 16107 16107 (java) 3183 658 13311954944 590486 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4659/container_1422482982071_4659_01_000242/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4659/container_1422482982071_4659_01_000242 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 37792 attempt_1422482982071_4659_r_000012_2 242 
	|- 16211 16198 16107 16107 (cat) 0 0 4231168 134 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 20:16:32 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 20:34:16 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 20:34:17 INFO mapreduce.Job: Job job_1422482982071_4659 failed with state FAILED due to: Task failed task_1422482982071_4659_r_000012
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 20:34:17 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=27762455676
		FILE: Number of bytes written=57981832241
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2093075836
		HDFS: Number of read operations=474
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=48
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Launched map tasks=135
		Launched reduce tasks=29
		Data-local map tasks=62
		Rack-local map tasks=73
		Total time spent by all maps in occupied slots (ms)=21031156
		Total time spent by all reduces in occupied slots (ms)=35451534
		Total time spent by all map tasks (ms)=10515578
		Total time spent by all reduce tasks (ms)=17725767
		Total vcore-seconds taken by all map tasks=10515578
		Total vcore-seconds taken by all reduce tasks=17725767
		Total megabyte-seconds taken by all map tasks=85134119488
		Total megabyte-seconds taken by all reduce tasks=212709204000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141612
		Map output bytes=29491545187
		Map output materialized bytes=30204071541
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=34953543
		Reduce shuffle bytes=27762474708
		Reduce input records=330302475
		Reduce output records=35143556
		Spilled Records=674444087
		Shuffled Maps =3216
		Failed Shuffles=0
		Merged Map outputs=3216
		GC time elapsed (ms)=107323
		CPU time spent (ms)=22421590
		Physical memory (bytes) snapshot=296741167104
		Virtual memory (bytes) snapshot=1550894809088
		Total committed heap usage (bytes)=421780439040
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2093075836
	rmr
		reduce calls=34953543
15/04/12 20:34:17 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 20:34:23 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file3d59db93491

real	74m51.677s
user	0m40.341s
sys	0m3.966s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-15-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=15"


15/04/12 20:34:29 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 20:34:29 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5842815153234599313.jar tmpDir=null
15/04/12 20:34:30 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 20:34:30 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 20:34:31 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 20:34:31 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 20:34:31 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4679
15/04/12 20:34:32 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4679
15/04/12 20:34:32 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4679/
15/04/12 20:34:32 INFO mapreduce.Job: Running job: job_1422482982071_4679
15/04/12 20:34:37 INFO mapreduce.Job: Job job_1422482982071_4679 running in uber mode : false
15/04/12 20:34:37 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 20:34:48 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 20:34:49 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 20:34:50 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 20:34:52 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 20:34:53 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 20:34:55 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 20:34:58 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 20:34:59 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 20:35:01 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 20:35:04 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 20:35:05 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 20:35:07 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 20:35:09 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 20:35:10 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 20:35:13 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 20:35:14 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 20:35:16 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 20:35:19 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 20:35:20 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 20:35:22 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 20:35:24 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 20:35:26 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 20:35:27 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 20:35:29 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 20:35:31 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 20:35:32 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 20:35:33 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 20:35:35 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 20:35:36 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 20:35:38 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 20:35:39 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 20:35:41 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 20:35:42 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 20:35:44 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 20:35:47 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 20:35:49 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 20:35:50 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 20:35:51 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 20:35:52 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 20:35:53 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 20:35:54 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 20:35:55 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 20:35:56 INFO mapreduce.Job:  map 88% reduce 0%
15/04/12 20:35:57 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 20:35:58 INFO mapreduce.Job:  map 90% reduce 0%
15/04/12 20:35:59 INFO mapreduce.Job:  map 91% reduce 0%
15/04/12 20:36:00 INFO mapreduce.Job:  map 91% reduce 8%
15/04/12 20:36:01 INFO mapreduce.Job:  map 92% reduce 15%
15/04/12 20:36:02 INFO mapreduce.Job:  map 92% reduce 19%
15/04/12 20:36:05 INFO mapreduce.Job:  map 93% reduce 19%
15/04/12 20:36:09 INFO mapreduce.Job:  map 93% reduce 22%
15/04/12 20:36:10 INFO mapreduce.Job:  map 93% reduce 24%
15/04/12 20:36:11 INFO mapreduce.Job:  map 93% reduce 25%
15/04/12 20:36:12 INFO mapreduce.Job:  map 94% reduce 26%
15/04/12 20:36:19 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 20:36:21 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 20:36:22 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 20:36:25 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 20:36:26 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 20:36:27 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 20:36:28 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 20:36:30 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 20:36:31 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 20:36:38 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 20:36:39 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 20:36:40 INFO mapreduce.Job:  map 100% reduce 36%
15/04/12 20:36:41 INFO mapreduce.Job:  map 100% reduce 40%
15/04/12 20:36:42 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 20:36:43 INFO mapreduce.Job:  map 100% reduce 47%
15/04/12 20:36:44 INFO mapreduce.Job:  map 100% reduce 51%
15/04/12 20:36:45 INFO mapreduce.Job:  map 100% reduce 55%
15/04/12 20:36:46 INFO mapreduce.Job:  map 100% reduce 58%
15/04/12 20:36:47 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 20:36:48 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 20:36:49 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 20:36:50 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 20:36:52 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 20:37:02 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 20:37:17 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 20:37:38 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 20:38:00 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 20:38:13 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 20:38:29 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 20:38:42 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 20:38:54 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 20:39:10 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 20:39:28 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 20:39:45 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 20:40:00 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 20:40:15 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 20:40:37 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 20:40:53 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 20:41:04 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 20:41:22 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 20:41:40 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 20:42:00 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 20:42:16 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 20:42:32 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 20:42:52 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 20:43:13 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 20:43:39 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 20:44:10 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 20:44:45 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 20:45:17 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 20:46:00 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 20:46:50 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 20:48:02 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 20:50:32 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 20:57:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4679_r_000012_0, Status : FAILED
Container [pid=17716,containerID=container_1422482982071_4679_01_000200] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.8 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4679_01_000200 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 17842 17829 17716 17716 (cat) 0 0 103391232 151 cat 
	|- 17716 7712 17716 17716 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4679/container_1422482982071_4679_01_000200/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4679/container_1422482982071_4679_01_000200 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 57265 attempt_1422482982071_4679_r_000012_0 200 1>/var/log/hadoop-yarn/containers/application_1422482982071_4679/container_1422482982071_4679_01_000200/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4679/container_1422482982071_4679_01_000200/stderr  
	|- 17841 17829 17716 17716 (cat) 1 26 103391232 159 cat 
	|- 17728 17716 17716 17716 (java) 4167 751 13411659776 585444 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4679/container_1422482982071_4679_01_000200/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4679/container_1422482982071_4679_01_000200 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 57265 attempt_1422482982071_4679_r_000012_0 200 
	|- 17829 17728 17716 17716 (R) 107496 17848 10784092160 2529635 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4b691cd7cac3 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 20:57:44 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 20:57:56 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 20:58:02 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 20:58:18 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 20:58:21 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 21:21:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4679_r_000012_1, Status : FAILED
Container [pid=36353,containerID=container_1422482982071_4679_01_000218] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4679_01_000218 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 36406 36363 36353 36353 (R) 116741 22309 10404610048 2517096 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4b691cd7cac3 
	|- 36417 36406 36353 36353 (cat) 0 27 4231168 142 cat 
	|- 36418 36406 36353 36353 (cat) 0 0 4231168 134 cat 
	|- 36353 29409 36353 36353 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4679/container_1422482982071_4679_01_000218/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4679/container_1422482982071_4679_01_000218 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 57265 attempt_1422482982071_4679_r_000012_1 218 1>/var/log/hadoop-yarn/containers/application_1422482982071_4679/container_1422482982071_4679_01_000218/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4679/container_1422482982071_4679_01_000218/stderr  
	|- 36363 36353 36353 36353 (java) 4662 951 13312323584 585977 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4679/container_1422482982071_4679_01_000218/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4679/container_1422482982071_4679_01_000218 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 57265 attempt_1422482982071_4679_r_000012_1 218 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 21:21:33 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 21:21:45 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 21:21:51 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 21:22:09 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 21:43:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4679_r_000012_2, Status : FAILED
Container [pid=12861,containerID=container_1422482982071_4679_01_000219] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.4 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4679_01_000219 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 12861 10211 12861 12861 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4679/container_1422482982071_4679_01_000219/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4679/container_1422482982071_4679_01_000219 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 57265 attempt_1422482982071_4679_r_000012_2 219 1>/var/log/hadoop-yarn/containers/application_1422482982071_4679/container_1422482982071_4679_01_000219/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4679/container_1422482982071_4679_01_000219/stderr  
	|- 12925 12913 12861 12861 (cat) 0 0 4231168 134 cat 
	|- 12924 12913 12861 12861 (cat) 0 26 4231168 142 cat 
	|- 12871 12861 12861 12861 (java) 4628 951 13312929792 584440 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4679/container_1422482982071_4679_01_000219/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4679/container_1422482982071_4679_01_000219 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 57265 attempt_1422482982071_4679_r_000012_2 219 
	|- 12913 12871 12861 12861 (R) 106238 19682 10683826176 2525926 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4b691cd7cac3 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 21:43:11 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 21:43:21 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 21:43:28 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 21:43:46 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 22:07:05 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 22:07:05 INFO mapreduce.Job: Job job_1422482982071_4679 failed with state FAILED due to: Task failed task_1422482982071_4679_r_000012
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 22:07:06 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=26662972862
		FILE: Number of bytes written=56881365069
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2034321711
		HDFS: Number of read operations=444
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=28
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Launched map tasks=135
		Launched reduce tasks=18
		Data-local map tasks=63
		Rack-local map tasks=72
		Total time spent by all maps in occupied slots (ms)=21125504
		Total time spent by all reduces in occupied slots (ms)=34346656
		Total time spent by all map tasks (ms)=10562752
		Total time spent by all reduce tasks (ms)=17173328
		Total vcore-seconds taken by all map tasks=10562752
		Total vcore-seconds taken by all reduce tasks=17173328
		Total megabyte-seconds taken by all map tasks=85516040192
		Total megabyte-seconds taken by all reduce tasks=206079936000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141627
		Map output bytes=29491564911
		Map output materialized bytes=30204083255
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=33982340
		Reduce shuffle bytes=26662983926
		Reduce input records=320795931
		Reduce output records=34162883
		Spilled Records=664937558
		Shuffled Maps =1876
		Failed Shuffles=0
		Merged Map outputs=1876
		GC time elapsed (ms)=111360
		CPU time spent (ms)=22222450
		Physical memory (bytes) snapshot=289656999936
		Virtual memory (bytes) snapshot=1418044735488
		Total committed heap usage (bytes)=401110986752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2034321711
	rmr
		reduce calls=33982340
15/04/12 22:07:06 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 22:07:12 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file4b6969e036a7

real	92m48.324s
user	0m41.144s
sys	0m4.852s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-15-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=15"


15/04/12 22:07:17 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 22:07:17 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4211771983121641294.jar tmpDir=null
15/04/12 22:07:18 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 22:07:18 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 22:07:19 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 22:07:19 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 22:07:19 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4694
15/04/12 22:07:20 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4694
15/04/12 22:07:20 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4694/
15/04/12 22:07:20 INFO mapreduce.Job: Running job: job_1422482982071_4694
15/04/12 22:07:24 INFO mapreduce.Job: Job job_1422482982071_4694 running in uber mode : false
15/04/12 22:07:24 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 22:07:35 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 22:07:36 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 22:07:38 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 22:07:39 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 22:07:41 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 22:07:42 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 22:07:44 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 22:07:45 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 22:07:47 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 22:07:48 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 22:07:50 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 22:07:51 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 22:07:53 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 22:07:54 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 22:07:56 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 22:07:57 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 22:07:59 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 22:08:00 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 22:08:02 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 22:08:03 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 22:08:04 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 22:08:05 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 22:08:06 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 22:08:08 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 22:08:09 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 22:08:11 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 22:08:13 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 22:08:14 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 22:08:15 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 22:08:16 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 22:08:18 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 22:08:19 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 22:08:20 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 22:08:21 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 22:08:22 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 22:08:23 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 22:08:24 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 22:08:25 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 22:08:26 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 22:08:27 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 22:08:28 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 22:08:31 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 22:08:33 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 22:08:35 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 22:08:36 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 22:08:37 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 22:08:38 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 22:08:39 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 22:08:40 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 22:08:41 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 22:08:42 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 22:08:43 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 22:08:44 INFO mapreduce.Job:  map 88% reduce 0%
15/04/12 22:08:45 INFO mapreduce.Job:  map 90% reduce 5%
15/04/12 22:08:46 INFO mapreduce.Job:  map 91% reduce 17%
15/04/12 22:08:47 INFO mapreduce.Job:  map 91% reduce 18%
15/04/12 22:08:48 INFO mapreduce.Job:  map 92% reduce 18%
15/04/12 22:08:51 INFO mapreduce.Job:  map 93% reduce 18%
15/04/12 22:08:52 INFO mapreduce.Job:  map 93% reduce 20%
15/04/12 22:08:54 INFO mapreduce.Job:  map 93% reduce 21%
15/04/12 22:08:55 INFO mapreduce.Job:  map 93% reduce 25%
15/04/12 22:08:56 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 22:08:58 INFO mapreduce.Job:  map 94% reduce 26%
15/04/12 22:09:01 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 22:09:08 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 22:09:10 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 22:09:11 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 22:09:12 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 22:09:13 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 22:09:15 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 22:09:17 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 22:09:19 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 22:09:20 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 22:09:21 INFO mapreduce.Job:  map 100% reduce 37%
15/04/12 22:09:22 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 22:09:23 INFO mapreduce.Job:  map 100% reduce 47%
15/04/12 22:09:24 INFO mapreduce.Job:  map 100% reduce 48%
15/04/12 22:09:25 INFO mapreduce.Job:  map 100% reduce 51%
15/04/12 22:09:26 INFO mapreduce.Job:  map 100% reduce 56%
15/04/12 22:09:28 INFO mapreduce.Job:  map 100% reduce 58%
15/04/12 22:09:29 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 22:09:31 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 22:09:32 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 22:09:35 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 22:09:43 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 22:09:59 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 22:10:17 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 22:10:35 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 22:10:51 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 22:11:05 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 22:11:17 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 22:11:30 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 22:11:45 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 22:12:00 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 22:12:16 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 22:12:35 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 22:12:50 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 22:13:08 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 22:13:24 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 22:13:37 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 22:13:56 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 22:14:12 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 22:14:30 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 22:14:51 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 22:15:03 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 22:15:24 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 22:15:47 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 22:16:13 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 22:16:38 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 22:17:11 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 22:17:43 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 22:18:25 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 22:19:17 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 22:20:23 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 22:23:06 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 22:30:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4694_r_000012_0, Status : FAILED
Container [pid=1032,containerID=container_1422482982071_4694_01_000197] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4694_01_000197 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 1110 1098 1032 1032 (cat) 0 0 4231168 134 cat 
	|- 1032 10887 1032 1032 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4694/container_1422482982071_4694_01_000197/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4694/container_1422482982071_4694_01_000197 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 37387 attempt_1422482982071_4694_r_000012_0 197 1>/var/log/hadoop-yarn/containers/application_1422482982071_4694/container_1422482982071_4694_01_000197/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4694/container_1422482982071_4694_01_000197/stderr  
	|- 1041 1032 1032 1032 (java) 4359 937 13312729088 584085 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4694/container_1422482982071_4694_01_000197/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4694/container_1422482982071_4694_01_000197 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 37387 attempt_1422482982071_4694_r_000012_0 197 
	|- 1109 1098 1032 1032 (cat) 0 27 4231168 142 cat 
	|- 1098 1041 1032 1032 (R) 107823 20060 10488422400 2537558 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce76e990994d5 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 22:30:43 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 22:30:54 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 22:31:00 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 22:31:16 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 22:50:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4694_r_000012_1, Status : FAILED
Container [pid=29170,containerID=container_1422482982071_4694_01_000215] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4694_01_000215 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 29170 9431 29170 29170 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4694/container_1422482982071_4694_01_000215/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4694/container_1422482982071_4694_01_000215 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 37387 attempt_1422482982071_4694_r_000012_1 215 1>/var/log/hadoop-yarn/containers/application_1422482982071_4694/container_1422482982071_4694_01_000215/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4694/container_1422482982071_4694_01_000215/stderr  
	|- 29226 29180 29170 29170 (R) 96355 17696 10528792576 2545057 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce76e990994d5 
	|- 29180 29170 29170 29170 (java) 3430 714 13312794624 585946 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4694/container_1422482982071_4694_01_000215/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4694/container_1422482982071_4694_01_000215 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 37387 attempt_1422482982071_4694_r_000012_1 215 
	|- 29237 29226 29170 29170 (cat) 0 23 4231168 142 cat 
	|- 29238 29226 29170 29170 (cat) 0 0 4231168 134 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 22:50:18 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 22:50:30 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 22:50:37 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 22:50:52 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 22:50:55 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 23:11:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4694_r_000012_2, Status : FAILED
Container [pid=30280,containerID=container_1422482982071_4694_01_000216] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4694_01_000216 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 30280 3817 30280 30280 (bash) 0 0 108650496 297 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4694/container_1422482982071_4694_01_000216/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4694/container_1422482982071_4694_01_000216 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 37387 attempt_1422482982071_4694_r_000012_2 216 1>/var/log/hadoop-yarn/containers/application_1422482982071_4694/container_1422482982071_4694_01_000216/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4694/container_1422482982071_4694_01_000216/stderr  
	|- 30344 30333 30280 30280 (cat) 0 25 103391232 159 cat 
	|- 30345 30333 30280 30280 (cat) 0 0 103391232 152 cat 
	|- 30333 30290 30280 30280 (R) 108235 16909 10580668416 2535970 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce76e990994d5 
	|- 30290 30280 30280 30280 (java) 4126 840 13411119104 584967 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4694/container_1422482982071_4694_01_000216/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4694/container_1422482982071_4694_01_000216 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.172 37387 attempt_1422482982071_4694_r_000012_2 216 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 23:11:49 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 23:12:00 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 23:12:06 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 23:12:22 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 23:12:25 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 23:33:14 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 23:33:15 INFO mapreduce.Job: Job job_1422482982071_4694 failed with state FAILED due to: Task failed task_1422482982071_4694_r_000012
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 23:33:15 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=26662852928
		FILE: Number of bytes written=56881231138
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2034330816
		HDFS: Number of read operations=444
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=28
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Launched map tasks=135
		Launched reduce tasks=18
		Data-local map tasks=59
		Rack-local map tasks=76
		Total time spent by all maps in occupied slots (ms)=21045492
		Total time spent by all reduces in occupied slots (ms)=32798258
		Total time spent by all map tasks (ms)=10522746
		Total time spent by all reduce tasks (ms)=16399129
		Total vcore-seconds taken by all map tasks=10522746
		Total vcore-seconds taken by all reduce tasks=16399129
		Total megabyte-seconds taken by all map tasks=85192151616
		Total megabyte-seconds taken by all reduce tasks=196789548000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141614
		Map output bytes=29491551532
		Map output materialized bytes=30204069850
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=33982364
		Reduce shuffle bytes=26662863992
		Reduce input records=320795151
		Reduce output records=34162958
		Spilled Records=664936765
		Shuffled Maps =1876
		Failed Shuffles=0
		Merged Map outputs=1876
		GC time elapsed (ms)=97580
		CPU time spent (ms)=21842580
		Physical memory (bytes) snapshot=290798907392
		Virtual memory (bytes) snapshot=1417662263296
		Total committed heap usage (bytes)=400611106816
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2034330816
	rmr
		reduce calls=33982364
15/04/12 23:33:15 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 23:33:22 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file76e962ac6e98

real	86m9.779s
user	0m41.272s
sys	0m4.524s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-15-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=15"


15/04/12 23:33:27 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 23:33:27 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2116703889643561796.jar tmpDir=null
15/04/12 23:33:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 23:33:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 23:33:29 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 23:33:30 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 23:33:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4702
15/04/12 23:33:31 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4702
15/04/12 23:33:31 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4702/
15/04/12 23:33:31 INFO mapreduce.Job: Running job: job_1422482982071_4702
15/04/12 23:33:35 INFO mapreduce.Job: Job job_1422482982071_4702 running in uber mode : false
15/04/12 23:33:35 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 23:33:45 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 23:33:46 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 23:33:47 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 23:33:48 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 23:33:49 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 23:33:50 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 23:33:51 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 23:33:52 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 23:33:55 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 23:33:56 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 23:33:58 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 23:33:59 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 23:34:01 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 23:34:02 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 23:34:04 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 23:34:05 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 23:34:07 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 23:34:08 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 23:34:09 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 23:34:10 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 23:34:11 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 23:34:13 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 23:34:14 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 23:34:16 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 23:34:17 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 23:34:19 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 23:34:20 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 23:34:22 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 23:34:23 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 23:34:25 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 23:34:26 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 23:34:28 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 23:34:29 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 23:34:31 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 23:34:32 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 23:34:34 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 23:34:35 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 23:34:37 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 23:34:38 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 23:34:42 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 23:34:44 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 23:34:45 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 23:34:46 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 23:34:47 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 23:34:48 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 23:34:49 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 23:34:50 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 23:34:51 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 23:34:52 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 23:34:53 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 23:34:54 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 23:34:55 INFO mapreduce.Job:  map 88% reduce 0%
15/04/12 23:34:56 INFO mapreduce.Job:  map 90% reduce 5%
15/04/12 23:34:57 INFO mapreduce.Job:  map 92% reduce 16%
15/04/12 23:34:58 INFO mapreduce.Job:  map 92% reduce 17%
15/04/12 23:34:59 INFO mapreduce.Job:  map 92% reduce 18%
15/04/12 23:35:01 INFO mapreduce.Job:  map 93% reduce 19%
15/04/12 23:35:04 INFO mapreduce.Job:  map 94% reduce 19%
15/04/12 23:35:06 INFO mapreduce.Job:  map 94% reduce 20%
15/04/12 23:35:07 INFO mapreduce.Job:  map 94% reduce 24%
15/04/12 23:35:09 INFO mapreduce.Job:  map 94% reduce 26%
15/04/12 23:35:16 INFO mapreduce.Job:  map 94% reduce 28%
15/04/12 23:35:17 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 23:35:21 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 23:35:22 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 23:35:23 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 23:35:25 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 23:35:27 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 23:35:28 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 23:35:29 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 23:35:31 INFO mapreduce.Job:  map 100% reduce 39%
15/04/12 23:35:32 INFO mapreduce.Job:  map 100% reduce 44%
15/04/12 23:35:34 INFO mapreduce.Job:  map 100% reduce 49%
15/04/12 23:35:35 INFO mapreduce.Job:  map 100% reduce 54%
15/04/12 23:35:37 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 23:35:38 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 23:35:39 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 23:35:40 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 23:35:41 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 23:35:53 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 23:36:09 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 23:36:26 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 23:36:46 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 23:37:00 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 23:37:16 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 23:37:28 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 23:37:41 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 23:37:59 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 23:38:11 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 23:38:28 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 23:38:46 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 23:39:04 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 23:39:24 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 23:39:43 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 23:39:57 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 23:40:17 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 23:40:31 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 23:40:56 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 23:41:14 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 23:41:39 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 23:41:56 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 23:42:20 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 23:42:47 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 23:43:13 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 23:43:45 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 23:44:21 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 23:45:01 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 23:45:49 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 23:46:56 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 23:49:26 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 23:56:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4702_r_000012_0, Status : FAILED
Container [pid=22269,containerID=container_1422482982071_4702_01_000197] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4702_01_000197 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 22349 22278 22269 22269 (R) 108762 18687 10538778624 2498742 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce95ab7902c207 
	|- 22361 22349 22269 22269 (cat) 1 27 103391232 159 cat 
	|- 22362 22349 22269 22269 (cat) 0 0 103391232 151 cat 
	|- 22278 22269 22269 22269 (java) 3656 700 13411614720 584440 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4702/container_1422482982071_4702_01_000197/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4702/container_1422482982071_4702_01_000197 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.181 54707 attempt_1422482982071_4702_r_000012_0 197 
	|- 22269 7712 22269 22269 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4702/container_1422482982071_4702_01_000197/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4702/container_1422482982071_4702_01_000197 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.181 54707 attempt_1422482982071_4702_r_000012_0 197 1>/var/log/hadoop-yarn/containers/application_1422482982071_4702/container_1422482982071_4702_01_000197/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4702/container_1422482982071_4702_01_000197/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 23:56:52 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 23:57:02 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 23:57:15 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 23:57:30 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 23:57:33 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 23:57:36 INFO mapreduce.Job:  map 100% reduce 98%
15/04/13 00:19:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4702_r_000012_1, Status : FAILED
Container [pid=48496,containerID=container_1422482982071_4702_01_000215] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.9 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4702_01_000215 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 48506 48496 48496 48496 (java) 3865 644 13312471040 611994 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4702/container_1422482982071_4702_01_000215/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4702/container_1422482982071_4702_01_000215 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.181 54707 attempt_1422482982071_4702_r_000012_1 215 
	|- 48496 9000 48496 48496 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4702/container_1422482982071_4702_01_000215/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4702/container_1422482982071_4702_01_000215 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.181 54707 attempt_1422482982071_4702_r_000012_1 215 1>/var/log/hadoop-yarn/containers/application_1422482982071_4702/container_1422482982071_4702_01_000215/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4702/container_1422482982071_4702_01_000215/stderr  
	|- 48636 48506 48496 48496 (R) 106734 27480 10228527104 2474140 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce95ab7902c207 
	|- 48648 48636 48496 48496 (cat) 0 0 4231168 134 cat 
	|- 48647 48636 48496 48496 (cat) 0 26 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 00:20:00 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 00:20:12 INFO mapreduce.Job:  map 100% reduce 94%
15/04/13 00:20:18 INFO mapreduce.Job:  map 100% reduce 95%
15/04/13 00:20:33 INFO mapreduce.Job:  map 100% reduce 96%
15/04/13 00:20:36 INFO mapreduce.Job:  map 100% reduce 98%
15/04/13 00:41:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4702_r_000012_2, Status : FAILED
Container [pid=44868,containerID=container_1422482982071_4702_01_000216] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.7 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4702_01_000216 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 44878 44868 44868 44868 (java) 4614 962 13411282944 585284 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4702/container_1422482982071_4702_01_000216/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4702/container_1422482982071_4702_01_000216 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.181 54707 attempt_1422482982071_4702_r_000012_2 216 
	|- 44922 44878 44868 44868 (R) 106032 18485 10650890240 2507498 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce95ab7902c207 
	|- 44868 3799 44868 44868 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4702/container_1422482982071_4702_01_000216/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4702/container_1422482982071_4702_01_000216 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.181 54707 attempt_1422482982071_4702_r_000012_2 216 1>/var/log/hadoop-yarn/containers/application_1422482982071_4702/container_1422482982071_4702_01_000216/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4702/container_1422482982071_4702_01_000216/stderr  
	|- 44933 44922 44868 44868 (cat) 0 26 103391232 159 cat 
	|- 44934 44922 44868 44868 (cat) 0 0 103391232 151 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 00:41:29 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 00:41:41 INFO mapreduce.Job:  map 100% reduce 94%
15/04/13 00:41:48 INFO mapreduce.Job:  map 100% reduce 95%
15/04/13 00:42:06 INFO mapreduce.Job:  map 100% reduce 98%
15/04/13 01:02:48 INFO mapreduce.Job:  map 100% reduce 100%
15/04/13 01:02:49 INFO mapreduce.Job: Job job_1422482982071_4702 failed with state FAILED due to: Task failed task_1422482982071_4702_r_000012
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/13 01:02:49 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=26662869311
		FILE: Number of bytes written=56881222857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2034316488
		HDFS: Number of read operations=444
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=28
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Launched map tasks=135
		Launched reduce tasks=18
		Data-local map tasks=64
		Rack-local map tasks=71
		Total time spent by all maps in occupied slots (ms)=21053882
		Total time spent by all reduces in occupied slots (ms)=33276998
		Total time spent by all map tasks (ms)=10526941
		Total time spent by all reduce tasks (ms)=16638499
		Total vcore-seconds taken by all map tasks=10526941
		Total vcore-seconds taken by all reduce tasks=16638499
		Total megabyte-seconds taken by all map tasks=85226114336
		Total megabyte-seconds taken by all reduce tasks=199661988000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141564
		Map output bytes=29491526376
		Map output materialized bytes=30204044594
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=33982231
		Reduce shuffle bytes=26662880375
		Reduce input records=320795391
		Reduce output records=34162786
		Spilled Records=664936955
		Shuffled Maps =1876
		Failed Shuffles=0
		Merged Map outputs=1876
		GC time elapsed (ms)=104094
		CPU time spent (ms)=21924290
		Physical memory (bytes) snapshot=291015704576
		Virtual memory (bytes) snapshot=1416868294656
		Total committed heap usage (bytes)=400663314432
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2034316488
	rmr
		reduce calls=33982231
15/04/13 01:02:49 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/13 01:02:56 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file95abe2bfde1

real	89m34.355s
user	0m42.317s
sys	0m4.477s

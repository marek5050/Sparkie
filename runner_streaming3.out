15/04/08 14:36:25 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 40
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-40-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3935931249774377193.jar tmpDir=null
15/04/08 14:36:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 14:36:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 14:36:29 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 14:36:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 14:36:29 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 14:36:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4195
15/04/08 14:36:30 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4195
15/04/08 14:36:30 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4195/
15/04/08 14:36:30 INFO mapreduce.Job: Running job: job_1422482982071_4195
15/04/08 14:36:35 INFO mapreduce.Job: Job job_1422482982071_4195 running in uber mode : false
15/04/08 14:36:35 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 14:36:46 INFO mapreduce.Job:  map 12% reduce 0%
15/04/08 14:36:47 INFO mapreduce.Job:  map 17% reduce 0%
15/04/08 14:36:48 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 14:36:49 INFO mapreduce.Job:  map 26% reduce 0%
15/04/08 14:36:50 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 14:36:51 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 14:36:52 INFO mapreduce.Job:  map 39% reduce 0%
15/04/08 14:36:53 INFO mapreduce.Job:  map 43% reduce 0%
15/04/08 14:36:54 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 14:36:55 INFO mapreduce.Job:  map 51% reduce 0%
15/04/08 14:36:56 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 14:36:57 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 14:36:58 INFO mapreduce.Job:  map 61% reduce 0%
15/04/08 14:36:59 INFO mapreduce.Job:  map 65% reduce 0%
15/04/08 14:37:00 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 14:37:02 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 14:37:10 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 14:37:11 INFO mapreduce.Job:  map 71% reduce 0%
15/04/08 14:37:12 INFO mapreduce.Job:  map 73% reduce 0%
15/04/08 14:37:13 INFO mapreduce.Job:  map 81% reduce 0%
15/04/08 14:37:14 INFO mapreduce.Job:  map 87% reduce 0%
15/04/08 14:37:15 INFO mapreduce.Job:  map 94% reduce 0%
15/04/08 14:37:16 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 14:37:17 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 14:37:19 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 14:37:21 INFO mapreduce.Job:  map 100% reduce 13%
15/04/08 14:37:22 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 14:37:23 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 14:37:24 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 14:37:25 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 14:37:26 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 14:37:27 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 14:37:28 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 14:37:29 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 14:37:30 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 14:37:31 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 14:37:33 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 14:37:34 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 14:37:35 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 14:37:37 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 14:37:38 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 14:37:39 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 14:37:40 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 14:37:42 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 14:37:43 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 14:37:45 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 14:37:46 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 14:37:47 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 14:37:49 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 14:37:51 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 14:37:52 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 14:37:55 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 14:37:56 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 14:37:59 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 14:38:01 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 14:38:03 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 14:38:04 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 14:38:07 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 14:38:13 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 14:38:19 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 14:38:22 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 14:38:26 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 14:39:11 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 14:40:24 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 14:40:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4195_r_000000_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta/_temporary/1/_temporary/attempt_1422482982071_4195_r_000000_0/part-00000 (inode 3574283): File does not exist. Holder DFSClient_attempt_1422482982071_4195_r_000000_0_-2103674275_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:2796)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2680)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:569)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:440)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:362)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1438)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1260)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:525)

15/04/08 14:40:46 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 14:42:10 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 14:42:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4195_r_000000_1, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta/_temporary/1/_temporary/attempt_1422482982071_4195_r_000000_1/part-00000 (inode 3574353): File does not exist. Holder DFSClient_attempt_1422482982071_4195_r_000000_1_-2097843916_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:2796)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2680)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:569)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:440)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:362)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1438)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1260)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:525)

15/04/08 14:42:34 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 14:43:59 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 14:44:25 INFO mapreduce.Job: Job job_1422482982071_4195 completed successfully
15/04/08 14:44:25 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10382210458
		FILE: Number of bytes written=20773026376
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Failed reduce tasks=2
		Killed reduce tasks=1
		Launched map tasks=50
		Launched reduce tasks=43
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=3672012
		Total time spent by all reduces in occupied slots (ms)=5575186
		Total time spent by all map tasks (ms)=1836006
		Total time spent by all reduce tasks (ms)=2787593
		Total vcore-seconds taken by all map tasks=1836006
		Total vcore-seconds taken by all reduce tasks=2787593
		Total megabyte-seconds taken by all map tasks=14864304576
		Total megabyte-seconds taken by all reduce tasks=33451116000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382222218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382222218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =2000
		Failed Shuffles=0
		Merged Map outputs=2000
		GC time elapsed (ms)=94852
		CPU time spent (ms)=4716460
		Physical memory (bytes) snapshot=115824381952
		Virtual memory (bytes) snapshot=993223041024
		Total committed heap usage (bytes)=222687342592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 14:44:25 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	8m3.073s
user	0m15.763s
sys	0m2.027s
15/04/08 14:44:27 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 40
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-40-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3581298430064131242.jar tmpDir=null
15/04/08 14:44:30 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 14:44:30 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 14:44:31 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 14:44:31 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 14:44:31 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 14:44:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4200
15/04/08 14:44:32 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4200
15/04/08 14:44:32 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4200/
15/04/08 14:44:32 INFO mapreduce.Job: Running job: job_1422482982071_4200
15/04/08 14:44:39 INFO mapreduce.Job: Job job_1422482982071_4200 running in uber mode : false
15/04/08 14:44:39 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 14:44:50 INFO mapreduce.Job:  map 2% reduce 0%
15/04/08 14:44:51 INFO mapreduce.Job:  map 18% reduce 0%
15/04/08 14:44:52 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 14:44:53 INFO mapreduce.Job:  map 20% reduce 0%
15/04/08 14:44:54 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 14:44:56 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 14:44:57 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 14:44:59 INFO mapreduce.Job:  map 45% reduce 0%
15/04/08 14:45:00 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 14:45:01 INFO mapreduce.Job:  map 58% reduce 0%
15/04/08 14:45:03 INFO mapreduce.Job:  map 65% reduce 0%
15/04/08 14:45:04 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 14:45:16 INFO mapreduce.Job:  map 76% reduce 0%
15/04/08 14:45:17 INFO mapreduce.Job:  map 83% reduce 0%
15/04/08 14:45:18 INFO mapreduce.Job:  map 89% reduce 0%
15/04/08 14:45:19 INFO mapreduce.Job:  map 96% reduce 0%
15/04/08 14:45:20 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 14:45:22 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 14:45:26 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 14:45:27 INFO mapreduce.Job:  map 100% reduce 48%
15/04/08 14:45:29 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 14:45:30 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 14:45:32 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 14:45:33 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 14:45:35 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 14:45:36 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 14:45:38 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 14:45:41 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 14:45:42 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 14:45:44 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 14:45:47 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 14:45:48 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 14:45:50 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 14:45:51 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 14:45:53 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 14:45:54 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 14:45:56 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 14:45:59 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 14:46:02 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 14:46:03 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 14:46:06 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 14:46:07 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 14:46:09 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 14:46:12 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 14:46:18 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 14:46:24 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 14:46:27 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 14:46:32 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 14:47:19 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 14:48:55 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 14:49:19 INFO mapreduce.Job: Job job_1422482982071_4200 completed successfully
15/04/08 14:49:20 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=10382210458
		FILE: Number of bytes written=20773026376
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Killed reduce tasks=2
		Launched map tasks=50
		Launched reduce tasks=42
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=3625174
		Total time spent by all reduces in occupied slots (ms)=4841116
		Total time spent by all map tasks (ms)=1812587
		Total time spent by all reduce tasks (ms)=2420558
		Total vcore-seconds taken by all map tasks=1812587
		Total vcore-seconds taken by all reduce tasks=2420558
		Total megabyte-seconds taken by all map tasks=14674704352
		Total megabyte-seconds taken by all reduce tasks=29046696000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382222218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382222218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =2000
		Failed Shuffles=0
		Merged Map outputs=2000
		GC time elapsed (ms)=74775
		CPU time spent (ms)=4602230
		Physical memory (bytes) snapshot=116163837952
		Virtual memory (bytes) snapshot=993218195456
		Total committed heap usage (bytes)=222689157120
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 14:49:20 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	4m54.720s
user	0m12.428s
sys	0m1.183s
15/04/08 14:49:23 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 40
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-40-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8921840189677683741.jar tmpDir=null
15/04/08 14:49:25 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 14:49:25 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 14:49:26 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 14:49:26 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 14:49:27 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 14:49:27 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 14:49:27 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4204
15/04/08 14:49:28 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4204
15/04/08 14:49:28 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4204/
15/04/08 14:49:28 INFO mapreduce.Job: Running job: job_1422482982071_4204
15/04/08 14:49:32 INFO mapreduce.Job: Job job_1422482982071_4204 running in uber mode : false
15/04/08 14:49:32 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 14:49:42 INFO mapreduce.Job:  map 14% reduce 0%
15/04/08 14:49:43 INFO mapreduce.Job:  map 22% reduce 0%
15/04/08 14:49:45 INFO mapreduce.Job:  map 30% reduce 0%
15/04/08 14:49:46 INFO mapreduce.Job:  map 36% reduce 0%
15/04/08 14:49:48 INFO mapreduce.Job:  map 43% reduce 0%
15/04/08 14:49:49 INFO mapreduce.Job:  map 49% reduce 0%
15/04/08 14:49:51 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 14:49:52 INFO mapreduce.Job:  map 63% reduce 0%
15/04/08 14:49:54 INFO mapreduce.Job:  map 64% reduce 0%
15/04/08 14:49:55 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 14:50:06 INFO mapreduce.Job:  map 76% reduce 0%
15/04/08 14:50:07 INFO mapreduce.Job:  map 83% reduce 0%
15/04/08 14:50:08 INFO mapreduce.Job:  map 86% reduce 0%
15/04/08 14:50:09 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 14:50:11 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 14:50:17 INFO mapreduce.Job:  map 100% reduce 20%
15/04/08 14:50:18 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 14:50:20 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 14:50:21 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 14:50:23 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 14:50:24 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 14:50:26 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 14:50:27 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 14:50:29 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 14:50:30 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 14:50:31 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 14:50:33 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 14:50:35 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 14:50:36 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 14:50:38 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 14:50:39 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 14:50:40 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 14:50:42 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 14:50:43 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 14:50:45 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 14:50:47 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 14:50:48 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 14:50:51 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 14:50:53 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 14:50:55 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 14:50:57 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 14:51:00 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 14:51:02 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 14:51:03 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 14:51:09 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 14:51:14 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 14:51:20 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 14:51:25 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 14:52:10 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 14:53:17 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 14:53:37 INFO mapreduce.Job: Job job_1422482982071_4204 completed successfully
15/04/08 14:53:38 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=10382210458
		FILE: Number of bytes written=20773026376
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Killed reduce tasks=2
		Launched map tasks=50
		Launched reduce tasks=42
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=3380356
		Total time spent by all reduces in occupied slots (ms)=4659288
		Total time spent by all map tasks (ms)=1690178
		Total time spent by all reduce tasks (ms)=2329644
		Total vcore-seconds taken by all map tasks=1690178
		Total vcore-seconds taken by all reduce tasks=2329644
		Total megabyte-seconds taken by all map tasks=13683681088
		Total megabyte-seconds taken by all reduce tasks=27955728000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382222218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382222218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =2000
		Failed Shuffles=0
		Merged Map outputs=2000
		GC time elapsed (ms)=84265
		CPU time spent (ms)=4635810
		Physical memory (bytes) snapshot=115925344256
		Virtual memory (bytes) snapshot=993840496640
		Total committed heap usage (bytes)=222683295744
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 14:53:38 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	4m17.960s
user	0m13.692s
sys	0m0.767s
15/04/08 14:53:40 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 30
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-30-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2747577717973083769.jar tmpDir=null
15/04/08 14:53:43 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 14:53:43 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 14:53:44 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 14:53:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 14:53:45 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 14:53:46 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4207
15/04/08 14:53:46 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4207
15/04/08 14:53:46 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4207/
15/04/08 14:53:46 INFO mapreduce.Job: Running job: job_1422482982071_4207
15/04/08 14:53:51 INFO mapreduce.Job: Job job_1422482982071_4207 running in uber mode : false
15/04/08 14:53:51 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 14:54:01 INFO mapreduce.Job:  map 10% reduce 0%
15/04/08 14:54:02 INFO mapreduce.Job:  map 22% reduce 0%
15/04/08 14:54:04 INFO mapreduce.Job:  map 27% reduce 0%
15/04/08 14:54:05 INFO mapreduce.Job:  map 35% reduce 0%
15/04/08 14:54:07 INFO mapreduce.Job:  map 40% reduce 0%
15/04/08 14:54:08 INFO mapreduce.Job:  map 49% reduce 0%
15/04/08 14:54:11 INFO mapreduce.Job:  map 53% reduce 0%
15/04/08 14:54:12 INFO mapreduce.Job:  map 63% reduce 0%
15/04/08 14:54:14 INFO mapreduce.Job:  map 64% reduce 0%
15/04/08 14:54:15 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 14:54:26 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 14:54:27 INFO mapreduce.Job:  map 82% reduce 0%
15/04/08 14:54:28 INFO mapreduce.Job:  map 85% reduce 0%
15/04/08 14:54:29 INFO mapreduce.Job:  map 94% reduce 0%
15/04/08 14:54:30 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 14:54:31 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 14:54:32 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 14:54:36 INFO mapreduce.Job:  map 100% reduce 3%
15/04/08 14:54:37 INFO mapreduce.Job:  map 100% reduce 42%
15/04/08 14:54:38 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 14:54:40 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 14:54:41 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 14:54:43 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 14:54:44 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 14:54:46 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 14:54:49 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 14:54:50 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 14:54:52 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 14:54:53 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 14:54:55 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 14:54:58 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 14:54:59 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 14:55:01 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 14:55:02 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 14:55:04 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 14:55:05 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 14:55:07 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 14:55:10 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 14:55:11 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 14:55:13 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 14:55:16 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 14:55:17 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 14:55:19 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 14:55:22 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 14:55:28 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 14:55:32 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 14:55:44 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 14:55:47 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 14:56:05 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 14:56:10 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 14:56:23 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 14:57:03 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 14:57:42 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 14:58:11 INFO mapreduce.Job: Job job_1422482982071_4207 completed successfully
15/04/08 14:58:11 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=10382210398
		FILE: Number of bytes written=20772061986
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=50
		Launched reduce tasks=31
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=3410608
		Total time spent by all reduces in occupied slots (ms)=4554700
		Total time spent by all map tasks (ms)=1705304
		Total time spent by all reduce tasks (ms)=2277350
		Total vcore-seconds taken by all map tasks=1705304
		Total vcore-seconds taken by all reduce tasks=2277350
		Total megabyte-seconds taken by all map tasks=13806141184
		Total megabyte-seconds taken by all reduce tasks=27328200000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382219218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382219218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=77113
		CPU time spent (ms)=4642570
		Physical memory (bytes) snapshot=113764724736
		Virtual memory (bytes) snapshot=860041441280
		Total committed heap usage (bytes)=201633361920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 14:58:11 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	4m33.802s
user	0m13.563s
sys	0m1.986s
15/04/08 14:58:14 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 30
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-30-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3058662736847649186.jar tmpDir=null
15/04/08 14:58:17 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 14:58:17 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 14:58:19 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 14:58:19 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 14:58:20 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 14:58:20 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4210
15/04/08 14:58:21 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4210
15/04/08 14:58:21 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4210/
15/04/08 14:58:21 INFO mapreduce.Job: Running job: job_1422482982071_4210
15/04/08 14:58:26 INFO mapreduce.Job: Job job_1422482982071_4210 running in uber mode : false
15/04/08 14:58:26 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 14:58:37 INFO mapreduce.Job:  map 20% reduce 0%
15/04/08 14:58:38 INFO mapreduce.Job:  map 21% reduce 0%
15/04/08 14:58:40 INFO mapreduce.Job:  map 34% reduce 0%
15/04/08 14:58:42 INFO mapreduce.Job:  map 35% reduce 0%
15/04/08 14:58:43 INFO mapreduce.Job:  map 47% reduce 0%
15/04/08 14:58:44 INFO mapreduce.Job:  map 48% reduce 0%
15/04/08 14:58:45 INFO mapreduce.Job:  map 49% reduce 0%
15/04/08 14:58:46 INFO mapreduce.Job:  map 61% reduce 0%
15/04/08 14:58:47 INFO mapreduce.Job:  map 62% reduce 0%
15/04/08 14:58:49 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 14:58:50 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 14:59:01 INFO mapreduce.Job:  map 75% reduce 0%
15/04/08 14:59:02 INFO mapreduce.Job:  map 82% reduce 0%
15/04/08 14:59:03 INFO mapreduce.Job:  map 93% reduce 0%
15/04/08 14:59:04 INFO mapreduce.Job:  map 96% reduce 0%
15/04/08 14:59:05 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 14:59:06 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 14:59:11 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 14:59:12 INFO mapreduce.Job:  map 100% reduce 44%
15/04/08 14:59:15 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 14:59:16 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 14:59:18 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 14:59:19 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 14:59:21 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 14:59:22 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 14:59:24 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 14:59:25 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 14:59:27 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 14:59:28 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 14:59:30 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 14:59:31 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 14:59:33 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 14:59:34 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 14:59:36 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 14:59:37 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 14:59:39 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 14:59:42 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 14:59:43 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 14:59:45 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 14:59:46 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 14:59:48 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 14:59:49 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 14:59:52 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 14:59:54 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 14:59:55 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 14:59:58 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 15:00:01 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 15:00:07 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 15:00:16 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 15:00:19 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 15:00:34 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 15:00:46 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 15:00:50 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 15:01:23 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 15:02:33 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 15:03:00 INFO mapreduce.Job: Job job_1422482982071_4210 completed successfully
15/04/08 15:03:00 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=10382210398
		FILE: Number of bytes written=20772061986
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=50
		Launched reduce tasks=31
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=3437752
		Total time spent by all reduces in occupied slots (ms)=4615464
		Total time spent by all map tasks (ms)=1718876
		Total time spent by all reduce tasks (ms)=2307732
		Total vcore-seconds taken by all map tasks=1718876
		Total vcore-seconds taken by all reduce tasks=2307732
		Total megabyte-seconds taken by all map tasks=13916020096
		Total megabyte-seconds taken by all reduce tasks=27692784000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382219218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382219218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=68791
		CPU time spent (ms)=4566710
		Physical memory (bytes) snapshot=113649733632
		Virtual memory (bytes) snapshot=860040142848
		Total committed heap usage (bytes)=201633759232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 15:03:00 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	4m48.775s
user	0m13.241s
sys	0m2.581s
15/04/08 15:03:03 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 30
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-30-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7891006036603224462.jar tmpDir=null
15/04/08 15:03:06 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:03:06 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:03:07 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 15:03:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 15:03:07 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 15:03:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4212
15/04/08 15:03:09 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4212
15/04/08 15:03:09 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4212/
15/04/08 15:03:09 INFO mapreduce.Job: Running job: job_1422482982071_4212
15/04/08 15:03:14 INFO mapreduce.Job: Job job_1422482982071_4212 running in uber mode : false
15/04/08 15:03:14 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 15:03:24 INFO mapreduce.Job:  map 1% reduce 0%
15/04/08 15:03:25 INFO mapreduce.Job:  map 13% reduce 0%
15/04/08 15:03:26 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 15:03:27 INFO mapreduce.Job:  map 20% reduce 0%
15/04/08 15:03:28 INFO mapreduce.Job:  map 26% reduce 0%
15/04/08 15:03:29 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 15:03:30 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 15:03:31 INFO mapreduce.Job:  map 38% reduce 0%
15/04/08 15:03:32 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 15:03:34 INFO mapreduce.Job:  map 51% reduce 0%
15/04/08 15:03:35 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 15:03:37 INFO mapreduce.Job:  map 61% reduce 0%
15/04/08 15:03:38 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 15:03:41 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 15:03:50 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 15:03:51 INFO mapreduce.Job:  map 74% reduce 0%
15/04/08 15:03:52 INFO mapreduce.Job:  map 77% reduce 0%
15/04/08 15:03:53 INFO mapreduce.Job:  map 84% reduce 0%
15/04/08 15:03:54 INFO mapreduce.Job:  map 89% reduce 0%
15/04/08 15:03:55 INFO mapreduce.Job:  map 95% reduce 0%
15/04/08 15:03:56 INFO mapreduce.Job:  map 98% reduce 0%
15/04/08 15:03:57 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 15:04:00 INFO mapreduce.Job:  map 100% reduce 4%
15/04/08 15:04:01 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 15:04:02 INFO mapreduce.Job:  map 100% reduce 44%
15/04/08 15:04:03 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 15:04:04 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 15:04:05 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 15:04:08 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 15:04:09 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 15:04:11 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 15:04:12 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 15:04:14 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 15:04:15 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 15:04:17 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 15:04:18 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 15:04:20 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 15:04:21 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 15:04:23 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 15:04:24 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 15:04:26 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 15:04:27 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 15:04:29 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 15:04:30 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 15:04:33 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 15:04:35 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 15:04:36 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 15:04:37 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 15:04:39 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 15:04:41 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 15:04:42 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 15:04:47 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 15:04:50 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 15:05:03 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 15:05:08 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 15:05:17 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 15:05:23 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 15:05:38 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 15:06:08 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 15:07:02 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 15:07:30 INFO mapreduce.Job: Job job_1422482982071_4212 completed successfully
15/04/08 15:07:30 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=10382210398
		FILE: Number of bytes written=20772061986
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=50
		Launched reduce tasks=31
		Data-local map tasks=30
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=3754968
		Total time spent by all reduces in occupied slots (ms)=4223936
		Total time spent by all map tasks (ms)=1877484
		Total time spent by all reduce tasks (ms)=2111968
		Total vcore-seconds taken by all map tasks=1877484
		Total vcore-seconds taken by all reduce tasks=2111968
		Total megabyte-seconds taken by all map tasks=15200110464
		Total megabyte-seconds taken by all reduce tasks=25343616000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382219218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382219218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=78680
		CPU time spent (ms)=4616410
		Physical memory (bytes) snapshot=113828352000
		Virtual memory (bytes) snapshot=860424478720
		Total committed heap usage (bytes)=201637781504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 15:07:30 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	4m29.920s
user	0m13.004s
sys	0m1.823s
15/04/08 15:07:33 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 20
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-20-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8004839136611446735.jar tmpDir=null
15/04/08 15:07:36 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:07:36 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:07:37 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 15:07:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 15:07:38 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 15:07:38 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4215
15/04/08 15:07:38 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4215
15/04/08 15:07:38 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4215/
15/04/08 15:07:38 INFO mapreduce.Job: Running job: job_1422482982071_4215
15/04/08 15:07:44 INFO mapreduce.Job: Job job_1422482982071_4215 running in uber mode : false
15/04/08 15:07:44 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 15:07:54 INFO mapreduce.Job:  map 9% reduce 0%
15/04/08 15:07:55 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 15:07:56 INFO mapreduce.Job:  map 20% reduce 0%
15/04/08 15:07:57 INFO mapreduce.Job:  map 26% reduce 0%
15/04/08 15:07:58 INFO mapreduce.Job:  map 33% reduce 0%
15/04/08 15:07:59 INFO mapreduce.Job:  map 34% reduce 0%
15/04/08 15:08:00 INFO mapreduce.Job:  map 38% reduce 0%
15/04/08 15:08:01 INFO mapreduce.Job:  map 46% reduce 0%
15/04/08 15:08:02 INFO mapreduce.Job:  map 48% reduce 0%
15/04/08 15:08:03 INFO mapreduce.Job:  map 50% reduce 0%
15/04/08 15:08:04 INFO mapreduce.Job:  map 60% reduce 0%
15/04/08 15:08:05 INFO mapreduce.Job:  map 61% reduce 0%
15/04/08 15:08:06 INFO mapreduce.Job:  map 62% reduce 0%
15/04/08 15:08:07 INFO mapreduce.Job:  map 65% reduce 0%
15/04/08 15:08:08 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 15:08:19 INFO mapreduce.Job:  map 73% reduce 0%
15/04/08 15:08:20 INFO mapreduce.Job:  map 79% reduce 0%
15/04/08 15:08:21 INFO mapreduce.Job:  map 89% reduce 0%
15/04/08 15:08:22 INFO mapreduce.Job:  map 95% reduce 0%
15/04/08 15:08:23 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 15:08:24 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 15:08:26 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 15:08:29 INFO mapreduce.Job:  map 100% reduce 22%
15/04/08 15:08:30 INFO mapreduce.Job:  map 100% reduce 38%
15/04/08 15:08:32 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 15:08:33 INFO mapreduce.Job:  map 100% reduce 46%
15/04/08 15:08:35 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 15:08:36 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 15:08:38 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 15:08:39 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 15:08:41 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 15:08:42 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 15:08:44 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 15:08:45 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 15:08:47 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 15:08:48 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 15:08:50 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 15:08:51 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 15:08:54 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 15:08:56 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 15:08:57 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 15:09:00 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 15:09:02 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 15:09:03 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 15:09:06 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 15:09:09 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 15:09:10 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 15:09:12 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 15:09:15 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 15:09:18 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 15:09:21 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 15:09:24 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 15:09:27 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 15:09:29 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 15:09:34 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 15:09:36 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 15:09:44 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 15:09:49 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 15:09:53 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 15:09:56 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 15:10:08 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 15:10:23 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 15:10:25 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 15:10:47 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 15:11:38 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 15:11:47 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 15:12:31 INFO mapreduce.Job: Job job_1422482982071_4215 completed successfully
15/04/08 15:12:31 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=10382210344
		FILE: Number of bytes written=20771097602
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=210
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=50
		Launched reduce tasks=21
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=3505164
		Total time spent by all reduces in occupied slots (ms)=4152122
		Total time spent by all map tasks (ms)=1752582
		Total time spent by all reduce tasks (ms)=2076061
		Total vcore-seconds taken by all map tasks=1752582
		Total vcore-seconds taken by all reduce tasks=2076061
		Total megabyte-seconds taken by all map tasks=14188903872
		Total megabyte-seconds taken by all reduce tasks=24912732000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382216218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382216218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1000
		Failed Shuffles=0
		Merged Map outputs=1000
		GC time elapsed (ms)=72823
		CPU time spent (ms)=4513670
		Physical memory (bytes) snapshot=111803342848
		Virtual memory (bytes) snapshot=725995892736
		Total committed heap usage (bytes)=180583194624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 15:12:31 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	5m0.655s
user	0m13.744s
sys	0m1.165s
15/04/08 15:12:33 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 20
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-20-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4513450337693738944.jar tmpDir=null
15/04/08 15:12:36 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:12:36 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:12:37 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 15:12:37 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 15:12:39 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 15:12:40 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4218
15/04/08 15:12:40 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4218
15/04/08 15:12:40 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4218/
15/04/08 15:12:40 INFO mapreduce.Job: Running job: job_1422482982071_4218
15/04/08 15:12:46 INFO mapreduce.Job: Job job_1422482982071_4218 running in uber mode : false
15/04/08 15:12:46 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 15:12:57 INFO mapreduce.Job:  map 13% reduce 0%
15/04/08 15:12:58 INFO mapreduce.Job:  map 18% reduce 0%
15/04/08 15:13:00 INFO mapreduce.Job:  map 27% reduce 0%
15/04/08 15:13:01 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 15:13:03 INFO mapreduce.Job:  map 38% reduce 0%
15/04/08 15:13:04 INFO mapreduce.Job:  map 43% reduce 0%
15/04/08 15:13:06 INFO mapreduce.Job:  map 50% reduce 0%
15/04/08 15:13:07 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 15:13:09 INFO mapreduce.Job:  map 61% reduce 0%
15/04/08 15:13:10 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 15:13:13 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 15:13:23 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 15:13:24 INFO mapreduce.Job:  map 70% reduce 0%
15/04/08 15:13:25 INFO mapreduce.Job:  map 73% reduce 0%
15/04/08 15:13:26 INFO mapreduce.Job:  map 75% reduce 0%
15/04/08 15:13:27 INFO mapreduce.Job:  map 80% reduce 0%
15/04/08 15:13:28 INFO mapreduce.Job:  map 90% reduce 0%
15/04/08 15:13:29 INFO mapreduce.Job:  map 93% reduce 0%
15/04/08 15:13:30 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 15:13:31 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 15:13:35 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 15:13:36 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 15:13:38 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 15:13:39 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 15:13:41 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 15:13:42 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 15:13:44 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 15:13:45 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 15:13:47 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 15:13:48 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 15:13:50 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 15:13:51 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 15:13:53 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 15:13:54 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 15:13:56 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 15:13:57 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 15:14:00 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 15:14:03 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 15:14:06 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 15:14:08 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 15:14:11 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 15:14:12 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 15:14:14 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 15:14:15 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 15:14:17 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 15:14:18 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 15:14:21 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 15:14:24 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 15:14:27 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 15:14:29 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 15:14:32 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 15:14:33 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 15:14:36 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 15:14:41 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 15:14:44 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 15:14:48 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 15:14:51 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 15:14:57 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 15:15:01 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 15:15:14 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 15:15:25 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 15:15:33 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 15:15:55 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 15:16:52 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 15:17:01 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 15:17:40 INFO mapreduce.Job: Job job_1422482982071_4218 completed successfully
15/04/08 15:17:40 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=10382210344
		FILE: Number of bytes written=20771097602
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=210
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=50
		Launched reduce tasks=21
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=3865540
		Total time spent by all reduces in occupied slots (ms)=4410470
		Total time spent by all map tasks (ms)=1932770
		Total time spent by all reduce tasks (ms)=2205235
		Total vcore-seconds taken by all map tasks=1932770
		Total vcore-seconds taken by all reduce tasks=2205235
		Total megabyte-seconds taken by all map tasks=15647705920
		Total megabyte-seconds taken by all reduce tasks=26462820000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382216218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382216218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1000
		Failed Shuffles=0
		Merged Map outputs=1000
		GC time elapsed (ms)=77791
		CPU time spent (ms)=4711420
		Physical memory (bytes) snapshot=111811379200
		Virtual memory (bytes) snapshot=726192529408
		Total committed heap usage (bytes)=180587020288
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 15:17:40 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	5m9.520s
user	0m19.331s
sys	0m35.618s
15/04/08 15:17:43 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 20
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-20-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6004418398342834962.jar tmpDir=null
15/04/08 15:17:46 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:17:46 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:17:47 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 15:17:47 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 15:17:47 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 15:17:47 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4222
15/04/08 15:17:48 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4222
15/04/08 15:17:48 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4222/
15/04/08 15:17:48 INFO mapreduce.Job: Running job: job_1422482982071_4222
15/04/08 15:17:52 INFO mapreduce.Job: Job job_1422482982071_4222 running in uber mode : false
15/04/08 15:17:52 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 15:18:02 INFO mapreduce.Job:  map 22% reduce 0%
15/04/08 15:18:03 INFO mapreduce.Job:  map 23% reduce 0%
15/04/08 15:18:05 INFO mapreduce.Job:  map 35% reduce 0%
15/04/08 15:18:06 INFO mapreduce.Job:  map 36% reduce 0%
15/04/08 15:18:08 INFO mapreduce.Job:  map 47% reduce 0%
15/04/08 15:18:09 INFO mapreduce.Job:  map 49% reduce 0%
15/04/08 15:18:11 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 15:18:12 INFO mapreduce.Job:  map 62% reduce 0%
15/04/08 15:18:14 INFO mapreduce.Job:  map 64% reduce 0%
15/04/08 15:18:15 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 15:18:27 INFO mapreduce.Job:  map 77% reduce 0%
15/04/08 15:18:28 INFO mapreduce.Job:  map 85% reduce 0%
15/04/08 15:18:29 INFO mapreduce.Job:  map 87% reduce 0%
15/04/08 15:18:30 INFO mapreduce.Job:  map 93% reduce 0%
15/04/08 15:18:31 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 15:18:33 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 15:18:37 INFO mapreduce.Job:  map 100% reduce 8%
15/04/08 15:18:38 INFO mapreduce.Job:  map 100% reduce 35%
15/04/08 15:18:39 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 15:18:40 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 15:18:41 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 15:18:42 INFO mapreduce.Job:  map 100% reduce 48%
15/04/08 15:18:43 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 15:18:44 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 15:18:45 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 15:18:46 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 15:18:47 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 15:18:50 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 15:18:51 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 15:18:53 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 15:18:54 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 15:18:57 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 15:18:58 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 15:19:00 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 15:19:03 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 15:19:06 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 15:19:09 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 15:19:11 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 15:19:13 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 15:19:16 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 15:19:19 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 15:19:22 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 15:19:25 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 15:19:28 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 15:19:33 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 15:19:34 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 15:19:37 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 15:19:40 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 15:19:42 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 15:19:46 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 15:19:51 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 15:19:52 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 15:19:58 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 15:20:04 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 15:20:16 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 15:20:30 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 15:20:31 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 15:20:55 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 15:21:48 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 15:21:57 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 15:22:38 INFO mapreduce.Job: Job job_1422482982071_4222 completed successfully
15/04/08 15:22:38 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=10382210344
		FILE: Number of bytes written=20771097602
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=210
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=50
		Launched reduce tasks=21
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=3463532
		Total time spent by all reduces in occupied slots (ms)=4101520
		Total time spent by all map tasks (ms)=1731766
		Total time spent by all reduce tasks (ms)=2050760
		Total vcore-seconds taken by all map tasks=1731766
		Total vcore-seconds taken by all reduce tasks=2050760
		Total megabyte-seconds taken by all map tasks=14020377536
		Total megabyte-seconds taken by all reduce tasks=24609120000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382216218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382216218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1000
		Failed Shuffles=0
		Merged Map outputs=1000
		GC time elapsed (ms)=73082
		CPU time spent (ms)=4534000
		Physical memory (bytes) snapshot=111854862336
		Virtual memory (bytes) snapshot=726610948096
		Total committed heap usage (bytes)=180580597760
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 15:22:38 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	4m57.777s
user	0m13.234s
sys	0m0.758s
15/04/08 15:22:40 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 10
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-10-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob451577493918121948.jar tmpDir=null
15/04/08 15:22:43 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:22:44 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:22:44 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 15:22:45 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 15:22:45 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 15:22:45 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4225
15/04/08 15:22:46 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4225
15/04/08 15:22:46 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4225/
15/04/08 15:22:46 INFO mapreduce.Job: Running job: job_1422482982071_4225
15/04/08 15:22:52 INFO mapreduce.Job: Job job_1422482982071_4225 running in uber mode : false
15/04/08 15:22:52 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 15:23:03 INFO mapreduce.Job:  map 11% reduce 0%
15/04/08 15:23:04 INFO mapreduce.Job:  map 20% reduce 0%
15/04/08 15:23:06 INFO mapreduce.Job:  map 26% reduce 0%
15/04/08 15:23:07 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 15:23:09 INFO mapreduce.Job:  map 38% reduce 0%
15/04/08 15:23:10 INFO mapreduce.Job:  map 45% reduce 0%
15/04/08 15:23:12 INFO mapreduce.Job:  map 51% reduce 0%
15/04/08 15:23:13 INFO mapreduce.Job:  map 58% reduce 0%
15/04/08 15:23:15 INFO mapreduce.Job:  map 61% reduce 0%
15/04/08 15:23:16 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 15:23:18 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 15:23:28 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 15:23:29 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 15:23:30 INFO mapreduce.Job:  map 71% reduce 0%
15/04/08 15:23:31 INFO mapreduce.Job:  map 77% reduce 0%
15/04/08 15:23:32 INFO mapreduce.Job:  map 81% reduce 0%
15/04/08 15:23:33 INFO mapreduce.Job:  map 89% reduce 0%
15/04/08 15:23:34 INFO mapreduce.Job:  map 95% reduce 0%
15/04/08 15:23:35 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 15:23:37 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 15:23:39 INFO mapreduce.Job:  map 100% reduce 6%
15/04/08 15:23:40 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 15:23:43 INFO mapreduce.Job:  map 100% reduce 35%
15/04/08 15:23:46 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 15:23:49 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 15:23:52 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 15:23:55 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 15:23:56 INFO mapreduce.Job:  map 100% reduce 46%
15/04/08 15:23:58 INFO mapreduce.Job:  map 100% reduce 48%
15/04/08 15:24:01 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 15:24:02 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 15:24:04 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 15:24:07 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 15:24:10 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 15:24:14 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 15:24:17 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 15:24:20 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 15:24:23 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 15:24:26 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 15:24:29 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 15:24:32 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 15:24:35 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 15:24:38 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 15:24:41 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 15:24:44 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 15:24:47 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 15:24:50 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 15:24:53 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 15:24:57 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 15:25:02 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 15:25:06 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 15:25:12 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 15:25:17 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 15:25:21 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 15:25:27 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 15:25:32 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 15:25:38 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 15:25:42 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 15:25:47 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 15:25:53 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 15:25:59 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 15:26:05 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 15:26:10 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 15:26:17 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 15:26:29 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 15:26:33 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 15:26:49 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 15:27:04 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 15:27:23 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 15:27:32 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 15:28:02 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 15:29:02 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 15:29:15 INFO mapreduce.Job: Job job_1422482982071_4225 completed successfully
15/04/08 15:29:16 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=10382210302
		FILE: Number of bytes written=20770133230
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=180
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Launched map tasks=50
		Launched reduce tasks=10
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=3884892
		Total time spent by all reduces in occupied slots (ms)=3887374
		Total time spent by all map tasks (ms)=1942446
		Total time spent by all reduce tasks (ms)=1943687
		Total vcore-seconds taken by all map tasks=1942446
		Total vcore-seconds taken by all reduce tasks=1943687
		Total megabyte-seconds taken by all map tasks=15726042816
		Total megabyte-seconds taken by all reduce tasks=23324244000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382213218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382213218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =500
		Failed Shuffles=0
		Merged Map outputs=500
		GC time elapsed (ms)=72978
		CPU time spent (ms)=4676200
		Physical memory (bytes) snapshot=110326689792
		Virtual memory (bytes) snapshot=592548872192
		Total committed heap usage (bytes)=159536128000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 15:29:16 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	6m37.504s
user	0m14.615s
sys	0m0.932s
15/04/08 15:29:18 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 10
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-10-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5587883014415984368.jar tmpDir=null
15/04/08 15:29:21 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:29:22 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:29:22 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 15:29:22 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 15:29:23 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 15:29:23 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4229
15/04/08 15:29:24 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4229
15/04/08 15:29:24 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4229/
15/04/08 15:29:24 INFO mapreduce.Job: Running job: job_1422482982071_4229
15/04/08 15:29:28 INFO mapreduce.Job: Job job_1422482982071_4229 running in uber mode : false
15/04/08 15:29:28 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 15:29:38 INFO mapreduce.Job:  map 21% reduce 0%
15/04/08 15:29:39 INFO mapreduce.Job:  map 23% reduce 0%
15/04/08 15:29:41 INFO mapreduce.Job:  map 35% reduce 0%
15/04/08 15:29:42 INFO mapreduce.Job:  map 36% reduce 0%
15/04/08 15:29:43 INFO mapreduce.Job:  map 37% reduce 0%
15/04/08 15:29:44 INFO mapreduce.Job:  map 49% reduce 0%
15/04/08 15:29:45 INFO mapreduce.Job:  map 50% reduce 0%
15/04/08 15:29:47 INFO mapreduce.Job:  map 63% reduce 0%
15/04/08 15:29:49 INFO mapreduce.Job:  map 64% reduce 0%
15/04/08 15:29:50 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 15:29:52 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 15:30:03 INFO mapreduce.Job:  map 70% reduce 0%
15/04/08 15:30:04 INFO mapreduce.Job:  map 86% reduce 0%
15/04/08 15:30:05 INFO mapreduce.Job:  map 89% reduce 0%
15/04/08 15:30:06 INFO mapreduce.Job:  map 91% reduce 0%
15/04/08 15:30:07 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 15:30:08 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 15:30:10 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 15:30:14 INFO mapreduce.Job:  map 100% reduce 10%
15/04/08 15:30:15 INFO mapreduce.Job:  map 100% reduce 29%
15/04/08 15:30:16 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 15:30:17 INFO mapreduce.Job:  map 100% reduce 34%
15/04/08 15:30:18 INFO mapreduce.Job:  map 100% reduce 35%
15/04/08 15:30:19 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 15:30:20 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 15:30:21 INFO mapreduce.Job:  map 100% reduce 38%
15/04/08 15:30:23 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 15:30:24 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 15:30:26 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 15:30:27 INFO mapreduce.Job:  map 100% reduce 44%
15/04/08 15:30:29 INFO mapreduce.Job:  map 100% reduce 46%
15/04/08 15:30:31 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 15:30:33 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 15:30:36 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 15:30:37 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 15:30:39 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 15:30:40 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 15:30:42 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 15:30:45 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 15:30:48 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 15:30:49 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 15:30:51 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 15:30:55 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 15:30:58 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 15:30:59 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 15:31:02 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 15:31:04 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 15:31:11 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 15:31:14 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 15:31:20 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 15:31:25 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 15:31:32 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 15:31:34 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 15:31:40 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 15:31:44 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 15:31:47 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 15:31:53 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 15:31:58 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 15:32:04 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 15:32:07 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 15:32:10 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 15:32:16 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 15:32:23 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 15:32:27 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 15:32:29 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 15:32:32 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 15:32:38 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 15:32:44 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 15:32:59 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 15:33:06 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 15:33:12 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 15:33:29 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 15:33:50 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 15:34:03 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 15:34:35 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 15:35:41 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 15:36:01 INFO mapreduce.Job: Job job_1422482982071_4229 completed successfully
15/04/08 15:36:01 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=10382210302
		FILE: Number of bytes written=20770133230
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=180
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Launched map tasks=50
		Launched reduce tasks=10
		Data-local map tasks=30
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=3500412
		Total time spent by all reduces in occupied slots (ms)=3845062
		Total time spent by all map tasks (ms)=1750206
		Total time spent by all reduce tasks (ms)=1922531
		Total vcore-seconds taken by all map tasks=1750206
		Total vcore-seconds taken by all reduce tasks=1922531
		Total megabyte-seconds taken by all map tasks=14169667776
		Total megabyte-seconds taken by all reduce tasks=23070372000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382213218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382213218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =500
		Failed Shuffles=0
		Merged Map outputs=500
		GC time elapsed (ms)=83307
		CPU time spent (ms)=4487370
		Physical memory (bytes) snapshot=110347448320
		Virtual memory (bytes) snapshot=593378533376
		Total committed heap usage (bytes)=159529549824
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 15:36:01 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	6m45.914s
user	0m14.599s
sys	0m0.973s
15/04/08 15:36:04 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 10
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-10-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5291279730173720993.jar tmpDir=null
15/04/08 15:36:08 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:36:08 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:36:10 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 15:36:10 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 15:36:10 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 15:36:11 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4232
15/04/08 15:36:11 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4232
15/04/08 15:36:11 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4232/
15/04/08 15:36:11 INFO mapreduce.Job: Running job: job_1422482982071_4232
15/04/08 15:36:17 INFO mapreduce.Job: Job job_1422482982071_4232 running in uber mode : false
15/04/08 15:36:17 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 15:36:29 INFO mapreduce.Job:  map 7% reduce 0%
15/04/08 15:36:30 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 15:36:32 INFO mapreduce.Job:  map 23% reduce 0%
15/04/08 15:36:33 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 15:36:35 INFO mapreduce.Job:  map 36% reduce 0%
15/04/08 15:36:36 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 15:36:38 INFO mapreduce.Job:  map 49% reduce 0%
15/04/08 15:36:39 INFO mapreduce.Job:  map 58% reduce 0%
15/04/08 15:36:41 INFO mapreduce.Job:  map 61% reduce 0%
15/04/08 15:36:42 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 15:36:56 INFO mapreduce.Job:  map 71% reduce 0%
15/04/08 15:36:57 INFO mapreduce.Job:  map 77% reduce 0%
15/04/08 15:36:58 INFO mapreduce.Job:  map 85% reduce 0%
15/04/08 15:36:59 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 15:37:00 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 15:37:01 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 15:37:06 INFO mapreduce.Job:  map 100% reduce 18%
15/04/08 15:37:07 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 15:37:09 INFO mapreduce.Job:  map 100% reduce 34%
15/04/08 15:37:10 INFO mapreduce.Job:  map 100% reduce 35%
15/04/08 15:37:12 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 15:37:13 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 15:37:16 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 15:37:19 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 15:37:21 INFO mapreduce.Job:  map 100% reduce 42%
15/04/08 15:37:22 INFO mapreduce.Job:  map 100% reduce 44%
15/04/08 15:37:25 INFO mapreduce.Job:  map 100% reduce 46%
15/04/08 15:37:28 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 15:37:31 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 15:37:34 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 15:37:37 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 15:37:40 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 15:37:43 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 15:37:46 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 15:37:49 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 15:37:52 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 15:37:58 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 15:38:01 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 15:38:04 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 15:38:07 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 15:38:10 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 15:38:13 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 15:38:19 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 15:38:25 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 15:38:32 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 15:38:35 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 15:38:41 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 15:38:47 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 15:38:50 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 15:38:56 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 15:39:00 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 15:39:05 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 15:39:11 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 15:39:17 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 15:39:20 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 15:39:27 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 15:39:32 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 15:39:35 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 15:39:42 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 15:39:50 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 15:40:00 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 15:40:11 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 15:40:14 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 15:40:37 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 15:40:51 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 15:41:00 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 15:41:30 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 15:42:30 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 15:42:44 INFO mapreduce.Job: Job job_1422482982071_4232 completed successfully
15/04/08 15:42:44 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=10382210302
		FILE: Number of bytes written=20770133230
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=180
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Launched map tasks=50
		Launched reduce tasks=10
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=3815374
		Total time spent by all reduces in occupied slots (ms)=3980166
		Total time spent by all map tasks (ms)=1907687
		Total time spent by all reduce tasks (ms)=1990083
		Total vcore-seconds taken by all map tasks=1907687
		Total vcore-seconds taken by all reduce tasks=1990083
		Total megabyte-seconds taken by all map tasks=15444633952
		Total megabyte-seconds taken by all reduce tasks=23880996000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382213218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382213218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =500
		Failed Shuffles=0
		Merged Map outputs=500
		GC time elapsed (ms)=73136
		CPU time spent (ms)=4664180
		Physical memory (bytes) snapshot=110297194496
		Virtual memory (bytes) snapshot=592954818560
		Total committed heap usage (bytes)=159536312320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 15:42:44 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	6m42.950s
user	0m13.537s
sys	0m2.799s
15/04/08 15:42:47 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 5
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-5-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob523872193489014010.jar tmpDir=null
15/04/08 15:42:49 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:42:50 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:42:50 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 15:42:51 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 15:42:51 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 15:42:51 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4235
15/04/08 15:42:52 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4235
15/04/08 15:42:52 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4235/
15/04/08 15:42:52 INFO mapreduce.Job: Running job: job_1422482982071_4235
15/04/08 15:42:58 INFO mapreduce.Job: Job job_1422482982071_4235 running in uber mode : false
15/04/08 15:42:58 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 15:43:08 INFO mapreduce.Job:  map 1% reduce 0%
15/04/08 15:43:09 INFO mapreduce.Job:  map 16% reduce 0%
15/04/08 15:43:10 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 15:43:12 INFO mapreduce.Job:  map 29% reduce 0%
15/04/08 15:43:13 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 15:43:14 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 15:43:15 INFO mapreduce.Job:  map 41% reduce 0%
15/04/08 15:43:16 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 15:43:18 INFO mapreduce.Job:  map 53% reduce 0%
15/04/08 15:43:19 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 15:43:21 INFO mapreduce.Job:  map 64% reduce 0%
15/04/08 15:43:22 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 15:43:24 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 15:43:39 INFO mapreduce.Job:  map 71% reduce 0%
15/04/08 15:43:40 INFO mapreduce.Job:  map 75% reduce 0%
15/04/08 15:43:41 INFO mapreduce.Job:  map 81% reduce 0%
15/04/08 15:43:42 INFO mapreduce.Job:  map 85% reduce 0%
15/04/08 15:43:43 INFO mapreduce.Job:  map 94% reduce 0%
15/04/08 15:43:44 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 15:43:45 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 15:43:49 INFO mapreduce.Job:  map 100% reduce 19%
15/04/08 15:44:15 INFO mapreduce.Job:  map 100% reduce 24%
15/04/08 15:44:18 INFO mapreduce.Job:  map 100% reduce 26%
15/04/08 15:44:21 INFO mapreduce.Job:  map 100% reduce 27%
15/04/08 15:44:24 INFO mapreduce.Job:  map 100% reduce 29%
15/04/08 15:44:27 INFO mapreduce.Job:  map 100% reduce 30%
15/04/08 15:44:30 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 15:44:33 INFO mapreduce.Job:  map 100% reduce 34%
15/04/08 15:44:37 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 15:44:39 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 15:44:40 INFO mapreduce.Job:  map 100% reduce 38%
15/04/08 15:44:42 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 15:44:45 INFO mapreduce.Job:  map 100% reduce 44%
15/04/08 15:44:48 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 15:45:00 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 15:45:04 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 15:45:06 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 15:45:07 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 15:45:13 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 15:45:16 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 15:45:19 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 15:45:22 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 15:45:36 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 15:45:43 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 15:45:58 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 15:46:06 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 15:46:28 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 15:46:38 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 15:46:47 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 15:47:05 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 15:47:23 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 15:47:35 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 15:47:39 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 15:47:41 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 15:47:53 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 15:48:00 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 15:48:14 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 15:48:24 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 15:48:26 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 15:48:35 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 15:48:47 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 15:48:57 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 15:49:09 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 15:49:24 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 15:49:37 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 15:49:47 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 15:50:03 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 15:50:10 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 15:50:21 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 15:50:31 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 15:50:58 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 15:51:40 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 15:52:00 INFO mapreduce.Job: Job job_1422482982071_4235 completed successfully
15/04/08 15:52:01 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=10382210296
		FILE: Number of bytes written=20769650954
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=165
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Launched map tasks=50
		Launched reduce tasks=5
		Data-local map tasks=33
		Rack-local map tasks=17
		Total time spent by all maps in occupied slots (ms)=4213048
		Total time spent by all reduces in occupied slots (ms)=4006620
		Total time spent by all map tasks (ms)=2106524
		Total time spent by all reduce tasks (ms)=2003310
		Total vcore-seconds taken by all map tasks=2106524
		Total vcore-seconds taken by all reduce tasks=2003310
		Total megabyte-seconds taken by all map tasks=17054418304
		Total megabyte-seconds taken by all reduce tasks=24039720000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382211718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382211718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =250
		Failed Shuffles=0
		Merged Map outputs=250
		GC time elapsed (ms)=69048
		CPU time spent (ms)=4930700
		Physical memory (bytes) snapshot=108438401024
		Virtual memory (bytes) snapshot=525932146688
		Total committed heap usage (bytes)=149193826304
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 15:52:01 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	9m16.133s
user	0m12.529s
sys	0m0.880s
15/04/08 15:52:04 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 5
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-5-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5311152515881406603.jar tmpDir=null
15/04/08 15:52:06 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:52:06 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 15:52:07 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 15:52:07 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 15:52:07 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 15:52:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4241
15/04/08 15:52:08 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4241
15/04/08 15:52:08 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4241/
15/04/08 15:52:08 INFO mapreduce.Job: Running job: job_1422482982071_4241
15/04/08 15:52:12 INFO mapreduce.Job: Job job_1422482982071_4241 running in uber mode : false
15/04/08 15:52:12 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 15:52:23 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 15:52:24 INFO mapreduce.Job:  map 22% reduce 0%
15/04/08 15:52:26 INFO mapreduce.Job:  map 27% reduce 0%
15/04/08 15:52:27 INFO mapreduce.Job:  map 35% reduce 0%
15/04/08 15:52:29 INFO mapreduce.Job:  map 37% reduce 0%
15/04/08 15:52:30 INFO mapreduce.Job:  map 48% reduce 0%
15/04/08 15:52:33 INFO mapreduce.Job:  map 61% reduce 0%
15/04/08 15:52:36 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 15:52:51 INFO mapreduce.Job:  map 75% reduce 0%
15/04/08 15:52:52 INFO mapreduce.Job:  map 81% reduce 0%
15/04/08 15:52:53 INFO mapreduce.Job:  map 83% reduce 0%
15/04/08 15:52:54 INFO mapreduce.Job:  map 90% reduce 0%
15/04/08 15:52:55 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 15:52:56 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 15:53:02 INFO mapreduce.Job:  map 100% reduce 19%
15/04/08 15:53:23 INFO mapreduce.Job:  map 100% reduce 21%
15/04/08 15:53:27 INFO mapreduce.Job:  map 100% reduce 27%
15/04/08 15:53:30 INFO mapreduce.Job:  map 100% reduce 34%
15/04/08 15:53:33 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 15:53:36 INFO mapreduce.Job:  map 100% reduce 38%
15/04/08 15:53:39 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 15:53:42 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 15:53:51 INFO mapreduce.Job:  map 100% reduce 46%
15/04/08 15:53:54 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 15:53:57 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 15:54:00 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 15:54:03 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 15:54:06 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 15:54:09 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 15:54:12 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 15:54:24 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 15:54:33 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 15:54:46 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 15:54:55 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 15:55:26 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 15:55:40 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 15:55:50 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 15:56:08 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 15:56:20 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 15:56:30 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 15:56:35 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 15:56:41 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 15:56:56 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 15:57:05 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 15:57:15 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 15:57:18 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 15:57:24 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 15:57:31 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 15:57:42 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 15:57:51 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 15:57:57 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 15:58:09 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 15:58:16 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 15:58:30 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 15:58:45 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 15:58:46 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 15:59:04 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 15:59:19 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 15:59:25 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 15:59:37 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 16:00:17 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 16:00:38 INFO mapreduce.Job: Job job_1422482982071_4241 completed successfully
15/04/08 16:00:38 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=10382210296
		FILE: Number of bytes written=20769650954
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=165
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Launched map tasks=50
		Launched reduce tasks=5
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=3803078
		Total time spent by all reduces in occupied slots (ms)=3947884
		Total time spent by all map tasks (ms)=1901539
		Total time spent by all reduce tasks (ms)=1973942
		Total vcore-seconds taken by all map tasks=1901539
		Total vcore-seconds taken by all reduce tasks=1973942
		Total megabyte-seconds taken by all map tasks=15394859744
		Total megabyte-seconds taken by all reduce tasks=23687304000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382211718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382211718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =250
		Failed Shuffles=0
		Merged Map outputs=250
		GC time elapsed (ms)=97787
		CPU time spent (ms)=4729570
		Physical memory (bytes) snapshot=108147056640
		Virtual memory (bytes) snapshot=525952700416
		Total committed heap usage (bytes)=149028536320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 16:00:38 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	8m37.168s
user	0m15.262s
sys	0m0.904s
15/04/08 16:00:40 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
50 5
py googlebooks-eng-all-5gram-20120701-ta mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-5-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1589765124191416962.jar tmpDir=null
15/04/08 16:00:43 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:00:43 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:00:44 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 16:00:44 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 16:00:44 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 16:00:44 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4245
15/04/08 16:00:45 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4245
15/04/08 16:00:45 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4245/
15/04/08 16:00:45 INFO mapreduce.Job: Running job: job_1422482982071_4245
15/04/08 16:00:51 INFO mapreduce.Job: Job job_1422482982071_4245 running in uber mode : false
15/04/08 16:00:51 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 16:01:02 INFO mapreduce.Job:  map 6% reduce 0%
15/04/08 16:01:03 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 16:01:05 INFO mapreduce.Job:  map 21% reduce 0%
15/04/08 16:01:06 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 16:01:08 INFO mapreduce.Job:  map 34% reduce 0%
15/04/08 16:01:09 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 16:01:11 INFO mapreduce.Job:  map 46% reduce 0%
15/04/08 16:01:12 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 16:01:14 INFO mapreduce.Job:  map 58% reduce 0%
15/04/08 16:01:15 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 16:01:18 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 16:01:31 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 16:01:32 INFO mapreduce.Job:  map 79% reduce 0%
15/04/08 16:01:33 INFO mapreduce.Job:  map 89% reduce 0%
15/04/08 16:01:34 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 16:01:36 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 16:01:41 INFO mapreduce.Job:  map 100% reduce 15%
15/04/08 16:01:42 INFO mapreduce.Job:  map 100% reduce 19%
15/04/08 16:02:25 INFO mapreduce.Job:  map 100% reduce 25%
15/04/08 16:02:28 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 16:02:31 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 16:02:34 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 16:02:37 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 16:02:40 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 16:02:52 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 16:02:55 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 16:02:58 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 16:03:04 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 16:03:07 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 16:03:10 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 16:03:19 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 16:03:31 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 16:03:43 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 16:03:49 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 16:04:10 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 16:04:25 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 16:04:44 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 16:04:47 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 16:05:00 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 16:05:18 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 16:05:23 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 16:05:27 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 16:05:39 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 16:05:45 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 16:05:57 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 16:06:03 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 16:06:12 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 16:06:15 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 16:06:24 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 16:06:36 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 16:06:48 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 16:07:00 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 16:07:09 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 16:07:21 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 16:07:37 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 16:07:47 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 16:07:53 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 16:08:13 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 16:08:17 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 16:08:35 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 16:09:14 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 16:09:36 INFO mapreduce.Job: Job job_1422482982071_4245 completed successfully
15/04/08 16:09:36 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=10382210296
		FILE: Number of bytes written=20769650954
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=165
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Launched map tasks=50
		Launched reduce tasks=5
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=3965802
		Total time spent by all reduces in occupied slots (ms)=3953042
		Total time spent by all map tasks (ms)=1982901
		Total time spent by all reduce tasks (ms)=1976521
		Total vcore-seconds taken by all map tasks=1982901
		Total vcore-seconds taken by all reduce tasks=1976521
		Total megabyte-seconds taken by all map tasks=16053566496
		Total megabyte-seconds taken by all reduce tasks=23718252000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382211718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382211718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =250
		Failed Shuffles=0
		Merged Map outputs=250
		GC time elapsed (ms)=78469
		CPU time spent (ms)=4767300
		Physical memory (bytes) snapshot=108487852032
		Virtual memory (bytes) snapshot=526123462656
		Total committed heap usage (bytes)=149011288064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 16:09:36 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-ta

real	8m58.444s
user	0m11.287s
sys	0m0.769s
50 40
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-40-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6617266475282912971.jar tmpDir=null
15/04/08 16:09:40 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:09:40 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:09:41 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 16:09:41 INFO mapreduce.JobSubmitter: number of splits:75
15/04/08 16:09:42 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4250
15/04/08 16:09:42 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4250
15/04/08 16:09:42 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4250/
15/04/08 16:09:42 INFO mapreduce.Job: Running job: job_1422482982071_4250
15/04/08 16:09:48 INFO mapreduce.Job: Job job_1422482982071_4250 running in uber mode : false
15/04/08 16:09:48 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 16:09:58 INFO mapreduce.Job:  map 1% reduce 0%
15/04/08 16:09:59 INFO mapreduce.Job:  map 17% reduce 0%
15/04/08 16:10:00 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 16:10:01 INFO mapreduce.Job:  map 20% reduce 0%
15/04/08 16:10:02 INFO mapreduce.Job:  map 29% reduce 0%
15/04/08 16:10:03 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 16:10:05 INFO mapreduce.Job:  map 42% reduce 0%
15/04/08 16:10:06 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 16:10:07 INFO mapreduce.Job:  map 45% reduce 0%
15/04/08 16:10:08 INFO mapreduce.Job:  map 55% reduce 0%
15/04/08 16:10:09 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 16:10:11 INFO mapreduce.Job:  map 65% reduce 0%
15/04/08 16:10:12 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 16:10:26 INFO mapreduce.Job:  map 72% reduce 0%
15/04/08 16:10:27 INFO mapreduce.Job:  map 81% reduce 0%
15/04/08 16:10:28 INFO mapreduce.Job:  map 88% reduce 0%
15/04/08 16:10:29 INFO mapreduce.Job:  map 96% reduce 0%
15/04/08 16:10:30 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 16:10:32 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 16:10:36 INFO mapreduce.Job:  map 100% reduce 3%
15/04/08 16:10:37 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 16:10:40 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 16:10:43 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 16:10:47 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 16:10:50 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 16:10:53 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 16:10:56 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 16:10:59 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 16:11:02 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 16:11:05 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 16:11:08 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 16:11:11 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 16:11:14 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 16:11:17 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 16:11:20 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 16:11:23 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 16:11:29 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 16:11:32 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 16:11:35 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 16:11:38 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 16:11:41 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 16:11:47 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 16:11:50 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 16:11:51 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 16:11:56 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 16:12:12 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 16:12:23 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 16:12:26 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 16:13:36 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 16:15:49 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 16:16:24 INFO mapreduce.Job: Job job_1422482982071_4250 completed successfully
15/04/08 16:16:25 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=16787700669
		FILE: Number of bytes written=33586410992
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=345
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Killed reduce tasks=2
		Launched map tasks=75
		Launched reduce tasks=42
		Data-local map tasks=55
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=5681194
		Total time spent by all reduces in occupied slots (ms)=7279758
		Total time spent by all map tasks (ms)=2840597
		Total time spent by all reduce tasks (ms)=3639879
		Total vcore-seconds taken by all map tasks=2840597
		Total vcore-seconds taken by all reduce tasks=3639879
		Total megabyte-seconds taken by all map tasks=22997473312
		Total megabyte-seconds taken by all reduce tasks=43678548000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787718423
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787718423
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =3000
		Failed Shuffles=0
		Merged Map outputs=3000
		GC time elapsed (ms)=95782
		CPU time spent (ms)=7146600
		Physical memory (bytes) snapshot=170973282304
		Virtual memory (bytes) snapshot=1223045341184
		Total committed heap usage (bytes)=291930980352
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/08 16:16:25 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	6m48.340s
user	0m10.742s
sys	0m0.606s
15/04/08 16:16:27 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 40
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-40-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5909977993967665583.jar tmpDir=null
15/04/08 16:16:30 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:16:30 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:16:31 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 16:16:31 INFO mapreduce.JobSubmitter: number of splits:75
15/04/08 16:16:31 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4254
15/04/08 16:16:32 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4254
15/04/08 16:16:32 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4254/
15/04/08 16:16:32 INFO mapreduce.Job: Running job: job_1422482982071_4254
15/04/08 16:17:51 INFO mapreduce.Job: Job job_1422482982071_4254 running in uber mode : false
15/04/08 16:17:51 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 16:18:46 INFO mapreduce.Job:  map 2% reduce 0%
15/04/08 16:18:47 INFO mapreduce.Job:  map 6% reduce 0%
15/04/08 16:18:48 INFO mapreduce.Job:  map 8% reduce 0%
15/04/08 16:18:49 INFO mapreduce.Job:  map 12% reduce 0%
15/04/08 16:18:50 INFO mapreduce.Job:  map 17% reduce 0%
15/04/08 16:18:51 INFO mapreduce.Job:  map 21% reduce 0%
15/04/08 16:18:52 INFO mapreduce.Job:  map 27% reduce 0%
15/04/08 16:18:53 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 16:18:54 INFO mapreduce.Job:  map 35% reduce 0%
15/04/08 16:18:55 INFO mapreduce.Job:  map 40% reduce 0%
15/04/08 16:18:56 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 16:18:57 INFO mapreduce.Job:  map 47% reduce 0%
15/04/08 16:18:58 INFO mapreduce.Job:  map 52% reduce 0%
15/04/08 16:18:59 INFO mapreduce.Job:  map 55% reduce 0%
15/04/08 16:19:00 INFO mapreduce.Job:  map 58% reduce 0%
15/04/08 16:19:01 INFO mapreduce.Job:  map 62% reduce 0%
15/04/08 16:19:02 INFO mapreduce.Job:  map 64% reduce 0%
15/04/08 16:19:03 INFO mapreduce.Job:  map 65% reduce 0%
15/04/08 16:19:04 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 16:19:05 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 16:19:15 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 16:19:16 INFO mapreduce.Job:  map 71% reduce 0%
15/04/08 16:19:17 INFO mapreduce.Job:  map 72% reduce 0%
15/04/08 16:19:18 INFO mapreduce.Job:  map 75% reduce 0%
15/04/08 16:19:19 INFO mapreduce.Job:  map 78% reduce 0%
15/04/08 16:19:20 INFO mapreduce.Job:  map 80% reduce 0%
15/04/08 16:19:21 INFO mapreduce.Job:  map 85% reduce 0%
15/04/08 16:19:22 INFO mapreduce.Job:  map 90% reduce 0%
15/04/08 16:19:23 INFO mapreduce.Job:  map 94% reduce 0%
15/04/08 16:19:24 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 16:19:25 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 16:19:26 INFO mapreduce.Job:  map 100% reduce 12%
15/04/08 16:19:27 INFO mapreduce.Job:  map 100% reduce 18%
15/04/08 16:19:28 INFO mapreduce.Job:  map 100% reduce 24%
15/04/08 16:19:29 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 16:19:30 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 16:19:31 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 16:19:32 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 16:19:33 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 16:19:34 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 16:19:35 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 16:19:36 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 16:19:37 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 16:19:38 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 16:19:39 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 16:19:41 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 16:19:42 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 16:19:44 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 16:19:45 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 16:19:46 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 16:19:48 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 16:19:49 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 16:19:51 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 16:19:52 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 16:19:54 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 16:19:55 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 16:19:57 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 16:19:58 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 16:20:00 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 16:20:01 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 16:20:03 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 16:20:04 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 16:20:06 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 16:20:07 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 16:20:09 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 16:20:11 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 16:20:13 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 16:20:16 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 16:20:19 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 16:20:24 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 16:20:29 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 16:20:32 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 16:20:37 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 16:20:39 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 16:20:40 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 16:20:49 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 16:21:01 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 16:21:11 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 16:21:13 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 16:22:22 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 16:24:21 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 16:24:56 INFO mapreduce.Job: Job job_1422482982071_4254 completed successfully
15/04/08 16:24:56 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=16787700669
		FILE: Number of bytes written=33586410992
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=345
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Killed reduce tasks=2
		Launched map tasks=75
		Launched reduce tasks=42
		Data-local map tasks=58
		Rack-local map tasks=17
		Total time spent by all maps in occupied slots (ms)=6035476
		Total time spent by all reduces in occupied slots (ms)=7337964
		Total time spent by all map tasks (ms)=3017738
		Total time spent by all reduce tasks (ms)=3668982
		Total vcore-seconds taken by all map tasks=3017738
		Total vcore-seconds taken by all reduce tasks=3668982
		Total megabyte-seconds taken by all map tasks=24431606848
		Total megabyte-seconds taken by all reduce tasks=44027784000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787718423
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787718423
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =3000
		Failed Shuffles=0
		Merged Map outputs=3000
		GC time elapsed (ms)=90404
		CPU time spent (ms)=7363210
		Physical memory (bytes) snapshot=170986622976
		Virtual memory (bytes) snapshot=1219867770880
		Total committed heap usage (bytes)=291922378752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/08 16:24:56 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	8m31.707s
user	0m13.979s
sys	0m0.871s
15/04/08 16:24:59 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 40
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-40-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5859754090335860126.jar tmpDir=null
15/04/08 16:25:02 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:25:02 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:25:03 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 16:25:06 INFO mapreduce.JobSubmitter: number of splits:75
15/04/08 16:25:06 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4257
15/04/08 16:25:06 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4257
15/04/08 16:25:06 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4257/
15/04/08 16:25:06 INFO mapreduce.Job: Running job: job_1422482982071_4257
15/04/08 16:25:15 INFO mapreduce.Job: Job job_1422482982071_4257 running in uber mode : false
15/04/08 16:25:15 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 16:25:25 INFO mapreduce.Job:  map 1% reduce 0%
15/04/08 16:25:26 INFO mapreduce.Job:  map 3% reduce 0%
15/04/08 16:25:27 INFO mapreduce.Job:  map 6% reduce 0%
15/04/08 16:25:28 INFO mapreduce.Job:  map 11% reduce 0%
15/04/08 16:25:29 INFO mapreduce.Job:  map 15% reduce 0%
15/04/08 16:25:30 INFO mapreduce.Job:  map 23% reduce 0%
15/04/08 16:25:31 INFO mapreduce.Job:  map 27% reduce 0%
15/04/08 16:25:32 INFO mapreduce.Job:  map 30% reduce 0%
15/04/08 16:25:33 INFO mapreduce.Job:  map 35% reduce 0%
15/04/08 16:25:34 INFO mapreduce.Job:  map 39% reduce 0%
15/04/08 16:25:35 INFO mapreduce.Job:  map 42% reduce 0%
15/04/08 16:25:36 INFO mapreduce.Job:  map 47% reduce 0%
15/04/08 16:25:37 INFO mapreduce.Job:  map 51% reduce 0%
15/04/08 16:25:38 INFO mapreduce.Job:  map 54% reduce 0%
15/04/08 16:25:39 INFO mapreduce.Job:  map 59% reduce 0%
15/04/08 16:25:40 INFO mapreduce.Job:  map 62% reduce 0%
15/04/08 16:25:41 INFO mapreduce.Job:  map 64% reduce 0%
15/04/08 16:25:42 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 16:25:43 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 16:25:55 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 16:25:56 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 16:25:57 INFO mapreduce.Job:  map 74% reduce 0%
15/04/08 16:25:58 INFO mapreduce.Job:  map 82% reduce 0%
15/04/08 16:25:59 INFO mapreduce.Job:  map 88% reduce 0%
15/04/08 16:26:00 INFO mapreduce.Job:  map 92% reduce 0%
15/04/08 16:26:01 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 16:26:02 INFO mapreduce.Job:  map 98% reduce 0%
15/04/08 16:26:03 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 16:26:05 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 16:26:06 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 16:26:07 INFO mapreduce.Job:  map 100% reduce 34%
15/04/08 16:26:09 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 16:26:10 INFO mapreduce.Job:  map 100% reduce 44%
15/04/08 16:26:12 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 16:26:13 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 16:26:15 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 16:26:16 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 16:26:18 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 16:26:19 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 16:26:21 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 16:26:24 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 16:26:26 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 16:26:27 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 16:26:29 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 16:26:30 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 16:26:33 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 16:26:36 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 16:26:37 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 16:26:39 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 16:26:41 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 16:26:42 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 16:26:43 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 16:26:45 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 16:26:47 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 16:26:49 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 16:26:51 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 16:26:52 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 16:26:57 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 16:27:01 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 16:27:04 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 16:27:09 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 16:27:13 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 16:27:15 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 16:27:19 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 16:27:25 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 16:27:37 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 16:27:52 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 16:27:56 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 16:28:56 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 16:30:59 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 16:31:32 INFO mapreduce.Job: Job job_1422482982071_4257 completed successfully
15/04/08 16:31:32 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=16787700669
		FILE: Number of bytes written=33586410992
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=345
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Killed reduce tasks=2
		Launched map tasks=75
		Launched reduce tasks=42
		Data-local map tasks=48
		Rack-local map tasks=27
		Total time spent by all maps in occupied slots (ms)=5877182
		Total time spent by all reduces in occupied slots (ms)=7363354
		Total time spent by all map tasks (ms)=2938591
		Total time spent by all reduce tasks (ms)=3681677
		Total vcore-seconds taken by all map tasks=2938591
		Total vcore-seconds taken by all reduce tasks=3681677
		Total megabyte-seconds taken by all map tasks=23790832736
		Total megabyte-seconds taken by all reduce tasks=44180124000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787718423
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787718423
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =3000
		Failed Shuffles=0
		Merged Map outputs=3000
		GC time elapsed (ms)=116617
		CPU time spent (ms)=7312880
		Physical memory (bytes) snapshot=170827476992
		Virtual memory (bytes) snapshot=1221246545920
		Total committed heap usage (bytes)=291923746816
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/08 16:31:32 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	6m35.564s
user	0m20.133s
sys	1m0.117s
15/04/08 16:31:34 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 30
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-30-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6235451709127165649.jar tmpDir=null
15/04/08 16:31:37 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:31:37 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:31:38 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 16:31:38 INFO mapreduce.JobSubmitter: number of splits:75
15/04/08 16:31:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4261
15/04/08 16:31:39 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4261
15/04/08 16:31:39 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4261/
15/04/08 16:31:39 INFO mapreduce.Job: Running job: job_1422482982071_4261
15/04/08 16:31:44 INFO mapreduce.Job: Job job_1422482982071_4261 running in uber mode : false
15/04/08 16:31:44 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 16:31:54 INFO mapreduce.Job:  map 20% reduce 0%
15/04/08 16:31:57 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 16:31:58 INFO mapreduce.Job:  map 33% reduce 0%
15/04/08 16:32:00 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 16:32:01 INFO mapreduce.Job:  map 45% reduce 0%
15/04/08 16:32:03 INFO mapreduce.Job:  map 55% reduce 0%
15/04/08 16:32:04 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 16:32:06 INFO mapreduce.Job:  map 64% reduce 0%
15/04/08 16:32:07 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 16:32:23 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 16:32:24 INFO mapreduce.Job:  map 74% reduce 0%
15/04/08 16:32:25 INFO mapreduce.Job:  map 82% reduce 0%
15/04/08 16:32:26 INFO mapreduce.Job:  map 86% reduce 0%
15/04/08 16:32:27 INFO mapreduce.Job:  map 90% reduce 0%
15/04/08 16:32:28 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 16:32:29 INFO mapreduce.Job:  map 98% reduce 0%
15/04/08 16:32:30 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 16:32:34 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 16:32:37 INFO mapreduce.Job:  map 100% reduce 46%
15/04/08 16:32:40 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 16:32:43 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 16:32:46 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 16:32:49 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 16:32:52 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 16:32:55 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 16:32:58 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 16:33:01 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 16:33:04 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 16:33:07 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 16:33:08 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 16:33:10 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 16:33:11 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 16:33:13 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 16:33:16 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 16:33:17 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 16:33:20 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 16:33:23 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 16:33:26 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 16:33:29 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 16:33:32 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 16:33:35 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 16:33:37 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 16:33:38 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 16:33:44 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 16:33:47 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 16:33:50 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 16:33:59 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 16:34:14 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 16:34:32 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 16:34:56 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 16:35:15 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 16:36:57 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 16:37:51 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 16:38:33 INFO mapreduce.Job: Job job_1422482982071_4261 completed successfully
15/04/08 16:38:33 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=16787700615
		FILE: Number of bytes written=33585439108
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=315
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=75
		Launched reduce tasks=31
		Data-local map tasks=48
		Rack-local map tasks=27
		Total time spent by all maps in occupied slots (ms)=5906960
		Total time spent by all reduces in occupied slots (ms)=6921864
		Total time spent by all map tasks (ms)=2953480
		Total time spent by all reduce tasks (ms)=3460932
		Total vcore-seconds taken by all map tasks=2953480
		Total vcore-seconds taken by all reduce tasks=3460932
		Total megabyte-seconds taken by all map tasks=23911374080
		Total megabyte-seconds taken by all reduce tasks=41531184000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787713923
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787713923
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =2250
		Failed Shuffles=0
		Merged Map outputs=2250
		GC time elapsed (ms)=88136
		CPU time spent (ms)=7193810
		Physical memory (bytes) snapshot=168921088000
		Virtual memory (bytes) snapshot=1091189252096
		Total committed heap usage (bytes)=270870867968
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/08 16:38:33 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	7m0.922s
user	0m12.617s
sys	0m0.782s
15/04/08 16:38:35 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 30
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-30-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3735887161133831635.jar tmpDir=null
15/04/08 16:38:38 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:38:38 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:38:39 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 16:38:39 INFO mapreduce.JobSubmitter: number of splits:75
15/04/08 16:38:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4265
15/04/08 16:38:39 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4265
15/04/08 16:38:40 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4265/
15/04/08 16:38:40 INFO mapreduce.Job: Running job: job_1422482982071_4265
15/04/08 16:38:45 INFO mapreduce.Job: Job job_1422482982071_4265 running in uber mode : false
15/04/08 16:38:45 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 16:38:55 INFO mapreduce.Job:  map 16% reduce 0%
15/04/08 16:38:56 INFO mapreduce.Job:  map 20% reduce 0%
15/04/08 16:38:57 INFO mapreduce.Job:  map 21% reduce 0%
15/04/08 16:38:58 INFO mapreduce.Job:  map 30% reduce 0%
15/04/08 16:38:59 INFO mapreduce.Job:  map 33% reduce 0%
15/04/08 16:39:01 INFO mapreduce.Job:  map 41% reduce 0%
15/04/08 16:39:02 INFO mapreduce.Job:  map 46% reduce 0%
15/04/08 16:39:04 INFO mapreduce.Job:  map 53% reduce 0%
15/04/08 16:39:05 INFO mapreduce.Job:  map 58% reduce 0%
15/04/08 16:39:07 INFO mapreduce.Job:  map 63% reduce 0%
15/04/08 16:39:08 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 16:39:21 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 16:39:22 INFO mapreduce.Job:  map 70% reduce 0%
15/04/08 16:39:23 INFO mapreduce.Job:  map 74% reduce 0%
15/04/08 16:39:24 INFO mapreduce.Job:  map 82% reduce 0%
15/04/08 16:39:25 INFO mapreduce.Job:  map 87% reduce 0%
15/04/08 16:39:26 INFO mapreduce.Job:  map 88% reduce 0%
15/04/08 16:39:27 INFO mapreduce.Job:  map 92% reduce 0%
15/04/08 16:39:28 INFO mapreduce.Job:  map 96% reduce 0%
15/04/08 16:39:29 INFO mapreduce.Job:  map 98% reduce 0%
15/04/08 16:39:30 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 16:39:31 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 16:39:32 INFO mapreduce.Job:  map 100% reduce 32%
15/04/08 16:39:35 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 16:39:38 INFO mapreduce.Job:  map 100% reduce 46%
15/04/08 16:39:41 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 16:39:44 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 16:39:47 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 16:39:50 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 16:39:53 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 16:39:56 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 16:39:59 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 16:40:02 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 16:40:05 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 16:40:08 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 16:40:12 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 16:40:15 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 16:40:18 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 16:40:21 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 16:40:24 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 16:40:25 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 16:40:27 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 16:40:30 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 16:40:31 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 16:40:34 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 16:40:37 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 16:40:40 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 16:40:43 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 16:40:49 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 16:40:55 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 16:41:04 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 16:41:19 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 16:41:31 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 16:41:49 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 16:42:13 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 16:43:32 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 16:44:24 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 16:45:07 INFO mapreduce.Job: Job job_1422482982071_4265 completed successfully
15/04/08 16:45:08 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=16787700615
		FILE: Number of bytes written=33585439108
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=315
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=75
		Launched reduce tasks=31
		Data-local map tasks=49
		Rack-local map tasks=26
		Total time spent by all maps in occupied slots (ms)=5807750
		Total time spent by all reduces in occupied slots (ms)=6820610
		Total time spent by all map tasks (ms)=2903875
		Total time spent by all reduce tasks (ms)=3410305
		Total vcore-seconds taken by all map tasks=2903875
		Total vcore-seconds taken by all reduce tasks=3410305
		Total megabyte-seconds taken by all map tasks=23509772000
		Total megabyte-seconds taken by all reduce tasks=40923660000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787713923
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787713923
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =2250
		Failed Shuffles=0
		Merged Map outputs=2250
		GC time elapsed (ms)=96990
		CPU time spent (ms)=7145460
		Physical memory (bytes) snapshot=168954761216
		Virtual memory (bytes) snapshot=1090210951168
		Total committed heap usage (bytes)=270873595904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/08 16:45:08 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	6m34.726s
user	0m13.074s
sys	0m0.846s
15/04/08 16:45:10 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 30
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-30-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1609106959905857841.jar tmpDir=null
15/04/08 16:45:12 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:45:12 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:45:14 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 16:45:15 INFO mapreduce.JobSubmitter: number of splits:75
15/04/08 16:45:15 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4268
15/04/08 16:45:15 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4268
15/04/08 16:45:16 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4268/
15/04/08 16:45:16 INFO mapreduce.Job: Running job: job_1422482982071_4268
15/04/08 16:45:21 INFO mapreduce.Job: Job job_1422482982071_4268 running in uber mode : false
15/04/08 16:45:21 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 16:45:31 INFO mapreduce.Job:  map 21% reduce 0%
15/04/08 16:45:34 INFO mapreduce.Job:  map 33% reduce 0%
15/04/08 16:45:37 INFO mapreduce.Job:  map 46% reduce 0%
15/04/08 16:45:40 INFO mapreduce.Job:  map 58% reduce 0%
15/04/08 16:45:43 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 16:45:57 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 16:45:58 INFO mapreduce.Job:  map 71% reduce 0%
15/04/08 16:45:59 INFO mapreduce.Job:  map 78% reduce 0%
15/04/08 16:46:00 INFO mapreduce.Job:  map 84% reduce 0%
15/04/08 16:46:02 INFO mapreduce.Job:  map 87% reduce 0%
15/04/08 16:46:03 INFO mapreduce.Job:  map 94% reduce 0%
15/04/08 16:46:04 INFO mapreduce.Job:  map 98% reduce 0%
15/04/08 16:46:05 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 16:46:08 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 16:46:11 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 16:46:14 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 16:46:17 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 16:46:20 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 16:46:23 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 16:46:26 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 16:46:27 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 16:46:29 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 16:46:32 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 16:46:35 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 16:46:36 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 16:46:38 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 16:46:41 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 16:46:44 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 16:46:45 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 16:46:47 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 16:46:50 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 16:46:51 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 16:46:54 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 16:46:57 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 16:47:00 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 16:47:04 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 16:47:07 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 16:47:10 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 16:47:13 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 16:47:16 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 16:47:19 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 16:47:23 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 16:47:28 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 16:47:34 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 16:47:49 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 16:48:07 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 16:48:31 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 16:48:53 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 16:50:24 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 16:51:21 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 16:52:02 INFO mapreduce.Job: Job job_1422482982071_4268 completed successfully
15/04/08 16:52:02 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=16787700615
		FILE: Number of bytes written=33585439108
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=315
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=75
		Launched reduce tasks=31
		Data-local map tasks=51
		Rack-local map tasks=24
		Total time spent by all maps in occupied slots (ms)=5784206
		Total time spent by all reduces in occupied slots (ms)=7022646
		Total time spent by all map tasks (ms)=2892103
		Total time spent by all reduce tasks (ms)=3511323
		Total vcore-seconds taken by all map tasks=2892103
		Total vcore-seconds taken by all reduce tasks=3511323
		Total megabyte-seconds taken by all map tasks=23414465888
		Total megabyte-seconds taken by all reduce tasks=42135876000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787713923
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787713923
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =2250
		Failed Shuffles=0
		Merged Map outputs=2250
		GC time elapsed (ms)=103103
		CPU time spent (ms)=7174970
		Physical memory (bytes) snapshot=169221070848
		Virtual memory (bytes) snapshot=1090400034816
		Total committed heap usage (bytes)=270869790720
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/08 16:52:02 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	6m54.836s
user	0m12.892s
sys	0m1.881s
15/04/08 16:52:05 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 20
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-20-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5233162121050729808.jar tmpDir=null
15/04/08 16:52:08 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:52:08 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:52:10 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 16:52:10 INFO mapreduce.JobSubmitter: number of splits:75
15/04/08 16:52:10 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4271
15/04/08 16:52:11 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4271
15/04/08 16:52:11 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4271/
15/04/08 16:52:11 INFO mapreduce.Job: Running job: job_1422482982071_4271
15/04/08 16:52:15 INFO mapreduce.Job: Job job_1422482982071_4271 running in uber mode : false
15/04/08 16:52:15 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 16:52:25 INFO mapreduce.Job:  map 14% reduce 0%
15/04/08 16:52:26 INFO mapreduce.Job:  map 21% reduce 0%
15/04/08 16:52:28 INFO mapreduce.Job:  map 29% reduce 0%
15/04/08 16:52:29 INFO mapreduce.Job:  map 33% reduce 0%
15/04/08 16:52:31 INFO mapreduce.Job:  map 41% reduce 0%
15/04/08 16:52:32 INFO mapreduce.Job:  map 46% reduce 0%
15/04/08 16:52:34 INFO mapreduce.Job:  map 52% reduce 0%
15/04/08 16:52:35 INFO mapreduce.Job:  map 58% reduce 0%
15/04/08 16:52:37 INFO mapreduce.Job:  map 61% reduce 0%
15/04/08 16:52:38 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 16:52:52 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 16:52:53 INFO mapreduce.Job:  map 75% reduce 0%
15/04/08 16:52:54 INFO mapreduce.Job:  map 82% reduce 0%
15/04/08 16:52:55 INFO mapreduce.Job:  map 88% reduce 0%
15/04/08 16:52:56 INFO mapreduce.Job:  map 95% reduce 0%
15/04/08 16:52:57 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 16:52:58 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 16:53:03 INFO mapreduce.Job:  map 100% reduce 10%
15/04/08 16:53:04 INFO mapreduce.Job:  map 100% reduce 35%
15/04/08 16:53:06 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 16:53:07 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 16:53:09 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 16:53:10 INFO mapreduce.Job:  map 100% reduce 44%
15/04/08 16:53:12 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 16:53:13 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 16:53:15 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 16:53:16 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 16:53:18 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 16:53:19 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 16:53:22 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 16:53:24 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 16:53:25 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 16:53:27 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 16:53:28 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 16:53:30 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 16:53:31 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 16:53:34 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 16:53:36 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 16:53:39 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 16:53:42 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 16:53:46 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 16:53:50 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 16:53:53 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 16:53:56 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 16:53:57 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 16:54:00 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 16:54:03 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 16:54:07 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 16:54:09 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 16:54:11 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 16:54:14 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 16:54:17 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 16:54:20 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 16:54:24 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 16:54:27 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 16:54:32 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 16:54:36 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 16:54:41 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 16:54:46 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 16:54:54 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 16:54:57 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 16:55:08 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 16:55:14 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 16:55:20 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 16:55:33 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 16:55:54 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 16:56:08 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 16:56:14 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 16:58:00 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 16:58:24 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 16:59:22 INFO mapreduce.Job: Job job_1422482982071_4271 completed successfully
15/04/08 16:59:22 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=16787700573
		FILE: Number of bytes written=33584467236
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=285
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=75
		Launched reduce tasks=21
		Data-local map tasks=49
		Rack-local map tasks=26
		Total time spent by all maps in occupied slots (ms)=5606302
		Total time spent by all reduces in occupied slots (ms)=6228390
		Total time spent by all map tasks (ms)=2803151
		Total time spent by all reduce tasks (ms)=3114195
		Total vcore-seconds taken by all map tasks=2803151
		Total vcore-seconds taken by all reduce tasks=3114195
		Total megabyte-seconds taken by all map tasks=22694310496
		Total megabyte-seconds taken by all reduce tasks=37370340000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787709423
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787709423
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=96046
		CPU time spent (ms)=6989350
		Physical memory (bytes) snapshot=167482839040
		Virtual memory (bytes) snapshot=955940372480
		Total committed heap usage (bytes)=249819758592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/08 16:59:22 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	7m19.297s
user	0m14.530s
sys	0m1.484s
15/04/08 16:59:24 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 20
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-20-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2766764585771299211.jar tmpDir=null
15/04/08 16:59:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:59:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 16:59:29 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 16:59:30 INFO mapreduce.JobSubmitter: number of splits:75
15/04/08 16:59:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4274
15/04/08 16:59:30 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4274
15/04/08 16:59:30 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4274/
15/04/08 16:59:30 INFO mapreduce.Job: Running job: job_1422482982071_4274
15/04/08 16:59:35 INFO mapreduce.Job: Job job_1422482982071_4274 running in uber mode : false
15/04/08 16:59:35 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 16:59:45 INFO mapreduce.Job:  map 15% reduce 0%
15/04/08 16:59:46 INFO mapreduce.Job:  map 21% reduce 0%
15/04/08 16:59:48 INFO mapreduce.Job:  map 30% reduce 0%
15/04/08 16:59:49 INFO mapreduce.Job:  map 34% reduce 0%
15/04/08 16:59:51 INFO mapreduce.Job:  map 42% reduce 0%
15/04/08 16:59:52 INFO mapreduce.Job:  map 46% reduce 0%
15/04/08 16:59:54 INFO mapreduce.Job:  map 55% reduce 0%
15/04/08 16:59:56 INFO mapreduce.Job:  map 59% reduce 0%
15/04/08 16:59:58 INFO mapreduce.Job:  map 64% reduce 0%
15/04/08 16:59:59 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 17:00:12 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 17:00:13 INFO mapreduce.Job:  map 76% reduce 0%
15/04/08 17:00:14 INFO mapreduce.Job:  map 83% reduce 0%
15/04/08 17:00:15 INFO mapreduce.Job:  map 89% reduce 0%
15/04/08 17:00:16 INFO mapreduce.Job:  map 96% reduce 0%
15/04/08 17:00:17 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 17:00:18 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 17:00:22 INFO mapreduce.Job:  map 100% reduce 4%
15/04/08 17:00:23 INFO mapreduce.Job:  map 100% reduce 27%
15/04/08 17:00:24 INFO mapreduce.Job:  map 100% reduce 35%
15/04/08 17:00:25 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 17:00:26 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 17:00:27 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 17:00:29 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 17:00:30 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 17:00:32 INFO mapreduce.Job:  map 100% reduce 48%
15/04/08 17:00:33 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 17:00:35 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 17:00:36 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 17:00:38 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 17:00:39 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 17:00:41 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 17:00:44 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 17:00:47 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 17:00:48 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 17:00:50 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 17:00:51 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 17:00:53 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 17:00:54 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 17:00:56 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 17:00:57 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 17:01:01 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 17:01:04 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 17:01:08 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 17:01:11 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 17:01:13 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 17:01:16 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 17:01:19 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 17:01:21 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 17:01:25 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 17:01:27 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 17:01:31 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 17:01:32 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 17:01:36 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 17:01:40 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 17:01:44 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 17:01:46 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 17:01:52 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 17:01:57 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 17:02:06 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 17:02:10 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 17:02:17 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 17:02:23 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 17:02:34 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 17:02:39 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 17:02:50 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 17:03:01 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 17:03:17 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 17:03:39 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 17:03:53 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 17:05:17 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 17:05:41 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 17:06:40 INFO mapreduce.Job: Job job_1422482982071_4274 completed successfully
15/04/08 17:06:40 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=16787700573
		FILE: Number of bytes written=33584467236
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=285
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=75
		Launched reduce tasks=21
		Data-local map tasks=51
		Rack-local map tasks=24
		Total time spent by all maps in occupied slots (ms)=5521028
		Total time spent by all reduces in occupied slots (ms)=6461518
		Total time spent by all map tasks (ms)=2760514
		Total time spent by all reduce tasks (ms)=3230759
		Total vcore-seconds taken by all map tasks=2760514
		Total vcore-seconds taken by all reduce tasks=3230759
		Total megabyte-seconds taken by all map tasks=22349121344
		Total megabyte-seconds taken by all reduce tasks=38769108000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787709423
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787709423
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=131626
		CPU time spent (ms)=7157670
		Physical memory (bytes) snapshot=167559782400
		Virtual memory (bytes) snapshot=955762675712
		Total committed heap usage (bytes)=249819033600
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/08 17:06:40 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	7m18.754s
user	0m28.736s
sys	0m6.199s
15/04/08 17:06:43 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 20
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-20-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3811706392522148056.jar tmpDir=null
15/04/08 17:06:47 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 17:06:47 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 17:06:48 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 17:06:48 INFO mapreduce.JobSubmitter: number of splits:75
15/04/08 17:06:48 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4275
15/04/08 17:06:49 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4275
15/04/08 17:06:49 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4275/
15/04/08 17:06:49 INFO mapreduce.Job: Running job: job_1422482982071_4275
15/04/08 17:06:55 INFO mapreduce.Job: Job job_1422482982071_4275 running in uber mode : false
15/04/08 17:06:55 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 17:07:06 INFO mapreduce.Job:  map 13% reduce 0%
15/04/08 17:07:07 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 17:07:09 INFO mapreduce.Job:  map 27% reduce 0%
15/04/08 17:07:10 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 17:07:12 INFO mapreduce.Job:  map 39% reduce 0%
15/04/08 17:07:13 INFO mapreduce.Job:  map 45% reduce 0%
15/04/08 17:07:15 INFO mapreduce.Job:  map 52% reduce 0%
15/04/08 17:07:16 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 17:07:18 INFO mapreduce.Job:  map 62% reduce 0%
15/04/08 17:07:19 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 17:07:22 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 17:07:33 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 17:07:34 INFO mapreduce.Job:  map 75% reduce 0%
15/04/08 17:07:35 INFO mapreduce.Job:  map 82% reduce 0%
15/04/08 17:07:36 INFO mapreduce.Job:  map 91% reduce 0%
15/04/08 17:07:37 INFO mapreduce.Job:  map 96% reduce 0%
15/04/08 17:07:38 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 17:07:39 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 17:07:43 INFO mapreduce.Job:  map 100% reduce 2%
15/04/08 17:07:44 INFO mapreduce.Job:  map 100% reduce 27%
15/04/08 17:07:45 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 17:07:46 INFO mapreduce.Job:  map 100% reduce 34%
15/04/08 17:07:47 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 17:07:48 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 17:07:50 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 17:07:53 INFO mapreduce.Job:  map 100% reduce 46%
15/04/08 17:07:54 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 17:07:56 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 17:07:57 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 17:07:59 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 17:08:00 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 17:08:02 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 17:08:03 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 17:08:06 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 17:08:08 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 17:08:09 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 17:08:11 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 17:08:12 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 17:08:15 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 17:08:20 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 17:08:23 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 17:08:26 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 17:08:29 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 17:08:32 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 17:08:35 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 17:08:38 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 17:08:42 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 17:08:45 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 17:08:48 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 17:08:50 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 17:08:53 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 17:08:56 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 17:08:59 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 17:09:03 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 17:09:08 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 17:09:13 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 17:09:17 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 17:09:21 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 17:09:26 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 17:09:32 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 17:09:41 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 17:09:59 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 17:10:04 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 17:10:05 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 17:10:20 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 17:10:45 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 17:10:56 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 17:11:12 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 17:12:35 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 17:13:00 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 17:14:01 INFO mapreduce.Job: Job job_1422482982071_4275 completed successfully
15/04/08 17:14:01 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=16787700573
		FILE: Number of bytes written=33584467236
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=285
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=75
		Launched reduce tasks=21
		Data-local map tasks=50
		Rack-local map tasks=25
		Total time spent by all maps in occupied slots (ms)=5650240
		Total time spent by all reduces in occupied slots (ms)=6393614
		Total time spent by all map tasks (ms)=2825120
		Total time spent by all reduce tasks (ms)=3196807
		Total vcore-seconds taken by all map tasks=2825120
		Total vcore-seconds taken by all reduce tasks=3196807
		Total megabyte-seconds taken by all map tasks=22872171520
		Total megabyte-seconds taken by all reduce tasks=38361684000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787709423
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787709423
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=129993
		CPU time spent (ms)=7161320
		Physical memory (bytes) snapshot=167618015232
		Virtual memory (bytes) snapshot=955762843648
		Total committed heap usage (bytes)=249828421632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/08 17:14:01 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	7m20.864s
user	0m14.519s
sys	0m0.964s
15/04/08 17:14:03 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 10
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-10-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3199954952601434922.jar tmpDir=null
15/04/08 17:14:06 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 17:14:06 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 17:14:07 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 17:14:07 INFO mapreduce.JobSubmitter: number of splits:75
15/04/08 17:14:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4276
15/04/08 17:14:08 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4276
15/04/08 17:14:08 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4276/
15/04/08 17:14:08 INFO mapreduce.Job: Running job: job_1422482982071_4276
15/04/08 17:14:14 INFO mapreduce.Job: Job job_1422482982071_4276 running in uber mode : false
15/04/08 17:14:14 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 17:14:26 INFO mapreduce.Job:  map 11% reduce 0%
15/04/08 17:14:27 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 17:14:29 INFO mapreduce.Job:  map 26% reduce 0%
15/04/08 17:14:30 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 17:14:32 INFO mapreduce.Job:  map 38% reduce 0%
15/04/08 17:14:33 INFO mapreduce.Job:  map 45% reduce 0%
15/04/08 17:14:35 INFO mapreduce.Job:  map 51% reduce 0%
15/04/08 17:14:36 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 17:14:38 INFO mapreduce.Job:  map 61% reduce 0%
15/04/08 17:14:39 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 17:14:42 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 17:14:53 INFO mapreduce.Job:  map 70% reduce 0%
15/04/08 17:14:54 INFO mapreduce.Job:  map 77% reduce 0%
15/04/08 17:14:55 INFO mapreduce.Job:  map 82% reduce 0%
15/04/08 17:14:56 INFO mapreduce.Job:  map 88% reduce 0%
15/04/08 17:14:57 INFO mapreduce.Job:  map 95% reduce 0%
15/04/08 17:14:58 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 17:14:59 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 17:15:04 INFO mapreduce.Job:  map 100% reduce 17%
15/04/08 17:15:05 INFO mapreduce.Job:  map 100% reduce 23%
15/04/08 17:15:23 INFO mapreduce.Job:  map 100% reduce 24%
15/04/08 17:15:25 INFO mapreduce.Job:  map 100% reduce 25%
15/04/08 17:15:26 INFO mapreduce.Job:  map 100% reduce 29%
15/04/08 17:15:28 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 17:15:29 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 17:15:31 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 17:15:32 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 17:15:34 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 17:15:35 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 17:15:37 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 17:15:38 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 17:15:41 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 17:15:44 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 17:15:50 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 17:15:53 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 17:15:56 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 17:15:58 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 17:16:01 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 17:16:02 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 17:16:05 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 17:16:08 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 17:16:09 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 17:16:10 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 17:16:19 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 17:16:24 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 17:16:36 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 17:16:42 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 17:16:49 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 17:16:58 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 17:17:11 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 17:17:17 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 17:17:26 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 17:17:32 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 17:17:39 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 17:17:48 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 17:17:53 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 17:18:02 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 17:18:07 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 17:18:16 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 17:18:22 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 17:18:31 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 17:18:40 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 17:18:51 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 17:18:59 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 17:19:13 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 17:19:22 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 17:19:39 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 17:19:58 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 17:20:07 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 17:20:10 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 17:20:35 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 17:20:52 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 17:21:10 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 17:22:06 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 17:22:40 INFO mapreduce.Job: Job job_1422482982071_4276 completed successfully
15/04/08 17:22:40 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=16787700561
		FILE: Number of bytes written=33583495394
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Launched map tasks=75
		Launched reduce tasks=10
		Data-local map tasks=50
		Rack-local map tasks=25
		Total time spent by all maps in occupied slots (ms)=5786220
		Total time spent by all reduces in occupied slots (ms)=6112450
		Total time spent by all map tasks (ms)=2893110
		Total time spent by all reduce tasks (ms)=3056225
		Total vcore-seconds taken by all map tasks=2893110
		Total vcore-seconds taken by all reduce tasks=3056225
		Total megabyte-seconds taken by all map tasks=23422618560
		Total megabyte-seconds taken by all reduce tasks=36674700000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787704923
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787704923
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=135471
		CPU time spent (ms)=7259180
		Physical memory (bytes) snapshot=165333655552
		Virtual memory (bytes) snapshot=822330568704
		Total committed heap usage (bytes)=228778422272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/08 17:22:40 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	8m38.787s
user	0m14.100s
sys	0m0.869s
15/04/08 17:22:43 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 10
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-10-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob567006982040528668.jar tmpDir=null
15/04/08 17:22:45 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 17:22:45 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 17:22:46 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 17:22:46 INFO mapreduce.JobSubmitter: number of splits:75
15/04/08 17:22:47 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4277
15/04/08 17:22:47 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4277
15/04/08 17:22:47 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4277/
15/04/08 17:22:47 INFO mapreduce.Job: Running job: job_1422482982071_4277
15/04/08 17:22:54 INFO mapreduce.Job: Job job_1422482982071_4277 running in uber mode : false
15/04/08 17:22:54 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 17:23:05 INFO mapreduce.Job:  map 17% reduce 0%
15/04/08 17:23:06 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 17:23:08 INFO mapreduce.Job:  map 29% reduce 0%
15/04/08 17:23:09 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 17:23:11 INFO mapreduce.Job:  map 42% reduce 0%
15/04/08 17:23:12 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 17:23:14 INFO mapreduce.Job:  map 54% reduce 0%
15/04/08 17:23:15 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 17:23:17 INFO mapreduce.Job:  map 64% reduce 0%
15/04/08 17:23:18 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 17:23:21 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 17:23:32 INFO mapreduce.Job:  map 72% reduce 0%
15/04/08 17:23:33 INFO mapreduce.Job:  map 76% reduce 0%
15/04/08 17:23:34 INFO mapreduce.Job:  map 82% reduce 0%
15/04/08 17:23:35 INFO mapreduce.Job:  map 91% reduce 0%
15/04/08 17:23:36 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 17:23:37 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 17:23:42 INFO mapreduce.Job:  map 100% reduce 2%
15/04/08 17:23:43 INFO mapreduce.Job:  map 100% reduce 21%
15/04/08 17:23:44 INFO mapreduce.Job:  map 100% reduce 23%
15/04/08 17:24:01 INFO mapreduce.Job:  map 100% reduce 24%
15/04/08 17:24:04 INFO mapreduce.Job:  map 100% reduce 25%
15/04/08 17:24:05 INFO mapreduce.Job:  map 100% reduce 26%
15/04/08 17:24:07 INFO mapreduce.Job:  map 100% reduce 32%
15/04/08 17:24:08 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 17:24:10 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 17:24:11 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 17:24:13 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 17:24:14 INFO mapreduce.Job:  map 100% reduce 48%
15/04/08 17:24:16 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 17:24:17 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 17:24:19 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 17:24:20 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 17:24:22 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 17:24:25 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 17:24:28 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 17:24:32 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 17:24:35 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 17:24:38 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 17:24:42 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 17:24:44 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 17:24:47 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 17:24:50 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 17:24:57 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 17:25:03 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 17:25:15 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 17:25:21 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 17:25:25 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 17:25:34 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 17:25:48 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 17:25:56 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 17:26:01 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 17:26:10 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 17:26:16 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 17:26:25 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 17:26:31 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 17:26:37 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 17:26:47 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 17:26:55 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 17:27:05 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 17:27:07 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 17:27:15 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 17:27:33 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 17:27:39 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 17:27:50 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 17:28:00 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 17:28:16 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 17:28:37 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 17:28:50 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 17:28:52 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 17:29:06 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 17:29:28 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 17:29:55 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 17:30:43 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 17:31:18 INFO mapreduce.Job: Job job_1422482982071_4277 completed successfully
15/04/08 17:31:18 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=16787700561
		FILE: Number of bytes written=33583495394
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Launched map tasks=75
		Launched reduce tasks=10
		Data-local map tasks=51
		Rack-local map tasks=24
		Total time spent by all maps in occupied slots (ms)=5783064
		Total time spent by all reduces in occupied slots (ms)=6076914
		Total time spent by all map tasks (ms)=2891532
		Total time spent by all reduce tasks (ms)=3038457
		Total vcore-seconds taken by all map tasks=2891532
		Total vcore-seconds taken by all reduce tasks=3038457
		Total megabyte-seconds taken by all map tasks=23409843072
		Total megabyte-seconds taken by all reduce tasks=36461484000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787704923
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787704923
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=133380
		CPU time spent (ms)=7244520
		Physical memory (bytes) snapshot=165499838464
		Virtual memory (bytes) snapshot=822517645312
		Total committed heap usage (bytes)=228778725376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/08 17:31:18 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	8m38.179s
user	0m14.555s
sys	0m0.938s
15/04/08 17:31:21 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 10
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-10-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5736839498512177401.jar tmpDir=null
15/04/08 17:31:24 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 17:31:24 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 17:31:24 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 17:31:25 INFO mapreduce.JobSubmitter: number of splits:75
15/04/08 17:31:25 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4278
15/04/08 17:31:26 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4278
15/04/08 17:31:26 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4278/
15/04/08 17:31:26 INFO mapreduce.Job: Running job: job_1422482982071_4278
15/04/08 17:31:32 INFO mapreduce.Job: Job job_1422482982071_4278 running in uber mode : false
15/04/08 17:31:32 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 17:31:43 INFO mapreduce.Job:  map 13% reduce 0%
15/04/08 17:31:44 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 17:31:46 INFO mapreduce.Job:  map 27% reduce 0%
15/04/08 17:31:47 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 17:31:49 INFO mapreduce.Job:  map 39% reduce 0%
15/04/08 17:31:50 INFO mapreduce.Job:  map 45% reduce 0%
15/04/08 17:31:52 INFO mapreduce.Job:  map 52% reduce 0%
15/04/08 17:31:53 INFO mapreduce.Job:  map 58% reduce 0%
15/04/08 17:31:55 INFO mapreduce.Job:  map 62% reduce 0%
15/04/08 17:31:56 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 17:31:59 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 17:32:09 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 17:32:10 INFO mapreduce.Job:  map 70% reduce 0%
15/04/08 17:32:11 INFO mapreduce.Job:  map 77% reduce 0%
15/04/08 17:32:12 INFO mapreduce.Job:  map 84% reduce 0%
15/04/08 17:32:13 INFO mapreduce.Job:  map 91% reduce 0%
15/04/08 17:32:14 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 17:32:15 INFO mapreduce.Job:  map 98% reduce 0%
15/04/08 17:32:16 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 17:32:20 INFO mapreduce.Job:  map 100% reduce 3%
15/04/08 17:32:21 INFO mapreduce.Job:  map 100% reduce 12%
15/04/08 17:32:22 INFO mapreduce.Job:  map 100% reduce 24%
15/04/08 17:32:40 INFO mapreduce.Job:  map 100% reduce 25%
15/04/08 17:32:43 INFO mapreduce.Job:  map 100% reduce 28%
15/04/08 17:32:45 INFO mapreduce.Job:  map 100% reduce 30%
15/04/08 17:32:46 INFO mapreduce.Job:  map 100% reduce 34%
15/04/08 17:32:47 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 17:32:48 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 17:32:50 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 17:32:51 INFO mapreduce.Job:  map 100% reduce 42%
15/04/08 17:32:52 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 17:32:53 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 17:32:54 INFO mapreduce.Job:  map 100% reduce 48%
15/04/08 17:32:55 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 17:32:56 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 17:32:59 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 17:33:02 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 17:33:05 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 17:33:08 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 17:33:11 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 17:33:14 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 17:33:17 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 17:33:24 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 17:33:27 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 17:33:30 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 17:33:35 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 17:33:41 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 17:33:51 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 17:33:56 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 17:34:03 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 17:34:12 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 17:34:24 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 17:34:34 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 17:34:40 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 17:34:48 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 17:34:54 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 17:35:01 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 17:35:07 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 17:35:14 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 17:35:23 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 17:35:31 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 17:35:38 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 17:35:52 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 17:35:55 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 17:36:08 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 17:36:17 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 17:36:28 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 17:36:44 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 17:37:01 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 17:37:22 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 17:37:30 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 17:37:36 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 17:38:04 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 17:38:21 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 17:38:38 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 17:39:29 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 17:40:04 INFO mapreduce.Job: Job job_1422482982071_4278 completed successfully
15/04/08 17:40:04 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=16787700561
		FILE: Number of bytes written=33583495394
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Launched map tasks=75
		Launched reduce tasks=10
		Data-local map tasks=52
		Rack-local map tasks=23
		Total time spent by all maps in occupied slots (ms)=5743884
		Total time spent by all reduces in occupied slots (ms)=6096532
		Total time spent by all map tasks (ms)=2871942
		Total time spent by all reduce tasks (ms)=3048266
		Total vcore-seconds taken by all map tasks=2871942
		Total vcore-seconds taken by all reduce tasks=3048266
		Total megabyte-seconds taken by all map tasks=23251242432
		Total megabyte-seconds taken by all reduce tasks=36579192000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787704923
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787704923
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=128856
		CPU time spent (ms)=7227580
		Physical memory (bytes) snapshot=165197475840
		Virtual memory (bytes) snapshot=821723590656
		Total committed heap usage (bytes)=228780957696
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/08 17:40:04 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	8m46.210s
user	0m14.690s
sys	0m0.968s
15/04/08 17:40:07 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 5
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-5-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8976101318801382715.jar tmpDir=null
15/04/08 17:40:11 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 17:40:11 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 17:40:11 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 17:40:12 INFO mapreduce.JobSubmitter: number of splits:75
15/04/08 17:40:12 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4279
15/04/08 17:40:13 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4279
15/04/08 17:40:13 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4279/
15/04/08 17:40:13 INFO mapreduce.Job: Running job: job_1422482982071_4279
15/04/08 17:40:18 INFO mapreduce.Job: Job job_1422482982071_4279 running in uber mode : false
15/04/08 17:40:18 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 17:40:29 INFO mapreduce.Job:  map 3% reduce 0%
15/04/08 17:40:30 INFO mapreduce.Job:  map 18% reduce 0%
15/04/08 17:40:31 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 17:40:32 INFO mapreduce.Job:  map 20% reduce 0%
15/04/08 17:40:33 INFO mapreduce.Job:  map 30% reduce 0%
15/04/08 17:40:34 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 17:40:35 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 17:40:36 INFO mapreduce.Job:  map 42% reduce 0%
15/04/08 17:40:37 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 17:40:38 INFO mapreduce.Job:  map 45% reduce 0%
15/04/08 17:40:39 INFO mapreduce.Job:  map 54% reduce 0%
15/04/08 17:40:40 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 17:40:42 INFO mapreduce.Job:  map 64% reduce 0%
15/04/08 17:40:43 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 17:40:46 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 17:40:57 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 17:40:58 INFO mapreduce.Job:  map 76% reduce 0%
15/04/08 17:40:59 INFO mapreduce.Job:  map 80% reduce 0%
15/04/08 17:41:00 INFO mapreduce.Job:  map 89% reduce 0%
15/04/08 17:41:01 INFO mapreduce.Job:  map 94% reduce 0%
15/04/08 17:41:02 INFO mapreduce.Job:  map 98% reduce 0%
15/04/08 17:41:03 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 17:41:04 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 17:41:08 INFO mapreduce.Job:  map 100% reduce 12%
15/04/08 17:41:29 INFO mapreduce.Job:  map 100% reduce 13%
15/04/08 17:41:32 INFO mapreduce.Job:  map 100% reduce 15%
15/04/08 17:41:33 INFO mapreduce.Job:  map 100% reduce 18%
15/04/08 17:41:35 INFO mapreduce.Job:  map 100% reduce 20%
15/04/08 17:41:36 INFO mapreduce.Job:  map 100% reduce 21%
15/04/08 17:41:39 INFO mapreduce.Job:  map 100% reduce 22%
15/04/08 17:41:55 INFO mapreduce.Job:  map 100% reduce 23%
15/04/08 17:41:57 INFO mapreduce.Job:  map 100% reduce 24%
15/04/08 17:41:58 INFO mapreduce.Job:  map 100% reduce 26%
15/04/08 17:42:00 INFO mapreduce.Job:  map 100% reduce 27%
15/04/08 17:42:01 INFO mapreduce.Job:  map 100% reduce 30%
15/04/08 17:42:04 INFO mapreduce.Job:  map 100% reduce 32%
15/04/08 17:42:07 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 17:42:09 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 17:42:13 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 17:42:16 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 17:42:24 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 17:42:25 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 17:42:27 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 17:42:28 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 17:42:30 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 17:42:31 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 17:42:32 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 17:42:33 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 17:42:34 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 17:42:36 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 17:42:37 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 17:42:38 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 17:42:39 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 17:42:42 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 17:42:45 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 17:42:47 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 17:42:48 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 17:42:50 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 17:42:58 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 17:43:17 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 17:43:44 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 17:43:52 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 17:44:10 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 17:44:42 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 17:45:05 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 17:45:16 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 17:45:35 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 17:45:55 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 17:46:23 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 17:46:42 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 17:47:00 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 17:47:07 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 17:47:16 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 17:47:33 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 17:47:48 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 17:48:06 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 17:48:33 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 17:48:37 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 17:48:42 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 17:48:58 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 17:49:29 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 17:49:37 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 17:49:59 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 17:50:06 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 17:50:23 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 17:50:39 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 17:51:06 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 17:51:36 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 17:52:07 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 17:52:44 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 17:53:13 INFO mapreduce.Job: Job job_1422482982071_4279 completed successfully
15/04/08 17:53:13 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=16787700537
		FILE: Number of bytes written=33583009300
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Launched map tasks=75
		Launched reduce tasks=5
		Data-local map tasks=47
		Rack-local map tasks=28
		Total time spent by all maps in occupied slots (ms)=5873232
		Total time spent by all reduces in occupied slots (ms)=6071686
		Total time spent by all map tasks (ms)=2936616
		Total time spent by all reduce tasks (ms)=3035843
		Total vcore-seconds taken by all map tasks=2936616
		Total vcore-seconds taken by all reduce tasks=3035843
		Total megabyte-seconds taken by all map tasks=23774843136
		Total megabyte-seconds taken by all reduce tasks=36430116000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787702673
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787702673
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =375
		Failed Shuffles=0
		Merged Map outputs=375
		GC time elapsed (ms)=126813
		CPU time spent (ms)=7304880
		Physical memory (bytes) snapshot=157883670528
		Virtual memory (bytes) snapshot=755886977024
		Total committed heap usage (bytes)=218297630720
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/08 17:53:13 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	13m8.476s
user	0m17.071s
sys	0m1.129s
15/04/08 17:53:16 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 5
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-5-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob655709587572655170.jar tmpDir=null
15/04/08 17:53:18 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 17:53:18 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 17:53:19 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 17:53:20 INFO mapreduce.JobSubmitter: number of splits:75
15/04/08 17:53:20 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4280
15/04/08 17:53:20 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4280
15/04/08 17:53:21 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4280/
15/04/08 17:53:21 INFO mapreduce.Job: Running job: job_1422482982071_4280
15/04/08 17:53:27 INFO mapreduce.Job: Job job_1422482982071_4280 running in uber mode : false
15/04/08 17:53:27 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 17:53:38 INFO mapreduce.Job:  map 9% reduce 0%
15/04/08 17:53:39 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 17:53:41 INFO mapreduce.Job:  map 24% reduce 0%
15/04/08 17:53:42 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 17:53:44 INFO mapreduce.Job:  map 37% reduce 0%
15/04/08 17:53:45 INFO mapreduce.Job:  map 45% reduce 0%
15/04/08 17:53:47 INFO mapreduce.Job:  map 49% reduce 0%
15/04/08 17:53:48 INFO mapreduce.Job:  map 58% reduce 0%
15/04/08 17:53:50 INFO mapreduce.Job:  map 60% reduce 0%
15/04/08 17:53:51 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 17:53:54 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 17:54:05 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 17:54:06 INFO mapreduce.Job:  map 73% reduce 0%
15/04/08 17:54:07 INFO mapreduce.Job:  map 78% reduce 0%
15/04/08 17:54:08 INFO mapreduce.Job:  map 86% reduce 0%
15/04/08 17:54:09 INFO mapreduce.Job:  map 91% reduce 0%
15/04/08 17:54:10 INFO mapreduce.Job:  map 96% reduce 0%
15/04/08 17:54:11 INFO mapreduce.Job:  map 98% reduce 0%
15/04/08 17:54:12 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 17:54:14 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 17:54:19 INFO mapreduce.Job:  map 100% reduce 12%
15/04/08 17:54:41 INFO mapreduce.Job:  map 100% reduce 14%
15/04/08 17:54:43 INFO mapreduce.Job:  map 100% reduce 18%
15/04/08 17:54:44 INFO mapreduce.Job:  map 100% reduce 20%
15/04/08 17:54:46 INFO mapreduce.Job:  map 100% reduce 21%
15/04/08 17:54:49 INFO mapreduce.Job:  map 100% reduce 22%
15/04/08 17:55:06 INFO mapreduce.Job:  map 100% reduce 24%
15/04/08 17:55:08 INFO mapreduce.Job:  map 100% reduce 26%
15/04/08 17:55:09 INFO mapreduce.Job:  map 100% reduce 29%
15/04/08 17:55:12 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 17:55:15 INFO mapreduce.Job:  map 100% reduce 32%
15/04/08 17:55:18 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 17:55:21 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 17:55:27 INFO mapreduce.Job:  map 100% reduce 38%
15/04/08 17:55:30 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 17:55:32 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 17:55:35 INFO mapreduce.Job:  map 100% reduce 42%
15/04/08 17:55:36 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 17:55:38 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 17:55:39 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 17:55:40 INFO mapreduce.Job:  map 100% reduce 48%
15/04/08 17:55:41 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 17:55:42 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 17:55:43 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 17:55:44 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 17:55:45 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 17:55:46 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 17:55:49 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 17:55:51 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 17:55:52 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 17:55:54 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 17:55:55 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 17:55:57 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 17:56:06 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 17:56:31 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 17:56:48 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 17:57:07 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 17:57:22 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 17:57:56 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 17:58:20 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 17:58:50 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 17:59:08 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 17:59:26 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 17:59:46 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 17:59:54 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 18:00:11 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 18:00:31 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 18:00:40 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 18:00:52 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 18:01:07 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 18:01:19 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 18:01:31 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 18:01:44 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 18:02:02 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 18:02:21 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 18:02:47 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 18:02:55 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 18:03:21 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 18:03:33 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 18:03:45 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 18:03:56 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 18:04:14 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 18:04:37 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 18:04:52 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 18:05:21 INFO mapreduce.Job: Job job_1422482982071_4280 completed successfully
15/04/08 18:05:22 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=16787700537
		FILE: Number of bytes written=33583009300
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Launched map tasks=75
		Launched reduce tasks=5
		Data-local map tasks=52
		Rack-local map tasks=23
		Total time spent by all maps in occupied slots (ms)=5853096
		Total time spent by all reduces in occupied slots (ms)=6053348
		Total time spent by all map tasks (ms)=2926548
		Total time spent by all reduce tasks (ms)=3026674
		Total vcore-seconds taken by all map tasks=2926548
		Total vcore-seconds taken by all reduce tasks=3026674
		Total megabyte-seconds taken by all map tasks=23693332608
		Total megabyte-seconds taken by all reduce tasks=36320088000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787702673
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787702673
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =375
		Failed Shuffles=0
		Merged Map outputs=375
		GC time elapsed (ms)=126354
		CPU time spent (ms)=7274430
		Physical memory (bytes) snapshot=158012641280
		Virtual memory (bytes) snapshot=755298050048
		Total committed heap usage (bytes)=218499788800
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/08 18:05:22 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	12m8.533s
user	0m15.096s
sys	0m1.055s
15/04/08 18:05:24 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
50 5
py googlebooks-eng-all-5gram-20120701-un mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-5-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7471268640097508076.jar tmpDir=null
15/04/08 18:05:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 18:05:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 18:05:27 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 18:05:28 INFO mapreduce.JobSubmitter: number of splits:75
15/04/08 18:05:28 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4281
15/04/08 18:05:29 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4281
15/04/08 18:05:29 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4281/
15/04/08 18:05:29 INFO mapreduce.Job: Running job: job_1422482982071_4281
15/04/08 18:05:35 INFO mapreduce.Job: Job job_1422482982071_4281 running in uber mode : false
15/04/08 18:05:35 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 18:05:46 INFO mapreduce.Job:  map 11% reduce 0%
15/04/08 18:05:47 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 18:05:49 INFO mapreduce.Job:  map 26% reduce 0%
15/04/08 18:05:50 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 18:05:52 INFO mapreduce.Job:  map 38% reduce 0%
15/04/08 18:05:53 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 18:05:55 INFO mapreduce.Job:  map 50% reduce 0%
15/04/08 18:05:56 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 18:05:58 INFO mapreduce.Job:  map 61% reduce 0%
15/04/08 18:05:59 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 18:06:02 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 18:06:14 INFO mapreduce.Job:  map 72% reduce 0%
15/04/08 18:06:15 INFO mapreduce.Job:  map 79% reduce 0%
15/04/08 18:06:16 INFO mapreduce.Job:  map 86% reduce 0%
15/04/08 18:06:17 INFO mapreduce.Job:  map 93% reduce 0%
15/04/08 18:06:18 INFO mapreduce.Job:  map 96% reduce 0%
15/04/08 18:06:19 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 18:06:20 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 18:06:26 INFO mapreduce.Job:  map 100% reduce 12%
15/04/08 18:06:49 INFO mapreduce.Job:  map 100% reduce 14%
15/04/08 18:06:51 INFO mapreduce.Job:  map 100% reduce 18%
15/04/08 18:06:52 INFO mapreduce.Job:  map 100% reduce 19%
15/04/08 18:06:54 INFO mapreduce.Job:  map 100% reduce 20%
15/04/08 18:06:55 INFO mapreduce.Job:  map 100% reduce 21%
15/04/08 18:06:58 INFO mapreduce.Job:  map 100% reduce 22%
15/04/08 18:07:14 INFO mapreduce.Job:  map 100% reduce 23%
15/04/08 18:07:16 INFO mapreduce.Job:  map 100% reduce 24%
15/04/08 18:07:17 INFO mapreduce.Job:  map 100% reduce 25%
15/04/08 18:07:18 INFO mapreduce.Job:  map 100% reduce 28%
15/04/08 18:07:19 INFO mapreduce.Job:  map 100% reduce 30%
15/04/08 18:07:23 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 18:07:25 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 18:07:26 INFO mapreduce.Job:  map 100% reduce 34%
15/04/08 18:07:29 INFO mapreduce.Job:  map 100% reduce 35%
15/04/08 18:07:32 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 18:07:35 INFO mapreduce.Job:  map 100% reduce 38%
15/04/08 18:07:42 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 18:07:43 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 18:07:45 INFO mapreduce.Job:  map 100% reduce 42%
15/04/08 18:07:46 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 18:07:49 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 18:07:52 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 18:07:55 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 18:07:56 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 18:07:58 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 18:07:59 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 18:08:01 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 18:08:02 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 18:08:05 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 18:08:19 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 18:08:40 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 18:08:59 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 18:09:12 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 18:09:30 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 18:10:01 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 18:10:30 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 18:10:57 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 18:11:09 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 18:11:31 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 18:11:59 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 18:12:05 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 18:12:20 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 18:12:35 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 18:12:47 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 18:13:05 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 18:13:23 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 18:13:33 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 18:13:35 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 18:13:48 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 18:14:04 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 18:14:31 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 18:14:40 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 18:15:14 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 18:15:31 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 18:15:41 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 18:15:47 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 18:16:05 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 18:16:17 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 18:16:41 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 18:17:04 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 18:17:55 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 18:18:27 INFO mapreduce.Job: Job job_1422482982071_4281 completed successfully
15/04/08 18:18:27 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=16787700537
		FILE: Number of bytes written=33583009300
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Launched map tasks=75
		Launched reduce tasks=5
		Data-local map tasks=52
		Rack-local map tasks=23
		Total time spent by all maps in occupied slots (ms)=5854936
		Total time spent by all reduces in occupied slots (ms)=6193724
		Total time spent by all map tasks (ms)=2927468
		Total time spent by all reduce tasks (ms)=3096862
		Total vcore-seconds taken by all map tasks=2927468
		Total vcore-seconds taken by all reduce tasks=3096862
		Total megabyte-seconds taken by all map tasks=23700780928
		Total megabyte-seconds taken by all reduce tasks=37162344000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787702673
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787702673
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =375
		Failed Shuffles=0
		Merged Map outputs=375
		GC time elapsed (ms)=133117
		CPU time spent (ms)=7374110
		Physical memory (bytes) snapshot=157990895616
		Virtual memory (bytes) snapshot=755701129216
		Total committed heap usage (bytes)=218428878848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/08 18:18:27 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-un

real	13m5.474s
user	0m14.886s
sys	0m1.111s
50 40
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-40-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3302287221814838141.jar tmpDir=null
15/04/08 18:18:32 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 18:18:32 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 18:18:33 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 18:18:34 INFO mapreduce.JobSubmitter: number of splits:134
15/04/08 18:18:34 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4282
15/04/08 18:18:34 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4282
15/04/08 18:18:34 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4282/
15/04/08 18:18:34 INFO mapreduce.Job: Running job: job_1422482982071_4282
15/04/08 18:18:41 INFO mapreduce.Job: Job job_1422482982071_4282 running in uber mode : false
15/04/08 18:18:41 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 18:18:52 INFO mapreduce.Job:  map 14% reduce 0%
15/04/08 18:18:53 INFO mapreduce.Job:  map 20% reduce 0%
15/04/08 18:18:55 INFO mapreduce.Job:  map 28% reduce 0%
15/04/08 18:18:56 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 18:18:58 INFO mapreduce.Job:  map 40% reduce 0%
15/04/08 18:18:59 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 18:19:01 INFO mapreduce.Job:  map 52% reduce 0%
15/04/08 18:19:02 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 18:19:04 INFO mapreduce.Job:  map 62% reduce 0%
15/04/08 18:19:05 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 18:19:19 INFO mapreduce.Job:  map 70% reduce 0%
15/04/08 18:19:20 INFO mapreduce.Job:  map 76% reduce 0%
15/04/08 18:19:21 INFO mapreduce.Job:  map 85% reduce 0%
15/04/08 18:19:22 INFO mapreduce.Job:  map 92% reduce 0%
15/04/08 18:19:23 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 18:19:24 INFO mapreduce.Job:  map 98% reduce 0%
15/04/08 18:19:25 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 18:19:26 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 18:19:29 INFO mapreduce.Job:  map 100% reduce 2%
15/04/08 18:19:30 INFO mapreduce.Job:  map 100% reduce 24%
15/04/08 18:19:31 INFO mapreduce.Job:  map 100% reduce 34%
15/04/08 18:19:33 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 18:19:34 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 18:19:35 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 18:19:36 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 18:19:37 INFO mapreduce.Job:  map 100% reduce 46%
15/04/08 18:19:39 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 18:19:40 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 18:19:41 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 18:19:42 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 18:19:43 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 18:19:45 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 18:19:46 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 18:19:48 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 18:19:49 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 18:19:51 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 18:19:54 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 18:19:56 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 18:19:57 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 18:20:00 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 18:20:01 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 18:20:03 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 18:20:04 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 18:20:07 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 18:20:10 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 18:20:11 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 18:20:14 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 18:20:16 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 18:20:19 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 18:20:22 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 18:20:23 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 18:20:26 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 18:20:29 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 18:20:33 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 18:20:36 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 18:20:39 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 18:20:42 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 18:20:46 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 18:20:50 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 18:20:55 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 18:20:59 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 18:21:06 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 18:21:12 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 18:21:22 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 18:21:30 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 18:21:34 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 18:21:41 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 18:21:50 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 18:22:09 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 18:22:22 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 18:22:42 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 18:24:37 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 18:28:08 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 18:29:17 INFO mapreduce.Job: Job job_1422482982071_4282 completed successfully
15/04/08 18:29:17 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=30424216087
		FILE: Number of bytes written=60865115900
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=522
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Killed reduce tasks=2
		Launched map tasks=134
		Launched reduce tasks=42
		Data-local map tasks=62
		Rack-local map tasks=72
		Total time spent by all maps in occupied slots (ms)=10123468
		Total time spent by all reduces in occupied slots (ms)=12651480
		Total time spent by all map tasks (ms)=5061734
		Total time spent by all reduce tasks (ms)=6325740
		Total vcore-seconds taken by all map tasks=5061734
		Total vcore-seconds taken by all reduce tasks=6325740
		Total megabyte-seconds taken by all map tasks=40979798464
		Total megabyte-seconds taken by all reduce tasks=75908880000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424247953
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424247953
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =5360
		Failed Shuffles=0
		Merged Map outputs=5360
		GC time elapsed (ms)=237151
		CPU time spent (ms)=12954520
		Physical memory (bytes) snapshot=299918544896
		Virtual memory (bytes) snapshot=1764230676480
		Total committed heap usage (bytes)=455337857024
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/08 18:29:17 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	10m49.907s
user	0m16.381s
sys	0m1.127s
15/04/08 18:29:20 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 40
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-40-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4526827769567025250.jar tmpDir=null
15/04/08 18:29:22 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 18:29:22 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 18:29:23 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 18:29:23 INFO mapreduce.JobSubmitter: number of splits:134
15/04/08 18:29:24 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4283
15/04/08 18:29:24 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4283
15/04/08 18:29:24 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4283/
15/04/08 18:29:24 INFO mapreduce.Job: Running job: job_1422482982071_4283
15/04/08 18:29:30 INFO mapreduce.Job: Job job_1422482982071_4283 running in uber mode : false
15/04/08 18:29:30 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 18:29:42 INFO mapreduce.Job:  map 12% reduce 0%
15/04/08 18:29:43 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 18:29:45 INFO mapreduce.Job:  map 26% reduce 0%
15/04/08 18:29:46 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 18:29:47 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 18:29:48 INFO mapreduce.Job:  map 38% reduce 0%
15/04/08 18:29:49 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 18:29:51 INFO mapreduce.Job:  map 51% reduce 0%
15/04/08 18:29:52 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 18:29:54 INFO mapreduce.Job:  map 62% reduce 0%
15/04/08 18:29:55 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 18:29:56 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 18:30:09 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 18:30:10 INFO mapreduce.Job:  map 75% reduce 0%
15/04/08 18:30:11 INFO mapreduce.Job:  map 85% reduce 0%
15/04/08 18:30:12 INFO mapreduce.Job:  map 91% reduce 0%
15/04/08 18:30:13 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 18:30:14 INFO mapreduce.Job:  map 98% reduce 0%
15/04/08 18:30:15 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 18:30:16 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 18:30:19 INFO mapreduce.Job:  map 100% reduce 1%
15/04/08 18:30:20 INFO mapreduce.Job:  map 100% reduce 20%
15/04/08 18:30:21 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 18:30:23 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 18:30:24 INFO mapreduce.Job:  map 100% reduce 38%
15/04/08 18:30:26 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 18:30:27 INFO mapreduce.Job:  map 100% reduce 44%
15/04/08 18:30:29 INFO mapreduce.Job:  map 100% reduce 48%
15/04/08 18:30:30 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 18:30:32 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 18:30:33 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 18:30:35 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 18:30:36 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 18:30:38 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 18:30:39 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 18:30:40 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 18:30:42 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 18:30:43 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 18:30:45 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 18:30:47 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 18:30:48 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 18:30:51 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 18:30:52 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 18:30:53 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 18:30:54 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 18:30:57 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 18:30:59 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 18:31:02 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 18:31:04 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 18:31:06 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 18:31:09 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 18:31:12 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 18:31:14 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 18:31:17 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 18:31:19 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 18:31:22 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 18:31:24 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 18:31:28 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 18:31:31 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 18:31:36 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 18:31:42 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 18:31:46 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 18:31:52 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 18:31:55 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 18:32:02 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 18:32:12 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 18:32:19 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 18:32:26 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 18:32:29 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 18:32:42 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 18:32:55 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 18:33:17 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 18:33:26 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 18:35:26 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 18:39:27 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 18:40:44 INFO mapreduce.Job: Job job_1422482982071_4283 completed successfully
15/04/08 18:40:44 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=30424216087
		FILE: Number of bytes written=60865115900
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=522
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Killed reduce tasks=2
		Launched map tasks=134
		Launched reduce tasks=42
		Data-local map tasks=64
		Rack-local map tasks=70
		Total time spent by all maps in occupied slots (ms)=10138484
		Total time spent by all reduces in occupied slots (ms)=12775394
		Total time spent by all map tasks (ms)=5069242
		Total time spent by all reduce tasks (ms)=6387697
		Total vcore-seconds taken by all map tasks=5069242
		Total vcore-seconds taken by all reduce tasks=6387697
		Total megabyte-seconds taken by all map tasks=41040583232
		Total megabyte-seconds taken by all reduce tasks=76652364000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424247953
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424247953
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =5360
		Failed Shuffles=0
		Merged Map outputs=5360
		GC time elapsed (ms)=225559
		CPU time spent (ms)=12937390
		Physical memory (bytes) snapshot=299936911360
		Virtual memory (bytes) snapshot=1765636599808
		Total committed heap usage (bytes)=455340154880
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/08 18:40:44 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	11m26.946s
user	0m15.563s
sys	0m1.017s
15/04/08 18:40:46 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 40
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-40-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3662908922385396374.jar tmpDir=null
15/04/08 18:40:49 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 18:40:49 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 18:40:51 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 18:40:51 INFO mapreduce.JobSubmitter: number of splits:134
15/04/08 18:40:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4284
15/04/08 18:40:52 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4284
15/04/08 18:40:52 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4284/
15/04/08 18:40:52 INFO mapreduce.Job: Running job: job_1422482982071_4284
15/04/08 18:40:59 INFO mapreduce.Job: Job job_1422482982071_4284 running in uber mode : false
15/04/08 18:40:59 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 18:41:10 INFO mapreduce.Job:  map 15% reduce 0%
15/04/08 18:41:11 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 18:41:12 INFO mapreduce.Job:  map 20% reduce 0%
15/04/08 18:41:13 INFO mapreduce.Job:  map 28% reduce 0%
15/04/08 18:41:14 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 18:41:16 INFO mapreduce.Job:  map 40% reduce 0%
15/04/08 18:41:17 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 18:41:19 INFO mapreduce.Job:  map 53% reduce 0%
15/04/08 18:41:20 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 18:41:23 INFO mapreduce.Job:  map 63% reduce 0%
15/04/08 18:41:24 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 18:41:38 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 18:41:39 INFO mapreduce.Job:  map 78% reduce 0%
15/04/08 18:41:40 INFO mapreduce.Job:  map 87% reduce 0%
15/04/08 18:41:41 INFO mapreduce.Job:  map 94% reduce 0%
15/04/08 18:41:42 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 18:41:43 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 18:41:45 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 18:41:48 INFO mapreduce.Job:  map 100% reduce 1%
15/04/08 18:41:49 INFO mapreduce.Job:  map 100% reduce 25%
15/04/08 18:41:50 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 18:41:52 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 18:41:53 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 18:41:55 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 18:41:56 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 18:41:58 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 18:41:59 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 18:42:01 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 18:42:02 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 18:42:04 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 18:42:05 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 18:42:07 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 18:42:08 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 18:42:10 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 18:42:13 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 18:42:16 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 18:42:18 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 18:42:19 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 18:42:20 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 18:42:22 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 18:42:23 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 18:42:27 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 18:42:29 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 18:42:32 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 18:42:35 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 18:42:37 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 18:42:40 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 18:42:41 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 18:42:44 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 18:42:47 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 18:42:50 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 18:42:53 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 18:42:55 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 18:42:57 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 18:43:02 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 18:43:06 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 18:43:11 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 18:43:15 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 18:43:17 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 18:43:24 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 18:43:32 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 18:43:44 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 18:43:50 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 18:43:57 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 18:44:09 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 18:44:26 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 18:44:39 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 18:44:48 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 18:47:14 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 18:50:36 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 18:51:45 INFO mapreduce.Job: Job job_1422482982071_4284 completed successfully
15/04/08 18:51:45 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=30424216087
		FILE: Number of bytes written=60865115900
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=522
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Killed reduce tasks=2
		Launched map tasks=134
		Launched reduce tasks=42
		Data-local map tasks=66
		Rack-local map tasks=68
		Total time spent by all maps in occupied slots (ms)=10133424
		Total time spent by all reduces in occupied slots (ms)=12781872
		Total time spent by all map tasks (ms)=5066712
		Total time spent by all reduce tasks (ms)=6390936
		Total vcore-seconds taken by all map tasks=5066712
		Total vcore-seconds taken by all reduce tasks=6390936
		Total megabyte-seconds taken by all map tasks=41020100352
		Total megabyte-seconds taken by all reduce tasks=76691232000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424247953
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424247953
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =5360
		Failed Shuffles=0
		Merged Map outputs=5360
		GC time elapsed (ms)=225669
		CPU time spent (ms)=12955060
		Physical memory (bytes) snapshot=299949592576
		Virtual memory (bytes) snapshot=1764044738560
		Total committed heap usage (bytes)=455337873408
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/08 18:51:45 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	11m1.521s
user	0m15.305s
sys	0m1.011s
15/04/08 18:51:48 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 30
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-30-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8821261956127768720.jar tmpDir=null
15/04/08 18:51:51 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 18:51:51 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 18:51:51 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 18:51:52 INFO mapreduce.JobSubmitter: number of splits:134
15/04/08 18:51:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4285
15/04/08 18:51:53 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4285
15/04/08 18:51:53 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4285/
15/04/08 18:51:53 INFO mapreduce.Job: Running job: job_1422482982071_4285
15/04/08 18:51:58 INFO mapreduce.Job: Job job_1422482982071_4285 running in uber mode : false
15/04/08 18:51:58 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 18:52:09 INFO mapreduce.Job:  map 3% reduce 0%
15/04/08 18:52:10 INFO mapreduce.Job:  map 17% reduce 0%
15/04/08 18:52:11 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 18:52:12 INFO mapreduce.Job:  map 21% reduce 0%
15/04/08 18:52:13 INFO mapreduce.Job:  map 30% reduce 0%
15/04/08 18:52:14 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 18:52:15 INFO mapreduce.Job:  map 33% reduce 0%
15/04/08 18:52:16 INFO mapreduce.Job:  map 42% reduce 0%
15/04/08 18:52:17 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 18:52:18 INFO mapreduce.Job:  map 45% reduce 0%
15/04/08 18:52:19 INFO mapreduce.Job:  map 54% reduce 0%
15/04/08 18:52:20 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 18:52:21 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 18:52:22 INFO mapreduce.Job:  map 65% reduce 0%
15/04/08 18:52:23 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 18:52:37 INFO mapreduce.Job:  map 70% reduce 0%
15/04/08 18:52:38 INFO mapreduce.Job:  map 77% reduce 0%
15/04/08 18:52:39 INFO mapreduce.Job:  map 85% reduce 0%
15/04/08 18:52:40 INFO mapreduce.Job:  map 94% reduce 0%
15/04/08 18:52:41 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 18:52:42 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 18:52:44 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 18:52:47 INFO mapreduce.Job:  map 100% reduce 9%
15/04/08 18:52:48 INFO mapreduce.Job:  map 100% reduce 29%
15/04/08 18:52:49 INFO mapreduce.Job:  map 100% reduce 32%
15/04/08 18:52:51 INFO mapreduce.Job:  map 100% reduce 34%
15/04/08 18:52:52 INFO mapreduce.Job:  map 100% reduce 35%
15/04/08 18:52:54 INFO mapreduce.Job:  map 100% reduce 38%
15/04/08 18:52:55 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 18:52:57 INFO mapreduce.Job:  map 100% reduce 42%
15/04/08 18:52:58 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 18:53:00 INFO mapreduce.Job:  map 100% reduce 46%
15/04/08 18:53:01 INFO mapreduce.Job:  map 100% reduce 48%
15/04/08 18:53:03 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 18:53:04 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 18:53:07 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 18:53:10 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 18:53:13 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 18:53:14 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 18:53:16 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 18:53:17 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 18:53:19 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 18:53:20 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 18:53:22 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 18:53:23 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 18:53:25 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 18:53:29 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 18:53:32 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 18:53:35 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 18:53:38 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 18:53:41 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 18:53:44 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 18:53:47 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 18:53:48 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 18:53:50 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 18:53:53 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 18:53:58 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 18:54:01 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 18:54:03 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 18:54:06 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 18:54:08 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 18:54:12 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 18:54:14 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 18:54:18 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 18:54:21 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 18:54:24 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 18:54:29 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 18:54:35 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 18:54:38 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 18:54:44 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 18:54:50 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 18:54:53 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 18:55:02 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 18:55:11 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 18:55:29 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 18:55:59 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 18:56:22 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 18:57:20 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 18:57:57 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 18:59:23 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 19:01:38 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 19:02:58 INFO mapreduce.Job: Job job_1422482982071_4285 completed successfully
15/04/08 19:02:58 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=30424216039
		FILE: Number of bytes written=60864126312
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=492
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Killed reduce tasks=2
		Launched map tasks=134
		Launched reduce tasks=32
		Data-local map tasks=60
		Rack-local map tasks=74
		Total time spent by all maps in occupied slots (ms)=10202174
		Total time spent by all reduces in occupied slots (ms)=12225558
		Total time spent by all map tasks (ms)=5101087
		Total time spent by all reduce tasks (ms)=6112779
		Total vcore-seconds taken by all map tasks=5101087
		Total vcore-seconds taken by all reduce tasks=6112779
		Total megabyte-seconds taken by all map tasks=41298400352
		Total megabyte-seconds taken by all reduce tasks=73353348000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424239913
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424239913
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =4020
		Failed Shuffles=0
		Merged Map outputs=4020
		GC time elapsed (ms)=212959
		CPU time spent (ms)=13012970
		Physical memory (bytes) snapshot=297678336000
		Virtual memory (bytes) snapshot=1630989815808
		Total committed heap usage (bytes)=434323087360
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/08 19:02:58 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	11m12.851s
user	0m15.020s
sys	0m1.014s
15/04/08 19:03:01 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 30
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-30-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2403181264686169668.jar tmpDir=null
15/04/08 19:03:04 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 19:03:04 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 19:03:05 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 19:03:05 INFO mapreduce.JobSubmitter: number of splits:134
15/04/08 19:03:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4286
15/04/08 19:03:06 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4286
15/04/08 19:03:06 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4286/
15/04/08 19:03:06 INFO mapreduce.Job: Running job: job_1422482982071_4286
15/04/08 19:03:11 INFO mapreduce.Job: Job job_1422482982071_4286 running in uber mode : false
15/04/08 19:03:11 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 19:03:22 INFO mapreduce.Job:  map 7% reduce 0%
15/04/08 19:03:23 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 19:03:25 INFO mapreduce.Job:  map 23% reduce 0%
15/04/08 19:03:26 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 19:03:27 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 19:03:28 INFO mapreduce.Job:  map 36% reduce 0%
15/04/08 19:03:29 INFO mapreduce.Job:  map 43% reduce 0%
15/04/08 19:03:30 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 19:03:31 INFO mapreduce.Job:  map 48% reduce 0%
15/04/08 19:03:32 INFO mapreduce.Job:  map 55% reduce 0%
15/04/08 19:03:33 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 19:03:34 INFO mapreduce.Job:  map 59% reduce 0%
15/04/08 19:03:35 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 19:03:36 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 19:03:49 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 19:03:50 INFO mapreduce.Job:  map 72% reduce 0%
15/04/08 19:03:51 INFO mapreduce.Job:  map 79% reduce 0%
15/04/08 19:03:53 INFO mapreduce.Job:  map 89% reduce 0%
15/04/08 19:03:54 INFO mapreduce.Job:  map 94% reduce 0%
15/04/08 19:03:55 INFO mapreduce.Job:  map 98% reduce 0%
15/04/08 19:03:56 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 19:03:58 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 19:04:01 INFO mapreduce.Job:  map 100% reduce 18%
15/04/08 19:04:02 INFO mapreduce.Job:  map 100% reduce 29%
15/04/08 19:04:03 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 19:04:04 INFO mapreduce.Job:  map 100% reduce 32%
15/04/08 19:04:05 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 19:04:07 INFO mapreduce.Job:  map 100% reduce 35%
15/04/08 19:04:08 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 19:04:10 INFO mapreduce.Job:  map 100% reduce 38%
15/04/08 19:04:11 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 19:04:12 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 19:04:13 INFO mapreduce.Job:  map 100% reduce 42%
15/04/08 19:04:14 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 19:04:15 INFO mapreduce.Job:  map 100% reduce 46%
15/04/08 19:04:17 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 19:04:19 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 19:04:20 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 19:04:23 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 19:04:24 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 19:04:25 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 19:04:26 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 19:04:27 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 19:04:29 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 19:04:31 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 19:04:32 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 19:04:35 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 19:04:38 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 19:04:40 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 19:04:44 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 19:04:47 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 19:04:50 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 19:04:53 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 19:04:56 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 19:04:59 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 19:05:02 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 19:05:04 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 19:05:08 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 19:05:10 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 19:05:13 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 19:05:15 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 19:05:20 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 19:05:21 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 19:05:24 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 19:05:26 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 19:05:30 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 19:05:34 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 19:05:39 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 19:05:42 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 19:05:47 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 19:05:53 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 19:05:57 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 19:06:06 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 19:06:12 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 19:06:19 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 19:06:31 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 19:06:58 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 19:07:22 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 19:07:44 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 19:08:33 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 19:08:50 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 19:10:02 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 19:12:40 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 19:14:08 INFO mapreduce.Job: Job job_1422482982071_4286 completed successfully
15/04/08 19:14:08 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=30424216039
		FILE: Number of bytes written=60864126312
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=492
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=134
		Launched reduce tasks=31
		Data-local map tasks=61
		Rack-local map tasks=73
		Total time spent by all maps in occupied slots (ms)=10213512
		Total time spent by all reduces in occupied slots (ms)=12068778
		Total time spent by all map tasks (ms)=5106756
		Total time spent by all reduce tasks (ms)=6034389
		Total vcore-seconds taken by all map tasks=5106756
		Total vcore-seconds taken by all reduce tasks=6034389
		Total megabyte-seconds taken by all map tasks=41344296576
		Total megabyte-seconds taken by all reduce tasks=72412668000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424239913
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424239913
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =4020
		Failed Shuffles=0
		Merged Map outputs=4020
		GC time elapsed (ms)=209964
		CPU time spent (ms)=12992180
		Physical memory (bytes) snapshot=297467613184
		Virtual memory (bytes) snapshot=1630594138112
		Total committed heap usage (bytes)=434288033792
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/08 19:14:08 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	11m10.069s
user	0m14.707s
sys	0m1.015s
15/04/08 19:14:10 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 30
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-30-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2427809006541030204.jar tmpDir=null
15/04/08 19:14:13 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 19:14:13 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 19:14:14 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 19:14:14 INFO mapreduce.JobSubmitter: number of splits:134
15/04/08 19:14:15 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4287
15/04/08 19:14:15 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4287
15/04/08 19:14:15 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4287/
15/04/08 19:14:15 INFO mapreduce.Job: Running job: job_1422482982071_4287
15/04/08 19:14:22 INFO mapreduce.Job: Job job_1422482982071_4287 running in uber mode : false
15/04/08 19:14:22 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 19:14:33 INFO mapreduce.Job:  map 11% reduce 0%
15/04/08 19:14:34 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 19:14:35 INFO mapreduce.Job:  map 20% reduce 0%
15/04/08 19:14:36 INFO mapreduce.Job:  map 26% reduce 0%
15/04/08 19:14:37 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 19:14:39 INFO mapreduce.Job:  map 38% reduce 0%
15/04/08 19:14:40 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 19:14:42 INFO mapreduce.Job:  map 50% reduce 0%
15/04/08 19:14:43 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 19:14:44 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 19:14:45 INFO mapreduce.Job:  map 61% reduce 0%
15/04/08 19:14:46 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 19:14:47 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 19:15:00 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 19:15:01 INFO mapreduce.Job:  map 73% reduce 0%
15/04/08 19:15:02 INFO mapreduce.Job:  map 81% reduce 0%
15/04/08 19:15:03 INFO mapreduce.Job:  map 91% reduce 0%
15/04/08 19:15:04 INFO mapreduce.Job:  map 96% reduce 0%
15/04/08 19:15:05 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 19:15:06 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 19:15:11 INFO mapreduce.Job:  map 100% reduce 21%
15/04/08 19:15:12 INFO mapreduce.Job:  map 100% reduce 32%
15/04/08 19:15:14 INFO mapreduce.Job:  map 100% reduce 34%
15/04/08 19:15:15 INFO mapreduce.Job:  map 100% reduce 35%
15/04/08 19:15:17 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 19:15:18 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 19:15:20 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 19:15:21 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 19:15:23 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 19:15:24 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 19:15:25 INFO mapreduce.Job:  map 100% reduce 48%
15/04/08 19:15:26 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 19:15:27 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 19:15:28 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 19:15:29 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 19:15:31 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 19:15:32 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 19:15:33 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 19:15:35 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 19:15:37 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 19:15:38 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 19:15:39 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 19:15:40 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 19:15:42 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 19:15:44 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 19:15:45 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 19:15:47 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 19:15:48 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 19:15:51 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 19:15:55 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 19:15:57 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 19:16:00 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 19:16:04 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 19:16:09 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 19:16:10 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 19:16:14 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 19:16:17 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 19:16:21 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 19:16:25 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 19:16:26 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 19:16:31 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 19:16:32 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 19:16:35 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 19:16:38 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 19:16:43 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 19:16:46 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 19:16:50 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 19:16:53 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 19:16:58 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 19:17:02 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 19:17:08 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 19:17:15 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 19:17:22 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 19:17:29 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 19:17:38 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 19:17:56 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 19:18:18 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 19:18:41 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 19:19:50 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 19:20:34 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 19:22:09 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 19:24:16 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 19:25:51 INFO mapreduce.Job: Job job_1422482982071_4287 completed successfully
15/04/08 19:25:51 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=30424216039
		FILE: Number of bytes written=60864126312
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=492
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Killed reduce tasks=2
		Launched map tasks=134
		Launched reduce tasks=32
		Data-local map tasks=64
		Rack-local map tasks=70
		Total time spent by all maps in occupied slots (ms)=10210068
		Total time spent by all reduces in occupied slots (ms)=12407936
		Total time spent by all map tasks (ms)=5105034
		Total time spent by all reduce tasks (ms)=6203968
		Total vcore-seconds taken by all map tasks=5105034
		Total vcore-seconds taken by all reduce tasks=6203968
		Total megabyte-seconds taken by all map tasks=41330355264
		Total megabyte-seconds taken by all reduce tasks=74447616000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424239913
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424239913
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =4020
		Failed Shuffles=0
		Merged Map outputs=4020
		GC time elapsed (ms)=218566
		CPU time spent (ms)=13019070
		Physical memory (bytes) snapshot=297611014144
		Virtual memory (bytes) snapshot=1631798648832
		Total committed heap usage (bytes)=434288087040
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/08 19:25:51 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	11m42.850s
user	0m15.016s
sys	0m1.007s
15/04/08 19:25:54 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 20
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-20-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5433435865879595914.jar tmpDir=null
15/04/08 19:25:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 19:25:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 19:25:58 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 19:25:58 INFO mapreduce.JobSubmitter: number of splits:134
15/04/08 19:25:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4288
15/04/08 19:25:59 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4288
15/04/08 19:25:59 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4288/
15/04/08 19:25:59 INFO mapreduce.Job: Running job: job_1422482982071_4288
15/04/08 19:26:06 INFO mapreduce.Job: Job job_1422482982071_4288 running in uber mode : false
15/04/08 19:26:06 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 19:26:16 INFO mapreduce.Job:  map 5% reduce 0%
15/04/08 19:26:17 INFO mapreduce.Job:  map 18% reduce 0%
15/04/08 19:26:18 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 19:26:19 INFO mapreduce.Job:  map 22% reduce 0%
15/04/08 19:26:20 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 19:26:21 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 19:26:22 INFO mapreduce.Job:  map 33% reduce 0%
15/04/08 19:26:23 INFO mapreduce.Job:  map 43% reduce 0%
15/04/08 19:26:24 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 19:26:25 INFO mapreduce.Job:  map 45% reduce 0%
15/04/08 19:26:26 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 19:26:27 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 19:26:28 INFO mapreduce.Job:  map 58% reduce 0%
15/04/08 19:26:29 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 19:26:30 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 19:26:44 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 19:26:45 INFO mapreduce.Job:  map 72% reduce 0%
15/04/08 19:26:46 INFO mapreduce.Job:  map 82% reduce 0%
15/04/08 19:26:47 INFO mapreduce.Job:  map 92% reduce 0%
15/04/08 19:26:48 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 19:26:49 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 19:26:50 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 19:26:58 INFO mapreduce.Job:  map 100% reduce 26%
15/04/08 19:27:01 INFO mapreduce.Job:  map 100% reduce 27%
15/04/08 19:27:07 INFO mapreduce.Job:  map 100% reduce 28%
15/04/08 19:27:11 INFO mapreduce.Job:  map 100% reduce 29%
15/04/08 19:27:14 INFO mapreduce.Job:  map 100% reduce 30%
15/04/08 19:27:16 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 19:27:17 INFO mapreduce.Job:  map 100% reduce 32%
15/04/08 19:27:19 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 19:27:20 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 19:27:22 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 19:27:23 INFO mapreduce.Job:  map 100% reduce 48%
15/04/08 19:27:25 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 19:27:26 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 19:27:28 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 19:27:29 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 19:27:32 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 19:27:35 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 19:27:38 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 19:27:41 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 19:27:44 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 19:27:47 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 19:27:53 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 19:27:56 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 19:27:59 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 19:28:02 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 19:28:08 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 19:28:13 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 19:28:21 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 19:28:24 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 19:28:30 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 19:28:33 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 19:28:39 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 19:28:46 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 19:28:55 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 19:28:58 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 19:29:04 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 19:29:07 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 19:29:15 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 19:29:24 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 19:29:31 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 19:29:37 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 19:29:42 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 19:29:45 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 19:29:51 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 19:30:04 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 19:30:15 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 19:30:34 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 19:30:40 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 19:31:14 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 19:31:26 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 19:31:43 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 19:32:13 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 19:32:31 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 19:32:54 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 19:35:48 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 19:36:12 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 19:38:15 INFO mapreduce.Job: Job job_1422482982071_4288 completed successfully
15/04/08 19:38:15 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=30424216033
		FILE: Number of bytes written=60863136766
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=462
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=134
		Launched reduce tasks=21
		Data-local map tasks=63
		Rack-local map tasks=71
		Total time spent by all maps in occupied slots (ms)=10309606
		Total time spent by all reduces in occupied slots (ms)=11483016
		Total time spent by all map tasks (ms)=5154803
		Total time spent by all reduce tasks (ms)=5741508
		Total vcore-seconds taken by all map tasks=5154803
		Total vcore-seconds taken by all reduce tasks=5741508
		Total megabyte-seconds taken by all map tasks=41733285088
		Total megabyte-seconds taken by all reduce tasks=68898096000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424231873
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424231873
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =2680
		Failed Shuffles=0
		Merged Map outputs=2680
		GC time elapsed (ms)=207839
		CPU time spent (ms)=13002550
		Physical memory (bytes) snapshot=295945588736
		Virtual memory (bytes) snapshot=1497570930688
		Total committed heap usage (bytes)=413237583872
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/08 19:38:15 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	12m24.077s
user	0m16.412s
sys	0m1.028s
15/04/08 19:38:17 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 20
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-20-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2790246521794428277.jar tmpDir=null
15/04/08 19:38:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 19:38:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 19:38:21 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 19:38:21 INFO mapreduce.JobSubmitter: number of splits:134
15/04/08 19:38:22 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4289
15/04/08 19:38:22 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4289
15/04/08 19:38:22 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4289/
15/04/08 19:38:22 INFO mapreduce.Job: Running job: job_1422482982071_4289
15/04/08 19:38:28 INFO mapreduce.Job: Job job_1422482982071_4289 running in uber mode : false
15/04/08 19:38:28 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 19:38:39 INFO mapreduce.Job:  map 15% reduce 0%
15/04/08 19:38:40 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 19:38:42 INFO mapreduce.Job:  map 28% reduce 0%
15/04/08 19:38:43 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 19:38:44 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 19:38:45 INFO mapreduce.Job:  map 41% reduce 0%
15/04/08 19:38:46 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 19:38:48 INFO mapreduce.Job:  map 53% reduce 0%
15/04/08 19:38:49 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 19:38:52 INFO mapreduce.Job:  map 64% reduce 0%
15/04/08 19:38:53 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 19:39:08 INFO mapreduce.Job:  map 70% reduce 0%
15/04/08 19:39:09 INFO mapreduce.Job:  map 78% reduce 0%
15/04/08 19:39:10 INFO mapreduce.Job:  map 89% reduce 0%
15/04/08 19:39:11 INFO mapreduce.Job:  map 94% reduce 0%
15/04/08 19:39:12 INFO mapreduce.Job:  map 98% reduce 0%
15/04/08 19:39:13 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 19:39:14 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 19:39:19 INFO mapreduce.Job:  map 100% reduce 13%
15/04/08 19:39:20 INFO mapreduce.Job:  map 100% reduce 22%
15/04/08 19:39:22 INFO mapreduce.Job:  map 100% reduce 24%
15/04/08 19:39:23 INFO mapreduce.Job:  map 100% reduce 26%
15/04/08 19:39:26 INFO mapreduce.Job:  map 100% reduce 27%
15/04/08 19:39:29 INFO mapreduce.Job:  map 100% reduce 28%
15/04/08 19:39:32 INFO mapreduce.Job:  map 100% reduce 29%
15/04/08 19:39:35 INFO mapreduce.Job:  map 100% reduce 30%
15/04/08 19:39:38 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 19:39:41 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 19:39:43 INFO mapreduce.Job:  map 100% reduce 38%
15/04/08 19:39:44 INFO mapreduce.Job:  map 100% reduce 42%
15/04/08 19:39:46 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 19:39:47 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 19:39:49 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 19:39:50 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 19:39:52 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 19:39:53 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 19:39:54 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 19:39:55 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 19:39:56 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 19:39:59 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 19:40:02 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 19:40:05 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 19:40:08 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 19:40:11 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 19:40:14 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 19:40:17 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 19:40:20 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 19:40:23 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 19:40:29 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 19:40:32 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 19:40:38 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 19:40:41 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 19:40:47 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 19:40:52 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 19:40:56 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 19:41:02 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 19:41:08 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 19:41:18 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 19:41:21 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 19:41:27 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 19:41:30 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 19:41:36 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 19:41:45 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 19:41:51 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 19:41:57 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 19:42:00 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 19:42:09 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 19:42:20 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 19:42:26 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 19:42:36 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 19:42:51 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 19:42:59 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 19:43:24 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 19:43:39 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 19:43:58 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 19:44:35 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 19:45:02 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 19:45:14 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 19:48:30 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 19:48:55 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 19:50:50 INFO mapreduce.Job: Job job_1422482982071_4289 completed successfully
15/04/08 19:50:50 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=30424216033
		FILE: Number of bytes written=60863136766
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=462
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=134
		Launched reduce tasks=21
		Data-local map tasks=63
		Rack-local map tasks=71
		Total time spent by all maps in occupied slots (ms)=10349662
		Total time spent by all reduces in occupied slots (ms)=11416254
		Total time spent by all map tasks (ms)=5174831
		Total time spent by all reduce tasks (ms)=5708127
		Total vcore-seconds taken by all map tasks=5174831
		Total vcore-seconds taken by all reduce tasks=5708127
		Total megabyte-seconds taken by all map tasks=41895431776
		Total megabyte-seconds taken by all reduce tasks=68497524000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424231873
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424231873
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =2680
		Failed Shuffles=0
		Merged Map outputs=2680
		GC time elapsed (ms)=214072
		CPU time spent (ms)=12952250
		Physical memory (bytes) snapshot=296386256896
		Virtual memory (bytes) snapshot=1496174153728
		Total committed heap usage (bytes)=413352153088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/08 19:50:50 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	12m34.816s
user	0m15.204s
sys	0m0.997s
15/04/08 19:50:53 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 20
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-20-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5217279128005376000.jar tmpDir=null
15/04/08 19:50:56 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 19:50:56 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 19:50:57 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 19:50:57 INFO mapreduce.JobSubmitter: number of splits:134
15/04/08 19:50:58 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4290
15/04/08 19:50:58 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4290
15/04/08 19:50:58 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4290/
15/04/08 19:50:58 INFO mapreduce.Job: Running job: job_1422482982071_4290
15/04/08 19:51:03 INFO mapreduce.Job: Job job_1422482982071_4290 running in uber mode : false
15/04/08 19:51:03 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 19:51:14 INFO mapreduce.Job:  map 8% reduce 0%
15/04/08 19:51:15 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 19:51:17 INFO mapreduce.Job:  map 24% reduce 0%
15/04/08 19:51:18 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 19:51:21 INFO mapreduce.Job:  map 36% reduce 0%
15/04/08 19:51:22 INFO mapreduce.Job:  map 43% reduce 0%
15/04/08 19:51:23 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 19:51:24 INFO mapreduce.Job:  map 48% reduce 0%
15/04/08 19:51:25 INFO mapreduce.Job:  map 55% reduce 0%
15/04/08 19:51:26 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 19:51:27 INFO mapreduce.Job:  map 59% reduce 0%
15/04/08 19:51:28 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 19:51:30 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 19:51:42 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 19:51:43 INFO mapreduce.Job:  map 70% reduce 0%
15/04/08 19:51:44 INFO mapreduce.Job:  map 74% reduce 0%
15/04/08 19:51:45 INFO mapreduce.Job:  map 84% reduce 0%
15/04/08 19:51:46 INFO mapreduce.Job:  map 92% reduce 0%
15/04/08 19:51:47 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 19:51:48 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 19:51:49 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 19:51:54 INFO mapreduce.Job:  map 100% reduce 8%
15/04/08 19:51:55 INFO mapreduce.Job:  map 100% reduce 26%
15/04/08 19:52:01 INFO mapreduce.Job:  map 100% reduce 27%
15/04/08 19:52:04 INFO mapreduce.Job:  map 100% reduce 28%
15/04/08 19:52:07 INFO mapreduce.Job:  map 100% reduce 29%
15/04/08 19:52:10 INFO mapreduce.Job:  map 100% reduce 30%
15/04/08 19:52:13 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 19:52:16 INFO mapreduce.Job:  map 100% reduce 34%
15/04/08 19:52:19 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 19:52:20 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 19:52:22 INFO mapreduce.Job:  map 100% reduce 48%
15/04/08 19:52:24 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 19:52:25 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 19:52:28 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 19:52:31 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 19:52:32 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 19:52:35 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 19:52:37 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 19:52:40 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 19:52:43 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 19:52:46 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 19:52:47 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 19:52:50 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 19:52:53 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 19:52:58 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 19:53:01 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 19:53:04 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 19:53:07 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 19:53:11 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 19:53:17 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 19:53:22 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 19:53:27 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 19:53:31 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 19:53:37 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 19:53:45 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 19:53:53 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 19:53:57 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 19:54:05 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 19:54:12 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 19:54:16 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 19:54:24 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 19:54:27 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 19:54:33 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 19:54:40 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 19:54:49 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 19:54:52 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 19:55:04 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 19:55:15 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 19:55:31 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 19:55:43 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 19:56:10 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 19:56:26 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 19:56:47 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 19:57:18 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 19:57:38 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 19:58:18 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 20:01:04 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 20:01:29 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 20:03:28 INFO mapreduce.Job: Job job_1422482982071_4290 completed successfully
15/04/08 20:03:28 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=30424216033
		FILE: Number of bytes written=60863136766
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=462
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=134
		Launched reduce tasks=21
		Data-local map tasks=62
		Rack-local map tasks=72
		Total time spent by all maps in occupied slots (ms)=10335836
		Total time spent by all reduces in occupied slots (ms)=11612442
		Total time spent by all map tasks (ms)=5167918
		Total time spent by all reduce tasks (ms)=5806221
		Total vcore-seconds taken by all map tasks=5167918
		Total vcore-seconds taken by all reduce tasks=5806221
		Total megabyte-seconds taken by all map tasks=41839464128
		Total megabyte-seconds taken by all reduce tasks=69674652000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424231873
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424231873
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =2680
		Failed Shuffles=0
		Merged Map outputs=2680
		GC time elapsed (ms)=226397
		CPU time spent (ms)=13137900
		Physical memory (bytes) snapshot=296298942464
		Virtual memory (bytes) snapshot=1497172897792
		Total committed heap usage (bytes)=413236662272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/08 20:03:28 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	12m38.016s
user	0m16.105s
sys	0m1.103s
15/04/08 20:03:31 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 10
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-10-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2659656185743783242.jar tmpDir=null
15/04/08 20:03:34 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 20:03:34 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 20:03:34 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 20:03:35 INFO mapreduce.JobSubmitter: number of splits:134
15/04/08 20:03:35 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4291
15/04/08 20:03:36 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4291
15/04/08 20:03:36 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4291/
15/04/08 20:03:36 INFO mapreduce.Job: Running job: job_1422482982071_4291
15/04/08 20:03:42 INFO mapreduce.Job: Job job_1422482982071_4291 running in uber mode : false
15/04/08 20:03:42 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 20:03:53 INFO mapreduce.Job:  map 8% reduce 0%
15/04/08 20:03:54 INFO mapreduce.Job:  map 18% reduce 0%
15/04/08 20:03:55 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 20:03:56 INFO mapreduce.Job:  map 24% reduce 0%
15/04/08 20:03:57 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 20:03:58 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 20:03:59 INFO mapreduce.Job:  map 36% reduce 0%
15/04/08 20:04:00 INFO mapreduce.Job:  map 43% reduce 0%
15/04/08 20:04:01 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 20:04:02 INFO mapreduce.Job:  map 48% reduce 0%
15/04/08 20:04:03 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 20:04:04 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 20:04:05 INFO mapreduce.Job:  map 60% reduce 0%
15/04/08 20:04:06 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 20:04:07 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 20:04:22 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 20:04:23 INFO mapreduce.Job:  map 78% reduce 0%
15/04/08 20:04:24 INFO mapreduce.Job:  map 83% reduce 0%
15/04/08 20:04:25 INFO mapreduce.Job:  map 89% reduce 0%
15/04/08 20:04:27 INFO mapreduce.Job:  map 96% reduce 0%
15/04/08 20:04:28 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 20:04:29 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 20:04:35 INFO mapreduce.Job:  map 100% reduce 6%
15/04/08 20:04:36 INFO mapreduce.Job:  map 100% reduce 13%
15/04/08 20:04:57 INFO mapreduce.Job:  map 100% reduce 14%
15/04/08 20:05:00 INFO mapreduce.Job:  map 100% reduce 21%
15/04/08 20:05:03 INFO mapreduce.Job:  map 100% reduce 24%
15/04/08 20:05:06 INFO mapreduce.Job:  map 100% reduce 25%
15/04/08 20:05:09 INFO mapreduce.Job:  map 100% reduce 26%
15/04/08 20:05:15 INFO mapreduce.Job:  map 100% reduce 27%
15/04/08 20:05:21 INFO mapreduce.Job:  map 100% reduce 28%
15/04/08 20:05:24 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 20:05:27 INFO mapreduce.Job:  map 100% reduce 35%
15/04/08 20:05:28 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 20:05:31 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 20:05:33 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 20:05:36 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 20:05:39 INFO mapreduce.Job:  map 100% reduce 42%
15/04/08 20:05:48 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 20:05:51 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 20:05:54 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 20:05:55 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 20:05:57 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 20:06:00 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 20:06:01 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 20:06:03 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 20:06:06 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 20:06:11 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 20:06:12 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 20:06:15 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 20:06:19 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 20:06:22 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 20:06:28 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 20:06:33 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 20:06:39 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 20:06:46 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 20:07:09 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 20:07:29 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 20:07:41 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 20:07:56 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 20:08:09 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 20:08:27 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 20:08:39 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 20:09:03 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 20:09:12 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 20:09:27 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 20:09:43 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 20:09:53 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 20:10:05 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 20:10:31 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 20:10:46 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 20:10:53 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 20:10:59 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 20:11:17 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 20:11:41 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 20:11:59 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 20:12:17 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 20:12:36 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 20:12:55 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 20:13:21 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 20:13:46 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 20:14:05 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 20:15:13 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 20:16:41 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 20:17:23 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 20:18:33 INFO mapreduce.Job: Job job_1422482982071_4291 completed successfully
15/04/08 20:18:33 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=30424216009
		FILE: Number of bytes written=60862147202
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=432
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Launched map tasks=134
		Launched reduce tasks=10
		Data-local map tasks=70
		Rack-local map tasks=64
		Total time spent by all maps in occupied slots (ms)=10603260
		Total time spent by all reduces in occupied slots (ms)=11215132
		Total time spent by all map tasks (ms)=5301630
		Total time spent by all reduce tasks (ms)=5607566
		Total vcore-seconds taken by all map tasks=5301630
		Total vcore-seconds taken by all reduce tasks=5607566
		Total megabyte-seconds taken by all map tasks=42921996480
		Total megabyte-seconds taken by all reduce tasks=67290792000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424223833
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424223833
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =1340
		Failed Shuffles=0
		Merged Map outputs=1340
		GC time elapsed (ms)=236037
		CPU time spent (ms)=13274910
		Physical memory (bytes) snapshot=284402827264
		Virtual memory (bytes) snapshot=1364331778048
		Total committed heap usage (bytes)=392186662912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/08 20:18:33 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	15m4.657s
user	0m16.058s
sys	0m1.103s
15/04/08 20:18:35 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 10
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-10-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob9083200672444134184.jar tmpDir=null
15/04/08 20:18:38 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 20:18:38 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 20:18:39 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 20:18:39 INFO mapreduce.JobSubmitter: number of splits:134
15/04/08 20:18:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4292
15/04/08 20:18:40 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4292
15/04/08 20:18:40 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4292/
15/04/08 20:18:40 INFO mapreduce.Job: Running job: job_1422482982071_4292
15/04/08 20:18:46 INFO mapreduce.Job: Job job_1422482982071_4292 running in uber mode : false
15/04/08 20:18:46 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 20:18:57 INFO mapreduce.Job:  map 14% reduce 0%
15/04/08 20:18:58 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 20:19:00 INFO mapreduce.Job:  map 28% reduce 0%
15/04/08 20:19:01 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 20:19:03 INFO mapreduce.Job:  map 40% reduce 0%
15/04/08 20:19:04 INFO mapreduce.Job:  map 43% reduce 0%
15/04/08 20:19:05 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 20:19:06 INFO mapreduce.Job:  map 53% reduce 0%
15/04/08 20:19:07 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 20:19:09 INFO mapreduce.Job:  map 63% reduce 0%
15/04/08 20:19:10 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 20:19:11 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 20:19:25 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 20:19:26 INFO mapreduce.Job:  map 72% reduce 0%
15/04/08 20:19:27 INFO mapreduce.Job:  map 81% reduce 0%
15/04/08 20:19:28 INFO mapreduce.Job:  map 87% reduce 0%
15/04/08 20:19:30 INFO mapreduce.Job:  map 93% reduce 0%
15/04/08 20:19:31 INFO mapreduce.Job:  map 98% reduce 0%
15/04/08 20:19:32 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 20:19:33 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 20:19:36 INFO mapreduce.Job:  map 100% reduce 4%
15/04/08 20:19:37 INFO mapreduce.Job:  map 100% reduce 12%
15/04/08 20:19:38 INFO mapreduce.Job:  map 100% reduce 13%
15/04/08 20:19:58 INFO mapreduce.Job:  map 100% reduce 14%
15/04/08 20:20:01 INFO mapreduce.Job:  map 100% reduce 18%
15/04/08 20:20:02 INFO mapreduce.Job:  map 100% reduce 19%
15/04/08 20:20:04 INFO mapreduce.Job:  map 100% reduce 21%
15/04/08 20:20:05 INFO mapreduce.Job:  map 100% reduce 24%
15/04/08 20:20:07 INFO mapreduce.Job:  map 100% reduce 25%
15/04/08 20:20:10 INFO mapreduce.Job:  map 100% reduce 26%
15/04/08 20:20:17 INFO mapreduce.Job:  map 100% reduce 27%
15/04/08 20:20:22 INFO mapreduce.Job:  map 100% reduce 29%
15/04/08 20:20:23 INFO mapreduce.Job:  map 100% reduce 30%
15/04/08 20:20:25 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 20:20:26 INFO mapreduce.Job:  map 100% reduce 32%
15/04/08 20:20:28 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 20:20:29 INFO mapreduce.Job:  map 100% reduce 35%
15/04/08 20:20:32 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 20:20:35 INFO mapreduce.Job:  map 100% reduce 38%
15/04/08 20:20:38 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 20:20:40 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 20:20:41 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 20:20:44 INFO mapreduce.Job:  map 100% reduce 42%
15/04/08 20:20:52 INFO mapreduce.Job:  map 100% reduce 44%
15/04/08 20:20:53 INFO mapreduce.Job:  map 100% reduce 48%
15/04/08 20:20:55 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 20:20:56 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 20:20:59 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 20:21:02 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 20:21:03 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 20:21:05 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 20:21:07 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 20:21:09 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 20:21:11 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 20:21:13 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 20:21:16 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 20:21:19 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 20:21:23 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 20:21:29 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 20:21:35 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 20:21:39 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 20:21:51 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 20:22:09 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 20:22:28 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 20:22:42 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 20:22:58 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 20:23:06 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 20:23:28 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 20:23:35 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 20:23:55 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 20:24:16 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 20:24:23 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 20:24:39 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 20:24:50 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 20:25:01 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 20:25:28 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 20:25:42 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 20:26:00 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 20:26:19 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 20:26:42 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 20:26:51 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 20:27:11 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 20:27:34 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 20:27:57 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 20:28:17 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 20:28:56 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 20:29:16 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 20:29:17 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 20:29:33 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 20:31:08 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 20:32:39 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 20:33:55 INFO mapreduce.Job: Job job_1422482982071_4292 completed successfully
15/04/08 20:33:55 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=30424216009
		FILE: Number of bytes written=60862147202
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=432
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Launched map tasks=134
		Launched reduce tasks=10
		Data-local map tasks=64
		Rack-local map tasks=70
		Total time spent by all maps in occupied slots (ms)=10606034
		Total time spent by all reduces in occupied slots (ms)=11124454
		Total time spent by all map tasks (ms)=5303017
		Total time spent by all reduce tasks (ms)=5562227
		Total vcore-seconds taken by all map tasks=5303017
		Total vcore-seconds taken by all reduce tasks=5562227
		Total megabyte-seconds taken by all map tasks=42933225632
		Total megabyte-seconds taken by all reduce tasks=66746724000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424223833
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424223833
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =1340
		Failed Shuffles=0
		Merged Map outputs=1340
		GC time elapsed (ms)=220808
		CPU time spent (ms)=13213690
		Physical memory (bytes) snapshot=284485079040
		Virtual memory (bytes) snapshot=1363539546112
		Total committed heap usage (bytes)=392260722688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/08 20:33:55 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	15m22.027s
user	0m15.759s
sys	0m1.137s
15/04/08 20:33:57 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 10
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-10-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4866056107824917762.jar tmpDir=null
15/04/08 20:34:00 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 20:34:00 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 20:34:01 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 20:34:01 INFO mapreduce.JobSubmitter: number of splits:134
15/04/08 20:34:01 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4293
15/04/08 20:34:02 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4293
15/04/08 20:34:02 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4293/
15/04/08 20:34:02 INFO mapreduce.Job: Running job: job_1422482982071_4293
15/04/08 20:34:08 INFO mapreduce.Job: Job job_1422482982071_4293 running in uber mode : false
15/04/08 20:34:08 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 20:34:19 INFO mapreduce.Job:  map 6% reduce 0%
15/04/08 20:34:20 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 20:34:22 INFO mapreduce.Job:  map 22% reduce 0%
15/04/08 20:34:23 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 20:34:24 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 20:34:25 INFO mapreduce.Job:  map 35% reduce 0%
15/04/08 20:34:26 INFO mapreduce.Job:  map 43% reduce 0%
15/04/08 20:34:27 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 20:34:28 INFO mapreduce.Job:  map 47% reduce 0%
15/04/08 20:34:29 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 20:34:30 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 20:34:31 INFO mapreduce.Job:  map 58% reduce 0%
15/04/08 20:34:32 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 20:34:33 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 20:34:47 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 20:34:48 INFO mapreduce.Job:  map 70% reduce 0%
15/04/08 20:34:49 INFO mapreduce.Job:  map 76% reduce 0%
15/04/08 20:34:50 INFO mapreduce.Job:  map 85% reduce 0%
15/04/08 20:34:51 INFO mapreduce.Job:  map 91% reduce 0%
15/04/08 20:34:52 INFO mapreduce.Job:  map 97% reduce 0%
15/04/08 20:34:53 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 20:34:54 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 20:34:58 INFO mapreduce.Job:  map 100% reduce 5%
15/04/08 20:34:59 INFO mapreduce.Job:  map 100% reduce 13%
15/04/08 20:35:23 INFO mapreduce.Job:  map 100% reduce 16%
15/04/08 20:35:25 INFO mapreduce.Job:  map 100% reduce 18%
15/04/08 20:35:26 INFO mapreduce.Job:  map 100% reduce 19%
15/04/08 20:35:27 INFO mapreduce.Job:  map 100% reduce 22%
15/04/08 20:35:28 INFO mapreduce.Job:  map 100% reduce 23%
15/04/08 20:35:30 INFO mapreduce.Job:  map 100% reduce 25%
15/04/08 20:35:34 INFO mapreduce.Job:  map 100% reduce 26%
15/04/08 20:35:40 INFO mapreduce.Job:  map 100% reduce 27%
15/04/08 20:35:46 INFO mapreduce.Job:  map 100% reduce 28%
15/04/08 20:35:48 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 20:35:49 INFO mapreduce.Job:  map 100% reduce 32%
15/04/08 20:35:51 INFO mapreduce.Job:  map 100% reduce 34%
15/04/08 20:35:52 INFO mapreduce.Job:  map 100% reduce 35%
15/04/08 20:35:55 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 20:35:57 INFO mapreduce.Job:  map 100% reduce 38%
15/04/08 20:35:58 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 20:36:01 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 20:36:04 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 20:36:07 INFO mapreduce.Job:  map 100% reduce 42%
15/04/08 20:36:13 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 20:36:15 INFO mapreduce.Job:  map 100% reduce 46%
15/04/08 20:36:18 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 20:36:20 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 20:36:21 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 20:36:23 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 20:36:24 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 20:36:26 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 20:36:28 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 20:36:30 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 20:36:32 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 20:36:33 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 20:36:35 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 20:36:38 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 20:36:41 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 20:36:46 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 20:36:52 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 20:36:58 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 20:37:01 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 20:37:10 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 20:37:31 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 20:37:57 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 20:38:03 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 20:38:21 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 20:38:31 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 20:38:48 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 20:39:00 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 20:39:23 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 20:39:35 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 20:39:49 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 20:40:02 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 20:40:17 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 20:40:30 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 20:40:54 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 20:41:12 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 20:41:19 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 20:41:28 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 20:41:46 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 20:42:05 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 20:42:15 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 20:42:31 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 20:42:55 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 20:43:16 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 20:43:38 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 20:44:18 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 20:44:36 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 20:44:42 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 20:45:21 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 20:46:13 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 20:48:05 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 20:49:23 INFO mapreduce.Job: Job job_1422482982071_4293 completed successfully
15/04/08 20:49:24 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=30424216009
		FILE: Number of bytes written=60862147202
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=432
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Launched map tasks=134
		Launched reduce tasks=10
		Data-local map tasks=64
		Rack-local map tasks=70
		Total time spent by all maps in occupied slots (ms)=10550588
		Total time spent by all reduces in occupied slots (ms)=11181966
		Total time spent by all map tasks (ms)=5275294
		Total time spent by all reduce tasks (ms)=5590983
		Total vcore-seconds taken by all map tasks=5275294
		Total vcore-seconds taken by all reduce tasks=5590983
		Total megabyte-seconds taken by all map tasks=42708780224
		Total megabyte-seconds taken by all reduce tasks=67091796000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424223833
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424223833
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =1340
		Failed Shuffles=0
		Merged Map outputs=1340
		GC time elapsed (ms)=216089
		CPU time spent (ms)=13231520
		Physical memory (bytes) snapshot=284764233728
		Virtual memory (bytes) snapshot=1363743633408
		Total committed heap usage (bytes)=392408821760
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/08 20:49:24 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	15m28.652s
user	0m16.241s
sys	0m1.143s
15/04/08 20:49:26 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 5
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-5-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob643788388538971767.jar tmpDir=null
15/04/08 20:49:29 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 20:49:29 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 20:49:30 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 20:49:30 INFO mapreduce.JobSubmitter: number of splits:134
15/04/08 20:49:31 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4294
15/04/08 20:49:31 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4294
15/04/08 20:49:31 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4294/
15/04/08 20:49:31 INFO mapreduce.Job: Running job: job_1422482982071_4294
15/04/08 20:49:37 INFO mapreduce.Job: Job job_1422482982071_4294 running in uber mode : false
15/04/08 20:49:37 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 20:49:49 INFO mapreduce.Job:  map 13% reduce 0%
15/04/08 20:49:50 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 20:49:52 INFO mapreduce.Job:  map 27% reduce 0%
15/04/08 20:49:53 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 20:49:55 INFO mapreduce.Job:  map 39% reduce 0%
15/04/08 20:49:56 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 20:49:58 INFO mapreduce.Job:  map 52% reduce 0%
15/04/08 20:49:59 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 20:50:01 INFO mapreduce.Job:  map 63% reduce 0%
15/04/08 20:50:02 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 20:50:17 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 20:50:18 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 20:50:19 INFO mapreduce.Job:  map 74% reduce 0%
15/04/08 20:50:20 INFO mapreduce.Job:  map 85% reduce 0%
15/04/08 20:50:21 INFO mapreduce.Job:  map 91% reduce 0%
15/04/08 20:50:22 INFO mapreduce.Job:  map 96% reduce 0%
15/04/08 20:50:23 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 20:50:24 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 20:50:27 INFO mapreduce.Job:  map 100% reduce 3%
15/04/08 20:50:28 INFO mapreduce.Job:  map 100% reduce 4%
15/04/08 20:50:29 INFO mapreduce.Job:  map 100% reduce 7%
15/04/08 20:50:52 INFO mapreduce.Job:  map 100% reduce 8%
15/04/08 20:50:55 INFO mapreduce.Job:  map 100% reduce 10%
15/04/08 20:50:56 INFO mapreduce.Job:  map 100% reduce 12%
15/04/08 20:50:58 INFO mapreduce.Job:  map 100% reduce 13%
15/04/08 20:51:19 INFO mapreduce.Job:  map 100% reduce 16%
15/04/08 20:51:23 INFO mapreduce.Job:  map 100% reduce 17%
15/04/08 20:51:26 INFO mapreduce.Job:  map 100% reduce 18%
15/04/08 20:51:27 INFO mapreduce.Job:  map 100% reduce 19%
15/04/08 20:51:43 INFO mapreduce.Job:  map 100% reduce 20%
15/04/08 20:51:47 INFO mapreduce.Job:  map 100% reduce 21%
15/04/08 20:51:50 INFO mapreduce.Job:  map 100% reduce 22%
15/04/08 20:51:53 INFO mapreduce.Job:  map 100% reduce 23%
15/04/08 20:51:57 INFO mapreduce.Job:  map 100% reduce 24%
15/04/08 20:52:00 INFO mapreduce.Job:  map 100% reduce 25%
15/04/08 20:52:11 INFO mapreduce.Job:  map 100% reduce 26%
15/04/08 20:52:12 INFO mapreduce.Job:  map 100% reduce 27%
15/04/08 20:52:19 INFO mapreduce.Job:  map 100% reduce 28%
15/04/08 20:52:21 INFO mapreduce.Job:  map 100% reduce 29%
15/04/08 20:52:28 INFO mapreduce.Job:  map 100% reduce 30%
15/04/08 20:52:36 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 20:52:46 INFO mapreduce.Job:  map 100% reduce 38%
15/04/08 20:52:49 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 20:52:50 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 20:52:52 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 20:52:58 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 20:53:01 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 20:53:03 INFO mapreduce.Job:  map 100% reduce 46%
15/04/08 20:53:04 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 20:53:06 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 20:53:07 INFO mapreduce.Job:  map 100% reduce 51%
15/04/08 20:53:09 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 20:53:20 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 20:53:23 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 20:53:25 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 20:53:27 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 20:53:29 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 20:53:30 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 20:53:33 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 20:53:36 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 20:53:39 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 20:53:52 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 20:54:25 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 20:55:22 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 20:55:31 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 20:55:54 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 20:56:52 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 20:57:32 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 20:58:20 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 20:58:38 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 20:59:27 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 21:00:13 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 21:00:47 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 21:01:00 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 21:01:23 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 21:01:47 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 21:02:11 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 21:02:39 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 21:02:58 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 21:03:10 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 21:03:37 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 21:03:52 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 21:04:17 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 21:04:50 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 21:05:39 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 21:06:05 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 21:06:37 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 21:07:05 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 21:07:30 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 21:07:56 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 21:08:49 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 21:09:44 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 21:10:51 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 21:11:49 INFO mapreduce.Job: Job job_1422482982071_4294 completed successfully
15/04/08 21:11:49 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=30424215991
		FILE: Number of bytes written=60861652141
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=417
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Launched map tasks=134
		Launched reduce tasks=5
		Data-local map tasks=65
		Rack-local map tasks=69
		Total time spent by all maps in occupied slots (ms)=10706404
		Total time spent by all reduces in occupied slots (ms)=10958504
		Total time spent by all map tasks (ms)=5353202
		Total time spent by all reduce tasks (ms)=5479252
		Total vcore-seconds taken by all map tasks=5353202
		Total vcore-seconds taken by all reduce tasks=5479252
		Total megabyte-seconds taken by all map tasks=43339523392
		Total megabyte-seconds taken by all reduce tasks=65751024000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424219813
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424219813
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =670
		Failed Shuffles=0
		Merged Map outputs=670
		GC time elapsed (ms)=235784
		CPU time spent (ms)=13218230
		Physical memory (bytes) snapshot=273660940288
		Virtual memory (bytes) snapshot=1297114624000
		Total committed heap usage (bytes)=382730301440
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/08 21:11:49 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	22m25.847s
user	0m18.717s
sys	0m1.553s
15/04/08 21:11:52 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 5
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-5-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3558333550800550668.jar tmpDir=null
15/04/08 21:11:55 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 21:11:55 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 21:11:55 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 21:11:56 INFO mapreduce.JobSubmitter: number of splits:134
15/04/08 21:11:56 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4295
15/04/08 21:11:57 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4295
15/04/08 21:11:57 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4295/
15/04/08 21:11:57 INFO mapreduce.Job: Running job: job_1422482982071_4295
15/04/08 21:12:03 INFO mapreduce.Job: Job job_1422482982071_4295 running in uber mode : false
15/04/08 21:12:03 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 21:12:14 INFO mapreduce.Job:  map 7% reduce 0%
15/04/08 21:12:15 INFO mapreduce.Job:  map 18% reduce 0%
15/04/08 21:12:16 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 21:12:17 INFO mapreduce.Job:  map 23% reduce 0%
15/04/08 21:12:18 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 21:12:20 INFO mapreduce.Job:  map 35% reduce 0%
15/04/08 21:12:21 INFO mapreduce.Job:  map 43% reduce 0%
15/04/08 21:12:22 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 21:12:23 INFO mapreduce.Job:  map 47% reduce 0%
15/04/08 21:12:24 INFO mapreduce.Job:  map 55% reduce 0%
15/04/08 21:12:25 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 21:12:26 INFO mapreduce.Job:  map 59% reduce 0%
15/04/08 21:12:27 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 21:12:28 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 21:12:43 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 21:12:44 INFO mapreduce.Job:  map 72% reduce 0%
15/04/08 21:12:45 INFO mapreduce.Job:  map 80% reduce 0%
15/04/08 21:12:46 INFO mapreduce.Job:  map 87% reduce 0%
15/04/08 21:12:47 INFO mapreduce.Job:  map 92% reduce 0%
15/04/08 21:12:48 INFO mapreduce.Job:  map 98% reduce 0%
15/04/08 21:12:49 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 21:12:54 INFO mapreduce.Job:  map 100% reduce 5%
15/04/08 21:12:55 INFO mapreduce.Job:  map 100% reduce 7%
15/04/08 21:12:58 INFO mapreduce.Job:  map 100% reduce 8%
15/04/08 21:13:19 INFO mapreduce.Job:  map 100% reduce 9%
15/04/08 21:13:20 INFO mapreduce.Job:  map 100% reduce 10%
15/04/08 21:13:22 INFO mapreduce.Job:  map 100% reduce 11%
15/04/08 21:13:23 INFO mapreduce.Job:  map 100% reduce 12%
15/04/08 21:13:25 INFO mapreduce.Job:  map 100% reduce 13%
15/04/08 21:13:44 INFO mapreduce.Job:  map 100% reduce 14%
15/04/08 21:13:47 INFO mapreduce.Job:  map 100% reduce 16%
15/04/08 21:13:50 INFO mapreduce.Job:  map 100% reduce 17%
15/04/08 21:13:53 INFO mapreduce.Job:  map 100% reduce 18%
15/04/08 21:13:55 INFO mapreduce.Job:  map 100% reduce 19%
15/04/08 21:14:10 INFO mapreduce.Job:  map 100% reduce 20%
15/04/08 21:14:13 INFO mapreduce.Job:  map 100% reduce 22%
15/04/08 21:14:22 INFO mapreduce.Job:  map 100% reduce 23%
15/04/08 21:14:23 INFO mapreduce.Job:  map 100% reduce 24%
15/04/08 21:14:34 INFO mapreduce.Job:  map 100% reduce 25%
15/04/08 21:14:37 INFO mapreduce.Job:  map 100% reduce 27%
15/04/08 21:14:40 INFO mapreduce.Job:  map 100% reduce 28%
15/04/08 21:14:52 INFO mapreduce.Job:  map 100% reduce 29%
15/04/08 21:14:53 INFO mapreduce.Job:  map 100% reduce 30%
15/04/08 21:15:02 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 21:15:05 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 21:15:11 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 21:15:14 INFO mapreduce.Job:  map 100% reduce 42%
15/04/08 21:15:17 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 21:15:20 INFO mapreduce.Job:  map 100% reduce 44%
15/04/08 21:15:21 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 21:15:24 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 21:15:29 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 21:15:32 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 21:15:36 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 21:15:51 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 21:15:54 INFO mapreduce.Job:  map 100% reduce 58%
15/04/08 21:15:57 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 21:16:00 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 21:16:03 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 21:16:19 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 21:16:49 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 21:17:52 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 21:18:01 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 21:18:22 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 21:19:30 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 21:20:06 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 21:20:33 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 21:21:07 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 21:21:58 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 21:22:52 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 21:23:20 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 21:23:29 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 21:24:08 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 21:24:48 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 21:25:00 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 21:25:08 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 21:25:25 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 21:25:55 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 21:26:11 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 21:26:35 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 21:27:08 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 21:27:47 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 21:27:54 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 21:28:30 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 21:29:04 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 21:29:13 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 21:29:43 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 21:30:29 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 21:30:59 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 21:31:47 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 21:33:08 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 21:34:03 INFO mapreduce.Job: Job job_1422482982071_4295 completed successfully
15/04/08 21:34:03 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=30424215991
		FILE: Number of bytes written=60861652141
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=417
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Launched map tasks=134
		Launched reduce tasks=5
		Data-local map tasks=63
		Rack-local map tasks=71
		Total time spent by all maps in occupied slots (ms)=10750308
		Total time spent by all reduces in occupied slots (ms)=11015402
		Total time spent by all map tasks (ms)=5375154
		Total time spent by all reduce tasks (ms)=5507701
		Total vcore-seconds taken by all map tasks=5375154
		Total vcore-seconds taken by all reduce tasks=5507701
		Total megabyte-seconds taken by all map tasks=43517246784
		Total megabyte-seconds taken by all reduce tasks=66092412000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424219813
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424219813
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =670
		Failed Shuffles=0
		Merged Map outputs=670
		GC time elapsed (ms)=239921
		CPU time spent (ms)=13293490
		Physical memory (bytes) snapshot=274206474240
		Virtual memory (bytes) snapshot=1297100541952
		Total committed heap usage (bytes)=383248752640
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/08 21:34:03 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	22m13.797s
user	0m18.467s
sys	0m1.389s
15/04/08 21:34:06 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
50 5
py googlebooks-eng-all-5gram-20120701-st mapper.py reducer.py
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=py-50-5-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.py,./reducer.py  -mapper ./mapper.py -reducer ./reducer.py -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7428220046910298827.jar tmpDir=null
15/04/08 21:34:08 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 21:34:08 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 21:34:09 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 21:34:10 INFO mapreduce.JobSubmitter: number of splits:134
15/04/08 21:34:10 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4296
15/04/08 21:34:10 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4296
15/04/08 21:34:10 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4296/
15/04/08 21:34:10 INFO mapreduce.Job: Running job: job_1422482982071_4296
15/04/08 21:34:16 INFO mapreduce.Job: Job job_1422482982071_4296 running in uber mode : false
15/04/08 21:34:16 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 21:34:27 INFO mapreduce.Job:  map 14% reduce 0%
15/04/08 21:34:28 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 21:34:30 INFO mapreduce.Job:  map 28% reduce 0%
15/04/08 21:34:31 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 21:34:33 INFO mapreduce.Job:  map 40% reduce 0%
15/04/08 21:34:34 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 21:34:36 INFO mapreduce.Job:  map 53% reduce 0%
15/04/08 21:34:37 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 21:34:39 INFO mapreduce.Job:  map 63% reduce 0%
15/04/08 21:34:40 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 21:34:56 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 21:34:57 INFO mapreduce.Job:  map 76% reduce 0%
15/04/08 21:34:58 INFO mapreduce.Job:  map 84% reduce 0%
15/04/08 21:34:59 INFO mapreduce.Job:  map 89% reduce 0%
15/04/08 21:35:00 INFO mapreduce.Job:  map 96% reduce 0%
15/04/08 21:35:01 INFO mapreduce.Job:  map 98% reduce 0%
15/04/08 21:35:02 INFO mapreduce.Job:  map 99% reduce 0%
15/04/08 21:35:03 INFO mapreduce.Job:  map 100% reduce 0%
15/04/08 21:35:06 INFO mapreduce.Job:  map 100% reduce 1%
15/04/08 21:35:07 INFO mapreduce.Job:  map 100% reduce 4%
15/04/08 21:35:08 INFO mapreduce.Job:  map 100% reduce 7%
15/04/08 21:35:30 INFO mapreduce.Job:  map 100% reduce 8%
15/04/08 21:35:32 INFO mapreduce.Job:  map 100% reduce 9%
15/04/08 21:35:33 INFO mapreduce.Job:  map 100% reduce 10%
15/04/08 21:35:34 INFO mapreduce.Job:  map 100% reduce 11%
15/04/08 21:35:38 INFO mapreduce.Job:  map 100% reduce 12%
15/04/08 21:35:40 INFO mapreduce.Job:  map 100% reduce 13%
15/04/08 21:35:58 INFO mapreduce.Job:  map 100% reduce 15%
15/04/08 21:36:01 INFO mapreduce.Job:  map 100% reduce 16%
15/04/08 21:36:03 INFO mapreduce.Job:  map 100% reduce 17%
15/04/08 21:36:09 INFO mapreduce.Job:  map 100% reduce 18%
15/04/08 21:36:11 INFO mapreduce.Job:  map 100% reduce 19%
15/04/08 21:36:23 INFO mapreduce.Job:  map 100% reduce 20%
15/04/08 21:36:25 INFO mapreduce.Job:  map 100% reduce 21%
15/04/08 21:36:27 INFO mapreduce.Job:  map 100% reduce 22%
15/04/08 21:36:37 INFO mapreduce.Job:  map 100% reduce 23%
15/04/08 21:36:40 INFO mapreduce.Job:  map 100% reduce 24%
15/04/08 21:36:42 INFO mapreduce.Job:  map 100% reduce 25%
15/04/08 21:36:47 INFO mapreduce.Job:  map 100% reduce 26%
15/04/08 21:36:52 INFO mapreduce.Job:  map 100% reduce 27%
15/04/08 21:36:54 INFO mapreduce.Job:  map 100% reduce 28%
15/04/08 21:37:07 INFO mapreduce.Job:  map 100% reduce 29%
15/04/08 21:37:08 INFO mapreduce.Job:  map 100% reduce 31%
15/04/08 21:37:11 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 21:37:12 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 21:37:16 INFO mapreduce.Job:  map 100% reduce 38%
15/04/08 21:37:25 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 21:37:28 INFO mapreduce.Job:  map 100% reduce 40%
15/04/08 21:37:31 INFO mapreduce.Job:  map 100% reduce 41%
15/04/08 21:37:34 INFO mapreduce.Job:  map 100% reduce 42%
15/04/08 21:37:35 INFO mapreduce.Job:  map 100% reduce 43%
15/04/08 21:37:37 INFO mapreduce.Job:  map 100% reduce 44%
15/04/08 21:37:40 INFO mapreduce.Job:  map 100% reduce 45%
15/04/08 21:37:41 INFO mapreduce.Job:  map 100% reduce 46%
15/04/08 21:37:42 INFO mapreduce.Job:  map 100% reduce 47%
15/04/08 21:37:43 INFO mapreduce.Job:  map 100% reduce 48%
15/04/08 21:37:44 INFO mapreduce.Job:  map 100% reduce 50%
15/04/08 21:37:47 INFO mapreduce.Job:  map 100% reduce 53%
15/04/08 21:37:50 INFO mapreduce.Job:  map 100% reduce 54%
15/04/08 21:38:05 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 21:38:08 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 21:38:11 INFO mapreduce.Job:  map 100% reduce 59%
15/04/08 21:38:12 INFO mapreduce.Job:  map 100% reduce 61%
15/04/08 21:38:14 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 21:38:15 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 21:38:18 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 21:38:33 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 21:39:02 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 21:40:01 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 21:40:10 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 21:40:36 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 21:41:30 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 21:42:26 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 21:42:54 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 21:43:18 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 21:44:20 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 21:44:56 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 21:45:52 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 21:46:00 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 21:46:06 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 21:46:33 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 21:47:04 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 21:47:37 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 21:47:55 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 21:48:02 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 21:48:30 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 21:48:47 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 21:49:23 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 21:50:09 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 21:50:46 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 21:51:23 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 21:51:44 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 21:52:06 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 21:52:44 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 21:53:36 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 21:54:06 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 21:55:08 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 21:56:36 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 21:57:36 INFO mapreduce.Job: Job job_1422482982071_4296 completed successfully
15/04/08 21:57:36 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=30424215991
		FILE: Number of bytes written=60861652141
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=417
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Launched map tasks=134
		Launched reduce tasks=5
		Data-local map tasks=63
		Rack-local map tasks=71
		Total time spent by all maps in occupied slots (ms)=10730588
		Total time spent by all reduces in occupied slots (ms)=11277456
		Total time spent by all map tasks (ms)=5365294
		Total time spent by all reduce tasks (ms)=5638728
		Total vcore-seconds taken by all map tasks=5365294
		Total vcore-seconds taken by all reduce tasks=5638728
		Total megabyte-seconds taken by all map tasks=43437420224
		Total megabyte-seconds taken by all reduce tasks=67664736000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424219813
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424219813
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =670
		Failed Shuffles=0
		Merged Map outputs=670
		GC time elapsed (ms)=236655
		CPU time spent (ms)=13442650
		Physical memory (bytes) snapshot=273521233920
		Virtual memory (bytes) snapshot=1296735690752
		Total committed heap usage (bytes)=382573146112
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/08 21:57:36 INFO streaming.StreamJob: Output directory: ./out/stream-py-0-googlebooks-eng-all-5gram-20120701-st

real	23m32.641s
user	0m18.636s
sys	0m1.461s
50 40
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-40-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1154357444970554391.jar tmpDir=null
15/04/08 21:57:41 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 21:57:41 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 21:57:42 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 21:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 21:57:42 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 21:57:43 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4297
15/04/08 21:57:43 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4297
15/04/08 21:57:43 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4297/
15/04/08 21:57:43 INFO mapreduce.Job: Running job: job_1422482982071_4297
15/04/08 21:57:49 INFO mapreduce.Job: Job job_1422482982071_4297 running in uber mode : false
15/04/08 21:57:49 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 21:57:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4297_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 21:57:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4297_m_000049_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 21:57:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4297_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 21:57:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4297_m_000027_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 21:57:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4297_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 21:57:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4297_m_000018_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 21:57:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4297_m_000038_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 21:57:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4297_m_000041_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 21:57:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4297_m_000005_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 21:57:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4297_m_000043_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 21:58:01 INFO mapreduce.Job:  map 1% reduce 0%
15/04/08 21:58:07 INFO mapreduce.Job:  map 2% reduce 0%
15/04/08 21:58:13 INFO mapreduce.Job:  map 3% reduce 0%
15/04/08 21:58:18 INFO mapreduce.Job:  map 4% reduce 0%
15/04/08 21:58:23 INFO mapreduce.Job:  map 5% reduce 0%
15/04/08 21:58:29 INFO mapreduce.Job:  map 6% reduce 0%
15/04/08 21:58:35 INFO mapreduce.Job:  map 7% reduce 0%
15/04/08 21:58:41 INFO mapreduce.Job:  map 8% reduce 0%
15/04/08 21:58:47 INFO mapreduce.Job:  map 9% reduce 0%
15/04/08 21:58:53 INFO mapreduce.Job:  map 10% reduce 0%
15/04/08 21:58:58 INFO mapreduce.Job:  map 11% reduce 0%
15/04/08 21:59:03 INFO mapreduce.Job:  map 12% reduce 0%
15/04/08 21:59:09 INFO mapreduce.Job:  map 13% reduce 0%
15/04/08 21:59:15 INFO mapreduce.Job:  map 14% reduce 0%
15/04/08 21:59:21 INFO mapreduce.Job:  map 15% reduce 0%
15/04/08 21:59:26 INFO mapreduce.Job:  map 16% reduce 0%
15/04/08 21:59:32 INFO mapreduce.Job:  map 17% reduce 0%
15/04/08 21:59:38 INFO mapreduce.Job:  map 18% reduce 0%
15/04/08 21:59:44 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 21:59:48 INFO mapreduce.Job:  map 20% reduce 0%
15/04/08 21:59:54 INFO mapreduce.Job:  map 21% reduce 0%
15/04/08 22:00:00 INFO mapreduce.Job:  map 22% reduce 0%
15/04/08 22:00:06 INFO mapreduce.Job:  map 23% reduce 0%
15/04/08 22:00:12 INFO mapreduce.Job:  map 24% reduce 0%
15/04/08 22:00:18 INFO mapreduce.Job:  map 25% reduce 0%
15/04/08 22:00:25 INFO mapreduce.Job:  map 26% reduce 0%
15/04/08 22:00:30 INFO mapreduce.Job:  map 27% reduce 0%
15/04/08 22:00:35 INFO mapreduce.Job:  map 28% reduce 0%
15/04/08 22:00:41 INFO mapreduce.Job:  map 29% reduce 0%
15/04/08 22:00:47 INFO mapreduce.Job:  map 30% reduce 0%
15/04/08 22:00:53 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 22:00:58 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 22:01:04 INFO mapreduce.Job:  map 33% reduce 0%
15/04/08 22:01:10 INFO mapreduce.Job:  map 34% reduce 0%
15/04/08 22:01:16 INFO mapreduce.Job:  map 35% reduce 0%
15/04/08 22:01:21 INFO mapreduce.Job:  map 36% reduce 0%
15/04/08 22:01:27 INFO mapreduce.Job:  map 37% reduce 0%
15/04/08 22:01:32 INFO mapreduce.Job:  map 38% reduce 0%
15/04/08 22:01:38 INFO mapreduce.Job:  map 39% reduce 0%
15/04/08 22:01:44 INFO mapreduce.Job:  map 40% reduce 0%
15/04/08 22:01:50 INFO mapreduce.Job:  map 41% reduce 0%
15/04/08 22:01:56 INFO mapreduce.Job:  map 42% reduce 0%
15/04/08 22:02:01 INFO mapreduce.Job:  map 43% reduce 0%
15/04/08 22:02:07 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 22:02:13 INFO mapreduce.Job:  map 45% reduce 0%
15/04/08 22:02:18 INFO mapreduce.Job:  map 46% reduce 0%
15/04/08 22:02:24 INFO mapreduce.Job:  map 47% reduce 0%
15/04/08 22:02:30 INFO mapreduce.Job:  map 48% reduce 0%
15/04/08 22:02:36 INFO mapreduce.Job:  map 49% reduce 0%
15/04/08 22:02:42 INFO mapreduce.Job:  map 50% reduce 0%
15/04/08 22:02:47 INFO mapreduce.Job:  map 51% reduce 0%
15/04/08 22:02:53 INFO mapreduce.Job:  map 52% reduce 0%
15/04/08 22:03:00 INFO mapreduce.Job:  map 53% reduce 0%
15/04/08 22:03:05 INFO mapreduce.Job:  map 54% reduce 0%
15/04/08 22:03:11 INFO mapreduce.Job:  map 55% reduce 0%
15/04/08 22:03:17 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 22:03:22 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 22:03:28 INFO mapreduce.Job:  map 58% reduce 0%
15/04/08 22:03:34 INFO mapreduce.Job:  map 59% reduce 0%
15/04/08 22:03:40 INFO mapreduce.Job:  map 60% reduce 0%
15/04/08 22:03:45 INFO mapreduce.Job:  map 61% reduce 0%
15/04/08 22:03:51 INFO mapreduce.Job:  map 62% reduce 0%
15/04/08 22:03:57 INFO mapreduce.Job:  map 63% reduce 0%
15/04/08 22:04:03 INFO mapreduce.Job:  map 64% reduce 0%
15/04/08 22:04:09 INFO mapreduce.Job:  map 65% reduce 0%
15/04/08 22:04:13 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 22:04:14 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 22:04:18 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 22:04:20 INFO mapreduce.Job:  map 70% reduce 0%
15/04/08 22:04:22 INFO mapreduce.Job:  map 72% reduce 0%
15/04/08 22:04:25 INFO mapreduce.Job:  map 73% reduce 0%
15/04/08 22:04:26 INFO mapreduce.Job:  map 74% reduce 0%
15/04/08 22:04:27 INFO mapreduce.Job:  map 75% reduce 0%
15/04/08 22:04:28 INFO mapreduce.Job:  map 77% reduce 0%
15/04/08 22:04:29 INFO mapreduce.Job:  map 78% reduce 8%
15/04/08 22:04:30 INFO mapreduce.Job:  map 79% reduce 11%
15/04/08 22:04:32 INFO mapreduce.Job:  map 81% reduce 13%
15/04/08 22:04:33 INFO mapreduce.Job:  map 83% reduce 14%
15/04/08 22:04:34 INFO mapreduce.Job:  map 87% reduce 14%
15/04/08 22:04:35 INFO mapreduce.Job:  map 89% reduce 20%
15/04/08 22:04:36 INFO mapreduce.Job:  map 90% reduce 22%
15/04/08 22:04:37 INFO mapreduce.Job:  map 91% reduce 22%
15/04/08 22:04:38 INFO mapreduce.Job:  map 93% reduce 25%
15/04/08 22:04:39 INFO mapreduce.Job:  map 93% reduce 27%
15/04/08 22:04:40 INFO mapreduce.Job:  map 95% reduce 27%
15/04/08 22:04:41 INFO mapreduce.Job:  map 95% reduce 28%
15/04/08 22:04:42 INFO mapreduce.Job:  map 96% reduce 29%
15/04/08 22:04:44 INFO mapreduce.Job:  map 97% reduce 30%
15/04/08 22:04:48 INFO mapreduce.Job:  map 97% reduce 31%
15/04/08 22:04:54 INFO mapreduce.Job:  map 98% reduce 31%
15/04/08 22:05:49 INFO mapreduce.Job:  map 99% reduce 31%
15/04/08 22:05:50 INFO mapreduce.Job:  map 99% reduce 32%
15/04/08 22:05:56 INFO mapreduce.Job:  map 99% reduce 33%
15/04/08 22:06:03 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 22:06:05 INFO mapreduce.Job:  map 100% reduce 36%
15/04/08 22:06:06 INFO mapreduce.Job:  map 100% reduce 37%
15/04/08 22:06:07 INFO mapreduce.Job:  map 100% reduce 39%
15/04/08 22:06:08 INFO mapreduce.Job:  map 100% reduce 52%
15/04/08 22:06:09 INFO mapreduce.Job:  map 100% reduce 55%
15/04/08 22:06:10 INFO mapreduce.Job:  map 100% reduce 56%
15/04/08 22:06:11 INFO mapreduce.Job:  map 100% reduce 62%
15/04/08 22:06:12 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 22:06:14 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 22:06:17 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 22:06:23 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 22:06:38 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 22:06:56 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 22:07:23 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 22:07:39 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 22:07:59 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 22:08:16 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 22:08:31 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 22:08:47 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 22:09:01 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 22:09:21 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 22:09:35 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 22:09:54 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 22:10:06 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 22:10:25 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 22:10:51 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 22:11:12 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 22:11:35 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 22:11:44 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 22:12:18 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 22:12:40 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 22:13:02 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 22:13:27 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 22:14:12 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 22:14:36 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 22:15:28 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 22:15:41 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 22:16:04 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 22:17:39 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 22:18:37 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 22:19:22 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 22:21:23 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 22:32:59 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 22:51:14 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 22:57:35 INFO mapreduce.Job: Job job_1422482982071_4297 completed successfully
15/04/08 22:57:35 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210458
		FILE: Number of bytes written=20773025006
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Failed map tasks=10
		Killed reduce tasks=2
		Launched map tasks=60
		Launched reduce tasks=42
		Other local map tasks=10
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=40454792
		Total time spent by all reduces in occupied slots (ms)=66506064
		Total time spent by all map tasks (ms)=20227396
		Total time spent by all reduce tasks (ms)=33253032
		Total vcore-seconds taken by all map tasks=20227396
		Total vcore-seconds taken by all reduce tasks=33253032
		Total megabyte-seconds taken by all map tasks=163760998016
		Total megabyte-seconds taken by all reduce tasks=399036384000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382222218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382222218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =2000
		Failed Shuffles=0
		Merged Map outputs=2000
		GC time elapsed (ms)=173533
		CPU time spent (ms)=56140610
		Physical memory (bytes) snapshot=116064419840
		Virtual memory (bytes) snapshot=993404641280
		Total committed heap usage (bytes)=222688956416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 22:57:35 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	59m59.337s
user	0m26.094s
sys	0m2.873s
15/04/08 22:57:38 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 40
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-40-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob9050378097968885028.jar tmpDir=null
15/04/08 22:57:41 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 22:57:41 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 22:57:42 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 22:57:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 22:57:42 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 22:57:43 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4298
15/04/08 22:57:43 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4298
15/04/08 22:57:43 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4298/
15/04/08 22:57:43 INFO mapreduce.Job: Running job: job_1422482982071_4298
15/04/08 22:57:49 INFO mapreduce.Job: Job job_1422482982071_4298 running in uber mode : false
15/04/08 22:57:49 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 22:57:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4298_m_000017_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 22:57:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4298_m_000023_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 22:57:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4298_m_000026_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 22:57:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4298_m_000045_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 22:57:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4298_m_000003_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 22:57:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4298_m_000018_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 22:57:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4298_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 22:57:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4298_m_000010_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 22:57:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4298_m_000011_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 22:57:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4298_m_000033_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 22:57:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4298_m_000019_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 22:57:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4298_m_000011_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 22:58:01 INFO mapreduce.Job:  map 1% reduce 0%
15/04/08 22:58:07 INFO mapreduce.Job:  map 2% reduce 0%
15/04/08 22:58:12 INFO mapreduce.Job:  map 3% reduce 0%
15/04/08 22:58:18 INFO mapreduce.Job:  map 4% reduce 0%
15/04/08 22:58:23 INFO mapreduce.Job:  map 5% reduce 0%
15/04/08 22:58:29 INFO mapreduce.Job:  map 6% reduce 0%
15/04/08 22:58:34 INFO mapreduce.Job:  map 7% reduce 0%
15/04/08 22:58:40 INFO mapreduce.Job:  map 8% reduce 0%
15/04/08 22:58:46 INFO mapreduce.Job:  map 9% reduce 0%
15/04/08 22:58:52 INFO mapreduce.Job:  map 10% reduce 0%
15/04/08 22:58:57 INFO mapreduce.Job:  map 11% reduce 0%
15/04/08 22:59:02 INFO mapreduce.Job:  map 12% reduce 0%
15/04/08 22:59:08 INFO mapreduce.Job:  map 13% reduce 0%
15/04/08 22:59:14 INFO mapreduce.Job:  map 14% reduce 0%
15/04/08 22:59:20 INFO mapreduce.Job:  map 15% reduce 0%
15/04/08 22:59:27 INFO mapreduce.Job:  map 16% reduce 0%
15/04/08 22:59:32 INFO mapreduce.Job:  map 17% reduce 0%
15/04/08 22:59:38 INFO mapreduce.Job:  map 18% reduce 0%
15/04/08 22:59:43 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 22:59:49 INFO mapreduce.Job:  map 20% reduce 0%
15/04/08 22:59:55 INFO mapreduce.Job:  map 21% reduce 0%
15/04/08 23:00:01 INFO mapreduce.Job:  map 22% reduce 0%
15/04/08 23:00:06 INFO mapreduce.Job:  map 23% reduce 0%
15/04/08 23:00:12 INFO mapreduce.Job:  map 24% reduce 0%
15/04/08 23:00:18 INFO mapreduce.Job:  map 25% reduce 0%
15/04/08 23:00:24 INFO mapreduce.Job:  map 26% reduce 0%
15/04/08 23:00:29 INFO mapreduce.Job:  map 27% reduce 0%
15/04/08 23:00:34 INFO mapreduce.Job:  map 28% reduce 0%
15/04/08 23:00:40 INFO mapreduce.Job:  map 29% reduce 0%
15/04/08 23:00:46 INFO mapreduce.Job:  map 30% reduce 0%
15/04/08 23:00:52 INFO mapreduce.Job:  map 31% reduce 0%
15/04/08 23:00:57 INFO mapreduce.Job:  map 32% reduce 0%
15/04/08 23:01:03 INFO mapreduce.Job:  map 33% reduce 0%
15/04/08 23:01:09 INFO mapreduce.Job:  map 34% reduce 0%
15/04/08 23:01:14 INFO mapreduce.Job:  map 35% reduce 0%
15/04/08 23:01:20 INFO mapreduce.Job:  map 36% reduce 0%
15/04/08 23:01:26 INFO mapreduce.Job:  map 37% reduce 0%
15/04/08 23:01:32 INFO mapreduce.Job:  map 38% reduce 0%
15/04/08 23:01:37 INFO mapreduce.Job:  map 39% reduce 0%
15/04/08 23:01:43 INFO mapreduce.Job:  map 40% reduce 0%
15/04/08 23:01:49 INFO mapreduce.Job:  map 41% reduce 0%
15/04/08 23:01:55 INFO mapreduce.Job:  map 42% reduce 0%
15/04/08 23:02:01 INFO mapreduce.Job:  map 43% reduce 0%
15/04/08 23:02:07 INFO mapreduce.Job:  map 44% reduce 0%
15/04/08 23:02:12 INFO mapreduce.Job:  map 45% reduce 0%
15/04/08 23:02:18 INFO mapreduce.Job:  map 46% reduce 0%
15/04/08 23:02:24 INFO mapreduce.Job:  map 47% reduce 0%
15/04/08 23:02:30 INFO mapreduce.Job:  map 48% reduce 0%
15/04/08 23:02:35 INFO mapreduce.Job:  map 49% reduce 0%
15/04/08 23:02:41 INFO mapreduce.Job:  map 50% reduce 0%
15/04/08 23:02:47 INFO mapreduce.Job:  map 51% reduce 0%
15/04/08 23:02:53 INFO mapreduce.Job:  map 52% reduce 0%
15/04/08 23:02:58 INFO mapreduce.Job:  map 53% reduce 0%
15/04/08 23:03:04 INFO mapreduce.Job:  map 54% reduce 0%
15/04/08 23:03:10 INFO mapreduce.Job:  map 55% reduce 0%
15/04/08 23:03:15 INFO mapreduce.Job:  map 56% reduce 0%
15/04/08 23:03:21 INFO mapreduce.Job:  map 57% reduce 0%
15/04/08 23:03:27 INFO mapreduce.Job:  map 58% reduce 0%
15/04/08 23:03:32 INFO mapreduce.Job:  map 59% reduce 0%
15/04/08 23:03:38 INFO mapreduce.Job:  map 60% reduce 0%
15/04/08 23:03:44 INFO mapreduce.Job:  map 61% reduce 0%
15/04/08 23:03:50 INFO mapreduce.Job:  map 62% reduce 0%
15/04/08 23:03:55 INFO mapreduce.Job:  map 63% reduce 0%
15/04/08 23:04:01 INFO mapreduce.Job:  map 64% reduce 0%
15/04/08 23:04:07 INFO mapreduce.Job:  map 65% reduce 0%
15/04/08 23:04:15 INFO mapreduce.Job:  map 66% reduce 0%
15/04/08 23:04:16 INFO mapreduce.Job:  map 67% reduce 0%
15/04/08 23:04:18 INFO mapreduce.Job:  map 68% reduce 0%
15/04/08 23:04:19 INFO mapreduce.Job:  map 69% reduce 0%
15/04/08 23:04:20 INFO mapreduce.Job:  map 70% reduce 0%
15/04/08 23:04:21 INFO mapreduce.Job:  map 71% reduce 0%
15/04/08 23:04:23 INFO mapreduce.Job:  map 73% reduce 0%
15/04/08 23:04:24 INFO mapreduce.Job:  map 75% reduce 0%
15/04/08 23:04:25 INFO mapreduce.Job:  map 76% reduce 0%
15/04/08 23:04:27 INFO mapreduce.Job:  map 78% reduce 0%
15/04/08 23:04:28 INFO mapreduce.Job:  map 79% reduce 4%
15/04/08 23:04:29 INFO mapreduce.Job:  map 80% reduce 11%
15/04/08 23:04:30 INFO mapreduce.Job:  map 84% reduce 12%
15/04/08 23:04:31 INFO mapreduce.Job:  map 84% reduce 14%
15/04/08 23:04:32 INFO mapreduce.Job:  map 86% reduce 17%
15/04/08 23:04:33 INFO mapreduce.Job:  map 86% reduce 18%
15/04/08 23:04:34 INFO mapreduce.Job:  map 87% reduce 19%
15/04/08 23:04:35 INFO mapreduce.Job:  map 87% reduce 20%
15/04/08 23:04:36 INFO mapreduce.Job:  map 89% reduce 21%
15/04/08 23:04:38 INFO mapreduce.Job:  map 90% reduce 22%
15/04/08 23:04:39 INFO mapreduce.Job:  map 91% reduce 23%
15/04/08 23:04:40 INFO mapreduce.Job:  map 92% reduce 24%
15/04/08 23:04:42 INFO mapreduce.Job:  map 92% reduce 26%
15/04/08 23:04:43 INFO mapreduce.Job:  map 94% reduce 26%
15/04/08 23:04:45 INFO mapreduce.Job:  map 94% reduce 28%
15/04/08 23:04:46 INFO mapreduce.Job:  map 95% reduce 28%
15/04/08 23:04:47 INFO mapreduce.Job:  map 96% reduce 28%
15/04/08 23:04:48 INFO mapreduce.Job:  map 96% reduce 29%
15/04/08 23:04:49 INFO mapreduce.Job:  map 97% reduce 29%
15/04/08 23:04:50 INFO mapreduce.Job:  map 97% reduce 30%
15/04/08 23:04:52 INFO mapreduce.Job:  map 97% reduce 31%
15/04/08 23:05:17 INFO mapreduce.Job:  map 98% reduce 31%
15/04/08 23:05:18 INFO mapreduce.Job:  map 99% reduce 31%
15/04/08 23:05:19 INFO mapreduce.Job:  map 99% reduce 32%
15/04/08 23:05:22 INFO mapreduce.Job:  map 100% reduce 33%
15/04/08 23:05:24 INFO mapreduce.Job:  map 100% reduce 35%
15/04/08 23:05:25 INFO mapreduce.Job:  map 100% reduce 42%
15/04/08 23:05:26 INFO mapreduce.Job:  map 100% reduce 46%
15/04/08 23:05:27 INFO mapreduce.Job:  map 100% reduce 49%
15/04/08 23:05:28 INFO mapreduce.Job:  map 100% reduce 57%
15/04/08 23:05:29 INFO mapreduce.Job:  map 100% reduce 60%
15/04/08 23:05:31 INFO mapreduce.Job:  map 100% reduce 63%
15/04/08 23:05:32 INFO mapreduce.Job:  map 100% reduce 64%
15/04/08 23:05:34 INFO mapreduce.Job:  map 100% reduce 65%
15/04/08 23:05:35 INFO mapreduce.Job:  map 100% reduce 66%
15/04/08 23:05:43 INFO mapreduce.Job:  map 100% reduce 67%
15/04/08 23:05:59 INFO mapreduce.Job:  map 100% reduce 68%
15/04/08 23:06:16 INFO mapreduce.Job:  map 100% reduce 69%
15/04/08 23:06:40 INFO mapreduce.Job:  map 100% reduce 70%
15/04/08 23:07:01 INFO mapreduce.Job:  map 100% reduce 71%
15/04/08 23:07:17 INFO mapreduce.Job:  map 100% reduce 72%
15/04/08 23:07:35 INFO mapreduce.Job:  map 100% reduce 73%
15/04/08 23:07:51 INFO mapreduce.Job:  map 100% reduce 74%
15/04/08 23:08:08 INFO mapreduce.Job:  map 100% reduce 75%
15/04/08 23:08:22 INFO mapreduce.Job:  map 100% reduce 76%
15/04/08 23:08:43 INFO mapreduce.Job:  map 100% reduce 77%
15/04/08 23:08:55 INFO mapreduce.Job:  map 100% reduce 78%
15/04/08 23:09:14 INFO mapreduce.Job:  map 100% reduce 79%
15/04/08 23:09:30 INFO mapreduce.Job:  map 100% reduce 80%
15/04/08 23:09:45 INFO mapreduce.Job:  map 100% reduce 81%
15/04/08 23:10:10 INFO mapreduce.Job:  map 100% reduce 82%
15/04/08 23:10:29 INFO mapreduce.Job:  map 100% reduce 83%
15/04/08 23:10:53 INFO mapreduce.Job:  map 100% reduce 84%
15/04/08 23:11:10 INFO mapreduce.Job:  map 100% reduce 85%
15/04/08 23:11:45 INFO mapreduce.Job:  map 100% reduce 86%
15/04/08 23:11:53 INFO mapreduce.Job:  map 100% reduce 87%
15/04/08 23:12:20 INFO mapreduce.Job:  map 100% reduce 88%
15/04/08 23:12:36 INFO mapreduce.Job:  map 100% reduce 89%
15/04/08 23:13:33 INFO mapreduce.Job:  map 100% reduce 90%
15/04/08 23:13:54 INFO mapreduce.Job:  map 100% reduce 91%
15/04/08 23:14:36 INFO mapreduce.Job:  map 100% reduce 92%
15/04/08 23:14:52 INFO mapreduce.Job:  map 100% reduce 93%
15/04/08 23:15:17 INFO mapreduce.Job:  map 100% reduce 94%
15/04/08 23:16:59 INFO mapreduce.Job:  map 100% reduce 95%
15/04/08 23:17:53 INFO mapreduce.Job:  map 100% reduce 96%
15/04/08 23:19:10 INFO mapreduce.Job:  map 100% reduce 97%
15/04/08 23:20:11 INFO mapreduce.Job:  map 100% reduce 98%
15/04/08 23:31:31 INFO mapreduce.Job:  map 100% reduce 99%
15/04/08 23:50:55 INFO mapreduce.Job:  map 100% reduce 100%
15/04/08 23:57:26 INFO mapreduce.Job: Job job_1422482982071_4298 completed successfully
15/04/08 23:57:27 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210458
		FILE: Number of bytes written=20773025006
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Failed map tasks=12
		Killed reduce tasks=2
		Launched map tasks=62
		Launched reduce tasks=42
		Other local map tasks=12
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=40326104
		Total time spent by all reduces in occupied slots (ms)=63280326
		Total time spent by all map tasks (ms)=20163052
		Total time spent by all reduce tasks (ms)=31640163
		Total vcore-seconds taken by all map tasks=20163052
		Total vcore-seconds taken by all reduce tasks=31640163
		Total megabyte-seconds taken by all map tasks=163240068992
		Total megabyte-seconds taken by all reduce tasks=379681956000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382222218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382222218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =2000
		Failed Shuffles=0
		Merged Map outputs=2000
		GC time elapsed (ms)=166919
		CPU time spent (ms)=55867110
		Physical memory (bytes) snapshot=115837173760
		Virtual memory (bytes) snapshot=993576013824
		Total committed heap usage (bytes)=222688800768
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/08 23:57:27 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	59m51.390s
user	0m27.559s
sys	0m2.950s
15/04/08 23:57:29 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 40
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-40-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3466664807906260454.jar tmpDir=null
15/04/08 23:57:32 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 23:57:32 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/08 23:57:33 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/08 23:57:33 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/08 23:57:34 INFO mapreduce.JobSubmitter: number of splits:50
15/04/08 23:57:34 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4299
15/04/08 23:57:35 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4299
15/04/08 23:57:35 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4299/
15/04/08 23:57:35 INFO mapreduce.Job: Running job: job_1422482982071_4299
15/04/08 23:57:41 INFO mapreduce.Job: Job job_1422482982071_4299 running in uber mode : false
15/04/08 23:57:41 INFO mapreduce.Job:  map 0% reduce 0%
15/04/08 23:57:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4299_m_000017_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 23:57:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4299_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 23:57:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4299_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 23:57:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4299_m_000026_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 23:57:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4299_m_000048_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 23:57:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4299_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 23:57:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4299_m_000000_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 23:57:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4299_m_000023_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 23:57:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4299_m_000032_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 23:57:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4299_m_000017_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/08 23:57:53 INFO mapreduce.Job:  map 1% reduce 0%
15/04/08 23:57:59 INFO mapreduce.Job:  map 2% reduce 0%
15/04/08 23:58:04 INFO mapreduce.Job:  map 3% reduce 0%
15/04/08 23:58:09 INFO mapreduce.Job:  map 4% reduce 0%
15/04/08 23:58:14 INFO mapreduce.Job:  map 5% reduce 0%
15/04/08 23:58:20 INFO mapreduce.Job:  map 6% reduce 0%
15/04/08 23:58:26 INFO mapreduce.Job:  map 7% reduce 0%
15/04/08 23:58:32 INFO mapreduce.Job:  map 8% reduce 0%
15/04/08 23:58:38 INFO mapreduce.Job:  map 9% reduce 0%
15/04/08 23:58:44 INFO mapreduce.Job:  map 10% reduce 0%
15/04/08 23:58:48 INFO mapreduce.Job:  map 11% reduce 0%
15/04/08 23:58:54 INFO mapreduce.Job:  map 12% reduce 0%
15/04/08 23:59:00 INFO mapreduce.Job:  map 13% reduce 0%
15/04/08 23:59:07 INFO mapreduce.Job:  map 14% reduce 0%
15/04/08 23:59:13 INFO mapreduce.Job:  map 15% reduce 0%
15/04/08 23:59:19 INFO mapreduce.Job:  map 16% reduce 0%
15/04/08 23:59:24 INFO mapreduce.Job:  map 17% reduce 0%
15/04/08 23:59:30 INFO mapreduce.Job:  map 18% reduce 0%
15/04/08 23:59:35 INFO mapreduce.Job:  map 19% reduce 0%
15/04/08 23:59:41 INFO mapreduce.Job:  map 20% reduce 0%
15/04/08 23:59:47 INFO mapreduce.Job:  map 21% reduce 0%
15/04/08 23:59:52 INFO mapreduce.Job:  map 22% reduce 0%
15/04/08 23:59:58 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 00:00:04 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 00:00:10 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 00:00:15 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 00:00:20 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 00:00:26 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 00:00:32 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 00:00:38 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 00:00:44 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 00:00:49 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 00:00:55 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 00:01:01 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 00:01:06 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 00:01:12 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 00:01:17 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 00:01:23 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 00:01:29 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 00:01:36 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 00:01:42 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 00:01:48 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 00:01:53 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 00:01:59 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 00:02:04 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 00:02:10 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 00:02:16 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 00:02:22 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 00:02:28 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 00:02:33 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 00:02:39 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 00:02:45 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 00:02:51 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 00:02:56 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 00:03:02 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 00:03:08 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 00:03:13 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 00:03:19 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 00:03:25 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 00:03:31 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 00:03:36 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 00:03:42 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 00:03:48 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 00:03:54 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 00:04:00 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 00:04:05 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 00:04:10 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 00:04:11 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 00:04:13 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 00:04:15 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 00:04:16 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 00:04:18 INFO mapreduce.Job:  map 73% reduce 0%
15/04/09 00:04:20 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 00:04:21 INFO mapreduce.Job:  map 77% reduce 4%
15/04/09 00:04:22 INFO mapreduce.Job:  map 79% reduce 9%
15/04/09 00:04:23 INFO mapreduce.Job:  map 80% reduce 10%
15/04/09 00:04:24 INFO mapreduce.Job:  map 82% reduce 12%
15/04/09 00:04:25 INFO mapreduce.Job:  map 82% reduce 14%
15/04/09 00:04:26 INFO mapreduce.Job:  map 86% reduce 15%
15/04/09 00:04:27 INFO mapreduce.Job:  map 88% reduce 17%
15/04/09 00:04:28 INFO mapreduce.Job:  map 90% reduce 21%
15/04/09 00:04:29 INFO mapreduce.Job:  map 90% reduce 22%
15/04/09 00:04:30 INFO mapreduce.Job:  map 92% reduce 23%
15/04/09 00:04:31 INFO mapreduce.Job:  map 92% reduce 25%
15/04/09 00:04:33 INFO mapreduce.Job:  map 93% reduce 26%
15/04/09 00:04:35 INFO mapreduce.Job:  map 93% reduce 27%
15/04/09 00:04:36 INFO mapreduce.Job:  map 94% reduce 27%
15/04/09 00:04:37 INFO mapreduce.Job:  map 95% reduce 27%
15/04/09 00:04:38 INFO mapreduce.Job:  map 96% reduce 28%
15/04/09 00:04:40 INFO mapreduce.Job:  map 96% reduce 29%
15/04/09 00:04:41 INFO mapreduce.Job:  map 98% reduce 29%
15/04/09 00:04:42 INFO mapreduce.Job:  map 98% reduce 30%
15/04/09 00:04:43 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 00:05:25 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 00:05:26 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 00:05:32 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 00:05:35 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 00:05:36 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 00:05:38 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 00:05:39 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 00:05:40 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 00:05:41 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 00:05:42 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 00:05:43 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 00:05:44 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 00:05:45 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 00:05:46 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 00:05:48 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 00:05:55 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 00:06:11 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 00:06:29 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 00:06:55 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 00:07:13 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 00:07:31 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 00:07:49 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 00:08:04 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 00:08:20 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 00:08:35 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 00:08:58 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 00:09:11 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 00:09:26 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 00:09:40 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 00:10:00 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 00:10:23 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 00:10:47 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 00:11:07 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 00:11:18 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 00:11:55 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 00:12:11 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 00:12:36 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 00:12:53 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 00:13:47 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 00:14:17 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 00:15:02 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 00:15:16 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 00:15:50 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 00:17:05 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 00:18:00 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 00:18:56 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 00:21:09 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 00:32:16 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 00:52:08 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 00:58:50 INFO mapreduce.Job: Job job_1422482982071_4299 completed successfully
15/04/09 00:58:50 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210458
		FILE: Number of bytes written=20773025006
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Failed map tasks=10
		Killed reduce tasks=2
		Launched map tasks=60
		Launched reduce tasks=42
		Other local map tasks=10
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=40448124
		Total time spent by all reduces in occupied slots (ms)=65358364
		Total time spent by all map tasks (ms)=20224062
		Total time spent by all reduce tasks (ms)=32679182
		Total vcore-seconds taken by all map tasks=20224062
		Total vcore-seconds taken by all reduce tasks=32679182
		Total megabyte-seconds taken by all map tasks=163734005952
		Total megabyte-seconds taken by all reduce tasks=392150184000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382222218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382222218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =2000
		Failed Shuffles=0
		Merged Map outputs=2000
		GC time elapsed (ms)=166186
		CPU time spent (ms)=56135100
		Physical memory (bytes) snapshot=116472967168
		Virtual memory (bytes) snapshot=993403535360
		Total committed heap usage (bytes)=222689218560
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 00:58:50 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	61m23.315s
user	0m27.097s
sys	0m2.952s
15/04/09 00:58:52 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 30
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-30-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2043244089505110336.jar tmpDir=null
15/04/09 00:58:56 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 00:58:56 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 00:58:56 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 00:58:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 00:58:57 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 00:58:57 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4300
15/04/09 00:58:57 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4300
15/04/09 00:58:58 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4300/
15/04/09 00:58:58 INFO mapreduce.Job: Running job: job_1422482982071_4300
15/04/09 00:59:03 INFO mapreduce.Job: Job job_1422482982071_4300 running in uber mode : false
15/04/09 00:59:03 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 00:59:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4300_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 00:59:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4300_m_000046_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 00:59:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4300_m_000049_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 00:59:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4300_m_000035_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 00:59:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4300_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 00:59:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4300_m_000015_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 00:59:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4300_m_000027_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 00:59:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4300_m_000038_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 00:59:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4300_m_000037_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 00:59:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4300_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 00:59:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4300_m_000036_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 00:59:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4300_m_000013_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 00:59:15 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 00:59:21 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 00:59:27 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 00:59:32 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 00:59:37 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 00:59:43 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 00:59:49 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 00:59:55 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 01:00:01 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 01:00:06 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 01:00:12 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 01:00:17 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 01:00:23 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 01:00:28 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 01:00:34 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 01:00:40 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 01:00:47 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 01:00:52 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 01:00:57 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 01:01:03 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 01:01:09 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 01:01:15 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 01:01:21 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 01:01:26 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 01:01:32 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 01:01:38 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 01:01:43 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 01:01:48 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 01:01:54 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 01:02:00 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 01:02:06 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 01:02:12 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 01:02:17 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 01:02:23 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 01:02:28 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 01:02:34 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 01:02:40 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 01:02:46 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 01:02:51 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 01:02:57 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 01:03:03 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 01:03:09 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 01:03:14 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 01:03:20 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 01:03:25 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 01:03:31 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 01:03:37 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 01:03:43 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 01:03:49 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 01:03:55 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 01:04:01 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 01:04:06 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 01:04:12 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 01:04:18 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 01:04:24 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 01:04:29 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 01:04:35 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 01:04:41 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 01:04:46 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 01:04:52 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 01:04:57 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 01:05:03 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 01:05:09 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 01:05:15 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 01:05:21 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 01:05:27 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 01:05:28 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 01:05:31 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 01:05:35 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 01:05:37 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 01:05:38 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 01:05:39 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 01:05:40 INFO mapreduce.Job:  map 77% reduce 0%
15/04/09 01:05:41 INFO mapreduce.Job:  map 79% reduce 0%
15/04/09 01:05:42 INFO mapreduce.Job:  map 81% reduce 10%
15/04/09 01:05:43 INFO mapreduce.Job:  map 82% reduce 11%
15/04/09 01:05:44 INFO mapreduce.Job:  map 82% reduce 12%
15/04/09 01:05:45 INFO mapreduce.Job:  map 84% reduce 16%
15/04/09 01:05:47 INFO mapreduce.Job:  map 84% reduce 17%
15/04/09 01:05:48 INFO mapreduce.Job:  map 85% reduce 18%
15/04/09 01:05:49 INFO mapreduce.Job:  map 88% reduce 18%
15/04/09 01:05:50 INFO mapreduce.Job:  map 89% reduce 18%
15/04/09 01:05:51 INFO mapreduce.Job:  map 90% reduce 22%
15/04/09 01:05:52 INFO mapreduce.Job:  map 90% reduce 23%
15/04/09 01:05:54 INFO mapreduce.Job:  map 93% reduce 25%
15/04/09 01:05:55 INFO mapreduce.Job:  map 94% reduce 25%
15/04/09 01:05:56 INFO mapreduce.Job:  map 94% reduce 26%
15/04/09 01:05:57 INFO mapreduce.Job:  map 94% reduce 27%
15/04/09 01:05:58 INFO mapreduce.Job:  map 94% reduce 28%
15/04/09 01:05:59 INFO mapreduce.Job:  map 96% reduce 28%
15/04/09 01:06:00 INFO mapreduce.Job:  map 96% reduce 29%
15/04/09 01:06:01 INFO mapreduce.Job:  map 96% reduce 30%
15/04/09 01:06:03 INFO mapreduce.Job:  map 98% reduce 30%
15/04/09 01:06:04 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 01:06:07 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 01:06:10 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 01:06:40 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 01:06:56 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 01:06:58 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 01:06:59 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 01:07:00 INFO mapreduce.Job:  map 100% reduce 44%
15/04/09 01:07:01 INFO mapreduce.Job:  map 100% reduce 46%
15/04/09 01:07:02 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 01:07:03 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 01:07:04 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 01:07:05 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 01:07:06 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 01:07:08 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 01:07:09 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 01:07:11 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 01:07:15 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 01:07:21 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 01:07:39 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 01:08:06 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 01:08:36 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 01:09:00 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 01:09:28 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 01:10:07 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 01:10:26 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 01:10:46 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 01:11:09 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 01:11:25 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 01:11:48 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 01:12:13 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 01:12:34 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 01:12:52 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 01:13:27 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 01:13:37 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 01:14:00 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 01:14:24 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 01:14:33 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 01:14:57 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 01:15:28 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 01:15:43 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 01:16:36 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 01:16:48 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 01:17:40 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 01:18:59 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 01:20:54 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 01:22:19 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 01:24:49 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 01:27:11 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 01:30:28 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 01:38:13 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 01:51:48 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 01:59:15 INFO mapreduce.Job: Job job_1422482982071_4300 completed successfully
15/04/09 01:59:15 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210398
		FILE: Number of bytes written=20772060746
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Failed map tasks=12
		Killed reduce tasks=1
		Launched map tasks=62
		Launched reduce tasks=31
		Other local map tasks=12
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=40255014
		Total time spent by all reduces in occupied slots (ms)=61798696
		Total time spent by all map tasks (ms)=20127507
		Total time spent by all reduce tasks (ms)=30899348
		Total vcore-seconds taken by all map tasks=20127507
		Total vcore-seconds taken by all reduce tasks=30899348
		Total megabyte-seconds taken by all map tasks=162952296672
		Total megabyte-seconds taken by all reduce tasks=370792176000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382219218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382219218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=167772
		CPU time spent (ms)=55753160
		Physical memory (bytes) snapshot=113944473600
		Virtual memory (bytes) snapshot=859024183296
		Total committed heap usage (bytes)=201638252544
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 01:59:15 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	60m25.069s
user	0m26.533s
sys	0m2.968s
15/04/09 01:59:18 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 30
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-30-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6242238661144931680.jar tmpDir=null
15/04/09 01:59:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 01:59:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 01:59:21 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 01:59:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 01:59:21 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 01:59:22 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4301
15/04/09 01:59:22 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4301
15/04/09 01:59:22 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4301/
15/04/09 01:59:22 INFO mapreduce.Job: Running job: job_1422482982071_4301
15/04/09 01:59:28 INFO mapreduce.Job: Job job_1422482982071_4301 running in uber mode : false
15/04/09 01:59:28 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 01:59:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000027_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000001_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000037_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000020_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000042_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000049_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000048_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000039_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000017_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000016_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000037_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000017_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000049_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:40 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 01:59:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4301_m_000049_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 01:59:46 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 01:59:52 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 01:59:58 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 02:00:04 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 02:00:09 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 02:00:14 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 02:00:20 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 02:00:26 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 02:00:32 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 02:00:38 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 02:00:44 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 02:00:49 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 02:00:55 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 02:01:00 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 02:01:06 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 02:01:13 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 02:01:19 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 02:01:24 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 02:01:30 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 02:01:36 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 02:01:42 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 02:01:48 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 02:01:53 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 02:01:59 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 02:02:05 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 02:02:10 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 02:02:16 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 02:02:22 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 02:02:28 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 02:02:34 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 02:02:40 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 02:02:46 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 02:02:52 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 02:02:57 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 02:03:03 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 02:03:09 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 02:03:14 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 02:03:20 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 02:03:26 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 02:03:32 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 02:03:38 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 02:03:44 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 02:03:50 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 02:03:56 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 02:04:02 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 02:04:08 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 02:04:14 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 02:04:20 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 02:04:26 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 02:04:32 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 02:04:37 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 02:04:43 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 02:04:49 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 02:04:54 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 02:05:00 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 02:05:06 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 02:05:12 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 02:05:18 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 02:05:24 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 02:05:30 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 02:05:36 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 02:05:41 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 02:05:47 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 02:05:54 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 02:05:56 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 02:05:58 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 02:06:01 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 02:06:03 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 02:06:06 INFO mapreduce.Job:  map 73% reduce 0%
15/04/09 02:06:07 INFO mapreduce.Job:  map 74% reduce 3%
15/04/09 02:06:08 INFO mapreduce.Job:  map 75% reduce 8%
15/04/09 02:06:10 INFO mapreduce.Job:  map 76% reduce 9%
15/04/09 02:06:11 INFO mapreduce.Job:  map 78% reduce 10%
15/04/09 02:06:12 INFO mapreduce.Job:  map 79% reduce 11%
15/04/09 02:06:13 INFO mapreduce.Job:  map 81% reduce 12%
15/04/09 02:06:14 INFO mapreduce.Job:  map 82% reduce 14%
15/04/09 02:06:15 INFO mapreduce.Job:  map 84% reduce 15%
15/04/09 02:06:16 INFO mapreduce.Job:  map 84% reduce 16%
15/04/09 02:06:17 INFO mapreduce.Job:  map 86% reduce 18%
15/04/09 02:06:18 INFO mapreduce.Job:  map 88% reduce 19%
15/04/09 02:06:19 INFO mapreduce.Job:  map 88% reduce 20%
15/04/09 02:06:20 INFO mapreduce.Job:  map 89% reduce 22%
15/04/09 02:06:21 INFO mapreduce.Job:  map 91% reduce 22%
15/04/09 02:06:22 INFO mapreduce.Job:  map 92% reduce 22%
15/04/09 02:06:23 INFO mapreduce.Job:  map 92% reduce 25%
15/04/09 02:06:25 INFO mapreduce.Job:  map 92% reduce 26%
15/04/09 02:06:26 INFO mapreduce.Job:  map 93% reduce 26%
15/04/09 02:06:30 INFO mapreduce.Job:  map 93% reduce 27%
15/04/09 02:06:34 INFO mapreduce.Job:  map 94% reduce 27%
15/04/09 02:06:49 INFO mapreduce.Job:  map 95% reduce 28%
15/04/09 02:06:52 INFO mapreduce.Job:  map 95% reduce 29%
15/04/09 02:06:55 INFO mapreduce.Job:  map 96% reduce 29%
15/04/09 02:06:59 INFO mapreduce.Job:  map 97% reduce 29%
15/04/09 02:07:01 INFO mapreduce.Job:  map 97% reduce 30%
15/04/09 02:07:03 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 02:07:16 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 02:07:17 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 02:07:25 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 02:07:27 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 02:07:28 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 02:07:29 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 02:07:30 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 02:07:31 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 02:07:32 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 02:07:33 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 02:07:34 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 02:07:35 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 02:07:36 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 02:07:37 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 02:07:38 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 02:07:40 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 02:07:43 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 02:07:46 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 02:07:53 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 02:08:10 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 02:08:38 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 02:09:05 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 02:09:31 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 02:10:00 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 02:10:38 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 02:10:54 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 02:11:19 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 02:11:39 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 02:12:02 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 02:12:25 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 02:12:46 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 02:13:06 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 02:13:27 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 02:13:52 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 02:14:08 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 02:14:29 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 02:14:49 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 02:15:07 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 02:15:44 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 02:15:59 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 02:16:18 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 02:17:11 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 02:17:22 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 02:18:10 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 02:19:25 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 02:21:27 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 02:22:47 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 02:25:35 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 02:27:45 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 02:31:10 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 02:37:15 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 02:52:46 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 03:00:22 INFO mapreduce.Job: Job job_1422482982071_4301 completed successfully
15/04/09 03:00:22 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210398
		FILE: Number of bytes written=20772060746
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Failed map tasks=17
		Killed reduce tasks=1
		Launched map tasks=67
		Launched reduce tasks=31
		Other local map tasks=17
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=41085296
		Total time spent by all reduces in occupied slots (ms)=62137856
		Total time spent by all map tasks (ms)=20542648
		Total time spent by all reduce tasks (ms)=31068928
		Total vcore-seconds taken by all map tasks=20542648
		Total vcore-seconds taken by all reduce tasks=31068928
		Total megabyte-seconds taken by all map tasks=166313278208
		Total megabyte-seconds taken by all reduce tasks=372827136000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382219218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382219218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=169987
		CPU time spent (ms)=56276840
		Physical memory (bytes) snapshot=113748291584
		Virtual memory (bytes) snapshot=859022254080
		Total committed heap usage (bytes)=201638248448
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 03:00:22 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	61m7.270s
user	0m25.733s
sys	0m2.896s
15/04/09 03:00:25 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 30
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-30-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1045084561190047526.jar tmpDir=null
15/04/09 03:00:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 03:00:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 03:00:29 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 03:00:29 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 03:00:29 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 03:00:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4302
15/04/09 03:00:30 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4302
15/04/09 03:00:30 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4302/
15/04/09 03:00:30 INFO mapreduce.Job: Running job: job_1422482982071_4302
15/04/09 03:00:36 INFO mapreduce.Job: Job job_1422482982071_4302 running in uber mode : false
15/04/09 03:00:36 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 03:00:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4302_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 03:00:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4302_m_000022_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 03:00:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4302_m_000039_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 03:00:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4302_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 03:00:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4302_m_000001_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 03:00:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4302_m_000042_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 03:00:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4302_m_000048_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 03:00:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4302_m_000011_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 03:00:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4302_m_000007_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 03:00:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4302_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 03:00:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4302_m_000044_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 03:00:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4302_m_000049_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 03:00:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4302_m_000028_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 03:00:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4302_m_000018_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 03:00:49 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 03:00:55 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 03:01:00 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 03:01:06 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 03:01:12 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 03:01:17 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 03:01:23 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 03:01:28 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 03:01:34 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 03:01:40 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 03:01:46 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 03:01:52 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 03:01:57 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 03:02:03 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 03:02:08 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 03:02:14 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 03:02:20 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 03:02:26 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 03:02:32 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 03:02:37 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 03:02:43 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 03:02:50 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 03:02:55 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 03:03:01 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 03:03:07 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 03:03:12 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 03:03:18 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 03:03:24 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 03:03:30 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 03:03:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4302_m_000015_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 03:03:39 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 03:03:44 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 03:03:50 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 03:03:55 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 03:04:01 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 03:04:07 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 03:04:13 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 03:04:19 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 03:04:25 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 03:04:30 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 03:04:36 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 03:04:42 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 03:04:47 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 03:04:53 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 03:04:59 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 03:05:04 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 03:05:10 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 03:05:17 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 03:05:23 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 03:05:29 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 03:05:34 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 03:05:40 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 03:05:46 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 03:05:51 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 03:05:57 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 03:06:03 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 03:06:09 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 03:06:14 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 03:06:20 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 03:06:26 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 03:06:32 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 03:06:37 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 03:06:43 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 03:06:49 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 03:06:55 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 03:07:02 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 03:07:03 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 03:07:08 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 03:07:09 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 03:07:13 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 03:07:14 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 03:07:15 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 03:07:16 INFO mapreduce.Job:  map 76% reduce 0%
15/04/09 03:07:18 INFO mapreduce.Job:  map 78% reduce 1%
15/04/09 03:07:19 INFO mapreduce.Job:  map 79% reduce 10%
15/04/09 03:07:20 INFO mapreduce.Job:  map 80% reduce 12%
15/04/09 03:07:21 INFO mapreduce.Job:  map 82% reduce 12%
15/04/09 03:07:22 INFO mapreduce.Job:  map 84% reduce 15%
15/04/09 03:07:23 INFO mapreduce.Job:  map 85% reduce 17%
15/04/09 03:07:24 INFO mapreduce.Job:  map 86% reduce 17%
15/04/09 03:07:25 INFO mapreduce.Job:  map 88% reduce 20%
15/04/09 03:07:26 INFO mapreduce.Job:  map 89% reduce 21%
15/04/09 03:07:28 INFO mapreduce.Job:  map 90% reduce 23%
15/04/09 03:07:29 INFO mapreduce.Job:  map 90% reduce 24%
15/04/09 03:07:30 INFO mapreduce.Job:  map 92% reduce 24%
15/04/09 03:07:31 INFO mapreduce.Job:  map 92% reduce 25%
15/04/09 03:07:32 INFO mapreduce.Job:  map 94% reduce 27%
15/04/09 03:07:33 INFO mapreduce.Job:  map 95% reduce 27%
15/04/09 03:07:34 INFO mapreduce.Job:  map 95% reduce 28%
15/04/09 03:07:35 INFO mapreduce.Job:  map 95% reduce 29%
15/04/09 03:07:37 INFO mapreduce.Job:  map 96% reduce 30%
15/04/09 03:08:03 INFO mapreduce.Job:  map 97% reduce 30%
15/04/09 03:08:06 INFO mapreduce.Job:  map 97% reduce 31%
15/04/09 03:08:15 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 03:08:17 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 03:08:18 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 03:08:19 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 03:10:08 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 03:10:10 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 03:10:11 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 03:10:12 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 03:10:13 INFO mapreduce.Job:  map 100% reduce 44%
15/04/09 03:10:14 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 03:10:15 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 03:10:16 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 03:10:17 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 03:10:18 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 03:10:19 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 03:10:20 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 03:10:21 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 03:10:23 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 03:10:26 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 03:10:33 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 03:10:54 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 03:11:20 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 03:11:49 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 03:12:13 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 03:12:42 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 03:13:17 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 03:13:36 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 03:13:59 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 03:14:22 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 03:14:43 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 03:15:05 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 03:15:28 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 03:15:50 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 03:16:06 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 03:16:34 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 03:16:49 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 03:17:12 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 03:17:36 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 03:17:48 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 03:18:14 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 03:18:35 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 03:19:03 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 03:19:47 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 03:20:03 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 03:20:54 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 03:22:03 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 03:23:58 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 03:25:25 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 03:27:59 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 03:29:59 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 03:33:56 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 03:40:47 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 03:55:34 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 04:03:06 INFO mapreduce.Job: Job job_1422482982071_4302 completed successfully
15/04/09 04:03:06 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210398
		FILE: Number of bytes written=20772060746
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Failed map tasks=15
		Killed reduce tasks=1
		Launched map tasks=65
		Launched reduce tasks=31
		Other local map tasks=15
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=40942616
		Total time spent by all reduces in occupied slots (ms)=67319994
		Total time spent by all map tasks (ms)=20471308
		Total time spent by all reduce tasks (ms)=33659997
		Total vcore-seconds taken by all map tasks=20471308
		Total vcore-seconds taken by all reduce tasks=33659997
		Total megabyte-seconds taken by all map tasks=165735709568
		Total megabyte-seconds taken by all reduce tasks=403919964000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382219218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382219218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=168670
		CPU time spent (ms)=56026100
		Physical memory (bytes) snapshot=113703964672
		Virtual memory (bytes) snapshot=860014714880
		Total committed heap usage (bytes)=201637941248
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 04:03:06 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	62m44.078s
user	0m27.915s
sys	0m2.976s
15/04/09 04:03:09 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 20
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-20-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob36791998683268641.jar tmpDir=null
15/04/09 04:03:11 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 04:03:12 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 04:03:12 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 04:03:12 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 04:03:13 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 04:03:13 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4303
15/04/09 04:03:14 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4303
15/04/09 04:03:14 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4303/
15/04/09 04:03:14 INFO mapreduce.Job: Running job: job_1422482982071_4303
15/04/09 04:03:19 INFO mapreduce.Job: Job job_1422482982071_4303 running in uber mode : false
15/04/09 04:03:19 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 04:03:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4303_m_000035_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 04:03:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4303_m_000042_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 04:03:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4303_m_000049_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 04:03:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4303_m_000047_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 04:03:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4303_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 04:03:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4303_m_000016_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 04:03:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4303_m_000025_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 04:03:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4303_m_000046_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 04:03:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4303_m_000030_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 04:03:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4303_m_000008_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 04:03:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4303_m_000045_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 04:03:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4303_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 04:03:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4303_m_000030_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 04:03:31 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 04:03:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4303_m_000030_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 04:03:37 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 04:03:43 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 04:03:49 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 04:03:54 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 04:03:59 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 04:04:05 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 04:04:11 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 04:04:16 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 04:04:22 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 04:04:28 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 04:04:33 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 04:04:38 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 04:04:45 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 04:04:51 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 04:04:57 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 04:05:03 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 04:05:08 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 04:05:13 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 04:05:19 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 04:05:25 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 04:05:31 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 04:05:37 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 04:05:42 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 04:05:48 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 04:05:53 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 04:05:58 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 04:06:04 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 04:06:10 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 04:06:16 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 04:06:22 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 04:06:28 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 04:06:33 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 04:06:38 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 04:06:44 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 04:06:49 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 04:06:55 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 04:07:01 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 04:07:07 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 04:07:13 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 04:07:19 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 04:07:24 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 04:07:29 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 04:07:35 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 04:07:41 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 04:07:48 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 04:07:53 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 04:07:59 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 04:08:05 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 04:08:11 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 04:08:16 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 04:08:22 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 04:08:27 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 04:08:33 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 04:08:39 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 04:08:45 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 04:08:50 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 04:08:56 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 04:09:02 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 04:09:07 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 04:09:13 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 04:09:19 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 04:09:24 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 04:09:30 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 04:09:36 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 04:09:42 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 04:09:51 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 04:09:52 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 04:09:53 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 04:09:55 INFO mapreduce.Job:  map 73% reduce 0%
15/04/09 04:09:57 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 04:09:58 INFO mapreduce.Job:  map 76% reduce 0%
15/04/09 04:09:59 INFO mapreduce.Job:  map 79% reduce 0%
15/04/09 04:10:00 INFO mapreduce.Job:  map 80% reduce 0%
15/04/09 04:10:01 INFO mapreduce.Job:  map 84% reduce 0%
15/04/09 04:10:02 INFO mapreduce.Job:  map 86% reduce 7%
15/04/09 04:10:03 INFO mapreduce.Job:  map 87% reduce 16%
15/04/09 04:10:04 INFO mapreduce.Job:  map 88% reduce 18%
15/04/09 04:10:05 INFO mapreduce.Job:  map 90% reduce 19%
15/04/09 04:10:06 INFO mapreduce.Job:  map 92% reduce 21%
15/04/09 04:10:07 INFO mapreduce.Job:  map 92% reduce 23%
15/04/09 04:10:08 INFO mapreduce.Job:  map 93% reduce 24%
15/04/09 04:10:09 INFO mapreduce.Job:  map 94% reduce 26%
15/04/09 04:10:10 INFO mapreduce.Job:  map 94% reduce 27%
15/04/09 04:10:11 INFO mapreduce.Job:  map 95% reduce 27%
15/04/09 04:10:12 INFO mapreduce.Job:  map 95% reduce 28%
15/04/09 04:10:13 INFO mapreduce.Job:  map 97% reduce 29%
15/04/09 04:10:15 INFO mapreduce.Job:  map 97% reduce 30%
15/04/09 04:10:16 INFO mapreduce.Job:  map 98% reduce 30%
15/04/09 04:10:17 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 04:10:18 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 04:10:20 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 04:10:44 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 04:10:55 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 04:10:58 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 04:10:59 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 04:11:00 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 04:11:01 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 04:11:02 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 04:11:03 INFO mapreduce.Job:  map 100% reduce 47%
15/04/09 04:11:04 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 04:11:05 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 04:11:06 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 04:11:07 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 04:11:08 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 04:11:10 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 04:11:11 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 04:11:13 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 04:11:15 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 04:11:18 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 04:11:19 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 04:11:20 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 04:11:58 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 04:12:56 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 04:13:47 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 04:14:26 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 04:15:02 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 04:15:50 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 04:16:45 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 04:17:24 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 04:18:02 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 04:18:33 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 04:18:46 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 04:19:13 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 04:19:58 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 04:20:36 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 04:21:08 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 04:22:05 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 04:22:57 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 04:23:25 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 04:23:44 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 04:24:35 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 04:25:42 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 04:26:28 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 04:27:24 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 04:28:02 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 04:28:11 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 04:29:13 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 04:31:37 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 04:34:44 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 04:37:27 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 04:37:42 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 04:43:29 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 04:55:19 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 04:57:42 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 05:09:09 INFO mapreduce.Job: Job job_1422482982071_4303 completed successfully
15/04/09 05:09:09 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210344
		FILE: Number of bytes written=20771096492
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=210
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Failed map tasks=14
		Killed reduce tasks=1
		Launched map tasks=64
		Launched reduce tasks=21
		Other local map tasks=14
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=40204366
		Total time spent by all reduces in occupied slots (ms)=58067126
		Total time spent by all map tasks (ms)=20102183
		Total time spent by all reduce tasks (ms)=29033563
		Total vcore-seconds taken by all map tasks=20102183
		Total vcore-seconds taken by all reduce tasks=29033563
		Total megabyte-seconds taken by all map tasks=162747273568
		Total megabyte-seconds taken by all reduce tasks=348402756000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382216218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382216218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1000
		Failed Shuffles=0
		Merged Map outputs=1000
		GC time elapsed (ms)=159023
		CPU time spent (ms)=55718900
		Physical memory (bytes) snapshot=112124227584
		Virtual memory (bytes) snapshot=725967810560
		Total committed heap usage (bytes)=180586868736
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 05:09:09 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	66m2.805s
user	0m26.565s
sys	0m3.152s
15/04/09 05:09:12 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 20
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-20-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob572967997842329121.jar tmpDir=null
15/04/09 05:09:14 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 05:09:14 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 05:09:15 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 05:09:15 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 05:09:15 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 05:09:16 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4304
15/04/09 05:09:16 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4304
15/04/09 05:09:16 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4304/
15/04/09 05:09:16 INFO mapreduce.Job: Running job: job_1422482982071_4304
15/04/09 05:09:23 INFO mapreduce.Job: Job job_1422482982071_4304 running in uber mode : false
15/04/09 05:09:23 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 05:09:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4304_m_000046_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 05:09:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4304_m_000038_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 05:09:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4304_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 05:09:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4304_m_000033_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 05:09:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4304_m_000048_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 05:09:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4304_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 05:09:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4304_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 05:09:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4304_m_000009_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 05:09:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4304_m_000007_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 05:09:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4304_m_000033_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 05:09:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4304_m_000007_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 05:09:35 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 05:09:40 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 05:09:46 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 05:09:52 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 05:09:56 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 05:10:02 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 05:10:08 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 05:10:14 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 05:10:20 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 05:10:26 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 05:10:30 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 05:10:36 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 05:10:42 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 05:10:48 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 05:10:54 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 05:11:00 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 05:11:05 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 05:11:11 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 05:11:16 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 05:11:22 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 05:11:28 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 05:11:34 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 05:11:40 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 05:11:45 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 05:11:51 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 05:11:56 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 05:12:02 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 05:12:08 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 05:12:14 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 05:12:19 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 05:12:25 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 05:12:30 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 05:12:36 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 05:12:41 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 05:12:47 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 05:12:53 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 05:12:59 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 05:13:05 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 05:13:10 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 05:13:16 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 05:13:21 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 05:13:28 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 05:13:34 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 05:13:39 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 05:13:45 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 05:13:51 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 05:13:57 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 05:14:02 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 05:14:08 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 05:14:14 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 05:14:19 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 05:14:25 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 05:14:31 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 05:14:37 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 05:14:42 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 05:14:48 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 05:14:54 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 05:14:59 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 05:15:05 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 05:15:11 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 05:15:16 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 05:15:22 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 05:15:28 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 05:15:34 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 05:15:40 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 05:15:47 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 05:15:48 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 05:15:50 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 05:15:51 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 05:15:53 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 05:15:54 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 05:15:59 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 05:16:01 INFO mapreduce.Job:  map 75% reduce 7%
15/04/09 05:16:02 INFO mapreduce.Job:  map 76% reduce 8%
15/04/09 05:16:03 INFO mapreduce.Job:  map 78% reduce 8%
15/04/09 05:16:04 INFO mapreduce.Job:  map 80% reduce 10%
15/04/09 05:16:05 INFO mapreduce.Job:  map 80% reduce 12%
15/04/09 05:16:08 INFO mapreduce.Job:  map 82% reduce 14%
15/04/09 05:16:09 INFO mapreduce.Job:  map 86% reduce 15%
15/04/09 05:16:10 INFO mapreduce.Job:  map 89% reduce 15%
15/04/09 05:16:11 INFO mapreduce.Job:  map 91% reduce 20%
15/04/09 05:16:12 INFO mapreduce.Job:  map 92% reduce 24%
15/04/09 05:16:13 INFO mapreduce.Job:  map 93% reduce 24%
15/04/09 05:16:14 INFO mapreduce.Job:  map 93% reduce 25%
15/04/09 05:16:15 INFO mapreduce.Job:  map 95% reduce 26%
15/04/09 05:16:17 INFO mapreduce.Job:  map 96% reduce 28%
15/04/09 05:16:18 INFO mapreduce.Job:  map 97% reduce 29%
15/04/09 05:16:19 INFO mapreduce.Job:  map 98% reduce 29%
15/04/09 05:16:20 INFO mapreduce.Job:  map 99% reduce 30%
15/04/09 05:16:21 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 05:16:22 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 05:16:52 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 05:16:57 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 05:17:00 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 05:17:01 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 05:17:03 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 05:17:04 INFO mapreduce.Job:  map 100% reduce 46%
15/04/09 05:17:06 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 05:17:07 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 05:17:09 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 05:17:10 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 05:17:12 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 05:17:13 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 05:17:15 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 05:17:16 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 05:17:19 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 05:17:27 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 05:18:01 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 05:18:52 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 05:19:50 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 05:20:25 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 05:21:04 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 05:21:46 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 05:22:46 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 05:23:22 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 05:24:04 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 05:24:16 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 05:24:40 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 05:25:11 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 05:25:47 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 05:26:27 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 05:27:07 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 05:27:56 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 05:29:02 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 05:29:21 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 05:29:39 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 05:30:25 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 05:31:14 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 05:32:05 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 05:33:31 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 05:33:56 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 05:34:45 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 05:35:38 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 05:37:24 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 05:40:40 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 05:43:24 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 05:44:07 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 05:49:26 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 06:01:53 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 06:04:19 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 06:15:52 INFO mapreduce.Job: Job job_1422482982071_4304 completed successfully
15/04/09 06:15:52 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210344
		FILE: Number of bytes written=20771096492
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=210
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Failed map tasks=11
		Killed reduce tasks=1
		Launched map tasks=61
		Launched reduce tasks=21
		Other local map tasks=11
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=40247278
		Total time spent by all reduces in occupied slots (ms)=58302352
		Total time spent by all map tasks (ms)=20123639
		Total time spent by all reduce tasks (ms)=29151176
		Total vcore-seconds taken by all map tasks=20123639
		Total vcore-seconds taken by all reduce tasks=29151176
		Total megabyte-seconds taken by all map tasks=162920981344
		Total megabyte-seconds taken by all reduce tasks=349814112000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382216218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382216218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1000
		Failed Shuffles=0
		Merged Map outputs=1000
		GC time elapsed (ms)=155752
		CPU time spent (ms)=55811950
		Physical memory (bytes) snapshot=111931072512
		Virtual memory (bytes) snapshot=726181191680
		Total committed heap usage (bytes)=180587175936
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 06:15:52 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	66m43.184s
user	0m26.921s
sys	0m3.162s
15/04/09 06:15:55 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 20
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-20-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5656897154834937764.jar tmpDir=null
15/04/09 06:15:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 06:15:58 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 06:15:58 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 06:15:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 06:15:59 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 06:15:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4305
15/04/09 06:15:59 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4305
15/04/09 06:16:00 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4305/
15/04/09 06:16:00 INFO mapreduce.Job: Running job: job_1422482982071_4305
15/04/09 06:16:06 INFO mapreduce.Job: Job job_1422482982071_4305 running in uber mode : false
15/04/09 06:16:06 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 06:16:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4305_m_000024_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 06:16:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4305_m_000044_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 06:16:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4305_m_000023_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 06:16:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4305_m_000042_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 06:16:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4305_m_000047_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 06:16:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4305_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 06:16:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4305_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 06:16:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4305_m_000027_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 06:16:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4305_m_000028_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 06:16:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4305_m_000007_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 06:16:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4305_m_000015_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 06:16:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4305_m_000001_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 06:16:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4305_m_000019_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 06:16:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4305_m_000030_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 06:16:17 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 06:16:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4305_m_000028_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 06:16:23 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 06:16:29 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 06:16:35 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 06:16:41 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 06:16:46 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 06:16:52 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 06:16:57 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 06:17:03 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 06:17:09 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 06:17:15 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 06:17:20 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 06:17:27 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 06:17:32 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 06:17:38 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 06:17:44 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 06:17:49 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 06:17:55 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 06:18:01 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 06:18:06 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 06:18:12 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 06:18:18 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 06:18:23 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 06:18:29 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 06:18:35 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 06:18:41 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 06:18:46 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 06:18:52 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 06:18:57 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 06:19:03 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 06:19:09 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 06:19:14 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 06:19:20 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 06:19:26 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 06:19:32 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 06:19:37 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 06:19:43 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 06:19:49 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 06:19:55 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 06:20:01 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 06:20:07 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 06:20:13 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 06:20:19 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 06:20:24 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 06:20:29 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 06:20:35 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 06:20:41 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 06:20:47 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 06:20:52 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 06:20:58 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 06:21:04 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 06:21:10 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 06:21:15 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 06:21:21 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 06:21:26 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 06:21:32 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 06:21:38 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 06:21:44 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 06:21:50 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 06:21:55 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 06:22:01 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 06:22:07 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 06:22:12 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 06:22:18 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 06:22:24 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 06:22:31 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 06:22:36 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 06:22:39 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 06:22:40 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 06:22:41 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 06:22:42 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 06:22:43 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 06:22:45 INFO mapreduce.Job:  map 76% reduce 0%
15/04/09 06:22:47 INFO mapreduce.Job:  map 78% reduce 0%
15/04/09 06:22:49 INFO mapreduce.Job:  map 80% reduce 0%
15/04/09 06:22:50 INFO mapreduce.Job:  map 81% reduce 0%
15/04/09 06:22:51 INFO mapreduce.Job:  map 82% reduce 11%
15/04/09 06:22:52 INFO mapreduce.Job:  map 84% reduce 14%
15/04/09 06:22:54 INFO mapreduce.Job:  map 86% reduce 17%
15/04/09 06:22:55 INFO mapreduce.Job:  map 90% reduce 19%
15/04/09 06:22:56 INFO mapreduce.Job:  map 92% reduce 19%
15/04/09 06:22:57 INFO mapreduce.Job:  map 93% reduce 23%
15/04/09 06:22:58 INFO mapreduce.Job:  map 93% reduce 25%
15/04/09 06:23:00 INFO mapreduce.Job:  map 95% reduce 27%
15/04/09 06:23:01 INFO mapreduce.Job:  map 95% reduce 28%
15/04/09 06:23:02 INFO mapreduce.Job:  map 97% reduce 28%
15/04/09 06:23:03 INFO mapreduce.Job:  map 97% reduce 29%
15/04/09 06:23:04 INFO mapreduce.Job:  map 97% reduce 30%
15/04/09 06:23:09 INFO mapreduce.Job:  map 98% reduce 30%
15/04/09 06:23:10 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 06:23:20 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 06:23:22 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 06:23:31 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 06:23:33 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 06:23:35 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 06:23:37 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 06:23:38 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 06:23:40 INFO mapreduce.Job:  map 100% reduce 47%
15/04/09 06:23:41 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 06:23:43 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 06:23:44 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 06:23:46 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 06:23:47 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 06:23:49 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 06:23:50 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 06:23:52 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 06:23:56 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 06:24:05 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 06:24:35 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 06:25:33 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 06:26:28 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 06:27:07 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 06:27:41 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 06:28:23 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 06:29:20 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 06:29:58 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 06:30:37 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 06:30:59 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 06:31:20 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 06:31:50 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 06:32:28 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 06:33:04 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 06:33:52 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 06:34:32 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 06:35:41 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 06:35:54 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 06:36:15 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 06:37:13 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 06:38:02 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 06:39:15 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 06:40:03 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 06:40:39 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 06:40:54 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 06:42:11 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 06:44:17 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 06:47:21 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 06:49:45 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 06:51:16 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 06:57:34 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 07:09:03 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 07:11:29 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 07:22:57 INFO mapreduce.Job: Job job_1422482982071_4305 completed successfully
15/04/09 07:22:58 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10382210344
		FILE: Number of bytes written=20771096492
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=210
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Failed map tasks=15
		Killed reduce tasks=1
		Launched map tasks=65
		Launched reduce tasks=21
		Other local map tasks=15
		Data-local map tasks=30
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=40432096
		Total time spent by all reduces in occupied slots (ms)=58142286
		Total time spent by all map tasks (ms)=20216048
		Total time spent by all reduce tasks (ms)=29071143
		Total vcore-seconds taken by all map tasks=20216048
		Total vcore-seconds taken by all reduce tasks=29071143
		Total megabyte-seconds taken by all map tasks=163669124608
		Total megabyte-seconds taken by all reduce tasks=348853716000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382216218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382216218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =1000
		Failed Shuffles=0
		Merged Map outputs=1000
		GC time elapsed (ms)=156747
		CPU time spent (ms)=55973730
		Physical memory (bytes) snapshot=112753291264
		Virtual memory (bytes) snapshot=726171750400
		Total committed heap usage (bytes)=180587241472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 07:22:58 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	67m5.217s
user	0m27.144s
sys	0m3.193s
15/04/09 07:23:00 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 10
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-10-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob532852391939507239.jar tmpDir=null
15/04/09 07:23:03 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 07:23:03 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 07:23:04 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 07:23:04 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 07:23:04 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 07:23:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4306
15/04/09 07:23:05 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4306
15/04/09 07:23:05 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4306/
15/04/09 07:23:05 INFO mapreduce.Job: Running job: job_1422482982071_4306
15/04/09 07:23:12 INFO mapreduce.Job: Job job_1422482982071_4306 running in uber mode : false
15/04/09 07:23:12 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 07:23:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4306_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 07:23:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4306_m_000035_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 07:23:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4306_m_000028_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 07:23:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4306_m_000021_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 07:23:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4306_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 07:23:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4306_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 07:23:18 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 07:23:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4306_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 07:23:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4306_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 07:23:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4306_m_000042_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 07:23:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4306_m_000048_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 07:23:19 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 07:23:24 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 07:23:29 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 07:23:35 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 07:23:40 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 07:23:45 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 07:23:51 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 07:23:57 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 07:24:03 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 07:24:08 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 07:24:14 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 07:24:19 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 07:24:25 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 07:24:31 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 07:24:36 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 07:24:42 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 07:24:47 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 07:24:52 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 07:24:58 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 07:25:04 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 07:25:11 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 07:25:17 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 07:25:22 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 07:25:27 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 07:25:33 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 07:25:38 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 07:25:44 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 07:25:50 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 07:25:56 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 07:26:01 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 07:26:07 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 07:26:12 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 07:26:18 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 07:26:24 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 07:26:29 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 07:26:35 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 07:26:41 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 07:26:46 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 07:26:52 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 07:26:58 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 07:27:03 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 07:27:09 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 07:27:15 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 07:27:20 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 07:27:26 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 07:27:32 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 07:27:38 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 07:27:44 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 07:27:50 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 07:27:55 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 07:28:01 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 07:28:07 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 07:28:12 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 07:28:18 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 07:28:24 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 07:28:29 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 07:28:35 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 07:28:41 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 07:28:47 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 07:28:52 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 07:28:58 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 07:29:03 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 07:29:09 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 07:29:15 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 07:29:20 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 07:29:26 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 07:29:32 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 07:29:35 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 07:29:43 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 07:29:45 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 07:29:46 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 07:29:47 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 07:29:49 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 07:29:51 INFO mapreduce.Job:  map 77% reduce 0%
15/04/09 07:29:52 INFO mapreduce.Job:  map 79% reduce 0%
15/04/09 07:29:53 INFO mapreduce.Job:  map 80% reduce 0%
15/04/09 07:29:54 INFO mapreduce.Job:  map 82% reduce 0%
15/04/09 07:29:55 INFO mapreduce.Job:  map 84% reduce 0%
15/04/09 07:29:56 INFO mapreduce.Job:  map 85% reduce 6%
15/04/09 07:29:57 INFO mapreduce.Job:  map 85% reduce 17%
15/04/09 07:29:58 INFO mapreduce.Job:  map 89% reduce 17%
15/04/09 07:29:59 INFO mapreduce.Job:  map 91% reduce 19%
15/04/09 07:30:00 INFO mapreduce.Job:  map 91% reduce 23%
15/04/09 07:30:01 INFO mapreduce.Job:  map 93% reduce 23%
15/04/09 07:30:02 INFO mapreduce.Job:  map 95% reduce 24%
15/04/09 07:30:03 INFO mapreduce.Job:  map 95% reduce 27%
15/04/09 07:30:04 INFO mapreduce.Job:  map 97% reduce 27%
15/04/09 07:30:05 INFO mapreduce.Job:  map 99% reduce 28%
15/04/09 07:30:06 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 07:30:13 INFO mapreduce.Job:  map 100% reduce 31%
15/04/09 07:30:15 INFO mapreduce.Job:  map 100% reduce 32%
15/04/09 07:30:18 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 07:30:21 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 07:30:23 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 07:30:25 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 07:30:26 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 07:30:28 INFO mapreduce.Job:  map 100% reduce 42%
15/04/09 07:30:29 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 07:30:31 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 07:30:32 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 07:30:34 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 07:30:35 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 07:30:37 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 07:30:38 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 07:30:40 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 07:30:41 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 07:30:43 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 07:30:46 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 07:30:49 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 07:32:36 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 07:34:28 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 07:36:08 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 07:38:22 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 07:38:56 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 07:40:59 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 07:42:23 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 07:44:19 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 07:45:40 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 07:46:52 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 07:48:14 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 07:50:19 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 07:50:43 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 07:51:37 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 07:52:33 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 07:54:17 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 07:55:59 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 07:57:09 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 07:58:26 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 07:58:40 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 07:59:49 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 08:01:28 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 08:03:15 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 08:03:53 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 08:05:47 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 08:09:18 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 08:11:07 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 08:11:58 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 08:15:34 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 08:15:52 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 08:22:56 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 08:31:28 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 08:43:56 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 08:47:32 INFO mapreduce.Job: Job job_1422482982071_4306 completed successfully
15/04/09 08:47:32 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10382210302
		FILE: Number of bytes written=20770132250
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=180
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Failed map tasks=10
		Launched map tasks=60
		Launched reduce tasks=10
		Other local map tasks=10
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=40140076
		Total time spent by all reduces in occupied slots (ms)=53434780
		Total time spent by all map tasks (ms)=20070038
		Total time spent by all reduce tasks (ms)=26717390
		Total vcore-seconds taken by all map tasks=20070038
		Total vcore-seconds taken by all reduce tasks=26717390
		Total megabyte-seconds taken by all map tasks=162487027648
		Total megabyte-seconds taken by all reduce tasks=320608680000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382213218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382213218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =500
		Failed Shuffles=0
		Merged Map outputs=500
		GC time elapsed (ms)=157755
		CPU time spent (ms)=55301450
		Physical memory (bytes) snapshot=110547828736
		Virtual memory (bytes) snapshot=592150585344
		Total committed heap usage (bytes)=159535767552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 08:47:32 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	84m34.448s
user	0m30.203s
sys	0m4.053s
15/04/09 08:47:34 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 10
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-10-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob954440578283308728.jar tmpDir=null
15/04/09 08:47:37 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 08:47:37 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 08:47:38 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 08:47:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 08:47:38 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 08:47:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4307
15/04/09 08:47:39 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4307
15/04/09 08:47:39 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4307/
15/04/09 08:47:39 INFO mapreduce.Job: Running job: job_1422482982071_4307
15/04/09 08:47:46 INFO mapreduce.Job: Job job_1422482982071_4307 running in uber mode : false
15/04/09 08:47:46 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 08:47:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4307_m_000000_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 08:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4307_m_000045_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 08:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4307_m_000024_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 08:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4307_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 08:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4307_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 08:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4307_m_000003_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 08:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4307_m_000028_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 08:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4307_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 08:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4307_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 08:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4307_m_000047_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 08:47:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4307_m_000009_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 08:47:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4307_m_000003_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 08:47:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4307_m_000045_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 08:47:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4307_m_000009_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 08:47:57 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 08:48:03 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 08:48:09 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 08:48:15 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 08:48:20 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 08:48:25 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 08:48:31 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 08:48:37 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 08:48:43 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 08:48:48 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 08:48:54 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 08:48:59 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 08:49:05 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 08:49:11 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 08:49:16 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 08:49:22 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 08:49:28 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 08:49:34 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 08:49:39 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 08:49:45 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 08:49:51 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 08:49:57 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 08:50:03 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 08:50:08 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 08:50:14 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 08:50:20 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 08:50:25 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 08:50:31 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 08:50:36 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 08:50:42 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 08:50:48 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 08:50:54 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 08:51:00 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 08:51:05 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 08:51:11 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 08:51:16 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 08:51:22 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 08:51:28 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 08:51:33 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 08:51:39 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 08:51:45 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 08:51:51 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 08:51:57 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 08:52:02 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 08:52:07 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 08:52:13 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 08:52:19 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 08:52:26 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 08:52:31 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 08:52:37 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 08:52:43 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 08:52:49 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 08:52:54 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 08:53:00 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 08:53:05 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 08:53:11 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 08:53:17 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 08:53:23 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 08:53:28 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 08:53:34 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 08:53:40 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 08:53:45 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 08:53:51 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 08:53:57 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 08:54:03 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 08:54:10 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 08:54:14 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 08:54:15 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 08:54:16 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 08:54:18 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 08:54:19 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 08:54:21 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 08:54:22 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 08:54:23 INFO mapreduce.Job:  map 76% reduce 0%
15/04/09 08:54:24 INFO mapreduce.Job:  map 78% reduce 0%
15/04/09 08:54:25 INFO mapreduce.Job:  map 80% reduce 2%
15/04/09 08:54:26 INFO mapreduce.Job:  map 80% reduce 10%
15/04/09 08:54:27 INFO mapreduce.Job:  map 82% reduce 12%
15/04/09 08:54:28 INFO mapreduce.Job:  map 82% reduce 13%
15/04/09 08:54:29 INFO mapreduce.Job:  map 82% reduce 15%
15/04/09 08:54:30 INFO mapreduce.Job:  map 83% reduce 16%
15/04/09 08:54:31 INFO mapreduce.Job:  map 85% reduce 16%
15/04/09 08:54:32 INFO mapreduce.Job:  map 86% reduce 18%
15/04/09 08:54:33 INFO mapreduce.Job:  map 88% reduce 19%
15/04/09 08:54:35 INFO mapreduce.Job:  map 88% reduce 22%
15/04/09 08:54:36 INFO mapreduce.Job:  map 90% reduce 22%
15/04/09 08:54:37 INFO mapreduce.Job:  map 92% reduce 22%
15/04/09 08:54:38 INFO mapreduce.Job:  map 94% reduce 24%
15/04/09 08:54:39 INFO mapreduce.Job:  map 96% reduce 26%
15/04/09 08:54:41 INFO mapreduce.Job:  map 96% reduce 28%
15/04/09 08:54:42 INFO mapreduce.Job:  map 96% reduce 29%
15/04/09 08:54:43 INFO mapreduce.Job:  map 97% reduce 29%
15/04/09 08:54:45 INFO mapreduce.Job:  map 98% reduce 29%
15/04/09 08:54:47 INFO mapreduce.Job:  map 98% reduce 30%
15/04/09 08:54:49 INFO mapreduce.Job:  map 99% reduce 30%
15/04/09 08:55:05 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 08:55:06 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 08:55:29 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 08:55:34 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 08:55:37 INFO mapreduce.Job:  map 100% reduce 40%
15/04/09 08:55:39 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 08:55:40 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 08:55:42 INFO mapreduce.Job:  map 100% reduce 46%
15/04/09 08:55:43 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 08:55:44 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 08:55:45 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 08:55:46 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 08:55:47 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 08:55:48 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 08:55:49 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 08:55:50 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 08:55:51 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 08:55:52 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 08:55:53 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 08:55:55 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 08:55:58 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 08:55:59 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 08:56:04 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 08:57:52 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 08:59:52 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 09:01:31 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 09:03:23 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 09:04:22 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 09:06:01 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 09:07:54 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 09:09:50 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 09:10:48 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 09:12:23 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 09:14:07 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 09:15:06 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 09:16:12 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 09:17:12 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 09:18:14 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 09:19:27 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 09:21:13 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 09:22:47 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 09:24:11 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 09:24:34 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 09:25:32 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 09:27:07 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 09:27:43 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 09:29:11 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 09:30:45 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 09:34:24 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 09:35:22 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 09:37:33 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 09:39:01 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 09:39:55 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 09:49:07 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 09:57:57 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 10:05:49 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 10:09:14 INFO mapreduce.Job: Job job_1422482982071_4307 completed successfully
15/04/09 10:09:14 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10382210302
		FILE: Number of bytes written=20770132250
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=180
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Failed map tasks=14
		Launched map tasks=64
		Launched reduce tasks=10
		Other local map tasks=14
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=40385958
		Total time spent by all reduces in occupied slots (ms)=54156956
		Total time spent by all map tasks (ms)=20192979
		Total time spent by all reduce tasks (ms)=27078478
		Total vcore-seconds taken by all map tasks=20192979
		Total vcore-seconds taken by all reduce tasks=27078478
		Total megabyte-seconds taken by all map tasks=163482357984
		Total megabyte-seconds taken by all reduce tasks=324941736000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382213218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382213218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =500
		Failed Shuffles=0
		Merged Map outputs=500
		GC time elapsed (ms)=136102
		CPU time spent (ms)=55388150
		Physical memory (bytes) snapshot=110548348928
		Virtual memory (bytes) snapshot=592357187584
		Total committed heap usage (bytes)=159536640000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 10:09:14 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	81m42.248s
user	0m29.495s
sys	0m3.852s
15/04/09 10:09:17 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 10
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-10-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1772726939144726376.jar tmpDir=null
15/04/09 10:09:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 10:09:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 10:09:21 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 10:09:21 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 10:09:21 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 10:09:21 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4308
15/04/09 10:09:22 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4308
15/04/09 10:09:22 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4308/
15/04/09 10:09:22 INFO mapreduce.Job: Running job: job_1422482982071_4308
15/04/09 10:09:28 INFO mapreduce.Job: Job job_1422482982071_4308 running in uber mode : false
15/04/09 10:09:28 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 10:09:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4308_m_000049_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 10:09:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4308_m_000042_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 10:09:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4308_m_000045_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 10:09:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4308_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 10:09:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4308_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 10:09:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4308_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 10:09:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4308_m_000022_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 10:09:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4308_m_000033_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 10:09:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4308_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 10:09:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4308_m_000002_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 10:09:40 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 10:09:46 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 10:09:52 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 10:09:57 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 10:10:02 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 10:10:08 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 10:10:14 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 10:10:20 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 10:10:26 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 10:10:31 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 10:10:36 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 10:10:42 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 10:10:49 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 10:10:55 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 10:11:01 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 10:11:06 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 10:11:12 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 10:11:17 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 10:11:22 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 10:11:28 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 10:11:34 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 10:11:40 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 10:11:46 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 10:11:52 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 10:11:57 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 10:12:03 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 10:12:08 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 10:12:14 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 10:12:20 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 10:12:26 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 10:12:32 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 10:12:37 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 10:12:43 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 10:12:49 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 10:12:54 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 10:12:59 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 10:13:05 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 10:13:11 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 10:13:17 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 10:13:23 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 10:13:29 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 10:13:35 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 10:13:40 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 10:13:47 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 10:13:52 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 10:13:58 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 10:14:04 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 10:14:10 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 10:14:15 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 10:14:21 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 10:14:27 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 10:14:33 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 10:14:39 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 10:14:44 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 10:14:50 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 10:14:55 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 10:15:01 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 10:15:07 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 10:15:13 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 10:15:18 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 10:15:24 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 10:15:30 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 10:15:36 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 10:15:42 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 10:15:48 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 10:15:54 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 10:15:55 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 10:16:00 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 10:16:01 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 10:16:03 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 10:16:04 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 10:16:06 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 10:16:07 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 10:16:09 INFO mapreduce.Job:  map 76% reduce 0%
15/04/09 10:16:10 INFO mapreduce.Job:  map 76% reduce 8%
15/04/09 10:16:11 INFO mapreduce.Job:  map 78% reduce 9%
15/04/09 10:16:13 INFO mapreduce.Job:  map 80% reduce 12%
15/04/09 10:16:14 INFO mapreduce.Job:  map 81% reduce 12%
15/04/09 10:16:15 INFO mapreduce.Job:  map 84% reduce 12%
15/04/09 10:16:16 INFO mapreduce.Job:  map 85% reduce 15%
15/04/09 10:16:17 INFO mapreduce.Job:  map 86% reduce 18%
15/04/09 10:16:18 INFO mapreduce.Job:  map 88% reduce 18%
15/04/09 10:16:19 INFO mapreduce.Job:  map 88% reduce 20%
15/04/09 10:16:20 INFO mapreduce.Job:  map 90% reduce 21%
15/04/09 10:16:21 INFO mapreduce.Job:  map 91% reduce 21%
15/04/09 10:16:22 INFO mapreduce.Job:  map 93% reduce 22%
15/04/09 10:16:23 INFO mapreduce.Job:  map 96% reduce 26%
15/04/09 10:16:24 INFO mapreduce.Job:  map 97% reduce 26%
15/04/09 10:16:26 INFO mapreduce.Job:  map 97% reduce 29%
15/04/09 10:16:29 INFO mapreduce.Job:  map 98% reduce 29%
15/04/09 10:16:30 INFO mapreduce.Job:  map 98% reduce 30%
15/04/09 10:16:32 INFO mapreduce.Job:  map 99% reduce 30%
15/04/09 10:16:50 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 10:16:51 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 10:17:07 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 10:17:11 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 10:17:12 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 10:17:13 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 10:17:15 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 10:17:16 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 10:17:17 INFO mapreduce.Job:  map 100% reduce 44%
15/04/09 10:17:18 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 10:17:19 INFO mapreduce.Job:  map 100% reduce 47%
15/04/09 10:17:20 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 10:17:22 INFO mapreduce.Job:  map 100% reduce 51%
15/04/09 10:17:23 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 10:17:24 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 10:17:25 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 10:17:27 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 10:17:28 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 10:17:31 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 10:17:34 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 10:17:37 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 10:17:40 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 10:19:29 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 10:21:26 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 10:23:06 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 10:25:12 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 10:25:59 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 10:27:56 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 10:29:26 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 10:31:22 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 10:33:07 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 10:34:07 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 10:35:18 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 10:37:08 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 10:38:08 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 10:38:54 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 10:39:52 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 10:41:30 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 10:43:17 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 10:44:15 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 10:45:47 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 10:47:00 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 10:47:18 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 10:49:26 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 10:49:51 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 10:51:24 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 10:53:23 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 10:56:41 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 10:58:32 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 11:00:24 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 11:03:33 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 11:11:51 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 11:20:46 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 11:32:15 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 11:35:57 INFO mapreduce.Job: Job job_1422482982071_4308 completed successfully
15/04/09 11:35:57 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10382210302
		FILE: Number of bytes written=20770132250
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=180
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Failed map tasks=10
		Launched map tasks=60
		Launched reduce tasks=10
		Other local map tasks=10
		Data-local map tasks=31
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=40526930
		Total time spent by all reduces in occupied slots (ms)=55206910
		Total time spent by all map tasks (ms)=20263465
		Total time spent by all reduce tasks (ms)=27603455
		Total vcore-seconds taken by all map tasks=20263465
		Total vcore-seconds taken by all reduce tasks=27603455
		Total megabyte-seconds taken by all map tasks=164053012640
		Total megabyte-seconds taken by all reduce tasks=331241460000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382213218
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382213218
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =500
		Failed Shuffles=0
		Merged Map outputs=500
		GC time elapsed (ms)=133218
		CPU time spent (ms)=56053630
		Physical memory (bytes) snapshot=110494916608
		Virtual memory (bytes) snapshot=593143844864
		Total committed heap usage (bytes)=159536656384
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 11:35:57 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	86m42.462s
user	0m29.545s
sys	0m3.924s
15/04/09 11:35:59 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 5
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-5-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3559604382462306471.jar tmpDir=null
15/04/09 11:36:02 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 11:36:03 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 11:36:03 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 11:36:03 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 11:36:04 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 11:36:04 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4309
15/04/09 11:36:04 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4309
15/04/09 11:36:05 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4309/
15/04/09 11:36:05 INFO mapreduce.Job: Running job: job_1422482982071_4309
15/04/09 11:36:11 INFO mapreduce.Job: Job job_1422482982071_4309 running in uber mode : false
15/04/09 11:36:11 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 11:36:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4309_m_000025_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 11:36:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4309_m_000048_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 11:36:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4309_m_000022_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 11:36:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4309_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 11:36:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4309_m_000015_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 11:36:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4309_m_000042_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 11:36:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4309_m_000044_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 11:36:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4309_m_000024_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 11:36:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4309_m_000019_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 11:36:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4309_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 11:36:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4309_m_000009_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 11:36:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4309_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 11:36:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4309_m_000015_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 11:36:22 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 11:36:28 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 11:36:34 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 11:36:40 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 11:36:45 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 11:36:50 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 11:36:56 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 11:37:02 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 11:37:08 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 11:37:14 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 11:37:19 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 11:37:24 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 11:37:30 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 11:37:36 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 11:37:42 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 11:37:49 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 11:37:54 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 11:38:00 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 11:38:05 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 11:38:10 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 11:38:16 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 11:38:22 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 11:38:28 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 11:38:34 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 11:38:40 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 11:38:45 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 11:38:50 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 11:38:56 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 11:39:02 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 11:39:07 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 11:39:13 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 11:39:19 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 11:39:25 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 11:39:30 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 11:39:35 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 11:39:41 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 11:39:47 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 11:39:53 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 11:39:59 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 11:40:04 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 11:40:10 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 11:40:16 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 11:40:22 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 11:40:28 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 11:40:33 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 11:40:39 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 11:40:45 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 11:40:51 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 11:40:57 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 11:41:02 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 11:41:08 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 11:41:13 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 11:41:19 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 11:41:25 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 11:41:31 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 11:41:36 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 11:41:42 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 11:41:48 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 11:41:53 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 11:41:59 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 11:42:05 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 11:42:10 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 11:42:16 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 11:42:22 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 11:42:28 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 11:42:35 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 11:42:39 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 11:42:41 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 11:42:42 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 11:42:43 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 11:42:44 INFO mapreduce.Job:  map 73% reduce 0%
15/04/09 11:42:46 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 11:42:50 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 11:42:51 INFO mapreduce.Job:  map 77% reduce 5%
15/04/09 11:42:52 INFO mapreduce.Job:  map 78% reduce 9%
15/04/09 11:42:53 INFO mapreduce.Job:  map 80% reduce 9%
15/04/09 11:42:54 INFO mapreduce.Job:  map 81% reduce 12%
15/04/09 11:42:55 INFO mapreduce.Job:  map 83% reduce 12%
15/04/09 11:42:56 INFO mapreduce.Job:  map 85% reduce 13%
15/04/09 11:42:57 INFO mapreduce.Job:  map 86% reduce 16%
15/04/09 11:42:58 INFO mapreduce.Job:  map 87% reduce 16%
15/04/09 11:42:59 INFO mapreduce.Job:  map 88% reduce 19%
15/04/09 11:43:00 INFO mapreduce.Job:  map 89% reduce 19%
15/04/09 11:43:01 INFO mapreduce.Job:  map 90% reduce 19%
15/04/09 11:43:02 INFO mapreduce.Job:  map 91% reduce 19%
15/04/09 11:43:03 INFO mapreduce.Job:  map 93% reduce 19%
15/04/09 11:43:05 INFO mapreduce.Job:  map 95% reduce 19%
15/04/09 11:43:07 INFO mapreduce.Job:  map 96% reduce 19%
15/04/09 11:43:08 INFO mapreduce.Job:  map 97% reduce 19%
15/04/09 11:43:10 INFO mapreduce.Job:  map 98% reduce 19%
15/04/09 11:43:11 INFO mapreduce.Job:  map 99% reduce 19%
15/04/09 11:43:24 INFO mapreduce.Job:  map 99% reduce 21%
15/04/09 11:43:25 INFO mapreduce.Job:  map 99% reduce 24%
15/04/09 11:43:26 INFO mapreduce.Job:  map 99% reduce 28%
15/04/09 11:43:27 INFO mapreduce.Job:  map 99% reduce 30%
15/04/09 11:43:29 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 11:43:47 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 11:43:48 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 11:43:52 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 11:43:53 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 11:43:55 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 11:43:56 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 11:43:57 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 11:43:58 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 11:43:59 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 11:44:02 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 11:44:05 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 11:44:14 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 11:48:41 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 11:52:04 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 11:53:32 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 11:57:04 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 12:01:31 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 12:09:08 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 12:12:50 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 12:15:32 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 12:19:15 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 12:23:03 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 12:25:22 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 12:25:53 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 12:30:21 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 12:33:00 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 12:36:25 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 12:36:39 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 12:37:46 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 12:39:44 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 12:42:04 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 12:44:58 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 12:48:26 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 12:50:16 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 12:52:53 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 12:55:11 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 12:57:36 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 13:01:47 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 13:05:42 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 13:08:09 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 13:10:57 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 13:18:09 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 13:21:31 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 13:27:04 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 13:33:10 INFO mapreduce.Job: Job job_1422482982071_4309 completed successfully
15/04/09 13:33:10 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10382210296
		FILE: Number of bytes written=20769650039
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=165
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Failed map tasks=13
		Launched map tasks=63
		Launched reduce tasks=5
		Other local map tasks=13
		Data-local map tasks=30
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=40414278
		Total time spent by all reduces in occupied slots (ms)=54844458
		Total time spent by all map tasks (ms)=20207139
		Total time spent by all reduce tasks (ms)=27422229
		Total vcore-seconds taken by all map tasks=20207139
		Total vcore-seconds taken by all reduce tasks=27422229
		Total megabyte-seconds taken by all map tasks=163596997344
		Total megabyte-seconds taken by all reduce tasks=329066748000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382211718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382211718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =250
		Failed Shuffles=0
		Merged Map outputs=250
		GC time elapsed (ms)=380585
		CPU time spent (ms)=56297790
		Physical memory (bytes) snapshot=108173500416
		Virtual memory (bytes) snapshot=525739655168
		Total committed heap usage (bytes)=149010915328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 13:33:10 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	117m13.614s
user	0m33.510s
sys	0m5.608s
15/04/09 13:33:13 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 5
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-5-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4794695830876309413.jar tmpDir=null
15/04/09 13:33:15 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:33:16 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 13:33:17 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 13:33:17 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 13:33:17 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 13:33:17 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4327
15/04/09 13:33:18 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4327
15/04/09 13:33:18 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4327/
15/04/09 13:33:18 INFO mapreduce.Job: Running job: job_1422482982071_4327
15/04/09 13:33:23 INFO mapreduce.Job: Job job_1422482982071_4327 running in uber mode : false
15/04/09 13:33:23 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 13:33:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4327_m_000042_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 13:33:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4327_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 13:33:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4327_m_000028_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 13:33:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4327_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 13:33:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4327_m_000019_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 13:33:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4327_m_000017_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 13:33:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4327_m_000012_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 13:33:35 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 13:33:40 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 13:33:46 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 13:33:52 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 13:33:58 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 13:34:04 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 13:34:09 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 13:34:15 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 13:34:21 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 13:34:27 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 13:34:33 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 13:34:38 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 13:34:44 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 13:34:50 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 13:34:56 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 13:35:01 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 13:35:08 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 13:35:13 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 13:35:19 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 13:35:25 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 13:35:31 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 13:35:37 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 13:35:43 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 13:35:49 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 13:35:55 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 13:36:00 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 13:36:06 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 13:36:12 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 13:36:18 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 13:36:24 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 13:36:30 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 13:36:36 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 13:36:42 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 13:36:48 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 13:36:54 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 13:36:59 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 13:37:05 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 13:37:11 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 13:37:17 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 13:37:23 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 13:37:28 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 13:37:34 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 13:37:40 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 13:37:46 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 13:37:52 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 13:37:57 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 13:38:03 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 13:38:09 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 13:38:15 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 13:38:20 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 13:38:26 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 13:38:32 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 13:38:38 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 13:38:44 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 13:38:49 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 13:38:55 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 13:39:01 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 13:39:07 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 13:39:13 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 13:39:18 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 13:39:24 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 13:39:30 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 13:39:36 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 13:39:43 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 13:39:49 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 13:39:57 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 13:40:00 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 13:40:01 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 13:40:02 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 13:40:03 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 13:40:04 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 13:40:05 INFO mapreduce.Job:  map 73% reduce 0%
15/04/09 13:40:08 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 13:40:09 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 13:40:11 INFO mapreduce.Job:  map 76% reduce 7%
15/04/09 13:40:12 INFO mapreduce.Job:  map 78% reduce 9%
15/04/09 13:40:13 INFO mapreduce.Job:  map 80% reduce 9%
15/04/09 13:40:14 INFO mapreduce.Job:  map 80% reduce 13%
15/04/09 13:40:15 INFO mapreduce.Job:  map 81% reduce 13%
15/04/09 13:40:16 INFO mapreduce.Job:  map 82% reduce 13%
15/04/09 13:40:17 INFO mapreduce.Job:  map 84% reduce 15%
15/04/09 13:40:18 INFO mapreduce.Job:  map 86% reduce 16%
15/04/09 13:40:19 INFO mapreduce.Job:  map 88% reduce 16%
15/04/09 13:40:20 INFO mapreduce.Job:  map 89% reduce 18%
15/04/09 13:40:21 INFO mapreduce.Job:  map 90% reduce 19%
15/04/09 13:40:23 INFO mapreduce.Job:  map 92% reduce 19%
15/04/09 13:40:24 INFO mapreduce.Job:  map 94% reduce 19%
15/04/09 13:40:25 INFO mapreduce.Job:  map 95% reduce 19%
15/04/09 13:40:31 INFO mapreduce.Job:  map 96% reduce 19%
15/04/09 13:40:40 INFO mapreduce.Job:  map 97% reduce 19%
15/04/09 13:40:45 INFO mapreduce.Job:  map 97% reduce 27%
15/04/09 13:40:48 INFO mapreduce.Job:  map 97% reduce 31%
15/04/09 13:40:49 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 13:41:05 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 13:41:06 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 13:41:12 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 13:41:14 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 13:41:18 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 13:41:19 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 13:41:21 INFO mapreduce.Job:  map 100% reduce 44%
15/04/09 13:41:22 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 13:41:24 INFO mapreduce.Job:  map 100% reduce 48%
15/04/09 13:41:25 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 13:41:27 INFO mapreduce.Job:  map 100% reduce 51%
15/04/09 13:41:28 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 13:41:31 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 13:41:33 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 13:41:36 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 13:41:42 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 13:46:00 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 13:50:03 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 13:50:57 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 13:54:28 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 13:59:05 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 14:06:16 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 14:10:02 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 14:11:41 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 14:15:20 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 14:19:01 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 14:22:50 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 14:24:03 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 14:26:40 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 14:29:26 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 14:32:30 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 14:34:46 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 14:35:33 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 14:36:49 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 14:39:38 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 14:42:30 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 14:44:05 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 14:46:52 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 14:49:44 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 14:51:58 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 14:55:47 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 15:00:13 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 15:02:37 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 15:04:57 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 15:09:46 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 15:11:16 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 15:15:59 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 15:26:54 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 15:33:21 INFO mapreduce.Job: Job job_1422482982071_4327 completed successfully
15/04/09 15:33:21 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10382210296
		FILE: Number of bytes written=20769650039
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=2443025
		HDFS: Number of read operations=165
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Failed map tasks=7
		Launched map tasks=57
		Launched reduce tasks=5
		Other local map tasks=7
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=41300352
		Total time spent by all reduces in occupied slots (ms)=54509372
		Total time spent by all map tasks (ms)=20650176
		Total time spent by all reduce tasks (ms)=27254686
		Total vcore-seconds taken by all map tasks=20650176
		Total vcore-seconds taken by all reduce tasks=27254686
		Total megabyte-seconds taken by all map tasks=167183824896
		Total megabyte-seconds taken by all reduce tasks=327056232000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085580592
		Map output bytes=8211049028
		Map output materialized bytes=10382211718
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=174410
		Reduce shuffle bytes=10382211718
		Reduce input records=1085580592
		Reduce output records=174410
		Spilled Records=2171161184
		Shuffled Maps =250
		Failed Shuffles=0
		Merged Map outputs=250
		GC time elapsed (ms)=234582
		CPU time spent (ms)=56430760
		Physical memory (bytes) snapshot=107923263488
		Virtual memory (bytes) snapshot=525543092224
		Total committed heap usage (bytes)=149010857984
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=2443025
15/04/09 15:33:21 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta

real	120m10.711s
user	0m33.434s
sys	0m5.010s
15/04/09 15:33:24 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
50 5
r googlebooks-eng-all-5gram-20120701-ta mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-5-googlebooks-eng-all-5gram-20120701-ta -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-ta -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7051999533012167223.jar tmpDir=null
15/04/09 15:33:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 15:33:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 15:33:28 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/09 15:33:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/09 15:33:28 INFO mapreduce.JobSubmitter: number of splits:50
15/04/09 15:33:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4359
15/04/09 15:33:29 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4359
15/04/09 15:33:29 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4359/
15/04/09 15:33:29 INFO mapreduce.Job: Running job: job_1422482982071_4359
15/04/09 15:33:34 INFO mapreduce.Job: Job job_1422482982071_4359 running in uber mode : false
15/04/09 15:33:34 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 15:33:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_m_000019_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 15:33:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_m_000048_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 15:33:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_m_000027_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 15:33:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_m_000043_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 15:33:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_m_000000_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 15:33:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_m_000049_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 15:33:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_m_000025_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 15:33:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_m_000015_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 15:33:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_m_000024_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 15:33:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_m_000007_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 15:33:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_m_000003_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 15:33:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_m_000048_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 15:33:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_m_000007_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 15:33:47 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 15:33:53 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 15:33:59 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 15:34:05 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 15:34:10 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 15:34:16 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 15:34:21 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 15:34:27 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 15:34:33 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 15:34:39 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 15:34:44 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 15:34:50 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 15:34:55 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 15:35:01 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 15:35:07 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 15:35:13 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 15:35:18 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 15:35:24 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 15:35:30 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 15:35:35 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 15:35:41 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 15:35:47 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 15:35:53 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 15:35:59 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 15:36:05 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 15:36:11 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 15:36:17 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 15:36:22 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 15:36:28 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 15:36:34 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 15:36:39 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 15:36:45 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 15:36:51 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 15:36:56 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 15:37:02 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 15:37:08 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 15:37:14 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 15:37:20 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 15:37:25 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 15:37:31 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 15:37:36 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 15:37:42 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 15:37:48 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 15:37:54 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 15:38:00 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 15:38:05 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 15:38:11 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 15:38:17 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 15:38:24 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 15:38:29 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 15:38:35 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 15:38:41 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 15:38:47 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 15:38:52 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 15:38:58 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 15:39:04 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 15:39:10 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 15:39:15 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 15:39:21 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 15:39:27 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 15:39:33 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 15:39:38 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 15:39:44 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 15:39:50 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 15:39:56 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 15:40:04 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 15:40:08 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 15:40:14 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 15:40:15 INFO mapreduce.Job:  map 71% reduce 1%
15/04/09 15:40:16 INFO mapreduce.Job:  map 73% reduce 5%
15/04/09 15:40:17 INFO mapreduce.Job:  map 74% reduce 5%
15/04/09 15:40:18 INFO mapreduce.Job:  map 75% reduce 5%
15/04/09 15:40:19 INFO mapreduce.Job:  map 77% reduce 8%
15/04/09 15:40:20 INFO mapreduce.Job:  map 78% reduce 8%
15/04/09 15:40:21 INFO mapreduce.Job:  map 79% reduce 9%
15/04/09 15:40:22 INFO mapreduce.Job:  map 84% reduce 13%
15/04/09 15:40:24 INFO mapreduce.Job:  map 84% reduce 14%
15/04/09 15:40:25 INFO mapreduce.Job:  map 85% reduce 18%
15/04/09 15:40:26 INFO mapreduce.Job:  map 86% reduce 18%
15/04/09 15:40:27 INFO mapreduce.Job:  map 88% reduce 18%
15/04/09 15:40:28 INFO mapreduce.Job:  map 92% reduce 19%
15/04/09 15:40:29 INFO mapreduce.Job:  map 93% reduce 19%
15/04/09 15:40:30 INFO mapreduce.Job:  map 94% reduce 19%
15/04/09 15:40:31 INFO mapreduce.Job:  map 95% reduce 19%
15/04/09 15:40:33 INFO mapreduce.Job:  map 96% reduce 19%
15/04/09 15:40:37 INFO mapreduce.Job:  map 97% reduce 19%
15/04/09 15:40:38 INFO mapreduce.Job:  map 98% reduce 19%
15/04/09 15:40:49 INFO mapreduce.Job:  map 98% reduce 22%
15/04/09 15:40:51 INFO mapreduce.Job:  map 98% reduce 24%
15/04/09 15:40:52 INFO mapreduce.Job:  map 98% reduce 30%
15/04/09 15:40:55 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 15:41:30 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 15:41:32 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 15:41:41 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 15:41:44 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 15:41:47 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 15:41:48 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 15:41:50 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 15:41:51 INFO mapreduce.Job:  map 100% reduce 46%
15/04/09 15:41:54 INFO mapreduce.Job:  map 100% reduce 51%
15/04/09 15:41:57 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 15:42:00 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 15:42:09 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 15:46:28 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 15:50:15 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 15:51:32 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 15:55:08 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 15:59:07 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 16:06:16 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 16:10:02 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 16:12:29 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 16:15:51 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 16:19:03 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 16:23:27 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 16:25:03 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 16:26:06 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 16:30:18 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 16:30:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_r_000001_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 16:30:33 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 16:30:45 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 16:30:46 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 16:31:12 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 16:31:33 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 16:31:42 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 16:31:45 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 16:33:53 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 16:35:18 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 16:37:10 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 16:40:03 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 16:42:11 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 16:44:50 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 16:45:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_r_000004_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(java.io.IOException): BP-1272212113-129.114.57.132-1408108439175:blk_1077927443_4186784 does not exist or is not under Constructionnull
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkUCBlock(FSNamesystem.java:5956)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updateBlockForPipeline(FSNamesystem.java:6023)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updateBlockForPipeline(NameNodeRpcServer.java:645)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:874)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:826)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:924)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:486)

15/04/09 16:45:44 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 16:45:55 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 16:46:19 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 16:46:22 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 16:46:25 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 16:46:28 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 16:46:31 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 16:46:34 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 16:48:46 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 16:51:19 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 16:52:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_r_000000_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 16:52:21 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 16:52:31 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 16:52:59 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 16:53:29 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 16:53:32 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 16:53:36 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 16:55:02 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 17:00:51 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 17:03:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_r_000003_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta/_temporary/1/_temporary/attempt_1422482982071_4359_r_000003_0/part-00003 (inode 3593178): File does not exist. Holder DFSClient_attempt_1422482982071_4359_r_000003_0_-860471737_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:03:08 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 17:03:19 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 17:03:43 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 17:03:46 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 17:04:12 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 17:06:37 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 17:11:46 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 17:13:06 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 17:15:21 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 17:16:26 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 17:17:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_r_000002_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta/_temporary/1/_temporary/attempt_1422482982071_4359_r_000002_0/part-00002 (inode 3593166): File does not exist. Holder DFSClient_attempt_1422482982071_4359_r_000002_0_-1821867752_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:17:10 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 17:17:21 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 17:17:45 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 17:17:48 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 17:18:16 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 17:18:19 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 17:18:35 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 17:21:59 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 17:26:46 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 17:30:26 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 17:32:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_r_000003_1, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:32:21 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 17:32:31 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 17:32:55 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 17:33:23 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 17:36:13 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 17:38:27 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 17:41:48 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 17:45:48 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 17:47:42 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 17:49:03 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 17:50:14 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 17:50:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_r_000004_1, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta/_temporary/1/_temporary/attempt_1422482982071_4359_r_000004_1/part-00004 (inode 3593847): File does not exist. Holder DFSClient_attempt_1422482982071_4359_r_000004_1_-877632262_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:50:53 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 17:51:04 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 17:51:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_r_000002_1, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 17:51:25 INFO mapreduce.Job:  map 100% reduce 54%
15/04/09 17:51:28 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 17:51:31 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 17:51:34 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 17:51:37 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 17:51:40 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 17:51:43 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 17:52:04 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 17:52:07 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 17:52:32 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 17:52:35 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 17:52:38 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 17:56:55 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 17:58:34 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 18:00:38 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 18:03:51 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 18:05:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_r_000000_1, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 18:05:36 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 18:05:47 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 18:06:14 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 18:06:17 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 18:06:45 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 18:06:48 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 18:06:51 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 18:06:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_r_000001_1, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta/_temporary/1/_temporary/attempt_1422482982071_4359_r_000001_1/part-00001 (inode 3593760): File does not exist. Holder DFSClient_attempt_1422482982071_4359_r_000001_1_-1985408392_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 18:06:53 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 18:06:54 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 18:07:04 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 18:07:32 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 18:07:59 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 18:08:02 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 18:10:26 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 18:15:21 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 18:17:33 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 18:20:30 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 18:23:52 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 18:25:23 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 18:27:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_r_000002_2, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 18:27:56 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 18:28:06 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 18:28:31 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 18:28:34 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 18:29:01 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 18:29:04 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 18:32:07 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 18:37:42 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 18:41:06 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 18:44:43 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 18:48:20 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 18:51:29 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 18:53:08 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 18:55:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_r_000003_2, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta/_temporary/1/_temporary/attempt_1422482982071_4359_r_000003_2/part-00003 (inode 3594410): File does not exist. Holder DFSClient_attempt_1422482982071_4359_r_000003_2_1557973517_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 18:55:29 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 18:55:41 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 18:56:05 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 18:56:32 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 18:56:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_r_000001_2, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 18:56:58 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 18:57:10 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 18:57:37 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 18:58:05 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 18:58:23 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 19:00:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_r_000004_2, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-ta/_temporary/1/_temporary/attempt_1422482982071_4359_r_000004_2/part-00004 (inode 3594639): File does not exist. Holder DFSClient_attempt_1422482982071_4359_r_000004_2_-1609247182_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:00:27 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 19:00:39 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 19:00:42 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 19:01:07 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 19:01:10 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 19:01:13 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 19:01:16 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 19:01:18 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 19:01:19 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 19:01:22 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 19:01:34 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 19:03:53 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 19:06:50 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 19:08:54 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 19:11:28 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 19:14:11 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 19:18:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4359_r_000000_2, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:18:39 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 19:18:51 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 19:18:57 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 19:19:21 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 19:19:24 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 19:19:55 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 19:19:58 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 19:20:01 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 19:22:19 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 19:23:28 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 19:23:28 INFO mapreduce.Job: Job job_1422482982071_4359 failed with state FAILED due to: Task failed task_1422482982071_4359_r_000003
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/09 19:23:28 INFO mapreduce.Job: Counters: 41
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=10386798296
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=150
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Job Counters 
		Failed map tasks=13
		Failed reduce tasks=16
		Killed reduce tasks=4
		Launched map tasks=63
		Launched reduce tasks=20
		Other local map tasks=13
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=40934922
		Total time spent by all reduces in occupied slots (ms)=133926098
		Total time spent by all map tasks (ms)=20467461
		Total time spent by all reduce tasks (ms)=66963049
		Total vcore-seconds taken by all map tasks=20467461
		Total vcore-seconds taken by all reduce tasks=66963049
		Total megabyte-seconds taken by all map tasks=165704564256
		Total megabyte-seconds taken by all reduce tasks=803556588000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=1085564136
		Map output bytes=8210915078
		Map output materialized bytes=10382044856
		Input split bytes=7900
		Combine input records=0
		Spilled Records=1085564136
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=46530
		CPU time spent (ms)=28339600
		Physical memory (bytes) snapshot=97339613184
		Virtual memory (bytes) snapshot=458919809024
		Total committed heap usage (bytes)=138485256192
	File Input Format Counters 
		Bytes Read=6039982789
15/04/09 19:23:28 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	230m6.549s
user	0m45.106s
sys	0m9.521s
50 40
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-40-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob111874787074173348.jar tmpDir=null
15/04/09 19:23:33 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 19:23:33 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 19:23:34 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 19:23:34 INFO mapreduce.JobSubmitter: number of splits:75
15/04/09 19:23:35 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4389
15/04/09 19:23:35 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4389
15/04/09 19:23:35 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4389/
15/04/09 19:23:35 INFO mapreduce.Job: Running job: job_1422482982071_4389
15/04/09 19:23:41 INFO mapreduce.Job: Job job_1422482982071_4389 running in uber mode : false
15/04/09 19:23:41 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 19:23:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4389_m_000041_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:23:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4389_m_000070_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:23:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4389_m_000074_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:23:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4389_m_000050_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:23:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4389_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:23:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4389_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:23:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4389_m_000002_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:23:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4389_m_000008_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 19:23:53 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 19:23:59 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 19:24:05 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 19:24:11 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 19:24:17 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 19:24:23 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 19:24:30 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 19:24:37 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 19:24:43 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 19:24:49 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 19:24:56 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 19:25:02 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 19:25:08 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 19:25:14 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 19:25:20 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 19:25:26 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 19:25:32 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 19:25:40 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 19:25:46 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 19:25:53 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 19:25:59 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 19:26:05 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 19:26:11 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 19:26:17 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 19:26:23 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 19:26:29 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 19:26:36 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 19:26:43 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 19:26:50 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 19:26:57 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 19:27:03 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 19:27:09 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 19:27:15 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 19:27:21 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 19:27:27 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 19:27:33 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 19:27:40 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 19:27:46 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 19:27:53 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 19:28:00 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 19:28:06 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 19:28:12 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 19:28:18 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 19:28:24 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 19:28:31 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 19:28:37 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 19:28:43 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 19:28:50 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 19:28:57 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 19:29:03 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 19:29:09 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 19:29:15 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 19:29:19 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 19:29:25 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 19:29:31 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 19:29:40 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 19:29:46 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 19:29:52 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 19:29:58 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 19:30:04 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 19:30:11 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 19:30:17 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 19:30:24 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 19:30:26 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 19:30:29 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 19:30:31 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 19:30:33 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 19:30:35 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 19:30:37 INFO mapreduce.Job:  map 69% reduce 3%
15/04/09 19:30:38 INFO mapreduce.Job:  map 71% reduce 5%
15/04/09 19:30:39 INFO mapreduce.Job:  map 73% reduce 6%
15/04/09 19:30:40 INFO mapreduce.Job:  map 73% reduce 8%
15/04/09 19:30:41 INFO mapreduce.Job:  map 74% reduce 9%
15/04/09 19:30:42 INFO mapreduce.Job:  map 76% reduce 10%
15/04/09 19:30:43 INFO mapreduce.Job:  map 77% reduce 11%
15/04/09 19:30:44 INFO mapreduce.Job:  map 77% reduce 13%
15/04/09 19:30:45 INFO mapreduce.Job:  map 78% reduce 13%
15/04/09 19:30:46 INFO mapreduce.Job:  map 78% reduce 14%
15/04/09 19:30:49 INFO mapreduce.Job:  map 79% reduce 14%
15/04/09 19:30:50 INFO mapreduce.Job:  map 79% reduce 15%
15/04/09 19:30:52 INFO mapreduce.Job:  map 80% reduce 15%
15/04/09 19:31:04 INFO mapreduce.Job:  map 81% reduce 15%
15/04/09 19:31:10 INFO mapreduce.Job:  map 82% reduce 15%
15/04/09 19:31:12 INFO mapreduce.Job:  map 82% reduce 16%
15/04/09 19:31:17 INFO mapreduce.Job:  map 83% reduce 16%
15/04/09 19:31:19 INFO mapreduce.Job:  map 84% reduce 17%
15/04/09 19:31:20 INFO mapreduce.Job:  map 85% reduce 17%
15/04/09 19:31:21 INFO mapreduce.Job:  map 86% reduce 18%
15/04/09 19:31:22 INFO mapreduce.Job:  map 87% reduce 19%
15/04/09 19:31:23 INFO mapreduce.Job:  map 88% reduce 20%
15/04/09 19:31:24 INFO mapreduce.Job:  map 88% reduce 21%
15/04/09 19:31:25 INFO mapreduce.Job:  map 89% reduce 21%
15/04/09 19:31:26 INFO mapreduce.Job:  map 90% reduce 22%
15/04/09 19:31:27 INFO mapreduce.Job:  map 90% reduce 23%
15/04/09 19:31:29 INFO mapreduce.Job:  map 90% reduce 24%
15/04/09 19:31:31 INFO mapreduce.Job:  map 91% reduce 24%
15/04/09 19:31:34 INFO mapreduce.Job:  map 91% reduce 25%
15/04/09 19:31:36 INFO mapreduce.Job:  map 92% reduce 25%
15/04/09 19:31:37 INFO mapreduce.Job:  map 93% reduce 25%
15/04/09 19:31:38 INFO mapreduce.Job:  map 93% reduce 26%
15/04/09 19:31:41 INFO mapreduce.Job:  map 93% reduce 27%
15/04/09 19:31:43 INFO mapreduce.Job:  map 94% reduce 27%
15/04/09 19:31:47 INFO mapreduce.Job:  map 95% reduce 28%
15/04/09 19:31:52 INFO mapreduce.Job:  map 96% reduce 28%
15/04/09 19:31:53 INFO mapreduce.Job:  map 96% reduce 29%
15/04/09 19:31:54 INFO mapreduce.Job:  map 97% reduce 29%
15/04/09 19:31:55 INFO mapreduce.Job:  map 97% reduce 30%
15/04/09 19:31:57 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 19:31:59 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 19:32:01 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 19:32:02 INFO mapreduce.Job:  map 100% reduce 32%
15/04/09 19:32:04 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 19:32:05 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 19:32:06 INFO mapreduce.Job:  map 100% reduce 37%
15/04/09 19:32:07 INFO mapreduce.Job:  map 100% reduce 39%
15/04/09 19:32:08 INFO mapreduce.Job:  map 100% reduce 46%
15/04/09 19:32:09 INFO mapreduce.Job:  map 100% reduce 49%
15/04/09 19:32:10 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 19:32:11 INFO mapreduce.Job:  map 100% reduce 55%
15/04/09 19:32:12 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 19:32:13 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 19:32:14 INFO mapreduce.Job:  map 100% reduce 61%
15/04/09 19:32:15 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 19:32:16 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 19:32:17 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 19:32:19 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 19:32:21 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 19:32:27 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 19:33:00 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 19:33:30 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 19:34:09 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 19:34:40 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 19:35:14 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 19:35:41 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 19:36:06 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 19:36:37 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 19:37:04 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 19:37:25 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 19:37:47 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 19:38:12 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 19:38:33 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 19:39:05 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 19:39:36 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 19:39:50 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 19:40:20 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 19:40:44 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 19:41:13 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 19:42:05 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 19:42:59 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 19:44:12 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 19:44:52 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 19:45:43 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 19:47:09 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 19:47:33 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 19:48:15 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 19:50:02 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 19:52:45 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 19:55:31 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 19:56:32 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 20:12:05 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 20:39:45 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 20:48:38 INFO mapreduce.Job: Job job_1422482982071_4389 completed successfully
15/04/09 20:48:38 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16787700669
		FILE: Number of bytes written=33586409197
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=345
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Failed map tasks=8
		Killed reduce tasks=2
		Launched map tasks=83
		Launched reduce tasks=42
		Other local map tasks=8
		Data-local map tasks=53
		Rack-local map tasks=22
		Total time spent by all maps in occupied slots (ms)=66572182
		Total time spent by all reduces in occupied slots (ms)=98602090
		Total time spent by all map tasks (ms)=33286091
		Total time spent by all reduce tasks (ms)=49301045
		Total vcore-seconds taken by all map tasks=33286091
		Total vcore-seconds taken by all reduce tasks=49301045
		Total megabyte-seconds taken by all map tasks=269484192736
		Total megabyte-seconds taken by all reduce tasks=591612540000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787718423
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787718423
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =3000
		Failed Shuffles=0
		Merged Map outputs=3000
		GC time elapsed (ms)=194557
		CPU time spent (ms)=89514570
		Physical memory (bytes) snapshot=171822751744
		Virtual memory (bytes) snapshot=1222809923584
		Total committed heap usage (bytes)=291931336704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/09 20:48:38 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	85m9.996s
user	0m29.820s
sys	0m3.941s
15/04/09 20:48:40 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 40
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-40-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6388626631422190851.jar tmpDir=null
15/04/09 20:48:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 20:48:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 20:48:43 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 20:48:44 INFO mapreduce.JobSubmitter: number of splits:75
15/04/09 20:48:44 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4394
15/04/09 20:48:45 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4394
15/04/09 20:48:45 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4394/
15/04/09 20:48:45 INFO mapreduce.Job: Running job: job_1422482982071_4394
15/04/09 20:48:50 INFO mapreduce.Job: Job job_1422482982071_4394 running in uber mode : false
15/04/09 20:48:50 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 20:48:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4394_m_000073_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 20:49:00 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 20:49:06 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 20:49:13 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 20:49:19 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 20:49:27 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 20:49:33 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 20:49:39 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 20:49:46 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 20:49:54 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 20:50:00 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 20:50:06 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 20:50:13 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 20:50:19 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 20:50:27 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 20:50:33 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 20:50:39 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 20:50:46 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 20:50:52 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 20:50:58 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 20:51:04 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 20:51:10 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 20:51:16 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 20:51:22 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 20:51:28 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 20:51:34 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 20:51:40 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 20:51:46 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 20:51:52 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 20:51:58 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 20:52:04 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 20:52:10 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 20:52:16 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 20:52:22 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 20:52:28 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 20:52:34 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 20:52:39 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 20:52:45 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 20:52:51 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 20:52:57 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 20:53:03 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 20:53:09 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 20:53:14 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 20:53:20 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 20:53:26 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 20:53:32 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 20:53:39 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 20:53:45 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 20:53:51 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 20:53:57 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 20:54:03 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 20:54:09 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 20:54:15 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 20:54:21 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 20:54:27 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 20:54:32 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 20:54:36 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 20:54:42 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 20:54:48 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 20:54:54 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 20:55:00 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 20:55:06 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 20:55:13 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 20:55:19 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 20:55:25 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 20:55:30 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 20:55:34 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 20:55:40 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 20:55:44 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 20:55:45 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 20:55:47 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 20:55:49 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 20:55:50 INFO mapreduce.Job:  map 72% reduce 4%
15/04/09 20:55:51 INFO mapreduce.Job:  map 72% reduce 5%
15/04/09 20:55:53 INFO mapreduce.Job:  map 73% reduce 6%
15/04/09 20:55:54 INFO mapreduce.Job:  map 74% reduce 6%
15/04/09 20:55:55 INFO mapreduce.Job:  map 75% reduce 6%
15/04/09 20:55:56 INFO mapreduce.Job:  map 76% reduce 8%
15/04/09 20:55:57 INFO mapreduce.Job:  map 77% reduce 9%
15/04/09 20:55:59 INFO mapreduce.Job:  map 79% reduce 11%
15/04/09 20:56:00 INFO mapreduce.Job:  map 81% reduce 12%
15/04/09 20:56:01 INFO mapreduce.Job:  map 83% reduce 12%
15/04/09 20:56:02 INFO mapreduce.Job:  map 84% reduce 15%
15/04/09 20:56:03 INFO mapreduce.Job:  map 85% reduce 17%
15/04/09 20:56:04 INFO mapreduce.Job:  map 87% reduce 17%
15/04/09 20:56:05 INFO mapreduce.Job:  map 88% reduce 20%
15/04/09 20:56:06 INFO mapreduce.Job:  map 89% reduce 21%
15/04/09 20:56:07 INFO mapreduce.Job:  map 90% reduce 21%
15/04/09 20:56:08 INFO mapreduce.Job:  map 91% reduce 24%
15/04/09 20:56:09 INFO mapreduce.Job:  map 92% reduce 25%
15/04/09 20:56:10 INFO mapreduce.Job:  map 93% reduce 25%
15/04/09 20:56:11 INFO mapreduce.Job:  map 94% reduce 26%
15/04/09 20:56:12 INFO mapreduce.Job:  map 94% reduce 27%
15/04/09 20:56:14 INFO mapreduce.Job:  map 95% reduce 27%
15/04/09 20:56:15 INFO mapreduce.Job:  map 96% reduce 28%
15/04/09 20:56:17 INFO mapreduce.Job:  map 96% reduce 29%
15/04/09 20:56:20 INFO mapreduce.Job:  map 96% reduce 30%
15/04/09 20:56:22 INFO mapreduce.Job:  map 97% reduce 30%
15/04/09 20:56:27 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 20:56:28 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 20:56:30 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 20:56:37 INFO mapreduce.Job:  map 100% reduce 32%
15/04/09 20:56:39 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 20:56:55 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 20:56:56 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 20:56:57 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 20:56:58 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 20:56:59 INFO mapreduce.Job:  map 100% reduce 45%
15/04/09 20:57:00 INFO mapreduce.Job:  map 100% reduce 47%
15/04/09 20:57:01 INFO mapreduce.Job:  map 100% reduce 53%
15/04/09 20:57:02 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 20:57:03 INFO mapreduce.Job:  map 100% reduce 58%
15/04/09 20:57:04 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 20:57:05 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 20:57:06 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 20:57:07 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 20:57:08 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 20:57:11 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 20:57:16 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 20:57:48 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 20:58:20 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 20:58:55 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 20:59:29 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 21:00:04 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 21:00:32 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 21:00:59 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 21:01:24 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 21:01:53 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 21:02:14 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 21:02:33 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 21:03:01 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 21:03:22 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 21:03:55 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 21:04:23 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 21:04:46 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 21:05:10 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 21:05:32 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 21:05:55 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 21:06:41 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 21:07:25 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 21:08:42 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 21:09:30 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 21:10:16 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 21:11:34 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 21:12:31 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 21:12:57 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 21:14:54 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 21:18:21 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 21:19:55 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 21:20:38 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 21:37:38 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 22:03:43 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 22:12:23 INFO mapreduce.Job: Job job_1422482982071_4394 completed successfully
15/04/09 22:12:23 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16787700669
		FILE: Number of bytes written=33586409197
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=345
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Failed map tasks=1
		Killed reduce tasks=2
		Launched map tasks=76
		Launched reduce tasks=42
		Other local map tasks=1
		Data-local map tasks=50
		Rack-local map tasks=25
		Total time spent by all maps in occupied slots (ms)=64551254
		Total time spent by all reduces in occupied slots (ms)=95902320
		Total time spent by all map tasks (ms)=32275627
		Total time spent by all reduce tasks (ms)=47951160
		Total vcore-seconds taken by all map tasks=32275627
		Total vcore-seconds taken by all reduce tasks=47951160
		Total megabyte-seconds taken by all map tasks=261303476192
		Total megabyte-seconds taken by all reduce tasks=575413920000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787718423
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787718423
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =3000
		Failed Shuffles=0
		Merged Map outputs=3000
		GC time elapsed (ms)=207385
		CPU time spent (ms)=88087750
		Physical memory (bytes) snapshot=171500576768
		Virtual memory (bytes) snapshot=1223609499648
		Total committed heap usage (bytes)=291930841088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/09 22:12:23 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	83m45.467s
user	0m28.552s
sys	0m3.829s
15/04/09 22:12:26 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 40
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-40-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3931385007685144696.jar tmpDir=null
15/04/09 22:12:29 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 22:12:29 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 22:12:30 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 22:12:30 INFO mapreduce.JobSubmitter: number of splits:75
15/04/09 22:12:31 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4399
15/04/09 22:12:31 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4399
15/04/09 22:12:31 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4399/
15/04/09 22:12:31 INFO mapreduce.Job: Running job: job_1422482982071_4399
15/04/09 22:12:35 INFO mapreduce.Job: Job job_1422482982071_4399 running in uber mode : false
15/04/09 22:12:35 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 22:12:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4399_m_000062_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 22:12:46 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 22:12:53 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 22:12:59 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 22:13:05 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 22:13:14 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 22:13:20 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 22:13:26 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 22:13:32 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 22:13:41 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 22:13:47 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 22:13:53 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 22:13:59 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 22:14:06 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 22:14:14 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 22:14:20 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 22:14:26 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 22:14:32 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 22:14:38 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 22:14:44 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 22:14:50 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 22:14:55 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 22:15:00 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 22:15:06 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 22:15:12 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 22:15:19 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 22:15:25 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 22:15:31 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 22:15:37 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 22:15:43 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 22:15:49 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 22:15:55 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 22:16:01 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 22:16:07 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 22:16:13 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 22:16:19 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 22:16:25 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 22:16:30 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 22:16:36 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 22:16:42 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 22:16:48 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 22:16:54 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 22:17:00 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 22:17:06 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 22:17:12 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 22:17:18 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 22:17:24 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 22:17:30 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 22:17:36 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 22:17:42 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 22:17:47 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 22:17:53 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 22:17:59 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 22:18:05 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 22:18:11 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 22:18:16 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 22:18:22 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 22:18:27 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 22:18:34 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 22:18:40 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 22:18:46 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 22:18:52 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 22:18:58 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 22:19:04 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 22:19:10 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 22:19:16 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 22:19:22 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 22:19:32 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 22:19:33 INFO mapreduce.Job:  map 68% reduce 0%
15/04/09 22:19:34 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 22:19:35 INFO mapreduce.Job:  map 70% reduce 0%
15/04/09 22:19:37 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 22:19:38 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 22:19:39 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 22:19:40 INFO mapreduce.Job:  map 77% reduce 0%
15/04/09 22:19:41 INFO mapreduce.Job:  map 78% reduce 0%
15/04/09 22:19:42 INFO mapreduce.Job:  map 79% reduce 0%
15/04/09 22:19:43 INFO mapreduce.Job:  map 80% reduce 5%
15/04/09 22:19:44 INFO mapreduce.Job:  map 84% reduce 12%
15/04/09 22:19:45 INFO mapreduce.Job:  map 85% reduce 13%
15/04/09 22:19:46 INFO mapreduce.Job:  map 87% reduce 15%
15/04/09 22:19:47 INFO mapreduce.Job:  map 87% reduce 19%
15/04/09 22:19:48 INFO mapreduce.Job:  map 88% reduce 20%
15/04/09 22:19:50 INFO mapreduce.Job:  map 89% reduce 21%
15/04/09 22:19:51 INFO mapreduce.Job:  map 91% reduce 22%
15/04/09 22:19:52 INFO mapreduce.Job:  map 92% reduce 22%
15/04/09 22:19:53 INFO mapreduce.Job:  map 93% reduce 25%
15/04/09 22:19:54 INFO mapreduce.Job:  map 94% reduce 25%
15/04/09 22:19:55 INFO mapreduce.Job:  map 94% reduce 26%
15/04/09 22:19:56 INFO mapreduce.Job:  map 96% reduce 27%
15/04/09 22:19:57 INFO mapreduce.Job:  map 96% reduce 28%
15/04/09 22:19:59 INFO mapreduce.Job:  map 96% reduce 29%
15/04/09 22:20:01 INFO mapreduce.Job:  map 97% reduce 29%
15/04/09 22:20:02 INFO mapreduce.Job:  map 98% reduce 30%
15/04/09 22:20:05 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 22:20:07 INFO mapreduce.Job:  map 99% reduce 31%
15/04/09 22:20:08 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 22:20:16 INFO mapreduce.Job:  map 100% reduce 32%
15/04/09 22:20:18 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 22:20:30 INFO mapreduce.Job:  map 100% reduce 35%
15/04/09 22:20:31 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 22:20:32 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 22:20:33 INFO mapreduce.Job:  map 100% reduce 46%
15/04/09 22:20:34 INFO mapreduce.Job:  map 100% reduce 47%
15/04/09 22:20:35 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 22:20:36 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 22:20:37 INFO mapreduce.Job:  map 100% reduce 57%
15/04/09 22:20:38 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 22:20:39 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 22:20:41 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 22:20:42 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 22:20:45 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 22:20:52 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 22:21:24 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 22:21:56 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 22:22:32 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 22:23:05 INFO mapreduce.Job:  map 100% reduce 71%
15/04/09 22:23:43 INFO mapreduce.Job:  map 100% reduce 72%
15/04/09 22:24:04 INFO mapreduce.Job:  map 100% reduce 73%
15/04/09 22:24:31 INFO mapreduce.Job:  map 100% reduce 74%
15/04/09 22:25:02 INFO mapreduce.Job:  map 100% reduce 75%
15/04/09 22:25:29 INFO mapreduce.Job:  map 100% reduce 76%
15/04/09 22:26:00 INFO mapreduce.Job:  map 100% reduce 77%
15/04/09 22:26:09 INFO mapreduce.Job:  map 100% reduce 78%
15/04/09 22:26:36 INFO mapreduce.Job:  map 100% reduce 79%
15/04/09 22:26:57 INFO mapreduce.Job:  map 100% reduce 80%
15/04/09 22:27:32 INFO mapreduce.Job:  map 100% reduce 81%
15/04/09 22:27:51 INFO mapreduce.Job:  map 100% reduce 82%
15/04/09 22:28:15 INFO mapreduce.Job:  map 100% reduce 83%
15/04/09 22:28:41 INFO mapreduce.Job:  map 100% reduce 84%
15/04/09 22:29:04 INFO mapreduce.Job:  map 100% reduce 85%
15/04/09 22:29:31 INFO mapreduce.Job:  map 100% reduce 86%
15/04/09 22:30:02 INFO mapreduce.Job:  map 100% reduce 87%
15/04/09 22:30:55 INFO mapreduce.Job:  map 100% reduce 88%
15/04/09 22:32:20 INFO mapreduce.Job:  map 100% reduce 89%
15/04/09 22:33:19 INFO mapreduce.Job:  map 100% reduce 90%
15/04/09 22:34:00 INFO mapreduce.Job:  map 100% reduce 91%
15/04/09 22:35:31 INFO mapreduce.Job:  map 100% reduce 92%
15/04/09 22:35:53 INFO mapreduce.Job:  map 100% reduce 93%
15/04/09 22:36:49 INFO mapreduce.Job:  map 100% reduce 94%
15/04/09 22:38:20 INFO mapreduce.Job:  map 100% reduce 95%
15/04/09 22:41:16 INFO mapreduce.Job:  map 100% reduce 96%
15/04/09 22:44:29 INFO mapreduce.Job:  map 100% reduce 97%
15/04/09 22:45:03 INFO mapreduce.Job:  map 100% reduce 98%
15/04/09 23:00:53 INFO mapreduce.Job:  map 100% reduce 99%
15/04/09 23:32:46 INFO mapreduce.Job:  map 100% reduce 100%
15/04/09 23:42:21 INFO mapreduce.Job: Job job_1422482982071_4399 completed successfully
15/04/09 23:42:21 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16787700669
		FILE: Number of bytes written=33586409197
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=345
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Failed map tasks=1
		Killed reduce tasks=2
		Launched map tasks=76
		Launched reduce tasks=42
		Other local map tasks=1
		Data-local map tasks=53
		Rack-local map tasks=22
		Total time spent by all maps in occupied slots (ms)=64169824
		Total time spent by all reduces in occupied slots (ms)=96436170
		Total time spent by all map tasks (ms)=32084912
		Total time spent by all reduce tasks (ms)=48218085
		Total vcore-seconds taken by all map tasks=32084912
		Total vcore-seconds taken by all reduce tasks=48218085
		Total megabyte-seconds taken by all map tasks=259759447552
		Total megabyte-seconds taken by all reduce tasks=578617020000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787718423
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787718423
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =3000
		Failed Shuffles=0
		Merged Map outputs=3000
		GC time elapsed (ms)=201383
		CPU time spent (ms)=88404670
		Physical memory (bytes) snapshot=171191250944
		Virtual memory (bytes) snapshot=1222399672320
		Total committed heap usage (bytes)=291931152384
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/09 23:42:21 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	89m58.101s
user	0m31.832s
sys	0m4.030s
15/04/09 23:42:24 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 30
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-30-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6533878193217777057.jar tmpDir=null
15/04/09 23:42:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 23:42:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/09 23:42:28 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/09 23:42:28 INFO mapreduce.JobSubmitter: number of splits:75
15/04/09 23:42:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4406
15/04/09 23:42:29 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4406
15/04/09 23:42:29 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4406/
15/04/09 23:42:29 INFO mapreduce.Job: Running job: job_1422482982071_4406
15/04/09 23:42:36 INFO mapreduce.Job: Job job_1422482982071_4406 running in uber mode : false
15/04/09 23:42:36 INFO mapreduce.Job:  map 0% reduce 0%
15/04/09 23:42:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4406_m_000073_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:42:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4406_m_000011_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:42:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4406_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:42:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4406_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:42:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4406_m_000051_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:42:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4406_m_000060_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:42:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4406_m_000013_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:42:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4406_m_000067_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:42:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4406_m_000071_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:42:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4406_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:42:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4406_m_000002_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:42:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4406_m_000045_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:42:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4406_m_000067_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:42:47 INFO mapreduce.Job:  map 1% reduce 0%
15/04/09 23:42:53 INFO mapreduce.Job:  map 2% reduce 0%
15/04/09 23:43:00 INFO mapreduce.Job:  map 3% reduce 0%
15/04/09 23:43:06 INFO mapreduce.Job:  map 4% reduce 0%
15/04/09 23:43:12 INFO mapreduce.Job:  map 5% reduce 0%
15/04/09 23:43:18 INFO mapreduce.Job:  map 6% reduce 0%
15/04/09 23:43:24 INFO mapreduce.Job:  map 7% reduce 0%
15/04/09 23:43:30 INFO mapreduce.Job:  map 8% reduce 0%
15/04/09 23:43:36 INFO mapreduce.Job:  map 9% reduce 0%
15/04/09 23:43:42 INFO mapreduce.Job:  map 10% reduce 0%
15/04/09 23:43:48 INFO mapreduce.Job:  map 11% reduce 0%
15/04/09 23:43:55 INFO mapreduce.Job:  map 12% reduce 0%
15/04/09 23:44:01 INFO mapreduce.Job:  map 13% reduce 0%
15/04/09 23:44:07 INFO mapreduce.Job:  map 14% reduce 0%
15/04/09 23:44:13 INFO mapreduce.Job:  map 15% reduce 0%
15/04/09 23:44:20 INFO mapreduce.Job:  map 16% reduce 0%
15/04/09 23:44:26 INFO mapreduce.Job:  map 17% reduce 0%
15/04/09 23:44:32 INFO mapreduce.Job:  map 18% reduce 0%
15/04/09 23:44:38 INFO mapreduce.Job:  map 19% reduce 0%
15/04/09 23:44:44 INFO mapreduce.Job:  map 20% reduce 0%
15/04/09 23:44:50 INFO mapreduce.Job:  map 21% reduce 0%
15/04/09 23:44:56 INFO mapreduce.Job:  map 22% reduce 0%
15/04/09 23:45:03 INFO mapreduce.Job:  map 23% reduce 0%
15/04/09 23:45:09 INFO mapreduce.Job:  map 24% reduce 0%
15/04/09 23:45:15 INFO mapreduce.Job:  map 25% reduce 0%
15/04/09 23:45:21 INFO mapreduce.Job:  map 26% reduce 0%
15/04/09 23:45:27 INFO mapreduce.Job:  map 27% reduce 0%
15/04/09 23:45:33 INFO mapreduce.Job:  map 28% reduce 0%
15/04/09 23:45:39 INFO mapreduce.Job:  map 29% reduce 0%
15/04/09 23:45:45 INFO mapreduce.Job:  map 30% reduce 0%
15/04/09 23:45:51 INFO mapreduce.Job:  map 31% reduce 0%
15/04/09 23:45:58 INFO mapreduce.Job:  map 32% reduce 0%
15/04/09 23:46:04 INFO mapreduce.Job:  map 33% reduce 0%
15/04/09 23:46:10 INFO mapreduce.Job:  map 34% reduce 0%
15/04/09 23:46:16 INFO mapreduce.Job:  map 35% reduce 0%
15/04/09 23:46:22 INFO mapreduce.Job:  map 36% reduce 0%
15/04/09 23:46:30 INFO mapreduce.Job:  map 37% reduce 0%
15/04/09 23:46:36 INFO mapreduce.Job:  map 38% reduce 0%
15/04/09 23:46:43 INFO mapreduce.Job:  map 39% reduce 0%
15/04/09 23:46:49 INFO mapreduce.Job:  map 40% reduce 0%
15/04/09 23:46:57 INFO mapreduce.Job:  map 41% reduce 0%
15/04/09 23:47:03 INFO mapreduce.Job:  map 42% reduce 0%
15/04/09 23:47:10 INFO mapreduce.Job:  map 43% reduce 0%
15/04/09 23:47:17 INFO mapreduce.Job:  map 44% reduce 0%
15/04/09 23:47:25 INFO mapreduce.Job:  map 45% reduce 0%
15/04/09 23:47:32 INFO mapreduce.Job:  map 46% reduce 0%
15/04/09 23:47:38 INFO mapreduce.Job:  map 47% reduce 0%
15/04/09 23:47:45 INFO mapreduce.Job:  map 48% reduce 0%
15/04/09 23:47:52 INFO mapreduce.Job:  map 49% reduce 0%
15/04/09 23:47:59 INFO mapreduce.Job:  map 50% reduce 0%
15/04/09 23:48:05 INFO mapreduce.Job:  map 51% reduce 0%
15/04/09 23:48:11 INFO mapreduce.Job:  map 52% reduce 0%
15/04/09 23:48:18 INFO mapreduce.Job:  map 53% reduce 0%
15/04/09 23:48:24 INFO mapreduce.Job:  map 54% reduce 0%
15/04/09 23:48:30 INFO mapreduce.Job:  map 55% reduce 0%
15/04/09 23:48:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4406_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/09 23:48:38 INFO mapreduce.Job:  map 56% reduce 0%
15/04/09 23:48:45 INFO mapreduce.Job:  map 57% reduce 0%
15/04/09 23:48:51 INFO mapreduce.Job:  map 58% reduce 0%
15/04/09 23:48:58 INFO mapreduce.Job:  map 59% reduce 0%
15/04/09 23:49:04 INFO mapreduce.Job:  map 60% reduce 0%
15/04/09 23:49:10 INFO mapreduce.Job:  map 61% reduce 0%
15/04/09 23:49:16 INFO mapreduce.Job:  map 62% reduce 0%
15/04/09 23:49:23 INFO mapreduce.Job:  map 63% reduce 0%
15/04/09 23:49:29 INFO mapreduce.Job:  map 64% reduce 0%
15/04/09 23:49:35 INFO mapreduce.Job:  map 65% reduce 0%
15/04/09 23:49:40 INFO mapreduce.Job:  map 66% reduce 0%
15/04/09 23:49:41 INFO mapreduce.Job:  map 67% reduce 0%
15/04/09 23:49:42 INFO mapreduce.Job:  map 69% reduce 0%
15/04/09 23:49:43 INFO mapreduce.Job:  map 71% reduce 0%
15/04/09 23:49:44 INFO mapreduce.Job:  map 72% reduce 0%
15/04/09 23:49:45 INFO mapreduce.Job:  map 73% reduce 0%
15/04/09 23:49:46 INFO mapreduce.Job:  map 74% reduce 0%
15/04/09 23:49:48 INFO mapreduce.Job:  map 75% reduce 0%
15/04/09 23:49:51 INFO mapreduce.Job:  map 76% reduce 6%
15/04/09 23:49:52 INFO mapreduce.Job:  map 77% reduce 11%
15/04/09 23:49:54 INFO mapreduce.Job:  map 79% reduce 12%
15/04/09 23:49:55 INFO mapreduce.Job:  map 80% reduce 13%
15/04/09 23:49:56 INFO mapreduce.Job:  map 81% reduce 13%
15/04/09 23:49:57 INFO mapreduce.Job:  map 82% reduce 15%
15/04/09 23:49:58 INFO mapreduce.Job:  map 84% reduce 17%
15/04/09 23:50:00 INFO mapreduce.Job:  map 85% reduce 18%
15/04/09 23:50:01 INFO mapreduce.Job:  map 85% reduce 19%
15/04/09 23:50:03 INFO mapreduce.Job:  map 85% reduce 20%
15/04/09 23:50:04 INFO mapreduce.Job:  map 86% reduce 20%
15/04/09 23:50:06 INFO mapreduce.Job:  map 87% reduce 21%
15/04/09 23:50:08 INFO mapreduce.Job:  map 88% reduce 21%
15/04/09 23:50:09 INFO mapreduce.Job:  map 88% reduce 22%
15/04/09 23:50:12 INFO mapreduce.Job:  map 89% reduce 23%
15/04/09 23:50:19 INFO mapreduce.Job:  map 90% reduce 23%
15/04/09 23:50:20 INFO mapreduce.Job:  map 90% reduce 24%
15/04/09 23:50:25 INFO mapreduce.Job:  map 92% reduce 24%
15/04/09 23:50:26 INFO mapreduce.Job:  map 92% reduce 25%
15/04/09 23:50:27 INFO mapreduce.Job:  map 94% reduce 26%
15/04/09 23:50:29 INFO mapreduce.Job:  map 94% reduce 27%
15/04/09 23:50:31 INFO mapreduce.Job:  map 95% reduce 28%
15/04/09 23:50:33 INFO mapreduce.Job:  map 95% reduce 29%
15/04/09 23:50:34 INFO mapreduce.Job:  map 96% reduce 29%
15/04/09 23:50:35 INFO mapreduce.Job:  map 97% reduce 29%
15/04/09 23:50:36 INFO mapreduce.Job:  map 98% reduce 30%
15/04/09 23:50:38 INFO mapreduce.Job:  map 98% reduce 31%
15/04/09 23:50:40 INFO mapreduce.Job:  map 98% reduce 32%
15/04/09 23:50:52 INFO mapreduce.Job:  map 99% reduce 32%
15/04/09 23:51:09 INFO mapreduce.Job:  map 99% reduce 33%
15/04/09 23:54:55 INFO mapreduce.Job:  map 100% reduce 33%
15/04/09 23:55:37 INFO mapreduce.Job:  map 100% reduce 34%
15/04/09 23:55:38 INFO mapreduce.Job:  map 100% reduce 36%
15/04/09 23:55:39 INFO mapreduce.Job:  map 100% reduce 38%
15/04/09 23:55:40 INFO mapreduce.Job:  map 100% reduce 41%
15/04/09 23:55:41 INFO mapreduce.Job:  map 100% reduce 43%
15/04/09 23:55:42 INFO mapreduce.Job:  map 100% reduce 46%
15/04/09 23:55:43 INFO mapreduce.Job:  map 100% reduce 50%
15/04/09 23:55:44 INFO mapreduce.Job:  map 100% reduce 52%
15/04/09 23:55:45 INFO mapreduce.Job:  map 100% reduce 56%
15/04/09 23:55:46 INFO mapreduce.Job:  map 100% reduce 59%
15/04/09 23:55:47 INFO mapreduce.Job:  map 100% reduce 60%
15/04/09 23:55:48 INFO mapreduce.Job:  map 100% reduce 62%
15/04/09 23:55:49 INFO mapreduce.Job:  map 100% reduce 63%
15/04/09 23:55:50 INFO mapreduce.Job:  map 100% reduce 64%
15/04/09 23:55:52 INFO mapreduce.Job:  map 100% reduce 65%
15/04/09 23:55:55 INFO mapreduce.Job:  map 100% reduce 66%
15/04/09 23:56:04 INFO mapreduce.Job:  map 100% reduce 67%
15/04/09 23:56:52 INFO mapreduce.Job:  map 100% reduce 68%
15/04/09 23:57:45 INFO mapreduce.Job:  map 100% reduce 69%
15/04/09 23:58:44 INFO mapreduce.Job:  map 100% reduce 70%
15/04/09 23:59:32 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 00:00:29 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 00:01:08 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 00:01:41 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 00:02:36 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 00:02:55 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 00:03:29 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 00:04:05 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 00:04:42 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 00:05:10 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 00:05:30 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 00:06:20 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 00:06:59 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 00:07:46 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 00:08:14 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 00:08:47 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 00:09:08 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 00:09:31 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 00:10:04 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 00:10:37 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 00:11:35 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 00:12:14 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 00:13:43 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 00:16:19 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 00:18:58 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 00:22:17 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 00:27:10 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 00:33:15 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 00:53:43 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 01:08:17 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 01:21:05 INFO mapreduce.Job: Job job_1422482982071_4406 completed successfully
15/04/10 01:21:05 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=16787700615
		FILE: Number of bytes written=33585437443
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=315
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Failed map tasks=14
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=90
		Launched reduce tasks=31
		Other local map tasks=15
		Data-local map tasks=52
		Rack-local map tasks=23
		Total time spent by all maps in occupied slots (ms)=67960330
		Total time spent by all reduces in occupied slots (ms)=113211474
		Total time spent by all map tasks (ms)=33980165
		Total time spent by all reduce tasks (ms)=56605737
		Total vcore-seconds taken by all map tasks=33980165
		Total vcore-seconds taken by all reduce tasks=56605737
		Total megabyte-seconds taken by all map tasks=275103415840
		Total megabyte-seconds taken by all reduce tasks=679268844000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787713923
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787713923
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =2250
		Failed Shuffles=0
		Merged Map outputs=2250
		GC time elapsed (ms)=186265
		CPU time spent (ms)=90936780
		Physical memory (bytes) snapshot=169712689152
		Virtual memory (bytes) snapshot=1089768828928
		Total committed heap usage (bytes)=270881030144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/10 01:21:05 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	98m43.810s
user	0m32.665s
sys	0m4.444s
15/04/10 01:21:08 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 30
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-30-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob108360428668040130.jar tmpDir=null
15/04/10 01:21:10 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 01:21:10 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 01:21:11 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 01:21:11 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 01:21:12 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4418
15/04/10 01:21:12 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4418
15/04/10 01:21:12 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4418/
15/04/10 01:21:12 INFO mapreduce.Job: Running job: job_1422482982071_4418
15/04/10 01:21:19 INFO mapreduce.Job: Job job_1422482982071_4418 running in uber mode : false
15/04/10 01:21:19 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 01:21:23 INFO mapreduce.Job: Task Id : attempt_1422482982071_4418_m_000074_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:21:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4418_m_000025_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:21:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4418_m_000066_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:21:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4418_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:21:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4418_m_000026_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:21:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4418_m_000052_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:21:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4418_m_000067_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:21:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4418_m_000022_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:21:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4418_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:21:31 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 01:21:36 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 01:21:42 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 01:21:48 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 01:21:55 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 01:22:00 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 01:22:06 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 01:22:12 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 01:22:18 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 01:22:24 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 01:22:30 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 01:22:36 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 01:22:42 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 01:22:48 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 01:22:54 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 01:23:00 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 01:23:06 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 01:23:12 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 01:23:18 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 01:23:25 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 01:23:31 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 01:23:37 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 01:23:43 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 01:23:49 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 01:23:55 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 01:24:01 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 01:24:07 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 01:24:12 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 01:24:18 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 01:24:24 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 01:24:30 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 01:24:36 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 01:24:42 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 01:24:48 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 01:24:54 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 01:24:59 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 01:25:05 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 01:25:11 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 01:25:17 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 01:25:23 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 01:25:29 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 01:25:35 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 01:25:41 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 01:25:47 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 01:25:53 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 01:25:59 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 01:26:05 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 01:26:11 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 01:26:17 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 01:26:23 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 01:26:30 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 01:26:36 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 01:26:42 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 01:26:48 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 01:26:54 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 01:26:57 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 01:27:03 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 01:27:09 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 01:27:15 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 01:27:21 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 01:27:27 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 01:27:33 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 01:27:39 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 01:27:45 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 01:27:52 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 01:28:00 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 01:28:03 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 01:28:05 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 01:28:06 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 01:28:07 INFO mapreduce.Job:  map 71% reduce 0%
15/04/10 01:28:09 INFO mapreduce.Job:  map 72% reduce 0%
15/04/10 01:28:10 INFO mapreduce.Job:  map 73% reduce 0%
15/04/10 01:28:11 INFO mapreduce.Job:  map 74% reduce 0%
15/04/10 01:28:13 INFO mapreduce.Job:  map 75% reduce 0%
15/04/10 01:28:14 INFO mapreduce.Job:  map 76% reduce 4%
15/04/10 01:28:15 INFO mapreduce.Job:  map 77% reduce 9%
15/04/10 01:28:16 INFO mapreduce.Job:  map 78% reduce 10%
15/04/10 01:28:17 INFO mapreduce.Job:  map 79% reduce 11%
15/04/10 01:28:18 INFO mapreduce.Job:  map 80% reduce 12%
15/04/10 01:28:19 INFO mapreduce.Job:  map 82% reduce 13%
15/04/10 01:28:20 INFO mapreduce.Job:  map 84% reduce 14%
15/04/10 01:28:21 INFO mapreduce.Job:  map 86% reduce 17%
15/04/10 01:28:22 INFO mapreduce.Job:  map 87% reduce 18%
15/04/10 01:28:22 INFO mapreduce.Job: Task Id : attempt_1422482982071_4418_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 01:28:23 INFO mapreduce.Job:  map 86% reduce 19%
15/04/10 01:28:24 INFO mapreduce.Job:  map 88% reduce 21%
15/04/10 01:28:25 INFO mapreduce.Job:  map 89% reduce 22%
15/04/10 01:28:26 INFO mapreduce.Job:  map 90% reduce 23%
15/04/10 01:28:27 INFO mapreduce.Job:  map 90% reduce 24%
15/04/10 01:28:28 INFO mapreduce.Job:  map 91% reduce 24%
15/04/10 01:28:29 INFO mapreduce.Job:  map 91% reduce 25%
15/04/10 01:28:32 INFO mapreduce.Job:  map 92% reduce 26%
15/04/10 01:28:34 INFO mapreduce.Job:  map 93% reduce 26%
15/04/10 01:28:36 INFO mapreduce.Job:  map 93% reduce 27%
15/04/10 01:28:38 INFO mapreduce.Job:  map 94% reduce 27%
15/04/10 01:28:39 INFO mapreduce.Job:  map 94% reduce 28%
15/04/10 01:28:43 INFO mapreduce.Job:  map 95% reduce 28%
15/04/10 01:28:45 INFO mapreduce.Job:  map 95% reduce 29%
15/04/10 01:28:50 INFO mapreduce.Job:  map 96% reduce 29%
15/04/10 01:28:54 INFO mapreduce.Job:  map 96% reduce 30%
15/04/10 01:29:03 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 01:29:04 INFO mapreduce.Job:  map 97% reduce 31%
15/04/10 01:29:07 INFO mapreduce.Job:  map 97% reduce 32%
15/04/10 01:29:11 INFO mapreduce.Job:  map 98% reduce 32%
15/04/10 01:29:26 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 01:29:27 INFO mapreduce.Job:  map 99% reduce 33%
15/04/10 01:34:37 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 01:35:20 INFO mapreduce.Job:  map 100% reduce 34%
15/04/10 01:35:21 INFO mapreduce.Job:  map 100% reduce 36%
15/04/10 01:35:22 INFO mapreduce.Job:  map 100% reduce 39%
15/04/10 01:35:23 INFO mapreduce.Job:  map 100% reduce 41%
15/04/10 01:35:24 INFO mapreduce.Job:  map 100% reduce 44%
15/04/10 01:35:25 INFO mapreduce.Job:  map 100% reduce 47%
15/04/10 01:35:26 INFO mapreduce.Job:  map 100% reduce 50%
15/04/10 01:35:27 INFO mapreduce.Job:  map 100% reduce 53%
15/04/10 01:35:28 INFO mapreduce.Job:  map 100% reduce 57%
15/04/10 01:35:29 INFO mapreduce.Job:  map 100% reduce 59%
15/04/10 01:35:30 INFO mapreduce.Job:  map 100% reduce 60%
15/04/10 01:35:31 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 01:35:34 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 01:35:35 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 01:35:38 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 01:35:46 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 01:36:30 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 01:37:12 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 01:38:03 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 01:38:53 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 01:39:50 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 01:40:28 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 01:41:05 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 01:41:52 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 01:42:13 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 01:42:44 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 01:43:21 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 01:43:57 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 01:44:23 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 01:44:50 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 01:45:36 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 01:46:14 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 01:46:56 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 01:47:08 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 01:47:35 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 01:48:04 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 01:48:11 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 01:48:56 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 01:49:31 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 01:50:22 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 01:51:08 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 01:52:50 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 01:55:18 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 01:57:27 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 02:02:12 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 02:06:24 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 02:12:13 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 02:26:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4418_r_000021_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-un/_temporary/1/_temporary/attempt_1422482982071_4418_r_000021_0/part-00021 (inode 3599737): File does not exist. Holder DFSClient_attempt_1422482982071_4418_r_000021_0_1051258821_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:26:35 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 02:26:47 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 02:26:56 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 02:30:12 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 02:34:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4418_r_000022_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-un/_temporary/1/_temporary/attempt_1422482982071_4418_r_000022_0/part-00022 (inode 3599703): File does not exist. Holder DFSClient_attempt_1422482982071_4418_r_000022_0_-1973287396_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:34:19 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 02:34:30 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 02:34:54 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 02:35:04 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 02:45:43 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 02:49:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4418_r_000020_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 02:49:49 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 03:03:53 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 03:31:46 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 03:31:49 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 03:35:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4418_r_000020_1, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 03:35:58 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 04:20:08 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 04:24:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4418_r_000020_2, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 04:24:06 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 05:17:58 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 05:22:56 INFO mapreduce.Job: Job job_1422482982071_4418 failed with state FAILED due to: Task failed task_1422482982071_4418_r_000020
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/10 05:22:56 INFO mapreduce.Job: Counters: 55
	File System Counters
		FILE: Number of bytes read=15396645076
		FILE: Number of bytes written=32194286984
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3633584
		HDFS: Number of read operations=312
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=58
	Job Counters 
		Failed map tasks=10
		Failed reduce tasks=6
		Killed map tasks=1
		Killed reduce tasks=2
		Launched map tasks=86
		Launched reduce tasks=37
		Other local map tasks=11
		Data-local map tasks=51
		Rack-local map tasks=24
		Total time spent by all maps in occupied slots (ms)=64860460
		Total time spent by all reduces in occupied slots (ms)=157478376
		Total time spent by all map tasks (ms)=32430230
		Total time spent by all reduce tasks (ms)=78739188
		Total vcore-seconds taken by all map tasks=32430230
		Total vcore-seconds taken by all reduce tasks=78739188
		Total megabyte-seconds taken by all map tasks=262555142080
		Total megabyte-seconds taken by all reduce tasks=944870256000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787713923
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=250500
		Reduce shuffle bytes=15396657946
		Reduce input records=1487875235
		Reduce output records=250500
		Spilled Records=3174740043
		Shuffled Maps =2175
		Failed Shuffles=0
		Merged Map outputs=2175
		GC time elapsed (ms)=206106
		CPU time spent (ms)=82333870
		Physical memory (bytes) snapshot=168141053952
		Virtual memory (bytes) snapshot=1075452514304
		Total committed heap usage (bytes)=268775604224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3633584
15/04/10 05:22:56 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	241m50.681s
user	0m43.458s
sys	0m9.558s
15/04/10 05:22:58 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 30
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-30-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5580798744702791171.jar tmpDir=null
15/04/10 05:23:02 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 05:23:02 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 05:23:02 WARN security.UserGroupInformation: PriviledgedActionException as:dotcz12 (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://name.rustler.tacc.utexas.edu:8020/user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-un already exists
15/04/10 05:23:02 WARN security.UserGroupInformation: PriviledgedActionException as:dotcz12 (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://name.rustler.tacc.utexas.edu:8020/user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-un already exists
15/04/10 05:23:02 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://name.rustler.tacc.utexas.edu:8020/user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-un already exists
Streaming Command Failed!

real	0m6.076s
user	0m9.940s
sys	0m0.530s
15/04/10 05:23:05 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 20
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-20-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7317270361392411705.jar tmpDir=null
15/04/10 05:23:08 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 05:23:08 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 05:23:09 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 05:23:09 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 05:23:09 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4427
15/04/10 05:23:10 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4427
15/04/10 05:23:10 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4427/
15/04/10 05:23:10 INFO mapreduce.Job: Running job: job_1422482982071_4427
15/04/10 05:23:15 INFO mapreduce.Job: Job job_1422482982071_4427 running in uber mode : false
15/04/10 05:23:15 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 05:23:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4427_m_000008_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:23:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4427_m_000004_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:23:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4427_m_000030_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:23:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4427_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:23:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4427_m_000059_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:23:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4427_m_000058_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:23:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4427_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:23:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4427_m_000042_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:23:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4427_m_000051_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:23:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4427_m_000025_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:23:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4427_m_000069_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:23:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4427_m_000030_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 05:23:26 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 05:23:32 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 05:23:38 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 05:23:44 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 05:23:50 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 05:23:57 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 05:24:03 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 05:24:10 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 05:24:16 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 05:24:22 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 05:24:29 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 05:24:35 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 05:24:41 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 05:24:47 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 05:24:53 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 05:25:00 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 05:25:06 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 05:25:12 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 05:25:18 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 05:25:24 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 05:25:30 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 05:25:36 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 05:25:42 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 05:25:48 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 05:25:54 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 05:26:00 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 05:26:06 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 05:26:12 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 05:26:18 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 05:26:24 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 05:26:30 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 05:26:37 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 05:26:43 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 05:26:49 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 05:26:55 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 05:27:01 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 05:27:08 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 05:27:15 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 05:27:21 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 05:27:28 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 05:27:34 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 05:27:40 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 05:27:46 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 05:27:52 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 05:27:58 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 05:28:04 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 05:28:10 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 05:28:16 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 05:28:22 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 05:28:28 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 05:28:35 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 05:28:41 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 05:28:47 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 05:28:51 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 05:28:57 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 05:29:03 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 05:29:10 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 05:29:16 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 05:29:22 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 05:29:28 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 05:29:35 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 05:29:41 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 05:29:47 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 05:29:55 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 05:29:59 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 05:30:01 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 05:30:03 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 05:30:04 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 05:30:07 INFO mapreduce.Job:  map 69% reduce 0%
15/04/10 05:30:08 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 05:30:09 INFO mapreduce.Job:  map 71% reduce 0%
15/04/10 05:30:10 INFO mapreduce.Job:  map 73% reduce 2%
15/04/10 05:30:11 INFO mapreduce.Job:  map 74% reduce 7%
15/04/10 05:30:12 INFO mapreduce.Job:  map 74% reduce 8%
15/04/10 05:30:13 INFO mapreduce.Job:  map 76% reduce 9%
15/04/10 05:30:14 INFO mapreduce.Job:  map 76% reduce 10%
15/04/10 05:30:16 INFO mapreduce.Job:  map 77% reduce 11%
15/04/10 05:30:17 INFO mapreduce.Job:  map 78% reduce 11%
15/04/10 05:30:18 INFO mapreduce.Job:  map 78% reduce 12%
15/04/10 05:30:19 INFO mapreduce.Job:  map 80% reduce 13%
15/04/10 05:30:20 INFO mapreduce.Job:  map 81% reduce 13%
15/04/10 05:30:21 INFO mapreduce.Job:  map 82% reduce 16%
15/04/10 05:30:22 INFO mapreduce.Job:  map 84% reduce 17%
15/04/10 05:30:24 INFO mapreduce.Job:  map 84% reduce 19%
15/04/10 05:30:30 INFO mapreduce.Job:  map 85% reduce 19%
15/04/10 05:30:33 INFO mapreduce.Job:  map 86% reduce 20%
15/04/10 05:30:39 INFO mapreduce.Job:  map 87% reduce 20%
15/04/10 05:30:40 INFO mapreduce.Job:  map 87% reduce 21%
15/04/10 05:30:44 INFO mapreduce.Job:  map 88% reduce 21%
15/04/10 05:30:46 INFO mapreduce.Job:  map 88% reduce 22%
15/04/10 05:30:48 INFO mapreduce.Job:  map 89% reduce 22%
15/04/10 05:30:50 INFO mapreduce.Job:  map 90% reduce 22%
15/04/10 05:30:51 INFO mapreduce.Job:  map 90% reduce 23%
15/04/10 05:30:52 INFO mapreduce.Job:  map 91% reduce 23%
15/04/10 05:30:53 INFO mapreduce.Job:  map 91% reduce 24%
15/04/10 05:30:55 INFO mapreduce.Job:  map 92% reduce 25%
15/04/10 05:30:57 INFO mapreduce.Job:  map 93% reduce 25%
15/04/10 05:30:58 INFO mapreduce.Job:  map 93% reduce 26%
15/04/10 05:31:03 INFO mapreduce.Job:  map 93% reduce 27%
15/04/10 05:31:04 INFO mapreduce.Job:  map 94% reduce 27%
15/04/10 05:31:08 INFO mapreduce.Job:  map 95% reduce 28%
15/04/10 05:31:22 INFO mapreduce.Job:  map 96% reduce 28%
15/04/10 05:31:23 INFO mapreduce.Job:  map 96% reduce 29%
15/04/10 05:31:26 INFO mapreduce.Job:  map 96% reduce 30%
15/04/10 05:31:27 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 05:31:29 INFO mapreduce.Job:  map 98% reduce 30%
15/04/10 05:31:30 INFO mapreduce.Job:  map 98% reduce 31%
15/04/10 05:31:31 INFO mapreduce.Job:  map 99% reduce 31%
15/04/10 05:31:33 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 05:31:37 INFO mapreduce.Job:  map 100% reduce 32%
15/04/10 05:31:38 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 05:31:41 INFO mapreduce.Job:  map 100% reduce 34%
15/04/10 05:31:42 INFO mapreduce.Job:  map 100% reduce 35%
15/04/10 05:31:43 INFO mapreduce.Job:  map 100% reduce 37%
15/04/10 05:31:44 INFO mapreduce.Job:  map 100% reduce 40%
15/04/10 05:31:46 INFO mapreduce.Job:  map 100% reduce 43%
15/04/10 05:31:47 INFO mapreduce.Job:  map 100% reduce 46%
15/04/10 05:31:49 INFO mapreduce.Job:  map 100% reduce 48%
15/04/10 05:31:50 INFO mapreduce.Job:  map 100% reduce 51%
15/04/10 05:31:51 INFO mapreduce.Job:  map 100% reduce 52%
15/04/10 05:31:52 INFO mapreduce.Job:  map 100% reduce 55%
15/04/10 05:31:53 INFO mapreduce.Job:  map 100% reduce 57%
15/04/10 05:31:54 INFO mapreduce.Job:  map 100% reduce 58%
15/04/10 05:31:55 INFO mapreduce.Job:  map 100% reduce 60%
15/04/10 05:31:56 INFO mapreduce.Job:  map 100% reduce 61%
15/04/10 05:31:58 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 05:31:59 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 05:32:00 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 05:32:02 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 05:32:03 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 05:32:06 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 05:33:18 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 05:34:45 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 05:36:15 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 05:37:13 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 05:38:20 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 05:39:38 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 05:41:14 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 05:41:54 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 05:42:40 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 05:43:41 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 05:44:28 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 05:44:55 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 05:45:41 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 05:46:35 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 05:47:20 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 05:48:23 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 05:49:10 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 05:49:56 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 05:51:21 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 05:52:21 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 05:53:02 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 05:54:41 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 05:57:30 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 05:59:28 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 06:01:36 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 06:02:32 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 06:04:32 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 06:07:45 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 06:16:48 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 06:17:13 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 06:20:16 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 06:41:36 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 06:48:30 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 07:06:27 INFO mapreduce.Job: Task Id : attempt_1422482982071_4427_r_000000_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-un/_temporary/1/_temporary/attempt_1422482982071_4427_r_000000_0/part-00000 (inode 3600704): File does not exist. Holder DFSClient_attempt_1422482982071_4427_r_000000_0_1580860259_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 07:06:28 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 07:47:48 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 07:54:30 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 07:54:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4427_r_000000_1, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 07:54:52 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 08:55:11 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 09:02:26 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 09:02:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4427_r_000000_2, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 09:02:49 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 10:06:12 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 10:13:54 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 10:14:16 INFO mapreduce.Job: Job job_1422482982071_4427 failed with state FAILED due to: Task failed task_1422482982071_4427_r_000000
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/10 10:14:16 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=15094216561
		FILE: Number of bytes written=31890886770
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3570384
		HDFS: Number of read operations=282
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=38
	Job Counters 
		Failed map tasks=12
		Failed reduce tasks=4
		Killed reduce tasks=1
		Launched map tasks=87
		Launched reduce tasks=24
		Other local map tasks=12
		Data-local map tasks=51
		Rack-local map tasks=24
		Total time spent by all maps in occupied slots (ms)=65330450
		Total time spent by all reduces in occupied slots (ms)=118477678
		Total time spent by all map tasks (ms)=32665225
		Total time spent by all reduce tasks (ms)=59238839
		Total vcore-seconds taken by all map tasks=32665225
		Total vcore-seconds taken by all reduce tasks=59238839
		Total megabyte-seconds taken by all map tasks=264457661600
		Total megabyte-seconds taken by all reduce tasks=710866068000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787709423
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=246064
		Reduce shuffle bytes=15094224973
		Reduce input records=1457268904
		Reduce output records=246064
		Spilled Records=3144133712
		Shuffled Maps =1425
		Failed Shuffles=0
		Merged Map outputs=1425
		GC time elapsed (ms)=171751
		CPU time spent (ms)=82908430
		Physical memory (bytes) snapshot=165660360704
		Virtual memory (bytes) snapshot=942233473024
		Total committed heap usage (bytes)=247726206976
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3570384
15/04/10 10:14:16 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	291m13.837s
user	0m48.660s
sys	0m11.687s
15/04/10 10:14:19 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 20
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-20-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8577030839195174495.jar tmpDir=null
15/04/10 10:14:22 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 10:14:22 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 10:14:22 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 10:14:23 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 10:14:23 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4443
15/04/10 10:14:24 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4443
15/04/10 10:14:24 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4443/
15/04/10 10:14:24 INFO mapreduce.Job: Running job: job_1422482982071_4443
15/04/10 10:14:30 INFO mapreduce.Job: Job job_1422482982071_4443 running in uber mode : false
15/04/10 10:14:30 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 10:14:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4443_m_000027_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:14:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4443_m_000022_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:14:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4443_m_000007_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:14:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4443_m_000026_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:14:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4443_m_000011_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:14:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4443_m_000052_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:14:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4443_m_000063_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:14:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4443_m_000024_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:14:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4443_m_000041_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:14:41 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 10:14:47 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 10:14:53 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 10:14:59 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 10:15:05 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 10:15:11 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 10:15:18 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 10:15:24 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 10:15:30 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 10:15:37 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 10:15:43 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 10:15:49 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 10:15:55 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 10:16:01 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 10:16:07 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 10:16:13 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 10:16:19 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 10:16:25 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 10:16:31 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 10:16:37 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 10:16:43 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 10:16:49 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 10:16:55 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 10:17:01 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 10:17:08 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 10:17:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4443_m_000059_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 10:17:18 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 10:17:24 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 10:17:31 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 10:17:39 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 10:17:45 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 10:17:52 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 10:18:00 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 10:18:06 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 10:18:13 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 10:18:21 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 10:18:27 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 10:18:35 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 10:18:42 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 10:18:49 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 10:18:56 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 10:19:02 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 10:19:10 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 10:19:16 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 10:19:23 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 10:19:29 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 10:19:35 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 10:19:41 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 10:19:47 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 10:19:54 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 10:20:01 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 10:20:07 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 10:20:13 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 10:20:20 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 10:20:24 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 10:20:29 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 10:20:35 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 10:20:41 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 10:20:47 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 10:20:54 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 10:21:01 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 10:21:07 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 10:21:13 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 10:21:20 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 10:21:26 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 10:21:35 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 10:21:38 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 10:21:41 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 10:21:42 INFO mapreduce.Job:  map 69% reduce 0%
15/04/10 10:21:43 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 10:21:45 INFO mapreduce.Job:  map 71% reduce 0%
15/04/10 10:21:46 INFO mapreduce.Job:  map 73% reduce 0%
15/04/10 10:21:47 INFO mapreduce.Job:  map 75% reduce 0%
15/04/10 10:21:48 INFO mapreduce.Job:  map 77% reduce 0%
15/04/10 10:21:50 INFO mapreduce.Job:  map 78% reduce 2%
15/04/10 10:21:51 INFO mapreduce.Job:  map 78% reduce 9%
15/04/10 10:21:52 INFO mapreduce.Job:  map 79% reduce 13%
15/04/10 10:21:54 INFO mapreduce.Job:  map 80% reduce 14%
15/04/10 10:21:56 INFO mapreduce.Job:  map 81% reduce 14%
15/04/10 10:21:57 INFO mapreduce.Job:  map 81% reduce 15%
15/04/10 10:21:58 INFO mapreduce.Job:  map 82% reduce 16%
15/04/10 10:21:59 INFO mapreduce.Job:  map 83% reduce 16%
15/04/10 10:22:00 INFO mapreduce.Job:  map 84% reduce 17%
15/04/10 10:22:01 INFO mapreduce.Job:  map 85% reduce 17%
15/04/10 10:22:02 INFO mapreduce.Job:  map 87% reduce 18%
15/04/10 10:22:03 INFO mapreduce.Job:  map 87% reduce 20%
15/04/10 10:22:04 INFO mapreduce.Job:  map 87% reduce 21%
15/04/10 10:22:07 INFO mapreduce.Job:  map 88% reduce 21%
15/04/10 10:22:09 INFO mapreduce.Job:  map 88% reduce 22%
15/04/10 10:22:10 INFO mapreduce.Job:  map 89% reduce 22%
15/04/10 10:22:13 INFO mapreduce.Job:  map 89% reduce 23%
15/04/10 10:22:15 INFO mapreduce.Job:  map 90% reduce 23%
15/04/10 10:22:18 INFO mapreduce.Job:  map 90% reduce 24%
15/04/10 10:22:20 INFO mapreduce.Job:  map 91% reduce 24%
15/04/10 10:22:25 INFO mapreduce.Job:  map 92% reduce 25%
15/04/10 10:22:28 INFO mapreduce.Job:  map 93% reduce 25%
15/04/10 10:22:29 INFO mapreduce.Job:  map 93% reduce 26%
15/04/10 10:22:33 INFO mapreduce.Job:  map 94% reduce 26%
15/04/10 10:22:34 INFO mapreduce.Job:  map 94% reduce 27%
15/04/10 10:22:36 INFO mapreduce.Job:  map 95% reduce 28%
15/04/10 10:22:41 INFO mapreduce.Job:  map 96% reduce 29%
15/04/10 10:22:42 INFO mapreduce.Job:  map 97% reduce 29%
15/04/10 10:22:43 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 10:22:44 INFO mapreduce.Job:  map 98% reduce 30%
15/04/10 10:22:46 INFO mapreduce.Job:  map 98% reduce 31%
15/04/10 10:22:49 INFO mapreduce.Job:  map 98% reduce 32%
15/04/10 10:22:56 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 10:23:00 INFO mapreduce.Job:  map 99% reduce 33%
15/04/10 10:24:14 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 10:24:57 INFO mapreduce.Job:  map 100% reduce 34%
15/04/10 10:24:58 INFO mapreduce.Job:  map 100% reduce 36%
15/04/10 10:24:59 INFO mapreduce.Job:  map 100% reduce 37%
15/04/10 10:25:00 INFO mapreduce.Job:  map 100% reduce 39%
15/04/10 10:25:01 INFO mapreduce.Job:  map 100% reduce 43%
15/04/10 10:25:02 INFO mapreduce.Job:  map 100% reduce 45%
15/04/10 10:25:03 INFO mapreduce.Job:  map 100% reduce 47%
15/04/10 10:25:04 INFO mapreduce.Job:  map 100% reduce 49%
15/04/10 10:25:05 INFO mapreduce.Job:  map 100% reduce 50%
15/04/10 10:25:06 INFO mapreduce.Job:  map 100% reduce 53%
15/04/10 10:25:07 INFO mapreduce.Job:  map 100% reduce 55%
15/04/10 10:25:08 INFO mapreduce.Job:  map 100% reduce 56%
15/04/10 10:25:09 INFO mapreduce.Job:  map 100% reduce 58%
15/04/10 10:25:10 INFO mapreduce.Job:  map 100% reduce 59%
15/04/10 10:25:11 INFO mapreduce.Job:  map 100% reduce 61%
15/04/10 10:25:12 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 10:25:14 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 10:25:16 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 10:25:18 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 10:25:21 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 10:26:36 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 10:28:07 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 10:29:47 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 10:30:51 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 10:32:05 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 10:33:27 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 10:34:50 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 10:35:29 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 10:36:18 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 10:37:45 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 10:38:17 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 10:39:17 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 10:39:50 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 10:40:53 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 10:41:36 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 10:42:31 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 10:43:24 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 10:44:26 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 10:45:44 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 10:47:09 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 10:47:24 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 10:49:08 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 10:51:54 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 10:53:02 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 10:55:14 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 10:56:18 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 10:58:25 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 11:03:18 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 11:09:25 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 11:14:06 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 11:15:35 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 11:33:06 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 11:39:52 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 11:56:17 INFO mapreduce.Job: Job job_1422482982071_4443 completed successfully
15/04/10 11:56:18 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16787700573
		FILE: Number of bytes written=33584465701
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=285
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Failed map tasks=10
		Killed map tasks=1
		Launched map tasks=86
		Launched reduce tasks=20
		Other local map tasks=11
		Data-local map tasks=52
		Rack-local map tasks=23
		Total time spent by all maps in occupied slots (ms)=68297044
		Total time spent by all reduces in occupied slots (ms)=94484282
		Total time spent by all map tasks (ms)=34148522
		Total time spent by all reduce tasks (ms)=47242141
		Total vcore-seconds taken by all map tasks=34148522
		Total vcore-seconds taken by all reduce tasks=47242141
		Total megabyte-seconds taken by all map tasks=276466434112
		Total megabyte-seconds taken by all reduce tasks=566905692000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787709423
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787709423
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=175471
		CPU time spent (ms)=91263120
		Physical memory (bytes) snapshot=167699689472
		Virtual memory (bytes) snapshot=956339699712
		Total committed heap usage (bytes)=249830789120
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/10 11:56:18 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	102m1.899s
user	0m31.617s
sys	0m4.524s
15/04/10 11:56:20 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 20
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-20-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5527896842412883257.jar tmpDir=null
15/04/10 11:56:23 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 11:56:23 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 11:56:25 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 11:56:25 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 11:56:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4448
15/04/10 11:56:26 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4448
15/04/10 11:56:26 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4448/
15/04/10 11:56:26 INFO mapreduce.Job: Running job: job_1422482982071_4448
15/04/10 11:56:32 INFO mapreduce.Job: Job job_1422482982071_4448 running in uber mode : false
15/04/10 11:56:32 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 11:56:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4448_m_000046_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 11:56:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4448_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 11:56:38 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 11:56:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4448_m_000037_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 11:56:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4448_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 11:56:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4448_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 11:56:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4448_m_000063_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 11:56:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4448_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 11:56:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4448_m_000060_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 11:56:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4448_m_000070_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 11:56:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4448_m_000007_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 11:56:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4448_m_000059_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 11:56:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4448_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 11:56:39 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 11:56:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4448_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 11:56:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4448_m_000050_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 11:56:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4448_m_000074_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 11:56:44 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 11:56:50 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 11:56:57 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 11:57:03 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 11:57:09 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 11:57:15 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 11:57:21 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 11:57:27 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 11:57:33 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 11:57:40 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 11:57:46 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 11:57:52 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 11:57:58 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 11:58:04 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 11:58:10 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 11:58:16 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 11:58:22 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 11:58:28 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 11:58:35 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 11:58:41 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 11:58:47 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 11:58:53 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 11:58:59 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 11:59:05 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 11:59:11 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 11:59:17 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 11:59:23 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 11:59:29 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 11:59:36 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 11:59:42 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 11:59:48 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 11:59:55 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 12:00:01 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 12:00:07 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 12:00:13 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 12:00:19 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 12:00:25 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 12:00:31 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 12:00:37 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 12:00:43 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 12:00:49 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 12:00:55 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 12:01:01 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 12:01:07 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 12:01:13 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 12:01:19 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 12:01:25 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 12:01:31 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 12:01:37 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 12:01:44 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 12:01:49 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 12:01:56 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 12:02:02 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 12:02:09 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 12:02:15 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 12:02:18 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 12:02:25 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 12:02:31 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 12:02:37 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 12:02:43 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 12:02:50 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 12:02:56 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 12:03:02 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 12:03:08 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 12:03:15 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 12:03:18 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 12:03:21 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 12:03:24 INFO mapreduce.Job:  map 69% reduce 0%
15/04/10 12:03:25 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 12:03:26 INFO mapreduce.Job:  map 72% reduce 0%
15/04/10 12:03:28 INFO mapreduce.Job:  map 73% reduce 0%
15/04/10 12:03:29 INFO mapreduce.Job:  map 73% reduce 1%
15/04/10 12:03:30 INFO mapreduce.Job:  map 74% reduce 8%
15/04/10 12:03:31 INFO mapreduce.Job:  map 76% reduce 8%
15/04/10 12:03:32 INFO mapreduce.Job:  map 78% reduce 8%
15/04/10 12:03:33 INFO mapreduce.Job:  map 78% reduce 12%
15/04/10 12:03:34 INFO mapreduce.Job:  map 79% reduce 12%
15/04/10 12:03:35 INFO mapreduce.Job:  map 80% reduce 13%
15/04/10 12:03:36 INFO mapreduce.Job:  map 80% reduce 14%
15/04/10 12:03:37 INFO mapreduce.Job:  map 81% reduce 14%
15/04/10 12:03:38 INFO mapreduce.Job:  map 82% reduce 15%
15/04/10 12:03:39 INFO mapreduce.Job:  map 83% reduce 16%
15/04/10 12:03:40 INFO mapreduce.Job:  map 84% reduce 17%
15/04/10 12:03:41 INFO mapreduce.Job:  map 85% reduce 17%
15/04/10 12:03:42 INFO mapreduce.Job:  map 86% reduce 19%
15/04/10 12:03:44 INFO mapreduce.Job:  map 87% reduce 20%
15/04/10 12:03:46 INFO mapreduce.Job:  map 88% reduce 21%
15/04/10 12:03:48 INFO mapreduce.Job:  map 88% reduce 22%
15/04/10 12:03:49 INFO mapreduce.Job:  map 89% reduce 22%
15/04/10 12:03:52 INFO mapreduce.Job:  map 89% reduce 23%
15/04/10 12:03:59 INFO mapreduce.Job:  map 90% reduce 23%
15/04/10 12:04:06 INFO mapreduce.Job:  map 91% reduce 23%
15/04/10 12:04:07 INFO mapreduce.Job:  map 91% reduce 24%
15/04/10 12:04:10 INFO mapreduce.Job:  map 92% reduce 24%
15/04/10 12:04:13 INFO mapreduce.Job:  map 92% reduce 25%
15/04/10 12:04:15 INFO mapreduce.Job:  map 93% reduce 25%
15/04/10 12:04:16 INFO mapreduce.Job:  map 93% reduce 26%
15/04/10 12:04:18 INFO mapreduce.Job:  map 95% reduce 26%
15/04/10 12:04:19 INFO mapreduce.Job:  map 96% reduce 28%
15/04/10 12:04:22 INFO mapreduce.Job:  map 96% reduce 29%
15/04/10 12:04:23 INFO mapreduce.Job:  map 97% reduce 29%
15/04/10 12:04:24 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 12:04:26 INFO mapreduce.Job:  map 98% reduce 30%
15/04/10 12:04:28 INFO mapreduce.Job:  map 98% reduce 31%
15/04/10 12:04:32 INFO mapreduce.Job:  map 99% reduce 31%
15/04/10 12:04:34 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 12:04:35 INFO mapreduce.Job:  map 100% reduce 32%
15/04/10 12:04:37 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 12:04:38 INFO mapreduce.Job:  map 100% reduce 34%
15/04/10 12:04:40 INFO mapreduce.Job:  map 100% reduce 36%
15/04/10 12:04:41 INFO mapreduce.Job:  map 100% reduce 38%
15/04/10 12:04:42 INFO mapreduce.Job:  map 100% reduce 39%
15/04/10 12:04:43 INFO mapreduce.Job:  map 100% reduce 41%
15/04/10 12:04:44 INFO mapreduce.Job:  map 100% reduce 44%
15/04/10 12:04:46 INFO mapreduce.Job:  map 100% reduce 47%
15/04/10 12:04:47 INFO mapreduce.Job:  map 100% reduce 51%
15/04/10 12:04:48 INFO mapreduce.Job:  map 100% reduce 52%
15/04/10 12:04:49 INFO mapreduce.Job:  map 100% reduce 53%
15/04/10 12:04:50 INFO mapreduce.Job:  map 100% reduce 58%
15/04/10 12:04:51 INFO mapreduce.Job:  map 100% reduce 59%
15/04/10 12:04:54 INFO mapreduce.Job:  map 100% reduce 61%
15/04/10 12:04:55 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 12:04:56 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 12:04:58 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 12:05:00 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 12:05:01 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 12:05:03 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 12:06:15 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 12:07:41 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 12:09:07 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 12:10:15 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 12:11:16 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 12:12:42 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 12:14:11 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 12:14:43 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 12:15:43 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 12:16:42 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 12:17:31 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 12:17:49 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 12:18:42 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 12:19:28 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 12:20:28 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 12:21:25 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 12:22:11 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 12:22:53 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 12:24:05 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 12:25:23 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 12:26:03 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 12:27:16 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 12:30:35 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 12:31:35 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 12:34:31 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 12:35:21 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 12:35:57 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 12:40:04 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 12:45:12 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 12:49:00 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 12:50:27 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 13:10:38 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 13:17:17 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 13:33:24 INFO mapreduce.Job: Job job_1422482982071_4448 completed successfully
15/04/10 13:33:24 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16787700573
		FILE: Number of bytes written=33584465701
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=285
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Failed map tasks=15
		Killed reduce tasks=1
		Launched map tasks=90
		Launched reduce tasks=21
		Other local map tasks=15
		Data-local map tasks=53
		Rack-local map tasks=22
		Total time spent by all maps in occupied slots (ms)=64632986
		Total time spent by all reduces in occupied slots (ms)=88316918
		Total time spent by all map tasks (ms)=32316493
		Total time spent by all reduce tasks (ms)=44158459
		Total vcore-seconds taken by all map tasks=32316493
		Total vcore-seconds taken by all reduce tasks=44158459
		Total megabyte-seconds taken by all map tasks=261634327328
		Total megabyte-seconds taken by all reduce tasks=529901508000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787709423
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787709423
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=223076
		CPU time spent (ms)=87507540
		Physical memory (bytes) snapshot=168266018816
		Virtual memory (bytes) snapshot=955348312064
		Total committed heap usage (bytes)=249830043648
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/10 13:33:24 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	97m6.524s
user	0m30.740s
sys	0m4.296s
15/04/10 13:33:27 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 10
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-10-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6765744912463654215.jar tmpDir=null
15/04/10 13:33:30 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 13:33:30 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 13:33:31 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 13:33:31 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 13:33:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4449
15/04/10 13:33:32 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4449
15/04/10 13:33:32 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4449/
15/04/10 13:33:32 INFO mapreduce.Job: Running job: job_1422482982071_4449
15/04/10 13:33:38 INFO mapreduce.Job: Job job_1422482982071_4449 running in uber mode : false
15/04/10 13:33:38 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 13:33:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_m_000070_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:33:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_m_000018_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:33:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_m_000058_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:33:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:33:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_m_000050_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:33:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:33:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_m_000030_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:33:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:33:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_m_000065_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:33:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_m_000038_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:33:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:33:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_m_000035_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:33:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_m_000010_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:33:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_m_000001_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:33:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_m_000016_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:33:51 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 13:33:56 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 13:34:03 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 13:34:09 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 13:34:15 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 13:34:21 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 13:34:27 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 13:34:33 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 13:34:39 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 13:34:45 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 13:34:51 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 13:34:57 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 13:35:03 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 13:35:09 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 13:35:15 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 13:35:21 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 13:35:27 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 13:35:33 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 13:35:39 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 13:35:45 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 13:35:51 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 13:35:57 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 13:36:03 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 13:36:09 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 13:36:15 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 13:36:21 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 13:36:28 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 13:36:34 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 13:36:40 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 13:36:46 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 13:36:52 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 13:36:58 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 13:37:04 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 13:37:10 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 13:37:16 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 13:37:22 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 13:37:28 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 13:37:34 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 13:37:40 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 13:37:46 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 13:37:52 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 13:37:58 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 13:38:04 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 13:38:11 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 13:38:17 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 13:38:23 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 13:38:29 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 13:38:35 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 13:38:41 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 13:38:47 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 13:38:53 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 13:38:59 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 13:39:06 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 13:39:11 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 13:39:17 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 13:39:24 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 13:39:30 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 13:39:37 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 13:39:43 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 13:39:49 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 13:39:55 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 13:39:59 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 13:40:05 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 13:40:11 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 13:40:17 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 13:40:24 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 13:40:27 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 13:40:29 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 13:40:32 INFO mapreduce.Job:  map 69% reduce 0%
15/04/10 13:40:33 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 13:40:34 INFO mapreduce.Job:  map 71% reduce 0%
15/04/10 13:40:35 INFO mapreduce.Job:  map 73% reduce 0%
15/04/10 13:40:36 INFO mapreduce.Job:  map 75% reduce 0%
15/04/10 13:40:37 INFO mapreduce.Job:  map 76% reduce 5%
15/04/10 13:40:38 INFO mapreduce.Job:  map 76% reduce 8%
15/04/10 13:40:39 INFO mapreduce.Job:  map 79% reduce 10%
15/04/10 13:40:40 INFO mapreduce.Job:  map 81% reduce 10%
15/04/10 13:40:41 INFO mapreduce.Job:  map 82% reduce 13%
15/04/10 13:40:42 INFO mapreduce.Job:  map 82% reduce 14%
15/04/10 13:40:43 INFO mapreduce.Job:  map 84% reduce 15%
15/04/10 13:40:44 INFO mapreduce.Job:  map 84% reduce 17%
15/04/10 13:40:45 INFO mapreduce.Job:  map 85% reduce 17%
15/04/10 13:40:46 INFO mapreduce.Job:  map 85% reduce 18%
15/04/10 13:40:47 INFO mapreduce.Job:  map 87% reduce 19%
15/04/10 13:40:48 INFO mapreduce.Job:  map 88% reduce 19%
15/04/10 13:40:50 INFO mapreduce.Job:  map 89% reduce 20%
15/04/10 13:40:52 INFO mapreduce.Job:  map 90% reduce 20%
15/04/10 13:40:53 INFO mapreduce.Job:  map 91% reduce 21%
15/04/10 13:40:55 INFO mapreduce.Job:  map 92% reduce 21%
15/04/10 13:40:57 INFO mapreduce.Job:  map 92% reduce 22%
15/04/10 13:41:06 INFO mapreduce.Job:  map 92% reduce 23%
15/04/10 13:41:07 INFO mapreduce.Job:  map 92% reduce 24%
15/04/10 13:41:13 INFO mapreduce.Job:  map 93% reduce 25%
15/04/10 13:41:14 INFO mapreduce.Job:  map 93% reduce 26%
15/04/10 13:41:19 INFO mapreduce.Job:  map 94% reduce 26%
15/04/10 13:41:20 INFO mapreduce.Job:  map 94% reduce 27%
15/04/10 13:41:22 INFO mapreduce.Job:  map 95% reduce 27%
15/04/10 13:41:23 INFO mapreduce.Job:  map 95% reduce 28%
15/04/10 13:41:24 INFO mapreduce.Job:  map 96% reduce 28%
15/04/10 13:41:26 INFO mapreduce.Job:  map 96% reduce 29%
15/04/10 13:41:28 INFO mapreduce.Job:  map 97% reduce 29%
15/04/10 13:41:30 INFO mapreduce.Job:  map 98% reduce 30%
15/04/10 13:41:31 INFO mapreduce.Job:  map 99% reduce 30%
15/04/10 13:41:32 INFO mapreduce.Job:  map 99% reduce 31%
15/04/10 13:41:33 INFO mapreduce.Job:  map 100% reduce 31%
15/04/10 13:41:35 INFO mapreduce.Job:  map 100% reduce 32%
15/04/10 13:41:38 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 13:41:39 INFO mapreduce.Job:  map 100% reduce 34%
15/04/10 13:41:40 INFO mapreduce.Job:  map 100% reduce 35%
15/04/10 13:41:42 INFO mapreduce.Job:  map 100% reduce 37%
15/04/10 13:41:44 INFO mapreduce.Job:  map 100% reduce 38%
15/04/10 13:41:45 INFO mapreduce.Job:  map 100% reduce 40%
15/04/10 13:41:46 INFO mapreduce.Job:  map 100% reduce 41%
15/04/10 13:41:47 INFO mapreduce.Job:  map 100% reduce 42%
15/04/10 13:41:48 INFO mapreduce.Job:  map 100% reduce 44%
15/04/10 13:41:49 INFO mapreduce.Job:  map 100% reduce 45%
15/04/10 13:41:50 INFO mapreduce.Job:  map 100% reduce 46%
15/04/10 13:41:51 INFO mapreduce.Job:  map 100% reduce 49%
15/04/10 13:41:53 INFO mapreduce.Job:  map 100% reduce 50%
15/04/10 13:41:54 INFO mapreduce.Job:  map 100% reduce 52%
15/04/10 13:41:55 INFO mapreduce.Job:  map 100% reduce 53%
15/04/10 13:41:56 INFO mapreduce.Job:  map 100% reduce 55%
15/04/10 13:41:58 INFO mapreduce.Job:  map 100% reduce 60%
15/04/10 13:41:59 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 13:42:02 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 13:42:05 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 13:42:08 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 13:45:31 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 13:48:20 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 13:51:28 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 13:55:35 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 13:56:16 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 13:59:23 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 13:59:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_r_000004_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 13:59:32 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 13:59:43 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 14:00:07 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 14:00:14 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 14:00:18 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 14:00:21 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 14:00:48 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 14:00:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_r_000008_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 14:00:49 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 14:01:01 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 14:01:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_r_000007_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 14:01:26 INFO mapreduce.Job:  map 100% reduce 61%
15/04/10 14:01:31 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 14:01:34 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 14:01:36 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 14:01:58 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 14:02:01 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 14:04:18 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 14:06:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_r_000003_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 14:06:10 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 14:06:20 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 14:06:42 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 14:06:57 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 14:07:09 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 14:08:30 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 14:10:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_r_000006_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 14:10:17 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 14:10:28 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 14:10:49 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 14:10:55 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 14:11:01 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 14:11:07 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 14:11:29 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 14:11:53 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 14:11:53 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_r_000005_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 14:11:54 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 14:12:05 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 14:12:50 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 14:12:53 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 14:13:41 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 14:15:23 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_r_000002_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 14:15:24 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 14:15:35 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 14:15:59 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 14:16:26 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 14:16:29 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 14:17:48 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 14:21:00 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 14:24:20 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 14:24:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_r_000009_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-un/_temporary/1/_temporary/attempt_1422482982071_4449_r_000009_0/part-00009 (inode 3603497): File does not exist. Holder DFSClient_attempt_1422482982071_4449_r_000009_0_1386264304_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 14:24:21 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 14:24:31 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 14:24:51 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 14:24:54 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 14:24:57 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 14:24:58 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 14:27:04 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 14:28:20 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 14:28:23 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 14:30:55 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 14:31:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_r_000001_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 14:31:59 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 14:32:11 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 14:32:26 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 14:32:38 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 14:32:44 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 14:32:56 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 14:33:00 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 14:33:28 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 14:36:02 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 14:38:53 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 14:41:37 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 14:43:00 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 14:44:49 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 14:46:59 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 14:49:39 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 14:50:54 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 14:52:17 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 14:53:59 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 14:55:13 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 14:56:58 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 14:59:54 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 15:02:12 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 15:04:52 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 15:06:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_r_000000_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 15:06:08 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 15:06:19 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 15:06:49 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 15:07:23 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 15:07:26 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 15:10:43 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 15:17:28 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 15:20:28 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 15:26:42 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 15:35:10 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 15:43:10 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 15:51:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_r_000002_1, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-un/_temporary/1/_temporary/attempt_1422482982071_4449_r_000002_1/part-00002 (inode 3603627): File does not exist. Holder DFSClient_attempt_1422482982071_4449_r_000002_1_-73508470_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 15:51:18 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 15:51:29 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 15:51:51 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 15:51:56 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 15:52:24 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 15:52:27 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 15:54:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_r_000001_1, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-un/_temporary/1/_temporary/attempt_1422482982071_4449_r_000001_1/part-00001 (inode 3603631): File does not exist. Holder DFSClient_attempt_1422482982071_4449_r_000001_1_-1627269346_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 15:54:14 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 15:54:25 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 15:54:49 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 15:54:52 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 15:54:58 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 15:55:07 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 15:55:13 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 16:01:41 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 16:16:19 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 16:24:23 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 16:27:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_r_000000_1, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 16:27:46 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 16:27:57 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 16:28:28 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 16:29:01 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 16:29:04 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 16:30:47 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 16:39:37 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 16:47:25 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 17:01:04 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 17:13:35 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 17:19:30 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 17:41:02 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 17:51:12 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 17:53:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4449_r_000000_2, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 17:53:18 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 17:53:30 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 17:54:02 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 17:54:32 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 17:54:35 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 19:00:13 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 19:09:30 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 19:11:28 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 19:11:28 INFO mapreduce.Job: Job job_1422482982071_4449 failed with state FAILED due to: Task failed task_1422482982071_4449_r_000000
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/10 19:11:28 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=14559282513
		FILE: Number of bytes written=31354981022
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3382720
		HDFS: Number of read operations=252
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=18
	Job Counters 
		Failed map tasks=15
		Failed reduce tasks=15
		Launched map tasks=90
		Launched reduce tasks=24
		Other local map tasks=15
		Data-local map tasks=52
		Rack-local map tasks=23
		Total time spent by all maps in occupied slots (ms)=64324498
		Total time spent by all reduces in occupied slots (ms)=164441010
		Total time spent by all map tasks (ms)=32162249
		Total time spent by all reduce tasks (ms)=82220505
		Total vcore-seconds taken by all map tasks=32162249
		Total vcore-seconds taken by all reduce tasks=82220505
		Total megabyte-seconds taken by all map tasks=260385567904
		Total megabyte-seconds taken by all reduce tasks=986646060000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787704923
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=233110
		Reduce shuffle bytes=14559286443
		Reduce input records=1414254211
		Reduce output records=233110
		Spilled Records=3101119019
		Shuffled Maps =675
		Failed Shuffles=0
		Merged Map outputs=675
		GC time elapsed (ms)=144438
		CPU time spent (ms)=80452590
		Physical memory (bytes) snapshot=163465834496
		Virtual memory (bytes) snapshot=808589963264
		Total committed heap usage (bytes)=226678079488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3382720
15/04/10 19:11:28 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	338m3.604s
user	0m49.734s
sys	0m13.318s
15/04/10 19:11:30 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 10
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-10-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5844763181384381380.jar tmpDir=null
15/04/10 19:11:33 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 19:11:33 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 19:11:34 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 19:11:34 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 19:11:35 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4459
15/04/10 19:11:35 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4459
15/04/10 19:11:35 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4459/
15/04/10 19:11:35 INFO mapreduce.Job: Running job: job_1422482982071_4459
15/04/10 19:11:39 INFO mapreduce.Job: Job job_1422482982071_4459 running in uber mode : false
15/04/10 19:11:39 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 19:11:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4459_m_000045_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:11:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4459_m_000022_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:11:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4459_m_000051_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:11:51 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 19:11:56 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 19:12:03 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 19:12:10 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 19:12:17 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 19:12:24 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 19:12:30 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 19:12:36 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 19:12:44 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 19:12:51 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 19:12:57 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 19:13:04 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 19:13:10 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 19:13:18 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 19:13:24 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 19:13:30 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 19:13:37 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 19:13:44 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 19:13:51 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 19:13:57 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 19:14:04 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 19:14:10 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 19:14:19 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 19:14:25 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 19:14:31 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 19:14:38 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 19:14:45 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 19:14:52 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 19:14:58 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 19:15:05 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 19:15:11 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 19:15:17 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 19:15:25 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 19:15:31 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 19:15:37 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 19:15:43 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 19:15:49 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 19:15:55 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 19:16:02 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 19:16:08 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 19:16:14 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 19:16:20 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 19:16:26 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 19:16:32 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 19:16:38 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 19:16:44 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 19:16:50 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 19:16:56 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 19:17:02 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 19:17:08 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 19:17:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4459_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 19:17:18 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 19:17:25 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 19:17:31 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 19:17:37 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 19:17:40 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 19:17:46 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 19:17:52 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 19:17:58 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 19:18:04 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 19:18:10 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 19:18:16 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 19:18:25 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 19:18:28 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 19:18:33 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 19:18:34 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 19:18:40 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 19:18:41 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 19:18:44 INFO mapreduce.Job:  map 67% reduce 3%
15/04/10 19:18:45 INFO mapreduce.Job:  map 68% reduce 3%
15/04/10 19:18:47 INFO mapreduce.Job:  map 68% reduce 4%
15/04/10 19:18:49 INFO mapreduce.Job:  map 69% reduce 4%
15/04/10 19:18:52 INFO mapreduce.Job:  map 70% reduce 4%
15/04/10 19:18:53 INFO mapreduce.Job:  map 70% reduce 5%
15/04/10 19:18:56 INFO mapreduce.Job:  map 71% reduce 5%
15/04/10 19:18:57 INFO mapreduce.Job:  map 71% reduce 6%
15/04/10 19:18:58 INFO mapreduce.Job:  map 72% reduce 6%
15/04/10 19:18:59 INFO mapreduce.Job:  map 73% reduce 7%
15/04/10 19:19:00 INFO mapreduce.Job:  map 74% reduce 8%
15/04/10 19:19:02 INFO mapreduce.Job:  map 75% reduce 8%
15/04/10 19:19:03 INFO mapreduce.Job:  map 76% reduce 9%
15/04/10 19:19:05 INFO mapreduce.Job:  map 78% reduce 10%
15/04/10 19:19:06 INFO mapreduce.Job:  map 78% reduce 12%
15/04/10 19:19:07 INFO mapreduce.Job:  map 79% reduce 12%
15/04/10 19:19:09 INFO mapreduce.Job:  map 80% reduce 13%
15/04/10 19:19:10 INFO mapreduce.Job:  map 81% reduce 13%
15/04/10 19:19:11 INFO mapreduce.Job:  map 82% reduce 14%
15/04/10 19:19:12 INFO mapreduce.Job:  map 83% reduce 16%
15/04/10 19:19:13 INFO mapreduce.Job:  map 84% reduce 16%
15/04/10 19:19:14 INFO mapreduce.Job:  map 85% reduce 16%
15/04/10 19:19:15 INFO mapreduce.Job:  map 86% reduce 18%
15/04/10 19:19:17 INFO mapreduce.Job:  map 87% reduce 18%
15/04/10 19:19:18 INFO mapreduce.Job:  map 88% reduce 20%
15/04/10 19:19:20 INFO mapreduce.Job:  map 89% reduce 20%
15/04/10 19:19:21 INFO mapreduce.Job:  map 90% reduce 21%
15/04/10 19:19:22 INFO mapreduce.Job:  map 91% reduce 21%
15/04/10 19:19:23 INFO mapreduce.Job:  map 93% reduce 21%
15/04/10 19:19:24 INFO mapreduce.Job:  map 93% reduce 22%
15/04/10 19:19:27 INFO mapreduce.Job:  map 94% reduce 22%
15/04/10 19:19:28 INFO mapreduce.Job:  map 95% reduce 22%
15/04/10 19:19:31 INFO mapreduce.Job:  map 96% reduce 23%
15/04/10 19:19:36 INFO mapreduce.Job:  map 96% reduce 24%
15/04/10 19:19:39 INFO mapreduce.Job:  map 96% reduce 25%
15/04/10 19:19:40 INFO mapreduce.Job:  map 97% reduce 26%
15/04/10 19:19:42 INFO mapreduce.Job:  map 97% reduce 29%
15/04/10 19:19:43 INFO mapreduce.Job:  map 98% reduce 30%
15/04/10 19:19:44 INFO mapreduce.Job:  map 99% reduce 30%
15/04/10 19:19:45 INFO mapreduce.Job:  map 99% reduce 31%
15/04/10 19:19:48 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 19:19:54 INFO mapreduce.Job:  map 99% reduce 33%
15/04/10 19:23:37 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 19:24:20 INFO mapreduce.Job:  map 100% reduce 37%
15/04/10 19:24:21 INFO mapreduce.Job:  map 100% reduce 39%
15/04/10 19:24:22 INFO mapreduce.Job:  map 100% reduce 40%
15/04/10 19:24:23 INFO mapreduce.Job:  map 100% reduce 50%
15/04/10 19:24:24 INFO mapreduce.Job:  map 100% reduce 53%
15/04/10 19:24:25 INFO mapreduce.Job:  map 100% reduce 55%
15/04/10 19:24:26 INFO mapreduce.Job:  map 100% reduce 58%
15/04/10 19:24:27 INFO mapreduce.Job:  map 100% reduce 59%
15/04/10 19:24:29 INFO mapreduce.Job:  map 100% reduce 61%
15/04/10 19:24:30 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 19:24:33 INFO mapreduce.Job:  map 100% reduce 63%
15/04/10 19:24:35 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 19:24:36 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 19:24:39 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 19:24:42 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 19:28:04 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 19:30:41 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 19:33:52 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 19:38:08 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 19:38:44 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 19:41:57 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 19:43:28 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 19:46:23 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 19:47:32 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 19:50:21 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 19:53:06 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 19:54:38 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 19:56:12 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 19:57:12 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 19:59:34 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 20:01:49 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 20:03:56 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 20:05:22 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 20:07:00 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 20:08:39 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 20:09:09 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 20:13:01 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 20:15:26 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 20:17:49 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 20:21:07 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 20:26:45 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 20:31:31 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 20:35:25 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 20:35:31 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 20:37:05 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 20:45:48 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 20:51:38 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 21:08:23 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 21:17:17 INFO mapreduce.Job: Job job_1422482982071_4459 completed successfully
15/04/10 21:17:17 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16787700561
		FILE: Number of bytes written=33583493989
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Failed map tasks=4
		Killed map tasks=1
		Launched map tasks=80
		Launched reduce tasks=10
		Other local map tasks=5
		Data-local map tasks=53
		Rack-local map tasks=22
		Total time spent by all maps in occupied slots (ms)=68441010
		Total time spent by all reduces in occupied slots (ms)=88716560
		Total time spent by all map tasks (ms)=34220505
		Total time spent by all reduce tasks (ms)=44358280
		Total vcore-seconds taken by all map tasks=34220505
		Total vcore-seconds taken by all reduce tasks=44358280
		Total megabyte-seconds taken by all map tasks=277049208480
		Total megabyte-seconds taken by all reduce tasks=532299360000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787704923
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787704923
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=175025
		CPU time spent (ms)=88762360
		Physical memory (bytes) snapshot=165366108160
		Virtual memory (bytes) snapshot=822134140928
		Total committed heap usage (bytes)=228779155456
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/10 21:17:17 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	125m49.655s
user	0m33.190s
sys	0m5.215s
15/04/10 21:17:20 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 10
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-10-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3666972941775379963.jar tmpDir=null
15/04/10 21:17:23 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 21:17:23 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 21:17:23 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 21:17:24 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 21:17:24 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4460
15/04/10 21:17:25 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4460
15/04/10 21:17:25 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4460/
15/04/10 21:17:25 INFO mapreduce.Job: Running job: job_1422482982071_4460
15/04/10 21:17:30 INFO mapreduce.Job: Job job_1422482982071_4460 running in uber mode : false
15/04/10 21:17:30 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 21:17:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000039_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:17:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:17:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000019_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:17:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000022_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:17:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000047_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:17:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000051_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:17:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000049_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 21:17:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000004_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:17:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000052_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:17:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000006_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:17:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:17:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000001_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 21:17:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000030_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:17:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000014_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 21:17:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000064_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 21:17:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4460_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/10 21:17:42 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 21:17:48 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 21:17:54 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 21:18:00 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 21:18:06 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 21:18:13 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 21:18:19 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 21:18:25 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 21:18:31 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 21:18:37 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 21:18:43 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 21:18:49 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 21:18:55 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 21:19:03 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 21:19:09 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 21:19:15 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 21:19:21 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 21:19:27 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 21:19:33 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 21:19:39 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 21:19:45 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 21:19:51 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 21:19:57 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 21:20:04 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 21:20:10 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 21:20:16 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 21:20:22 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 21:20:28 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 21:20:34 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 21:20:40 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 21:20:46 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 21:20:52 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 21:20:58 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 21:21:05 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 21:21:11 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 21:21:17 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 21:21:23 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 21:21:29 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 21:21:35 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 21:21:41 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 21:21:48 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 21:21:54 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 21:22:00 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 21:22:07 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 21:22:14 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 21:22:20 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 21:22:26 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 21:22:32 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 21:22:38 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 21:22:45 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 21:22:51 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 21:22:57 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 21:23:03 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 21:23:09 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 21:23:15 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 21:23:21 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 21:23:27 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 21:23:33 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 21:23:39 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 21:23:45 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 21:23:50 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 21:23:55 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 21:24:01 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 21:24:09 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 21:24:17 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 21:24:19 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 21:24:21 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 21:24:23 INFO mapreduce.Job:  map 69% reduce 0%
15/04/10 21:24:24 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 21:24:26 INFO mapreduce.Job:  map 72% reduce 0%
15/04/10 21:24:27 INFO mapreduce.Job:  map 73% reduce 0%
15/04/10 21:24:29 INFO mapreduce.Job:  map 75% reduce 2%
15/04/10 21:24:30 INFO mapreduce.Job:  map 75% reduce 8%
15/04/10 21:24:31 INFO mapreduce.Job:  map 77% reduce 9%
15/04/10 21:24:32 INFO mapreduce.Job:  map 77% reduce 10%
15/04/10 21:24:33 INFO mapreduce.Job:  map 78% reduce 11%
15/04/10 21:24:34 INFO mapreduce.Job:  map 80% reduce 12%
15/04/10 21:24:35 INFO mapreduce.Job:  map 81% reduce 12%
15/04/10 21:24:36 INFO mapreduce.Job:  map 82% reduce 14%
15/04/10 21:24:37 INFO mapreduce.Job:  map 83% reduce 16%
15/04/10 21:24:38 INFO mapreduce.Job:  map 84% reduce 16%
15/04/10 21:24:39 INFO mapreduce.Job:  map 84% reduce 17%
15/04/10 21:24:40 INFO mapreduce.Job:  map 85% reduce 18%
15/04/10 21:24:42 INFO mapreduce.Job:  map 86% reduce 19%
15/04/10 21:24:43 INFO mapreduce.Job:  map 87% reduce 19%
15/04/10 21:24:45 INFO mapreduce.Job:  map 88% reduce 20%
15/04/10 21:24:58 INFO mapreduce.Job:  map 89% reduce 20%
15/04/10 21:25:01 INFO mapreduce.Job:  map 89% reduce 21%
15/04/10 21:25:07 INFO mapreduce.Job:  map 90% reduce 22%
15/04/10 21:25:08 INFO mapreduce.Job:  map 90% reduce 23%
15/04/10 21:25:11 INFO mapreduce.Job:  map 91% reduce 24%
15/04/10 21:25:14 INFO mapreduce.Job:  map 91% reduce 25%
15/04/10 21:25:15 INFO mapreduce.Job:  map 92% reduce 25%
15/04/10 21:25:16 INFO mapreduce.Job:  map 93% reduce 25%
15/04/10 21:25:17 INFO mapreduce.Job:  map 93% reduce 26%
15/04/10 21:25:18 INFO mapreduce.Job:  map 94% reduce 26%
15/04/10 21:25:20 INFO mapreduce.Job:  map 95% reduce 27%
15/04/10 21:25:22 INFO mapreduce.Job:  map 95% reduce 28%
15/04/10 21:25:23 INFO mapreduce.Job:  map 96% reduce 28%
15/04/10 21:25:26 INFO mapreduce.Job:  map 96% reduce 29%
15/04/10 21:25:28 INFO mapreduce.Job:  map 97% reduce 29%
15/04/10 21:25:30 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 21:25:31 INFO mapreduce.Job:  map 98% reduce 30%
15/04/10 21:25:33 INFO mapreduce.Job:  map 99% reduce 30%
15/04/10 21:25:35 INFO mapreduce.Job:  map 99% reduce 31%
15/04/10 21:25:38 INFO mapreduce.Job:  map 99% reduce 32%
15/04/10 21:25:41 INFO mapreduce.Job:  map 100% reduce 32%
15/04/10 21:25:45 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 21:25:51 INFO mapreduce.Job:  map 100% reduce 36%
15/04/10 21:25:53 INFO mapreduce.Job:  map 100% reduce 39%
15/04/10 21:25:54 INFO mapreduce.Job:  map 100% reduce 43%
15/04/10 21:25:56 INFO mapreduce.Job:  map 100% reduce 48%
15/04/10 21:25:57 INFO mapreduce.Job:  map 100% reduce 51%
15/04/10 21:25:58 INFO mapreduce.Job:  map 100% reduce 52%
15/04/10 21:25:59 INFO mapreduce.Job:  map 100% reduce 55%
15/04/10 21:26:00 INFO mapreduce.Job:  map 100% reduce 58%
15/04/10 21:26:01 INFO mapreduce.Job:  map 100% reduce 59%
15/04/10 21:26:02 INFO mapreduce.Job:  map 100% reduce 61%
15/04/10 21:26:04 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 21:26:05 INFO mapreduce.Job:  map 100% reduce 65%
15/04/10 21:26:08 INFO mapreduce.Job:  map 100% reduce 66%
15/04/10 21:26:11 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 21:29:39 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 21:32:13 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 21:35:30 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 21:39:49 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 21:39:57 INFO mapreduce.Job:  map 100% reduce 72%
15/04/10 21:43:30 INFO mapreduce.Job:  map 100% reduce 73%
15/04/10 21:45:07 INFO mapreduce.Job:  map 100% reduce 74%
15/04/10 21:47:50 INFO mapreduce.Job:  map 100% reduce 75%
15/04/10 21:50:17 INFO mapreduce.Job:  map 100% reduce 76%
15/04/10 21:53:17 INFO mapreduce.Job:  map 100% reduce 77%
15/04/10 21:55:38 INFO mapreduce.Job:  map 100% reduce 78%
15/04/10 21:57:21 INFO mapreduce.Job:  map 100% reduce 79%
15/04/10 21:59:08 INFO mapreduce.Job:  map 100% reduce 80%
15/04/10 21:59:56 INFO mapreduce.Job:  map 100% reduce 81%
15/04/10 22:02:14 INFO mapreduce.Job:  map 100% reduce 82%
15/04/10 22:04:38 INFO mapreduce.Job:  map 100% reduce 83%
15/04/10 22:05:54 INFO mapreduce.Job:  map 100% reduce 84%
15/04/10 22:08:28 INFO mapreduce.Job:  map 100% reduce 85%
15/04/10 22:10:11 INFO mapreduce.Job:  map 100% reduce 86%
15/04/10 22:11:51 INFO mapreduce.Job:  map 100% reduce 87%
15/04/10 22:12:18 INFO mapreduce.Job:  map 100% reduce 88%
15/04/10 22:16:23 INFO mapreduce.Job:  map 100% reduce 89%
15/04/10 22:20:02 INFO mapreduce.Job:  map 100% reduce 90%
15/04/10 22:21:08 INFO mapreduce.Job:  map 100% reduce 91%
15/04/10 22:24:52 INFO mapreduce.Job:  map 100% reduce 92%
15/04/10 22:30:10 INFO mapreduce.Job:  map 100% reduce 93%
15/04/10 22:33:58 INFO mapreduce.Job:  map 100% reduce 94%
15/04/10 22:35:08 INFO mapreduce.Job:  map 100% reduce 95%
15/04/10 22:36:51 INFO mapreduce.Job:  map 100% reduce 96%
15/04/10 22:41:50 INFO mapreduce.Job:  map 100% reduce 97%
15/04/10 22:47:46 INFO mapreduce.Job:  map 100% reduce 98%
15/04/10 22:52:48 INFO mapreduce.Job:  map 100% reduce 99%
15/04/10 23:07:12 INFO mapreduce.Job:  map 100% reduce 100%
15/04/10 23:15:52 INFO mapreduce.Job: Job job_1422482982071_4460 completed successfully
15/04/10 23:15:53 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=16787700561
		FILE: Number of bytes written=33583493989
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Failed map tasks=16
		Launched map tasks=91
		Launched reduce tasks=10
		Other local map tasks=16
		Data-local map tasks=51
		Rack-local map tasks=24
		Total time spent by all maps in occupied slots (ms)=65193904
		Total time spent by all reduces in occupied slots (ms)=85470688
		Total time spent by all map tasks (ms)=32596952
		Total time spent by all reduce tasks (ms)=42735344
		Total vcore-seconds taken by all map tasks=32596952
		Total vcore-seconds taken by all reduce tasks=42735344
		Total megabyte-seconds taken by all map tasks=263904923392
		Total megabyte-seconds taken by all reduce tasks=512824128000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787704923
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787704923
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=174902
		CPU time spent (ms)=88470700
		Physical memory (bytes) snapshot=165908447232
		Virtual memory (bytes) snapshot=822916149248
		Total committed heap usage (bytes)=228779380736
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/10 23:15:53 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	118m35.185s
user	0m32.600s
sys	0m5.421s
15/04/10 23:15:55 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 5
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-5-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2780195716137139035.jar tmpDir=null
15/04/10 23:15:58 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 23:15:58 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/10 23:15:59 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/10 23:15:59 INFO mapreduce.JobSubmitter: number of splits:75
15/04/10 23:16:00 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4462
15/04/10 23:16:00 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4462
15/04/10 23:16:00 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4462/
15/04/10 23:16:00 INFO mapreduce.Job: Running job: job_1422482982071_4462
15/04/10 23:16:05 INFO mapreduce.Job: Job job_1422482982071_4462 running in uber mode : false
15/04/10 23:16:05 INFO mapreduce.Job:  map 0% reduce 0%
15/04/10 23:16:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000010_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000009_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000039_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000012_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000047_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000025_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000064_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000063_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000066_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000051_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000011_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000060_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000023_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000041_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000070_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000070_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000063_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4462_m_000060_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/10 23:16:17 INFO mapreduce.Job:  map 1% reduce 0%
15/04/10 23:16:24 INFO mapreduce.Job:  map 2% reduce 0%
15/04/10 23:16:30 INFO mapreduce.Job:  map 3% reduce 0%
15/04/10 23:16:36 INFO mapreduce.Job:  map 4% reduce 0%
15/04/10 23:16:42 INFO mapreduce.Job:  map 5% reduce 0%
15/04/10 23:16:48 INFO mapreduce.Job:  map 6% reduce 0%
15/04/10 23:16:54 INFO mapreduce.Job:  map 7% reduce 0%
15/04/10 23:17:00 INFO mapreduce.Job:  map 8% reduce 0%
15/04/10 23:17:07 INFO mapreduce.Job:  map 9% reduce 0%
15/04/10 23:17:13 INFO mapreduce.Job:  map 10% reduce 0%
15/04/10 23:17:19 INFO mapreduce.Job:  map 11% reduce 0%
15/04/10 23:17:25 INFO mapreduce.Job:  map 12% reduce 0%
15/04/10 23:17:31 INFO mapreduce.Job:  map 13% reduce 0%
15/04/10 23:17:37 INFO mapreduce.Job:  map 14% reduce 0%
15/04/10 23:17:43 INFO mapreduce.Job:  map 15% reduce 0%
15/04/10 23:17:50 INFO mapreduce.Job:  map 16% reduce 0%
15/04/10 23:17:56 INFO mapreduce.Job:  map 17% reduce 0%
15/04/10 23:18:02 INFO mapreduce.Job:  map 18% reduce 0%
15/04/10 23:18:08 INFO mapreduce.Job:  map 19% reduce 0%
15/04/10 23:18:14 INFO mapreduce.Job:  map 20% reduce 0%
15/04/10 23:18:21 INFO mapreduce.Job:  map 21% reduce 0%
15/04/10 23:18:27 INFO mapreduce.Job:  map 22% reduce 0%
15/04/10 23:18:33 INFO mapreduce.Job:  map 23% reduce 0%
15/04/10 23:18:39 INFO mapreduce.Job:  map 24% reduce 0%
15/04/10 23:18:45 INFO mapreduce.Job:  map 25% reduce 0%
15/04/10 23:18:51 INFO mapreduce.Job:  map 26% reduce 0%
15/04/10 23:18:57 INFO mapreduce.Job:  map 27% reduce 0%
15/04/10 23:19:03 INFO mapreduce.Job:  map 28% reduce 0%
15/04/10 23:19:09 INFO mapreduce.Job:  map 29% reduce 0%
15/04/10 23:19:15 INFO mapreduce.Job:  map 30% reduce 0%
15/04/10 23:19:22 INFO mapreduce.Job:  map 31% reduce 0%
15/04/10 23:19:29 INFO mapreduce.Job:  map 32% reduce 0%
15/04/10 23:19:35 INFO mapreduce.Job:  map 33% reduce 0%
15/04/10 23:19:41 INFO mapreduce.Job:  map 34% reduce 0%
15/04/10 23:19:47 INFO mapreduce.Job:  map 35% reduce 0%
15/04/10 23:19:54 INFO mapreduce.Job:  map 36% reduce 0%
15/04/10 23:20:00 INFO mapreduce.Job:  map 37% reduce 0%
15/04/10 23:20:06 INFO mapreduce.Job:  map 38% reduce 0%
15/04/10 23:20:12 INFO mapreduce.Job:  map 39% reduce 0%
15/04/10 23:20:18 INFO mapreduce.Job:  map 40% reduce 0%
15/04/10 23:20:25 INFO mapreduce.Job:  map 41% reduce 0%
15/04/10 23:20:31 INFO mapreduce.Job:  map 42% reduce 0%
15/04/10 23:20:37 INFO mapreduce.Job:  map 43% reduce 0%
15/04/10 23:20:43 INFO mapreduce.Job:  map 44% reduce 0%
15/04/10 23:20:49 INFO mapreduce.Job:  map 45% reduce 0%
15/04/10 23:20:55 INFO mapreduce.Job:  map 46% reduce 0%
15/04/10 23:21:01 INFO mapreduce.Job:  map 47% reduce 0%
15/04/10 23:21:07 INFO mapreduce.Job:  map 48% reduce 0%
15/04/10 23:21:13 INFO mapreduce.Job:  map 49% reduce 0%
15/04/10 23:21:19 INFO mapreduce.Job:  map 50% reduce 0%
15/04/10 23:21:25 INFO mapreduce.Job:  map 51% reduce 0%
15/04/10 23:21:32 INFO mapreduce.Job:  map 52% reduce 0%
15/04/10 23:21:38 INFO mapreduce.Job:  map 53% reduce 0%
15/04/10 23:21:44 INFO mapreduce.Job:  map 54% reduce 0%
15/04/10 23:21:50 INFO mapreduce.Job:  map 55% reduce 0%
15/04/10 23:21:56 INFO mapreduce.Job:  map 56% reduce 0%
15/04/10 23:22:02 INFO mapreduce.Job:  map 57% reduce 0%
15/04/10 23:22:09 INFO mapreduce.Job:  map 58% reduce 0%
15/04/10 23:22:15 INFO mapreduce.Job:  map 59% reduce 0%
15/04/10 23:22:21 INFO mapreduce.Job:  map 60% reduce 0%
15/04/10 23:22:27 INFO mapreduce.Job:  map 61% reduce 0%
15/04/10 23:22:35 INFO mapreduce.Job:  map 62% reduce 0%
15/04/10 23:22:41 INFO mapreduce.Job:  map 63% reduce 0%
15/04/10 23:22:45 INFO mapreduce.Job:  map 64% reduce 0%
15/04/10 23:22:51 INFO mapreduce.Job:  map 65% reduce 0%
15/04/10 23:22:52 INFO mapreduce.Job:  map 66% reduce 0%
15/04/10 23:22:57 INFO mapreduce.Job:  map 67% reduce 0%
15/04/10 23:22:58 INFO mapreduce.Job:  map 68% reduce 0%
15/04/10 23:22:59 INFO mapreduce.Job:  map 69% reduce 0%
15/04/10 23:23:00 INFO mapreduce.Job:  map 70% reduce 0%
15/04/10 23:23:01 INFO mapreduce.Job:  map 71% reduce 0%
15/04/10 23:23:02 INFO mapreduce.Job:  map 72% reduce 0%
15/04/10 23:23:03 INFO mapreduce.Job:  map 74% reduce 3%
15/04/10 23:23:04 INFO mapreduce.Job:  map 74% reduce 6%
15/04/10 23:23:05 INFO mapreduce.Job:  map 74% reduce 8%
15/04/10 23:23:06 INFO mapreduce.Job:  map 75% reduce 8%
15/04/10 23:23:07 INFO mapreduce.Job:  map 77% reduce 10%
15/04/10 23:23:08 INFO mapreduce.Job:  map 78% reduce 10%
15/04/10 23:23:09 INFO mapreduce.Job:  map 80% reduce 10%
15/04/10 23:23:10 INFO mapreduce.Job:  map 82% reduce 12%
15/04/10 23:23:13 INFO mapreduce.Job:  map 84% reduce 12%
15/04/10 23:23:14 INFO mapreduce.Job:  map 85% reduce 12%
15/04/10 23:23:16 INFO mapreduce.Job:  map 86% reduce 12%
15/04/10 23:23:18 INFO mapreduce.Job:  map 87% reduce 12%
15/04/10 23:23:21 INFO mapreduce.Job:  map 88% reduce 12%
15/04/10 23:23:31 INFO mapreduce.Job:  map 88% reduce 16%
15/04/10 23:23:32 INFO mapreduce.Job:  map 88% reduce 18%
15/04/10 23:23:33 INFO mapreduce.Job:  map 89% reduce 18%
15/04/10 23:23:34 INFO mapreduce.Job:  map 89% reduce 19%
15/04/10 23:23:40 INFO mapreduce.Job:  map 89% reduce 22%
15/04/10 23:23:46 INFO mapreduce.Job:  map 90% reduce 22%
15/04/10 23:23:48 INFO mapreduce.Job:  map 91% reduce 22%
15/04/10 23:23:49 INFO mapreduce.Job:  map 92% reduce 22%
15/04/10 23:23:55 INFO mapreduce.Job:  map 93% reduce 22%
15/04/10 23:23:56 INFO mapreduce.Job:  map 93% reduce 23%
15/04/10 23:23:58 INFO mapreduce.Job:  map 94% reduce 24%
15/04/10 23:23:59 INFO mapreduce.Job:  map 94% reduce 25%
15/04/10 23:24:01 INFO mapreduce.Job:  map 94% reduce 26%
15/04/10 23:24:03 INFO mapreduce.Job:  map 95% reduce 26%
15/04/10 23:24:08 INFO mapreduce.Job:  map 95% reduce 27%
15/04/10 23:24:11 INFO mapreduce.Job:  map 95% reduce 28%
15/04/10 23:24:15 INFO mapreduce.Job:  map 96% reduce 28%
15/04/10 23:24:16 INFO mapreduce.Job:  map 96% reduce 29%
15/04/10 23:24:20 INFO mapreduce.Job:  map 96% reduce 30%
15/04/10 23:24:21 INFO mapreduce.Job:  map 97% reduce 30%
15/04/10 23:24:25 INFO mapreduce.Job:  map 98% reduce 30%
15/04/10 23:24:26 INFO mapreduce.Job:  map 99% reduce 30%
15/04/10 23:24:29 INFO mapreduce.Job:  map 99% reduce 31%
15/04/10 23:24:30 INFO mapreduce.Job:  map 100% reduce 31%
15/04/10 23:24:32 INFO mapreduce.Job:  map 100% reduce 32%
15/04/10 23:24:33 INFO mapreduce.Job:  map 100% reduce 33%
15/04/10 23:24:35 INFO mapreduce.Job:  map 100% reduce 35%
15/04/10 23:24:36 INFO mapreduce.Job:  map 100% reduce 36%
15/04/10 23:24:38 INFO mapreduce.Job:  map 100% reduce 38%
15/04/10 23:24:39 INFO mapreduce.Job:  map 100% reduce 39%
15/04/10 23:24:41 INFO mapreduce.Job:  map 100% reduce 42%
15/04/10 23:24:42 INFO mapreduce.Job:  map 100% reduce 43%
15/04/10 23:24:44 INFO mapreduce.Job:  map 100% reduce 47%
15/04/10 23:24:45 INFO mapreduce.Job:  map 100% reduce 48%
15/04/10 23:24:47 INFO mapreduce.Job:  map 100% reduce 52%
15/04/10 23:24:48 INFO mapreduce.Job:  map 100% reduce 53%
15/04/10 23:24:50 INFO mapreduce.Job:  map 100% reduce 56%
15/04/10 23:24:51 INFO mapreduce.Job:  map 100% reduce 57%
15/04/10 23:24:53 INFO mapreduce.Job:  map 100% reduce 59%
15/04/10 23:24:56 INFO mapreduce.Job:  map 100% reduce 62%
15/04/10 23:24:59 INFO mapreduce.Job:  map 100% reduce 64%
15/04/10 23:25:02 INFO mapreduce.Job:  map 100% reduce 67%
15/04/10 23:32:23 INFO mapreduce.Job:  map 100% reduce 68%
15/04/10 23:39:11 INFO mapreduce.Job:  map 100% reduce 69%
15/04/10 23:40:18 INFO mapreduce.Job:  map 100% reduce 70%
15/04/10 23:47:00 INFO mapreduce.Job:  map 100% reduce 71%
15/04/10 23:52:35 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 00:03:16 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 00:08:28 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 00:14:26 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 00:19:12 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 00:24:56 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 00:31:26 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 00:33:03 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 00:36:35 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 00:43:31 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 00:45:29 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 00:49:39 INFO mapreduce.Job:  map 100% reduce 83%
15/04/11 00:50:22 INFO mapreduce.Job:  map 100% reduce 85%
15/04/11 00:53:08 INFO mapreduce.Job:  map 100% reduce 86%
15/04/11 00:57:23 INFO mapreduce.Job:  map 100% reduce 87%
15/04/11 01:00:01 INFO mapreduce.Job:  map 100% reduce 88%
15/04/11 01:04:57 INFO mapreduce.Job:  map 100% reduce 89%
15/04/11 01:09:38 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 01:15:00 INFO mapreduce.Job:  map 100% reduce 91%
15/04/11 01:19:59 INFO mapreduce.Job:  map 100% reduce 92%
15/04/11 01:27:12 INFO mapreduce.Job:  map 100% reduce 93%
15/04/11 01:30:17 INFO mapreduce.Job:  map 100% reduce 94%
15/04/11 01:30:48 INFO mapreduce.Job:  map 100% reduce 95%
15/04/11 01:34:54 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 01:39:03 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 01:44:50 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 01:50:54 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 01:58:24 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 02:06:22 INFO mapreduce.Job: Job job_1422482982071_4462 completed successfully
15/04/11 02:06:22 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=16787700537
		FILE: Number of bytes written=33583007960
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Failed map tasks=18
		Launched map tasks=93
		Launched reduce tasks=5
		Other local map tasks=18
		Data-local map tasks=53
		Rack-local map tasks=22
		Total time spent by all maps in occupied slots (ms)=65594448
		Total time spent by all reduces in occupied slots (ms)=84694762
		Total time spent by all map tasks (ms)=32797224
		Total time spent by all reduce tasks (ms)=42347381
		Total vcore-seconds taken by all map tasks=32797224
		Total vcore-seconds taken by all reduce tasks=42347381
		Total megabyte-seconds taken by all map tasks=265526325504
		Total megabyte-seconds taken by all reduce tasks=508168572000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787702673
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787702673
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =375
		Failed Shuffles=0
		Merged Map outputs=375
		GC time elapsed (ms)=186321
		CPU time spent (ms)=88817800
		Physical memory (bytes) snapshot=158061965312
		Virtual memory (bytes) snapshot=755306139648
		Total committed heap usage (bytes)=218253893632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/11 02:06:22 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	170m29.692s
user	0m37.851s
sys	0m6.850s
15/04/11 02:06:25 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 5
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-5-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1242852837201277538.jar tmpDir=null
15/04/11 02:06:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 02:06:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 02:06:29 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/11 02:06:30 INFO mapreduce.JobSubmitter: number of splits:75
15/04/11 02:06:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4464
15/04/11 02:06:31 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4464
15/04/11 02:06:31 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4464/
15/04/11 02:06:31 INFO mapreduce.Job: Running job: job_1422482982071_4464
15/04/11 02:06:36 INFO mapreduce.Job: Job job_1422482982071_4464 running in uber mode : false
15/04/11 02:06:36 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 02:06:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000005_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000004_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000009_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000048_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000035_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000068_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:42 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 02:06:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/11 02:06:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000073_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000057_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000051_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000010_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000058_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000042_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000071_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000003_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:43 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 02:06:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000003_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000013_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000058_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000073_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000035_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000034_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000048_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4464_m_000043_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 02:06:48 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 02:06:54 INFO mapreduce.Job:  map 2% reduce 0%
15/04/11 02:07:00 INFO mapreduce.Job:  map 3% reduce 0%
15/04/11 02:07:06 INFO mapreduce.Job:  map 4% reduce 0%
15/04/11 02:07:12 INFO mapreduce.Job:  map 5% reduce 0%
15/04/11 02:07:19 INFO mapreduce.Job:  map 6% reduce 0%
15/04/11 02:07:25 INFO mapreduce.Job:  map 7% reduce 0%
15/04/11 02:07:31 INFO mapreduce.Job:  map 8% reduce 0%
15/04/11 02:07:37 INFO mapreduce.Job:  map 9% reduce 0%
15/04/11 02:07:43 INFO mapreduce.Job:  map 10% reduce 0%
15/04/11 02:07:49 INFO mapreduce.Job:  map 11% reduce 0%
15/04/11 02:07:55 INFO mapreduce.Job:  map 12% reduce 0%
15/04/11 02:08:02 INFO mapreduce.Job:  map 13% reduce 0%
15/04/11 02:08:08 INFO mapreduce.Job:  map 14% reduce 0%
15/04/11 02:08:14 INFO mapreduce.Job:  map 15% reduce 0%
15/04/11 02:08:20 INFO mapreduce.Job:  map 16% reduce 0%
15/04/11 02:08:26 INFO mapreduce.Job:  map 17% reduce 0%
15/04/11 02:08:32 INFO mapreduce.Job:  map 18% reduce 0%
15/04/11 02:08:39 INFO mapreduce.Job:  map 19% reduce 0%
15/04/11 02:08:44 INFO mapreduce.Job:  map 20% reduce 0%
15/04/11 02:08:51 INFO mapreduce.Job:  map 21% reduce 0%
15/04/11 02:08:56 INFO mapreduce.Job:  map 22% reduce 0%
15/04/11 02:09:03 INFO mapreduce.Job:  map 23% reduce 0%
15/04/11 02:09:09 INFO mapreduce.Job:  map 24% reduce 0%
15/04/11 02:09:15 INFO mapreduce.Job:  map 25% reduce 0%
15/04/11 02:09:21 INFO mapreduce.Job:  map 26% reduce 0%
15/04/11 02:09:27 INFO mapreduce.Job:  map 27% reduce 0%
15/04/11 02:09:33 INFO mapreduce.Job:  map 28% reduce 0%
15/04/11 02:09:39 INFO mapreduce.Job:  map 29% reduce 0%
15/04/11 02:09:45 INFO mapreduce.Job:  map 30% reduce 0%
15/04/11 02:09:51 INFO mapreduce.Job:  map 31% reduce 0%
15/04/11 02:09:57 INFO mapreduce.Job:  map 32% reduce 0%
15/04/11 02:10:03 INFO mapreduce.Job:  map 33% reduce 0%
15/04/11 02:10:09 INFO mapreduce.Job:  map 34% reduce 0%
15/04/11 02:10:15 INFO mapreduce.Job:  map 35% reduce 0%
15/04/11 02:10:21 INFO mapreduce.Job:  map 36% reduce 0%
15/04/11 02:10:27 INFO mapreduce.Job:  map 37% reduce 0%
15/04/11 02:10:33 INFO mapreduce.Job:  map 38% reduce 0%
15/04/11 02:10:39 INFO mapreduce.Job:  map 39% reduce 0%
15/04/11 02:10:46 INFO mapreduce.Job:  map 40% reduce 0%
15/04/11 02:10:52 INFO mapreduce.Job:  map 41% reduce 0%
15/04/11 02:10:58 INFO mapreduce.Job:  map 42% reduce 0%
15/04/11 02:11:04 INFO mapreduce.Job:  map 43% reduce 0%
15/04/11 02:11:11 INFO mapreduce.Job:  map 44% reduce 0%
15/04/11 02:11:17 INFO mapreduce.Job:  map 45% reduce 0%
15/04/11 02:11:23 INFO mapreduce.Job:  map 46% reduce 0%
15/04/11 02:11:29 INFO mapreduce.Job:  map 47% reduce 0%
15/04/11 02:11:35 INFO mapreduce.Job:  map 48% reduce 0%
15/04/11 02:11:41 INFO mapreduce.Job:  map 49% reduce 0%
15/04/11 02:11:47 INFO mapreduce.Job:  map 50% reduce 0%
15/04/11 02:11:53 INFO mapreduce.Job:  map 51% reduce 0%
15/04/11 02:11:59 INFO mapreduce.Job:  map 52% reduce 0%
15/04/11 02:12:05 INFO mapreduce.Job:  map 53% reduce 0%
15/04/11 02:12:11 INFO mapreduce.Job:  map 54% reduce 0%
15/04/11 02:12:17 INFO mapreduce.Job:  map 55% reduce 0%
15/04/11 02:12:23 INFO mapreduce.Job:  map 56% reduce 0%
15/04/11 02:12:27 INFO mapreduce.Job:  map 57% reduce 0%
15/04/11 02:12:33 INFO mapreduce.Job:  map 58% reduce 0%
15/04/11 02:12:39 INFO mapreduce.Job:  map 59% reduce 0%
15/04/11 02:12:45 INFO mapreduce.Job:  map 60% reduce 0%
15/04/11 02:12:52 INFO mapreduce.Job:  map 61% reduce 0%
15/04/11 02:12:58 INFO mapreduce.Job:  map 62% reduce 0%
15/04/11 02:13:04 INFO mapreduce.Job:  map 63% reduce 0%
15/04/11 02:13:11 INFO mapreduce.Job:  map 64% reduce 0%
15/04/11 02:13:15 INFO mapreduce.Job:  map 65% reduce 0%
15/04/11 02:13:21 INFO mapreduce.Job:  map 66% reduce 0%
15/04/11 02:13:22 INFO mapreduce.Job:  map 67% reduce 0%
15/04/11 02:13:24 INFO mapreduce.Job:  map 68% reduce 0%
15/04/11 02:13:28 INFO mapreduce.Job:  map 69% reduce 0%
15/04/11 02:13:30 INFO mapreduce.Job:  map 71% reduce 0%
15/04/11 02:13:32 INFO mapreduce.Job:  map 73% reduce 3%
15/04/11 02:13:33 INFO mapreduce.Job:  map 74% reduce 5%
15/04/11 02:13:34 INFO mapreduce.Job:  map 74% reduce 6%
15/04/11 02:13:35 INFO mapreduce.Job:  map 76% reduce 8%
15/04/11 02:13:36 INFO mapreduce.Job:  map 78% reduce 10%
15/04/11 02:13:37 INFO mapreduce.Job:  map 80% reduce 10%
15/04/11 02:13:38 INFO mapreduce.Job:  map 80% reduce 11%
15/04/11 02:13:39 INFO mapreduce.Job:  map 82% reduce 12%
15/04/11 02:13:41 INFO mapreduce.Job:  map 83% reduce 12%
15/04/11 02:13:42 INFO mapreduce.Job:  map 84% reduce 12%
15/04/11 02:13:44 INFO mapreduce.Job:  map 85% reduce 12%
15/04/11 02:13:45 INFO mapreduce.Job:  map 87% reduce 12%
15/04/11 02:13:47 INFO mapreduce.Job:  map 88% reduce 12%
15/04/11 02:13:48 INFO mapreduce.Job:  map 89% reduce 12%
15/04/11 02:13:49 INFO mapreduce.Job:  map 90% reduce 12%
15/04/11 02:13:53 INFO mapreduce.Job:  map 91% reduce 12%
15/04/11 02:14:00 INFO mapreduce.Job:  map 91% reduce 14%
15/04/11 02:14:01 INFO mapreduce.Job:  map 91% reduce 15%
15/04/11 02:14:03 INFO mapreduce.Job:  map 91% reduce 17%
15/04/11 02:14:04 INFO mapreduce.Job:  map 91% reduce 20%
15/04/11 02:14:06 INFO mapreduce.Job:  map 92% reduce 22%
15/04/11 02:14:16 INFO mapreduce.Job:  map 93% reduce 22%
15/04/11 02:14:25 INFO mapreduce.Job:  map 93% reduce 23%
15/04/11 02:14:28 INFO mapreduce.Job:  map 93% reduce 24%
15/04/11 02:14:29 INFO mapreduce.Job:  map 93% reduce 25%
15/04/11 02:14:30 INFO mapreduce.Job:  map 94% reduce 26%
15/04/11 02:14:32 INFO mapreduce.Job:  map 95% reduce 26%
15/04/11 02:14:34 INFO mapreduce.Job:  map 95% reduce 27%
15/04/11 02:14:36 INFO mapreduce.Job:  map 96% reduce 27%
15/04/11 02:14:37 INFO mapreduce.Job:  map 96% reduce 29%
15/04/11 02:14:42 INFO mapreduce.Job:  map 97% reduce 29%
15/04/11 02:14:43 INFO mapreduce.Job:  map 97% reduce 30%
15/04/11 02:14:44 INFO mapreduce.Job:  map 98% reduce 30%
15/04/11 02:14:46 INFO mapreduce.Job:  map 98% reduce 31%
15/04/11 02:14:51 INFO mapreduce.Job:  map 99% reduce 31%
15/04/11 02:15:00 INFO mapreduce.Job:  map 99% reduce 32%
15/04/11 02:15:01 INFO mapreduce.Job:  map 100% reduce 32%
15/04/11 02:15:03 INFO mapreduce.Job:  map 100% reduce 33%
15/04/11 02:15:04 INFO mapreduce.Job:  map 100% reduce 34%
15/04/11 02:15:06 INFO mapreduce.Job:  map 100% reduce 37%
15/04/11 02:15:07 INFO mapreduce.Job:  map 100% reduce 38%
15/04/11 02:15:08 INFO mapreduce.Job:  map 100% reduce 39%
15/04/11 02:15:09 INFO mapreduce.Job:  map 100% reduce 43%
15/04/11 02:15:10 INFO mapreduce.Job:  map 100% reduce 44%
15/04/11 02:15:11 INFO mapreduce.Job:  map 100% reduce 45%
15/04/11 02:15:12 INFO mapreduce.Job:  map 100% reduce 49%
15/04/11 02:15:13 INFO mapreduce.Job:  map 100% reduce 51%
15/04/11 02:15:14 INFO mapreduce.Job:  map 100% reduce 53%
15/04/11 02:15:15 INFO mapreduce.Job:  map 100% reduce 55%
15/04/11 02:15:16 INFO mapreduce.Job:  map 100% reduce 57%
15/04/11 02:15:17 INFO mapreduce.Job:  map 100% reduce 58%
15/04/11 02:15:18 INFO mapreduce.Job:  map 100% reduce 59%
15/04/11 02:15:19 INFO mapreduce.Job:  map 100% reduce 60%
15/04/11 02:15:20 INFO mapreduce.Job:  map 100% reduce 64%
15/04/11 02:15:21 INFO mapreduce.Job:  map 100% reduce 65%
15/04/11 02:15:23 INFO mapreduce.Job:  map 100% reduce 66%
15/04/11 02:15:24 INFO mapreduce.Job:  map 100% reduce 67%
15/04/11 02:22:34 INFO mapreduce.Job:  map 100% reduce 68%
15/04/11 02:29:27 INFO mapreduce.Job:  map 100% reduce 69%
15/04/11 02:30:37 INFO mapreduce.Job:  map 100% reduce 70%
15/04/11 02:37:16 INFO mapreduce.Job:  map 100% reduce 71%
15/04/11 02:42:51 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 02:54:08 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 02:59:06 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 03:02:46 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 03:08:15 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 03:14:06 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 03:21:51 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 03:22:14 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 03:25:54 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 03:32:01 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 03:35:27 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 03:39:01 INFO mapreduce.Job:  map 100% reduce 83%
15/04/11 03:39:59 INFO mapreduce.Job:  map 100% reduce 85%
15/04/11 03:42:42 INFO mapreduce.Job:  map 100% reduce 86%
15/04/11 03:47:13 INFO mapreduce.Job:  map 100% reduce 87%
15/04/11 03:49:57 INFO mapreduce.Job:  map 100% reduce 88%
15/04/11 03:54:14 INFO mapreduce.Job:  map 100% reduce 89%
15/04/11 03:59:03 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 04:01:07 INFO mapreduce.Job:  map 100% reduce 91%
15/04/11 04:10:16 INFO mapreduce.Job:  map 100% reduce 92%
15/04/11 04:15:32 INFO mapreduce.Job:  map 100% reduce 93%
15/04/11 04:16:27 INFO mapreduce.Job:  map 100% reduce 94%
15/04/11 04:20:27 INFO mapreduce.Job:  map 100% reduce 95%
15/04/11 04:23:15 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 04:27:31 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 04:31:40 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 04:38:10 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 04:47:45 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 04:55:43 INFO mapreduce.Job: Job job_1422482982071_4464 completed successfully
15/04/11 04:55:43 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=16787700537
		FILE: Number of bytes written=33583007960
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Failed map tasks=28
		Launched map tasks=103
		Launched reduce tasks=5
		Other local map tasks=28
		Data-local map tasks=52
		Rack-local map tasks=23
		Total time spent by all maps in occupied slots (ms)=64776286
		Total time spent by all reduces in occupied slots (ms)=83512500
		Total time spent by all map tasks (ms)=32388143
		Total time spent by all reduce tasks (ms)=41756250
		Total vcore-seconds taken by all map tasks=32388143
		Total vcore-seconds taken by all reduce tasks=41756250
		Total megabyte-seconds taken by all map tasks=262214405728
		Total megabyte-seconds taken by all reduce tasks=501075000000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686864808
		Map output bytes=13413970807
		Map output materialized bytes=16787702673
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787702673
		Reduce input records=1686864808
		Reduce output records=258960
		Spilled Records=3373729616
		Shuffled Maps =375
		Failed Shuffles=0
		Merged Map outputs=375
		GC time elapsed (ms)=175041
		CPU time spent (ms)=87611970
		Physical memory (bytes) snapshot=158053605376
		Virtual memory (bytes) snapshot=756092600320
		Total committed heap usage (bytes)=218329624576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/11 04:55:43 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	169m20.999s
user	0m38.029s
sys	0m6.777s
15/04/11 04:55:46 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
50 5
r googlebooks-eng-all-5gram-20120701-un mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-5-googlebooks-eng-all-5gram-20120701-un -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-un -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7025746617481311713.jar tmpDir=null
15/04/11 04:55:49 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 04:55:49 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 04:55:50 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/11 04:55:50 INFO mapreduce.JobSubmitter: number of splits:75
15/04/11 04:55:51 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4466
15/04/11 04:55:51 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4466
15/04/11 04:55:51 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4466/
15/04/11 04:55:51 INFO mapreduce.Job: Running job: job_1422482982071_4466
15/04/11 04:55:56 INFO mapreduce.Job: Job job_1422482982071_4466 running in uber mode : false
15/04/11 04:55:56 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 04:56:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000007_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000006_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000021_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000003_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000066_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000044_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000025_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000013_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000060_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000020_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000042_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000022_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000070_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000045_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000000_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000009_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000041_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000015_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000065_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000009_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4466_m_000036_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 04:56:09 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 04:56:15 INFO mapreduce.Job:  map 2% reduce 0%
15/04/11 04:56:21 INFO mapreduce.Job:  map 3% reduce 0%
15/04/11 04:56:27 INFO mapreduce.Job:  map 4% reduce 0%
15/04/11 04:56:34 INFO mapreduce.Job:  map 5% reduce 0%
15/04/11 04:56:40 INFO mapreduce.Job:  map 6% reduce 0%
15/04/11 04:56:46 INFO mapreduce.Job:  map 7% reduce 0%
15/04/11 04:56:52 INFO mapreduce.Job:  map 8% reduce 0%
15/04/11 04:56:58 INFO mapreduce.Job:  map 9% reduce 0%
15/04/11 04:57:04 INFO mapreduce.Job:  map 10% reduce 0%
15/04/11 04:57:11 INFO mapreduce.Job:  map 11% reduce 0%
15/04/11 04:57:17 INFO mapreduce.Job:  map 12% reduce 0%
15/04/11 04:57:23 INFO mapreduce.Job:  map 13% reduce 0%
15/04/11 04:57:29 INFO mapreduce.Job:  map 14% reduce 0%
15/04/11 04:57:36 INFO mapreduce.Job:  map 15% reduce 0%
15/04/11 04:57:42 INFO mapreduce.Job:  map 16% reduce 0%
15/04/11 04:57:48 INFO mapreduce.Job:  map 17% reduce 0%
15/04/11 04:57:54 INFO mapreduce.Job:  map 18% reduce 0%
15/04/11 04:58:00 INFO mapreduce.Job:  map 19% reduce 0%
15/04/11 04:58:06 INFO mapreduce.Job:  map 20% reduce 0%
15/04/11 04:58:12 INFO mapreduce.Job:  map 21% reduce 0%
15/04/11 04:58:18 INFO mapreduce.Job:  map 22% reduce 0%
15/04/11 04:58:24 INFO mapreduce.Job:  map 23% reduce 0%
15/04/11 04:58:31 INFO mapreduce.Job:  map 24% reduce 0%
15/04/11 04:58:38 INFO mapreduce.Job:  map 25% reduce 0%
15/04/11 04:58:44 INFO mapreduce.Job:  map 26% reduce 0%
15/04/11 04:58:50 INFO mapreduce.Job:  map 27% reduce 0%
15/04/11 04:58:56 INFO mapreduce.Job:  map 28% reduce 0%
15/04/11 04:59:02 INFO mapreduce.Job:  map 29% reduce 0%
15/04/11 04:59:09 INFO mapreduce.Job:  map 30% reduce 0%
15/04/11 04:59:15 INFO mapreduce.Job:  map 31% reduce 0%
15/04/11 04:59:21 INFO mapreduce.Job:  map 32% reduce 0%
15/04/11 04:59:27 INFO mapreduce.Job:  map 33% reduce 0%
15/04/11 04:59:33 INFO mapreduce.Job:  map 34% reduce 0%
15/04/11 04:59:40 INFO mapreduce.Job:  map 35% reduce 0%
15/04/11 04:59:46 INFO mapreduce.Job:  map 36% reduce 0%
15/04/11 04:59:52 INFO mapreduce.Job:  map 37% reduce 0%
15/04/11 04:59:58 INFO mapreduce.Job:  map 38% reduce 0%
15/04/11 05:00:04 INFO mapreduce.Job:  map 39% reduce 0%
15/04/11 05:00:10 INFO mapreduce.Job:  map 40% reduce 0%
15/04/11 05:00:16 INFO mapreduce.Job:  map 41% reduce 0%
15/04/11 05:00:22 INFO mapreduce.Job:  map 42% reduce 0%
15/04/11 05:00:28 INFO mapreduce.Job:  map 43% reduce 0%
15/04/11 05:00:34 INFO mapreduce.Job:  map 44% reduce 0%
15/04/11 05:00:40 INFO mapreduce.Job:  map 45% reduce 0%
15/04/11 05:00:47 INFO mapreduce.Job:  map 46% reduce 0%
15/04/11 05:00:53 INFO mapreduce.Job:  map 47% reduce 0%
15/04/11 05:00:59 INFO mapreduce.Job:  map 48% reduce 0%
15/04/11 05:01:05 INFO mapreduce.Job:  map 49% reduce 0%
15/04/11 05:01:11 INFO mapreduce.Job:  map 50% reduce 0%
15/04/11 05:01:18 INFO mapreduce.Job:  map 51% reduce 0%
15/04/11 05:01:24 INFO mapreduce.Job:  map 52% reduce 0%
15/04/11 05:01:30 INFO mapreduce.Job:  map 53% reduce 0%
15/04/11 05:01:36 INFO mapreduce.Job:  map 54% reduce 0%
15/04/11 05:01:42 INFO mapreduce.Job:  map 55% reduce 0%
15/04/11 05:01:46 INFO mapreduce.Job:  map 56% reduce 0%
15/04/11 05:01:53 INFO mapreduce.Job:  map 57% reduce 0%
15/04/11 05:02:00 INFO mapreduce.Job:  map 58% reduce 0%
15/04/11 05:02:06 INFO mapreduce.Job:  map 59% reduce 0%
15/04/11 05:02:12 INFO mapreduce.Job:  map 60% reduce 0%
15/04/11 05:02:18 INFO mapreduce.Job:  map 61% reduce 0%
15/04/11 05:02:25 INFO mapreduce.Job:  map 62% reduce 0%
15/04/11 05:02:31 INFO mapreduce.Job:  map 63% reduce 0%
15/04/11 05:02:38 INFO mapreduce.Job:  map 64% reduce 0%
15/04/11 05:02:44 INFO mapreduce.Job:  map 65% reduce 0%
15/04/11 05:02:46 INFO mapreduce.Job:  map 66% reduce 0%
15/04/11 05:02:47 INFO mapreduce.Job:  map 67% reduce 0%
15/04/11 05:02:49 INFO mapreduce.Job:  map 69% reduce 0%
15/04/11 05:02:50 INFO mapreduce.Job:  map 70% reduce 0%
15/04/11 05:02:51 INFO mapreduce.Job:  map 71% reduce 0%
15/04/11 05:02:53 INFO mapreduce.Job:  map 72% reduce 0%
15/04/11 05:02:54 INFO mapreduce.Job:  map 73% reduce 0%
15/04/11 05:02:55 INFO mapreduce.Job:  map 73% reduce 5%
15/04/11 05:02:56 INFO mapreduce.Job:  map 74% reduce 7%
15/04/11 05:02:57 INFO mapreduce.Job:  map 74% reduce 9%
15/04/11 05:02:58 INFO mapreduce.Job:  map 76% reduce 9%
15/04/11 05:02:59 INFO mapreduce.Job:  map 77% reduce 10%
15/04/11 05:03:00 INFO mapreduce.Job:  map 78% reduce 10%
15/04/11 05:03:01 INFO mapreduce.Job:  map 78% reduce 12%
15/04/11 05:03:02 INFO mapreduce.Job:  map 79% reduce 12%
15/04/11 05:03:03 INFO mapreduce.Job:  map 80% reduce 12%
15/04/11 05:03:05 INFO mapreduce.Job:  map 81% reduce 12%
15/04/11 05:03:07 INFO mapreduce.Job:  map 83% reduce 12%
15/04/11 05:03:11 INFO mapreduce.Job:  map 84% reduce 12%
15/04/11 05:03:12 INFO mapreduce.Job:  map 86% reduce 12%
15/04/11 05:03:14 INFO mapreduce.Job:  map 87% reduce 12%
15/04/11 05:03:23 INFO mapreduce.Job:  map 88% reduce 14%
15/04/11 05:03:24 INFO mapreduce.Job:  map 88% reduce 16%
15/04/11 05:03:25 INFO mapreduce.Job:  map 88% reduce 18%
15/04/11 05:03:27 INFO mapreduce.Job:  map 88% reduce 19%
15/04/11 05:03:28 INFO mapreduce.Job:  map 88% reduce 21%
15/04/11 05:03:34 INFO mapreduce.Job:  map 89% reduce 21%
15/04/11 05:03:35 INFO mapreduce.Job:  map 89% reduce 22%
15/04/11 05:03:40 INFO mapreduce.Job:  map 90% reduce 22%
15/04/11 05:03:48 INFO mapreduce.Job:  map 91% reduce 22%
15/04/11 05:03:51 INFO mapreduce.Job:  map 92% reduce 23%
15/04/11 05:03:53 INFO mapreduce.Job:  map 92% reduce 25%
15/04/11 05:03:54 INFO mapreduce.Job:  map 93% reduce 25%
15/04/11 05:03:57 INFO mapreduce.Job:  map 94% reduce 25%
15/04/11 05:03:59 INFO mapreduce.Job:  map 94% reduce 27%
15/04/11 05:04:00 INFO mapreduce.Job:  map 95% reduce 27%
15/04/11 05:04:02 INFO mapreduce.Job:  map 96% reduce 27%
15/04/11 05:04:04 INFO mapreduce.Job:  map 96% reduce 28%
15/04/11 05:04:05 INFO mapreduce.Job:  map 96% reduce 29%
15/04/11 05:04:06 INFO mapreduce.Job:  map 96% reduce 30%
15/04/11 05:04:07 INFO mapreduce.Job:  map 97% reduce 30%
15/04/11 05:04:10 INFO mapreduce.Job:  map 98% reduce 30%
15/04/11 05:04:11 INFO mapreduce.Job:  map 98% reduce 31%
15/04/11 05:04:12 INFO mapreduce.Job:  map 99% reduce 31%
15/04/11 05:04:14 INFO mapreduce.Job:  map 100% reduce 31%
15/04/11 05:04:23 INFO mapreduce.Job:  map 100% reduce 32%
15/04/11 05:04:26 INFO mapreduce.Job:  map 100% reduce 33%
15/04/11 05:04:28 INFO mapreduce.Job:  map 100% reduce 34%
15/04/11 05:04:29 INFO mapreduce.Job:  map 100% reduce 36%
15/04/11 05:04:30 INFO mapreduce.Job:  map 100% reduce 37%
15/04/11 05:04:31 INFO mapreduce.Job:  map 100% reduce 39%
15/04/11 05:04:32 INFO mapreduce.Job:  map 100% reduce 41%
15/04/11 05:04:34 INFO mapreduce.Job:  map 100% reduce 45%
15/04/11 05:04:35 INFO mapreduce.Job:  map 100% reduce 46%
15/04/11 05:04:37 INFO mapreduce.Job:  map 100% reduce 50%
15/04/11 05:04:38 INFO mapreduce.Job:  map 100% reduce 53%
15/04/11 05:04:40 INFO mapreduce.Job:  map 100% reduce 57%
15/04/11 05:04:41 INFO mapreduce.Job:  map 100% reduce 60%
15/04/11 05:04:42 INFO mapreduce.Job:  map 100% reduce 61%
15/04/11 05:04:43 INFO mapreduce.Job:  map 100% reduce 62%
15/04/11 05:04:45 INFO mapreduce.Job:  map 100% reduce 65%
15/04/11 05:04:48 INFO mapreduce.Job:  map 100% reduce 67%
15/04/11 05:12:00 INFO mapreduce.Job:  map 100% reduce 68%
15/04/11 05:18:41 INFO mapreduce.Job:  map 100% reduce 69%
15/04/11 05:19:57 INFO mapreduce.Job:  map 100% reduce 70%
15/04/11 05:26:24 INFO mapreduce.Job:  map 100% reduce 71%
15/04/11 05:32:20 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 05:43:14 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 05:48:15 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 05:52:07 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 05:57:33 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 06:03:20 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 06:10:07 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 06:12:05 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 06:14:19 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 06:21:58 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 06:24:42 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 06:28:26 INFO mapreduce.Job:  map 100% reduce 83%
15/04/11 06:30:37 INFO mapreduce.Job:  map 100% reduce 85%
15/04/11 06:31:50 INFO mapreduce.Job:  map 100% reduce 86%
15/04/11 06:36:27 INFO mapreduce.Job:  map 100% reduce 87%
15/04/11 06:39:32 INFO mapreduce.Job:  map 100% reduce 88%
15/04/11 06:44:28 INFO mapreduce.Job:  map 100% reduce 89%
15/04/11 06:49:09 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 06:50:28 INFO mapreduce.Job:  map 100% reduce 91%
15/04/11 06:59:40 INFO mapreduce.Job:  map 100% reduce 92%
15/04/11 07:05:12 INFO mapreduce.Job:  map 100% reduce 93%
15/04/11 07:07:01 INFO mapreduce.Job:  map 100% reduce 94%
15/04/11 07:09:08 INFO mapreduce.Job:  map 100% reduce 95%
15/04/11 07:13:15 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 07:18:00 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 07:22:45 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 07:29:29 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 07:39:39 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 07:47:46 INFO mapreduce.Job: Job job_1422482982071_4466 completed successfully
15/04/11 07:47:46 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=16787659082
		FILE: Number of bytes written=33582925050
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=3756929
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Failed map tasks=24
		Launched map tasks=99
		Launched reduce tasks=5
		Other local map tasks=24
		Data-local map tasks=48
		Rack-local map tasks=27
		Total time spent by all maps in occupied slots (ms)=65766750
		Total time spent by all reduces in occupied slots (ms)=83866466
		Total time spent by all map tasks (ms)=32883375
		Total time spent by all reduce tasks (ms)=41933233
		Total vcore-seconds taken by all map tasks=32883375
		Total vcore-seconds taken by all reduce tasks=41933233
		Total megabyte-seconds taken by all map tasks=266223804000
		Total megabyte-seconds taken by all reduce tasks=503198796000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=1686860360
		Map output bytes=13413938248
		Map output materialized bytes=16787661218
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=258960
		Reduce shuffle bytes=16787661218
		Reduce input records=1686860360
		Reduce output records=258960
		Spilled Records=3373720720
		Shuffled Maps =375
		Failed Shuffles=0
		Merged Map outputs=375
		GC time elapsed (ms)=186377
		CPU time spent (ms)=88274510
		Physical memory (bytes) snapshot=157723824128
		Virtual memory (bytes) snapshot=756291842048
		Total committed heap usage (bytes)=218349023232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=3756929
15/04/11 07:47:46 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-un

real	172m3.067s
user	0m36.772s
sys	0m7.124s
15/04/11 07:47:49 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 40
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-40-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3352457071292933995.jar tmpDir=null
15/04/11 07:47:52 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 07:47:52 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 07:47:53 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/11 07:47:53 INFO mapreduce.JobSubmitter: number of splits:134
15/04/11 07:47:54 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4468
15/04/11 07:47:54 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4468
15/04/11 07:47:54 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4468/
15/04/11 07:47:54 INFO mapreduce.Job: Running job: job_1422482982071_4468
15/04/11 07:47:59 INFO mapreduce.Job: Job job_1422482982071_4468 running in uber mode : false
15/04/11 07:47:59 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 07:48:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000008_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000042_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000102_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000073_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000074_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000030_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000052_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000077_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000038_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000072_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000080_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000115_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000110_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000127_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000120_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4468_m_000127_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 07:48:11 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 07:48:17 INFO mapreduce.Job:  map 2% reduce 0%
15/04/11 07:48:23 INFO mapreduce.Job:  map 3% reduce 0%
15/04/11 07:48:30 INFO mapreduce.Job:  map 4% reduce 0%
15/04/11 07:48:38 INFO mapreduce.Job:  map 5% reduce 0%
15/04/11 07:48:44 INFO mapreduce.Job:  map 6% reduce 0%
15/04/11 07:48:51 INFO mapreduce.Job:  map 7% reduce 0%
15/04/11 07:48:57 INFO mapreduce.Job:  map 8% reduce 0%
15/04/11 07:49:03 INFO mapreduce.Job:  map 9% reduce 0%
15/04/11 07:49:10 INFO mapreduce.Job:  map 10% reduce 0%
15/04/11 07:49:16 INFO mapreduce.Job:  map 11% reduce 0%
15/04/11 07:49:23 INFO mapreduce.Job:  map 12% reduce 0%
15/04/11 07:49:29 INFO mapreduce.Job:  map 13% reduce 0%
15/04/11 07:49:36 INFO mapreduce.Job:  map 14% reduce 0%
15/04/11 07:49:42 INFO mapreduce.Job:  map 15% reduce 0%
15/04/11 07:49:48 INFO mapreduce.Job:  map 16% reduce 0%
15/04/11 07:49:55 INFO mapreduce.Job:  map 17% reduce 0%
15/04/11 07:50:02 INFO mapreduce.Job:  map 18% reduce 0%
15/04/11 07:50:08 INFO mapreduce.Job:  map 19% reduce 0%
15/04/11 07:50:15 INFO mapreduce.Job:  map 20% reduce 0%
15/04/11 07:50:21 INFO mapreduce.Job:  map 21% reduce 0%
15/04/11 07:50:27 INFO mapreduce.Job:  map 22% reduce 0%
15/04/11 07:50:33 INFO mapreduce.Job:  map 23% reduce 0%
15/04/11 07:50:40 INFO mapreduce.Job:  map 24% reduce 0%
15/04/11 07:50:45 INFO mapreduce.Job:  map 25% reduce 0%
15/04/11 07:50:51 INFO mapreduce.Job:  map 26% reduce 0%
15/04/11 07:50:58 INFO mapreduce.Job:  map 27% reduce 0%
15/04/11 07:51:05 INFO mapreduce.Job:  map 28% reduce 0%
15/04/11 07:51:12 INFO mapreduce.Job:  map 29% reduce 0%
15/04/11 07:51:18 INFO mapreduce.Job:  map 30% reduce 0%
15/04/11 07:51:24 INFO mapreduce.Job:  map 31% reduce 0%
15/04/11 07:51:31 INFO mapreduce.Job:  map 32% reduce 0%
15/04/11 07:51:38 INFO mapreduce.Job:  map 33% reduce 0%
15/04/11 07:51:46 INFO mapreduce.Job:  map 34% reduce 0%
15/04/11 07:51:52 INFO mapreduce.Job:  map 35% reduce 0%
15/04/11 07:51:58 INFO mapreduce.Job:  map 36% reduce 0%
15/04/11 07:52:05 INFO mapreduce.Job:  map 37% reduce 0%
15/04/11 07:52:12 INFO mapreduce.Job:  map 38% reduce 0%
15/04/11 07:52:19 INFO mapreduce.Job:  map 39% reduce 0%
15/04/11 07:52:25 INFO mapreduce.Job:  map 40% reduce 0%
15/04/11 07:52:31 INFO mapreduce.Job:  map 41% reduce 0%
15/04/11 07:52:38 INFO mapreduce.Job:  map 42% reduce 0%
15/04/11 07:52:45 INFO mapreduce.Job:  map 43% reduce 0%
15/04/11 07:52:52 INFO mapreduce.Job:  map 44% reduce 0%
15/04/11 07:52:58 INFO mapreduce.Job:  map 45% reduce 0%
15/04/11 07:53:04 INFO mapreduce.Job:  map 46% reduce 0%
15/04/11 07:53:11 INFO mapreduce.Job:  map 47% reduce 0%
15/04/11 07:53:17 INFO mapreduce.Job:  map 48% reduce 0%
15/04/11 07:53:25 INFO mapreduce.Job:  map 49% reduce 0%
15/04/11 07:53:31 INFO mapreduce.Job:  map 50% reduce 0%
15/04/11 07:53:37 INFO mapreduce.Job:  map 51% reduce 0%
15/04/11 07:53:44 INFO mapreduce.Job:  map 52% reduce 0%
15/04/11 07:53:50 INFO mapreduce.Job:  map 53% reduce 0%
15/04/11 07:53:58 INFO mapreduce.Job:  map 54% reduce 0%
15/04/11 07:54:04 INFO mapreduce.Job:  map 55% reduce 0%
15/04/11 07:54:10 INFO mapreduce.Job:  map 56% reduce 0%
15/04/11 07:54:17 INFO mapreduce.Job:  map 57% reduce 0%
15/04/11 07:54:23 INFO mapreduce.Job:  map 58% reduce 0%
15/04/11 07:54:31 INFO mapreduce.Job:  map 59% reduce 0%
15/04/11 07:54:37 INFO mapreduce.Job:  map 60% reduce 0%
15/04/11 07:54:43 INFO mapreduce.Job:  map 61% reduce 0%
15/04/11 07:54:50 INFO mapreduce.Job:  map 62% reduce 0%
15/04/11 07:54:58 INFO mapreduce.Job:  map 63% reduce 0%
15/04/11 07:55:02 INFO mapreduce.Job:  map 64% reduce 0%
15/04/11 07:55:04 INFO mapreduce.Job:  map 65% reduce 0%
15/04/11 07:55:05 INFO mapreduce.Job:  map 66% reduce 0%
15/04/11 07:55:07 INFO mapreduce.Job:  map 67% reduce 0%
15/04/11 07:55:09 INFO mapreduce.Job:  map 68% reduce 0%
15/04/11 07:55:10 INFO mapreduce.Job:  map 69% reduce 0%
15/04/11 07:55:12 INFO mapreduce.Job:  map 70% reduce 0%
15/04/11 07:55:13 INFO mapreduce.Job:  map 71% reduce 0%
15/04/11 07:55:15 INFO mapreduce.Job:  map 71% reduce 7%
15/04/11 07:55:16 INFO mapreduce.Job:  map 72% reduce 7%
15/04/11 07:55:17 INFO mapreduce.Job:  map 73% reduce 7%
15/04/11 07:55:18 INFO mapreduce.Job:  map 74% reduce 8%
15/04/11 07:55:19 INFO mapreduce.Job:  map 74% reduce 9%
15/04/11 07:55:20 INFO mapreduce.Job:  map 75% reduce 9%
15/04/11 07:55:21 INFO mapreduce.Job:  map 76% reduce 11%
15/04/11 07:55:22 INFO mapreduce.Job:  map 77% reduce 12%
15/04/11 07:55:23 INFO mapreduce.Job:  map 78% reduce 12%
15/04/11 07:55:24 INFO mapreduce.Job:  map 78% reduce 13%
15/04/11 07:55:26 INFO mapreduce.Job:  map 79% reduce 13%
15/04/11 07:55:27 INFO mapreduce.Job:  map 79% reduce 14%
15/04/11 07:55:30 INFO mapreduce.Job:  map 80% reduce 15%
15/04/11 07:55:31 INFO mapreduce.Job:  map 81% reduce 15%
15/04/11 07:55:34 INFO mapreduce.Job:  map 81% reduce 16%
15/04/11 07:55:36 INFO mapreduce.Job:  map 82% reduce 16%
15/04/11 07:55:47 INFO mapreduce.Job:  map 83% reduce 16%
15/04/11 07:55:52 INFO mapreduce.Job:  map 83% reduce 17%
15/04/11 07:55:53 INFO mapreduce.Job:  map 84% reduce 17%
15/04/11 07:56:01 INFO mapreduce.Job:  map 85% reduce 18%
15/04/11 07:56:03 INFO mapreduce.Job:  map 86% reduce 18%
15/04/11 07:56:04 INFO mapreduce.Job:  map 86% reduce 19%
15/04/11 07:56:05 INFO mapreduce.Job:  map 87% reduce 19%
15/04/11 07:56:06 INFO mapreduce.Job:  map 89% reduce 19%
15/04/11 07:56:07 INFO mapreduce.Job:  map 90% reduce 21%
15/04/11 07:56:08 INFO mapreduce.Job:  map 91% reduce 22%
15/04/11 07:56:09 INFO mapreduce.Job:  map 92% reduce 22%
15/04/11 07:56:10 INFO mapreduce.Job:  map 92% reduce 24%
15/04/11 07:56:11 INFO mapreduce.Job:  map 93% reduce 25%
15/04/11 07:56:12 INFO mapreduce.Job:  map 94% reduce 25%
15/04/11 07:56:13 INFO mapreduce.Job:  map 95% reduce 27%
15/04/11 07:56:14 INFO mapreduce.Job:  map 96% reduce 27%
15/04/11 07:56:16 INFO mapreduce.Job:  map 96% reduce 29%
15/04/11 07:56:17 INFO mapreduce.Job:  map 97% reduce 29%
15/04/11 07:56:20 INFO mapreduce.Job:  map 98% reduce 30%
15/04/11 07:56:22 INFO mapreduce.Job:  map 99% reduce 31%
15/04/11 07:56:28 INFO mapreduce.Job:  map 99% reduce 32%
15/04/11 07:56:31 INFO mapreduce.Job:  map 100% reduce 32%
15/04/11 07:56:38 INFO mapreduce.Job:  map 100% reduce 33%
15/04/11 07:56:43 INFO mapreduce.Job:  map 100% reduce 34%
15/04/11 07:56:44 INFO mapreduce.Job:  map 100% reduce 35%
15/04/11 07:56:45 INFO mapreduce.Job:  map 100% reduce 36%
15/04/11 07:56:46 INFO mapreduce.Job:  map 100% reduce 39%
15/04/11 07:56:47 INFO mapreduce.Job:  map 100% reduce 41%
15/04/11 07:56:48 INFO mapreduce.Job:  map 100% reduce 42%
15/04/11 07:56:49 INFO mapreduce.Job:  map 100% reduce 46%
15/04/11 07:56:50 INFO mapreduce.Job:  map 100% reduce 48%
15/04/11 07:56:51 INFO mapreduce.Job:  map 100% reduce 49%
15/04/11 07:56:52 INFO mapreduce.Job:  map 100% reduce 52%
15/04/11 07:56:53 INFO mapreduce.Job:  map 100% reduce 55%
15/04/11 07:56:55 INFO mapreduce.Job:  map 100% reduce 57%
15/04/11 07:56:56 INFO mapreduce.Job:  map 100% reduce 59%
15/04/11 07:56:58 INFO mapreduce.Job:  map 100% reduce 60%
15/04/11 07:56:59 INFO mapreduce.Job:  map 100% reduce 61%
15/04/11 07:57:00 INFO mapreduce.Job:  map 100% reduce 62%
15/04/11 07:57:02 INFO mapreduce.Job:  map 100% reduce 63%
15/04/11 07:57:03 INFO mapreduce.Job:  map 100% reduce 64%
15/04/11 07:57:04 INFO mapreduce.Job:  map 100% reduce 65%
15/04/11 07:57:07 INFO mapreduce.Job:  map 100% reduce 67%
15/04/11 07:58:21 INFO mapreduce.Job:  map 100% reduce 68%
15/04/11 07:59:11 INFO mapreduce.Job:  map 100% reduce 69%
15/04/11 08:00:26 INFO mapreduce.Job:  map 100% reduce 70%
15/04/11 08:01:24 INFO mapreduce.Job:  map 100% reduce 71%
15/04/11 08:02:15 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 08:03:08 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 08:03:45 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 08:04:43 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 08:05:22 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 08:06:07 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 08:06:58 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 08:07:35 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 08:08:07 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 08:08:54 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 08:09:50 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 08:10:47 INFO mapreduce.Job:  map 100% reduce 83%
15/04/11 08:11:27 INFO mapreduce.Job:  map 100% reduce 84%
15/04/11 08:12:22 INFO mapreduce.Job:  map 100% reduce 85%
15/04/11 08:13:26 INFO mapreduce.Job:  map 100% reduce 86%
15/04/11 08:15:01 INFO mapreduce.Job:  map 100% reduce 87%
15/04/11 08:16:25 INFO mapreduce.Job:  map 100% reduce 88%
15/04/11 08:17:45 INFO mapreduce.Job:  map 100% reduce 89%
15/04/11 08:18:59 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 08:21:57 INFO mapreduce.Job:  map 100% reduce 91%
15/04/11 08:24:30 INFO mapreduce.Job:  map 100% reduce 92%
15/04/11 08:25:01 INFO mapreduce.Job:  map 100% reduce 93%
15/04/11 08:26:03 INFO mapreduce.Job:  map 100% reduce 94%
15/04/11 08:29:40 INFO mapreduce.Job:  map 100% reduce 95%
15/04/11 08:33:32 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 08:36:43 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 08:41:16 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 09:10:19 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 10:06:19 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 10:25:44 INFO mapreduce.Job: Job job_1422482982071_4468 completed successfully
15/04/11 10:25:44 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=30424216087
		FILE: Number of bytes written=60865113102
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=522
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Failed map tasks=16
		Killed reduce tasks=2
		Launched map tasks=150
		Launched reduce tasks=42
		Other local map tasks=16
		Data-local map tasks=63
		Rack-local map tasks=71
		Total time spent by all maps in occupied slots (ms)=123121848
		Total time spent by all reduces in occupied slots (ms)=176081278
		Total time spent by all map tasks (ms)=61560924
		Total time spent by all reduce tasks (ms)=88040639
		Total vcore-seconds taken by all map tasks=61560924
		Total vcore-seconds taken by all reduce tasks=88040639
		Total megabyte-seconds taken by all map tasks=498397240704
		Total megabyte-seconds taken by all reduce tasks=1056487668000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424247953
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424247953
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =5360
		Failed Shuffles=0
		Merged Map outputs=5360
		GC time elapsed (ms)=375711
		CPU time spent (ms)=165007420
		Physical memory (bytes) snapshot=300366102528
		Virtual memory (bytes) snapshot=1765007200256
		Total committed heap usage (bytes)=455344754688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/11 10:25:44 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st

real	157m57.623s
user	0m35.202s
sys	0m6.600s
15/04/11 10:25:47 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 40
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-40-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8791043093602748528.jar tmpDir=null
15/04/11 10:25:50 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 10:25:50 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 10:25:51 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/11 10:25:51 INFO mapreduce.JobSubmitter: number of splits:134
15/04/11 10:25:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4469
15/04/11 10:25:52 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4469
15/04/11 10:25:52 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4469/
15/04/11 10:25:52 INFO mapreduce.Job: Running job: job_1422482982071_4469
15/04/11 10:25:57 INFO mapreduce.Job: Job job_1422482982071_4469 running in uber mode : false
15/04/11 10:25:57 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 10:26:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4469_m_000014_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 10:26:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4469_m_000027_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 10:26:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4469_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 10:26:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4469_m_000066_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 10:26:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4469_m_000041_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 10:26:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4469_m_000101_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 10:26:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4469_m_000078_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 10:26:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4469_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 10:26:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4469_m_000047_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 10:26:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4469_m_000031_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 10:26:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4469_m_000123_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 10:26:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4469_m_000121_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 10:26:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4469_m_000031_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 10:26:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4469_m_000123_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 10:26:09 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 10:26:16 INFO mapreduce.Job:  map 2% reduce 0%
15/04/11 10:26:22 INFO mapreduce.Job:  map 3% reduce 0%
15/04/11 10:26:29 INFO mapreduce.Job:  map 4% reduce 0%
15/04/11 10:26:36 INFO mapreduce.Job:  map 5% reduce 0%
15/04/11 10:26:43 INFO mapreduce.Job:  map 6% reduce 0%
15/04/11 10:26:49 INFO mapreduce.Job:  map 7% reduce 0%
15/04/11 10:26:55 INFO mapreduce.Job:  map 8% reduce 0%
15/04/11 10:27:01 INFO mapreduce.Job:  map 9% reduce 0%
15/04/11 10:27:08 INFO mapreduce.Job:  map 10% reduce 0%
15/04/11 10:27:14 INFO mapreduce.Job:  map 11% reduce 0%
15/04/11 10:27:22 INFO mapreduce.Job:  map 12% reduce 0%
15/04/11 10:27:28 INFO mapreduce.Job:  map 13% reduce 0%
15/04/11 10:27:34 INFO mapreduce.Job:  map 14% reduce 0%
15/04/11 10:27:40 INFO mapreduce.Job:  map 15% reduce 0%
15/04/11 10:27:47 INFO mapreduce.Job:  map 16% reduce 0%
15/04/11 10:27:53 INFO mapreduce.Job:  map 17% reduce 0%
15/04/11 10:28:00 INFO mapreduce.Job:  map 18% reduce 0%
15/04/11 10:28:07 INFO mapreduce.Job:  map 19% reduce 0%
15/04/11 10:28:13 INFO mapreduce.Job:  map 20% reduce 0%
15/04/11 10:28:19 INFO mapreduce.Job:  map 21% reduce 0%
15/04/11 10:28:25 INFO mapreduce.Job:  map 22% reduce 0%
15/04/11 10:28:32 INFO mapreduce.Job:  map 23% reduce 0%
15/04/11 10:28:38 INFO mapreduce.Job:  map 24% reduce 0%
15/04/11 10:28:45 INFO mapreduce.Job:  map 25% reduce 0%
15/04/11 10:28:50 INFO mapreduce.Job:  map 26% reduce 0%
15/04/11 10:28:56 INFO mapreduce.Job:  map 27% reduce 0%
15/04/11 10:29:04 INFO mapreduce.Job:  map 28% reduce 0%
15/04/11 10:29:10 INFO mapreduce.Job:  map 29% reduce 0%
15/04/11 10:29:17 INFO mapreduce.Job:  map 30% reduce 0%
15/04/11 10:29:24 INFO mapreduce.Job:  map 31% reduce 0%
15/04/11 10:29:30 INFO mapreduce.Job:  map 32% reduce 0%
15/04/11 10:29:38 INFO mapreduce.Job:  map 33% reduce 0%
15/04/11 10:29:44 INFO mapreduce.Job:  map 34% reduce 0%
15/04/11 10:29:50 INFO mapreduce.Job:  map 35% reduce 0%
15/04/11 10:29:57 INFO mapreduce.Job:  map 36% reduce 0%
15/04/11 10:30:03 INFO mapreduce.Job:  map 37% reduce 0%
15/04/11 10:30:10 INFO mapreduce.Job:  map 38% reduce 0%
15/04/11 10:30:17 INFO mapreduce.Job:  map 39% reduce 0%
15/04/11 10:30:23 INFO mapreduce.Job:  map 40% reduce 0%
15/04/11 10:30:30 INFO mapreduce.Job:  map 41% reduce 0%
15/04/11 10:30:36 INFO mapreduce.Job:  map 42% reduce 0%
15/04/11 10:30:43 INFO mapreduce.Job:  map 43% reduce 0%
15/04/11 10:30:50 INFO mapreduce.Job:  map 44% reduce 0%
15/04/11 10:30:56 INFO mapreduce.Job:  map 45% reduce 0%
15/04/11 10:31:03 INFO mapreduce.Job:  map 46% reduce 0%
15/04/11 10:31:09 INFO mapreduce.Job:  map 47% reduce 0%
15/04/11 10:31:15 INFO mapreduce.Job:  map 48% reduce 0%
15/04/11 10:31:23 INFO mapreduce.Job:  map 49% reduce 0%
15/04/11 10:31:29 INFO mapreduce.Job:  map 50% reduce 0%
15/04/11 10:31:35 INFO mapreduce.Job:  map 51% reduce 0%
15/04/11 10:31:42 INFO mapreduce.Job:  map 52% reduce 0%
15/04/11 10:31:48 INFO mapreduce.Job:  map 53% reduce 0%
15/04/11 10:31:56 INFO mapreduce.Job:  map 54% reduce 0%
15/04/11 10:32:02 INFO mapreduce.Job:  map 55% reduce 0%
15/04/11 10:32:09 INFO mapreduce.Job:  map 56% reduce 0%
15/04/11 10:32:15 INFO mapreduce.Job:  map 57% reduce 0%
15/04/11 10:32:21 INFO mapreduce.Job:  map 58% reduce 0%
15/04/11 10:32:28 INFO mapreduce.Job:  map 59% reduce 0%
15/04/11 10:32:35 INFO mapreduce.Job:  map 60% reduce 0%
15/04/11 10:32:43 INFO mapreduce.Job:  map 61% reduce 0%
15/04/11 10:32:49 INFO mapreduce.Job:  map 62% reduce 0%
15/04/11 10:32:57 INFO mapreduce.Job:  map 63% reduce 0%
15/04/11 10:33:01 INFO mapreduce.Job:  map 64% reduce 0%
15/04/11 10:33:04 INFO mapreduce.Job:  map 65% reduce 0%
15/04/11 10:33:05 INFO mapreduce.Job:  map 66% reduce 0%
15/04/11 10:33:07 INFO mapreduce.Job:  map 67% reduce 0%
15/04/11 10:33:09 INFO mapreduce.Job:  map 68% reduce 0%
15/04/11 10:33:10 INFO mapreduce.Job:  map 69% reduce 0%
15/04/11 10:33:11 INFO mapreduce.Job:  map 71% reduce 0%
15/04/11 10:33:12 INFO mapreduce.Job:  map 72% reduce 0%
15/04/11 10:33:14 INFO mapreduce.Job:  map 73% reduce 5%
15/04/11 10:33:15 INFO mapreduce.Job:  map 73% reduce 8%
15/04/11 10:33:16 INFO mapreduce.Job:  map 74% reduce 9%
15/04/11 10:33:18 INFO mapreduce.Job:  map 75% reduce 10%
15/04/11 10:33:19 INFO mapreduce.Job:  map 76% reduce 10%
15/04/11 10:33:20 INFO mapreduce.Job:  map 77% reduce 10%
15/04/11 10:33:21 INFO mapreduce.Job:  map 77% reduce 12%
15/04/11 10:33:22 INFO mapreduce.Job:  map 78% reduce 12%
15/04/11 10:33:24 INFO mapreduce.Job:  map 78% reduce 14%
15/04/11 10:33:25 INFO mapreduce.Job:  map 79% reduce 14%
15/04/11 10:33:26 INFO mapreduce.Job:  map 80% reduce 14%
15/04/11 10:33:27 INFO mapreduce.Job:  map 80% reduce 15%
15/04/11 10:33:28 INFO mapreduce.Job:  map 81% reduce 15%
15/04/11 10:33:30 INFO mapreduce.Job:  map 81% reduce 16%
15/04/11 10:33:37 INFO mapreduce.Job:  map 82% reduce 16%
15/04/11 10:33:50 INFO mapreduce.Job:  map 83% reduce 16%
15/04/11 10:33:53 INFO mapreduce.Job:  map 84% reduce 16%
15/04/11 10:33:54 INFO mapreduce.Job:  map 84% reduce 17%
15/04/11 10:33:55 INFO mapreduce.Job:  map 85% reduce 17%
15/04/11 10:33:57 INFO mapreduce.Job:  map 85% reduce 18%
15/04/11 10:33:58 INFO mapreduce.Job:  map 86% reduce 18%
15/04/11 10:33:59 INFO mapreduce.Job:  map 87% reduce 19%
15/04/11 10:34:00 INFO mapreduce.Job:  map 87% reduce 20%
15/04/11 10:34:01 INFO mapreduce.Job:  map 88% reduce 20%
15/04/11 10:34:02 INFO mapreduce.Job:  map 89% reduce 20%
15/04/11 10:34:03 INFO mapreduce.Job:  map 90% reduce 22%
15/04/11 10:34:04 INFO mapreduce.Job:  map 90% reduce 23%
15/04/11 10:34:05 INFO mapreduce.Job:  map 91% reduce 23%
15/04/11 10:34:06 INFO mapreduce.Job:  map 92% reduce 24%
15/04/11 10:34:07 INFO mapreduce.Job:  map 92% reduce 25%
15/04/11 10:34:08 INFO mapreduce.Job:  map 93% reduce 25%
15/04/11 10:34:09 INFO mapreduce.Job:  map 94% reduce 26%
15/04/11 10:34:10 INFO mapreduce.Job:  map 94% reduce 27%
15/04/11 10:34:12 INFO mapreduce.Job:  map 95% reduce 27%
15/04/11 10:34:13 INFO mapreduce.Job:  map 95% reduce 28%
15/04/11 10:34:14 INFO mapreduce.Job:  map 96% reduce 28%
15/04/11 10:34:15 INFO mapreduce.Job:  map 96% reduce 29%
15/04/11 10:34:16 INFO mapreduce.Job:  map 97% reduce 29%
15/04/11 10:34:18 INFO mapreduce.Job:  map 97% reduce 30%
15/04/11 10:34:20 INFO mapreduce.Job:  map 98% reduce 30%
15/04/11 10:34:25 INFO mapreduce.Job:  map 98% reduce 31%
15/04/11 10:34:30 INFO mapreduce.Job:  map 99% reduce 31%
15/04/11 10:34:32 INFO mapreduce.Job:  map 100% reduce 32%
15/04/11 10:34:37 INFO mapreduce.Job:  map 100% reduce 33%
15/04/11 10:34:44 INFO mapreduce.Job:  map 100% reduce 34%
15/04/11 10:34:45 INFO mapreduce.Job:  map 100% reduce 36%
15/04/11 10:34:46 INFO mapreduce.Job:  map 100% reduce 39%
15/04/11 10:34:47 INFO mapreduce.Job:  map 100% reduce 40%
15/04/11 10:34:48 INFO mapreduce.Job:  map 100% reduce 42%
15/04/11 10:34:49 INFO mapreduce.Job:  map 100% reduce 46%
15/04/11 10:34:50 INFO mapreduce.Job:  map 100% reduce 47%
15/04/11 10:34:51 INFO mapreduce.Job:  map 100% reduce 49%
15/04/11 10:34:52 INFO mapreduce.Job:  map 100% reduce 53%
15/04/11 10:34:53 INFO mapreduce.Job:  map 100% reduce 54%
15/04/11 10:34:54 INFO mapreduce.Job:  map 100% reduce 55%
15/04/11 10:34:55 INFO mapreduce.Job:  map 100% reduce 58%
15/04/11 10:34:56 INFO mapreduce.Job:  map 100% reduce 59%
15/04/11 10:34:58 INFO mapreduce.Job:  map 100% reduce 61%
15/04/11 10:35:00 INFO mapreduce.Job:  map 100% reduce 62%
15/04/11 10:35:01 INFO mapreduce.Job:  map 100% reduce 63%
15/04/11 10:35:03 INFO mapreduce.Job:  map 100% reduce 64%
15/04/11 10:35:06 INFO mapreduce.Job:  map 100% reduce 65%
15/04/11 10:35:07 INFO mapreduce.Job:  map 100% reduce 67%
15/04/11 10:36:23 INFO mapreduce.Job:  map 100% reduce 68%
15/04/11 10:37:17 INFO mapreduce.Job:  map 100% reduce 69%
15/04/11 10:38:28 INFO mapreduce.Job:  map 100% reduce 70%
15/04/11 10:39:29 INFO mapreduce.Job:  map 100% reduce 71%
15/04/11 10:40:22 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 10:41:10 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 10:41:49 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 10:42:52 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 10:43:29 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 10:44:08 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 10:45:10 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 10:45:38 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 10:46:11 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 10:46:59 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 10:47:58 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 10:48:43 INFO mapreduce.Job:  map 100% reduce 83%
15/04/11 10:49:36 INFO mapreduce.Job:  map 100% reduce 84%
15/04/11 10:50:37 INFO mapreduce.Job:  map 100% reduce 85%
15/04/11 10:51:31 INFO mapreduce.Job:  map 100% reduce 86%
15/04/11 10:52:58 INFO mapreduce.Job:  map 100% reduce 87%
15/04/11 10:54:03 INFO mapreduce.Job:  map 100% reduce 88%
15/04/11 10:55:50 INFO mapreduce.Job:  map 100% reduce 89%
15/04/11 10:57:18 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 11:00:09 INFO mapreduce.Job:  map 100% reduce 91%
15/04/11 11:01:55 INFO mapreduce.Job:  map 100% reduce 92%
15/04/11 11:03:10 INFO mapreduce.Job:  map 100% reduce 93%
15/04/11 11:04:18 INFO mapreduce.Job:  map 100% reduce 94%
15/04/11 11:07:25 INFO mapreduce.Job:  map 100% reduce 95%
15/04/11 11:10:50 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 11:14:31 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 11:20:06 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 11:48:04 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 12:43:52 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 13:03:05 INFO mapreduce.Job: Job job_1422482982071_4469 completed successfully
15/04/11 13:03:05 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=30424216087
		FILE: Number of bytes written=60865113102
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=522
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Failed map tasks=14
		Killed reduce tasks=2
		Launched map tasks=148
		Launched reduce tasks=42
		Other local map tasks=14
		Data-local map tasks=63
		Rack-local map tasks=71
		Total time spent by all maps in occupied slots (ms)=123122308
		Total time spent by all reduces in occupied slots (ms)=175347630
		Total time spent by all map tasks (ms)=61561154
		Total time spent by all reduce tasks (ms)=87673815
		Total vcore-seconds taken by all map tasks=61561154
		Total vcore-seconds taken by all reduce tasks=87673815
		Total megabyte-seconds taken by all map tasks=498399102784
		Total megabyte-seconds taken by all reduce tasks=1052085780000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424247953
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424247953
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =5360
		Failed Shuffles=0
		Merged Map outputs=5360
		GC time elapsed (ms)=360468
		CPU time spent (ms)=164834200
		Physical memory (bytes) snapshot=300829143040
		Virtual memory (bytes) snapshot=1765204246528
		Total committed heap usage (bytes)=455344173056
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/11 13:03:05 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st

real	157m20.921s
user	0m36.089s
sys	0m6.722s
15/04/11 13:03:07 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 40
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-40-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=40 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7704930537332211366.jar tmpDir=null
15/04/11 13:03:10 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 13:03:10 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 13:03:11 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/11 13:03:11 INFO mapreduce.JobSubmitter: number of splits:134
15/04/11 13:03:12 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4470
15/04/11 13:03:12 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4470
15/04/11 13:03:12 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4470/
15/04/11 13:03:12 INFO mapreduce.Job: Running job: job_1422482982071_4470
15/04/11 13:03:18 INFO mapreduce.Job: Job job_1422482982071_4470 running in uber mode : false
15/04/11 13:03:18 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 13:03:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_m_000069_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:03:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:03:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_m_000124_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:03:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:03:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_m_000052_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:03:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:03:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_m_000062_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:03:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_m_000032_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:03:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_m_000073_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:03:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_m_000054_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:03:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_m_000085_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:03:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:03:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_m_000095_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:03:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_m_000044_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:03:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_m_000129_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:03:30 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 13:03:37 INFO mapreduce.Job:  map 2% reduce 0%
15/04/11 13:03:43 INFO mapreduce.Job:  map 3% reduce 0%
15/04/11 13:03:50 INFO mapreduce.Job:  map 4% reduce 0%
15/04/11 13:03:57 INFO mapreduce.Job:  map 5% reduce 0%
15/04/11 13:04:03 INFO mapreduce.Job:  map 6% reduce 0%
15/04/11 13:04:10 INFO mapreduce.Job:  map 7% reduce 0%
15/04/11 13:04:16 INFO mapreduce.Job:  map 8% reduce 0%
15/04/11 13:04:22 INFO mapreduce.Job:  map 9% reduce 0%
15/04/11 13:04:29 INFO mapreduce.Job:  map 10% reduce 0%
15/04/11 13:04:35 INFO mapreduce.Job:  map 11% reduce 0%
15/04/11 13:04:42 INFO mapreduce.Job:  map 12% reduce 0%
15/04/11 13:04:48 INFO mapreduce.Job:  map 13% reduce 0%
15/04/11 13:04:55 INFO mapreduce.Job:  map 14% reduce 0%
15/04/11 13:05:01 INFO mapreduce.Job:  map 15% reduce 0%
15/04/11 13:05:07 INFO mapreduce.Job:  map 16% reduce 0%
15/04/11 13:05:14 INFO mapreduce.Job:  map 17% reduce 0%
15/04/11 13:05:21 INFO mapreduce.Job:  map 18% reduce 0%
15/04/11 13:05:27 INFO mapreduce.Job:  map 19% reduce 0%
15/04/11 13:05:34 INFO mapreduce.Job:  map 20% reduce 0%
15/04/11 13:05:40 INFO mapreduce.Job:  map 21% reduce 0%
15/04/11 13:05:46 INFO mapreduce.Job:  map 22% reduce 0%
15/04/11 13:05:52 INFO mapreduce.Job:  map 23% reduce 0%
15/04/11 13:05:59 INFO mapreduce.Job:  map 24% reduce 0%
15/04/11 13:06:06 INFO mapreduce.Job:  map 25% reduce 0%
15/04/11 13:06:10 INFO mapreduce.Job:  map 26% reduce 0%
15/04/11 13:06:18 INFO mapreduce.Job:  map 27% reduce 0%
15/04/11 13:06:25 INFO mapreduce.Job:  map 28% reduce 0%
15/04/11 13:06:32 INFO mapreduce.Job:  map 29% reduce 0%
15/04/11 13:06:38 INFO mapreduce.Job:  map 30% reduce 0%
15/04/11 13:06:44 INFO mapreduce.Job:  map 31% reduce 0%
15/04/11 13:06:51 INFO mapreduce.Job:  map 32% reduce 0%
15/04/11 13:06:57 INFO mapreduce.Job:  map 33% reduce 0%
15/04/11 13:07:05 INFO mapreduce.Job:  map 34% reduce 0%
15/04/11 13:07:11 INFO mapreduce.Job:  map 35% reduce 0%
15/04/11 13:07:17 INFO mapreduce.Job:  map 36% reduce 0%
15/04/11 13:07:23 INFO mapreduce.Job:  map 37% reduce 0%
15/04/11 13:07:30 INFO mapreduce.Job:  map 38% reduce 0%
15/04/11 13:07:38 INFO mapreduce.Job:  map 39% reduce 0%
15/04/11 13:07:44 INFO mapreduce.Job:  map 40% reduce 0%
15/04/11 13:07:50 INFO mapreduce.Job:  map 41% reduce 0%
15/04/11 13:07:56 INFO mapreduce.Job:  map 42% reduce 0%
15/04/11 13:08:03 INFO mapreduce.Job:  map 43% reduce 0%
15/04/11 13:08:10 INFO mapreduce.Job:  map 44% reduce 0%
15/04/11 13:08:17 INFO mapreduce.Job:  map 45% reduce 0%
15/04/11 13:08:23 INFO mapreduce.Job:  map 46% reduce 0%
15/04/11 13:08:29 INFO mapreduce.Job:  map 47% reduce 0%
15/04/11 13:08:36 INFO mapreduce.Job:  map 48% reduce 0%
15/04/11 13:08:43 INFO mapreduce.Job:  map 49% reduce 0%
15/04/11 13:08:50 INFO mapreduce.Job:  map 50% reduce 0%
15/04/11 13:08:56 INFO mapreduce.Job:  map 51% reduce 0%
15/04/11 13:09:02 INFO mapreduce.Job:  map 52% reduce 0%
15/04/11 13:09:09 INFO mapreduce.Job:  map 53% reduce 0%
15/04/11 13:09:15 INFO mapreduce.Job:  map 54% reduce 0%
15/04/11 13:09:23 INFO mapreduce.Job:  map 55% reduce 0%
15/04/11 13:09:29 INFO mapreduce.Job:  map 56% reduce 0%
15/04/11 13:09:35 INFO mapreduce.Job:  map 57% reduce 0%
15/04/11 13:09:42 INFO mapreduce.Job:  map 58% reduce 0%
15/04/11 13:09:49 INFO mapreduce.Job:  map 59% reduce 0%
15/04/11 13:09:56 INFO mapreduce.Job:  map 60% reduce 0%
15/04/11 13:10:03 INFO mapreduce.Job:  map 61% reduce 0%
15/04/11 13:10:09 INFO mapreduce.Job:  map 62% reduce 0%
15/04/11 13:10:17 INFO mapreduce.Job:  map 63% reduce 0%
15/04/11 13:10:21 INFO mapreduce.Job:  map 64% reduce 0%
15/04/11 13:10:24 INFO mapreduce.Job:  map 65% reduce 0%
15/04/11 13:10:26 INFO mapreduce.Job:  map 66% reduce 0%
15/04/11 13:10:28 INFO mapreduce.Job:  map 67% reduce 0%
15/04/11 13:10:29 INFO mapreduce.Job:  map 68% reduce 0%
15/04/11 13:10:30 INFO mapreduce.Job:  map 69% reduce 0%
15/04/11 13:10:31 INFO mapreduce.Job:  map 70% reduce 0%
15/04/11 13:10:33 INFO mapreduce.Job:  map 71% reduce 0%
15/04/11 13:10:34 INFO mapreduce.Job:  map 72% reduce 6%
15/04/11 13:10:35 INFO mapreduce.Job:  map 72% reduce 7%
15/04/11 13:10:36 INFO mapreduce.Job:  map 73% reduce 7%
15/04/11 13:10:37 INFO mapreduce.Job:  map 73% reduce 8%
15/04/11 13:10:38 INFO mapreduce.Job:  map 74% reduce 9%
15/04/11 13:10:39 INFO mapreduce.Job:  map 75% reduce 9%
15/04/11 13:10:40 INFO mapreduce.Job:  map 76% reduce 10%
15/04/11 13:10:41 INFO mapreduce.Job:  map 77% reduce 11%
15/04/11 13:10:43 INFO mapreduce.Job:  map 78% reduce 13%
15/04/11 13:10:44 INFO mapreduce.Job:  map 79% reduce 13%
15/04/11 13:10:46 INFO mapreduce.Job:  map 79% reduce 14%
15/04/11 13:10:49 INFO mapreduce.Job:  map 80% reduce 15%
15/04/11 13:10:50 INFO mapreduce.Job:  map 81% reduce 15%
15/04/11 13:10:53 INFO mapreduce.Job:  map 81% reduce 16%
15/04/11 13:10:56 INFO mapreduce.Job:  map 82% reduce 16%
15/04/11 13:11:10 INFO mapreduce.Job:  map 83% reduce 16%
15/04/11 13:11:14 INFO mapreduce.Job:  map 83% reduce 17%
15/04/11 13:11:15 INFO mapreduce.Job:  map 84% reduce 17%
15/04/11 13:11:16 INFO mapreduce.Job:  map 85% reduce 17%
15/04/11 13:11:17 INFO mapreduce.Job:  map 85% reduce 18%
15/04/11 13:11:18 INFO mapreduce.Job:  map 86% reduce 18%
15/04/11 13:11:19 INFO mapreduce.Job:  map 87% reduce 18%
15/04/11 13:11:20 INFO mapreduce.Job:  map 87% reduce 20%
15/04/11 13:11:21 INFO mapreduce.Job:  map 88% reduce 20%
15/04/11 13:11:22 INFO mapreduce.Job:  map 89% reduce 20%
15/04/11 13:11:23 INFO mapreduce.Job:  map 90% reduce 22%
15/04/11 13:11:24 INFO mapreduce.Job:  map 91% reduce 23%
15/04/11 13:11:25 INFO mapreduce.Job:  map 92% reduce 23%
15/04/11 13:11:26 INFO mapreduce.Job:  map 93% reduce 24%
15/04/11 13:11:27 INFO mapreduce.Job:  map 94% reduce 25%
15/04/11 13:11:28 INFO mapreduce.Job:  map 95% reduce 25%
15/04/11 13:11:29 INFO mapreduce.Job:  map 95% reduce 27%
15/04/11 13:11:30 INFO mapreduce.Job:  map 96% reduce 28%
15/04/11 13:11:32 INFO mapreduce.Job:  map 97% reduce 29%
15/04/11 13:11:35 INFO mapreduce.Job:  map 98% reduce 30%
15/04/11 13:11:38 INFO mapreduce.Job:  map 98% reduce 31%
15/04/11 13:11:44 INFO mapreduce.Job:  map 99% reduce 31%
15/04/11 13:11:47 INFO mapreduce.Job:  map 99% reduce 32%
15/04/11 13:11:48 INFO mapreduce.Job:  map 100% reduce 32%
15/04/11 13:11:54 INFO mapreduce.Job:  map 100% reduce 33%
15/04/11 13:11:56 INFO mapreduce.Job:  map 100% reduce 35%
15/04/11 13:11:57 INFO mapreduce.Job:  map 100% reduce 36%
15/04/11 13:11:58 INFO mapreduce.Job:  map 100% reduce 38%
15/04/11 13:11:59 INFO mapreduce.Job:  map 100% reduce 40%
15/04/11 13:12:00 INFO mapreduce.Job:  map 100% reduce 43%
15/04/11 13:12:01 INFO mapreduce.Job:  map 100% reduce 44%
15/04/11 13:12:02 INFO mapreduce.Job:  map 100% reduce 47%
15/04/11 13:12:03 INFO mapreduce.Job:  map 100% reduce 50%
15/04/11 13:12:04 INFO mapreduce.Job:  map 100% reduce 51%
15/04/11 13:12:05 INFO mapreduce.Job:  map 100% reduce 54%
15/04/11 13:12:06 INFO mapreduce.Job:  map 100% reduce 56%
15/04/11 13:12:07 INFO mapreduce.Job:  map 100% reduce 57%
15/04/11 13:12:08 INFO mapreduce.Job:  map 100% reduce 58%
15/04/11 13:12:09 INFO mapreduce.Job:  map 100% reduce 60%
15/04/11 13:12:11 INFO mapreduce.Job:  map 100% reduce 61%
15/04/11 13:12:12 INFO mapreduce.Job:  map 100% reduce 62%
15/04/11 13:12:14 INFO mapreduce.Job:  map 100% reduce 63%
15/04/11 13:12:15 INFO mapreduce.Job:  map 100% reduce 64%
15/04/11 13:12:18 INFO mapreduce.Job:  map 100% reduce 65%
15/04/11 13:12:20 INFO mapreduce.Job:  map 100% reduce 66%
15/04/11 13:12:23 INFO mapreduce.Job:  map 100% reduce 67%
15/04/11 13:13:39 INFO mapreduce.Job:  map 100% reduce 68%
15/04/11 13:14:25 INFO mapreduce.Job:  map 100% reduce 69%
15/04/11 13:15:39 INFO mapreduce.Job:  map 100% reduce 70%
15/04/11 13:16:41 INFO mapreduce.Job:  map 100% reduce 71%
15/04/11 13:17:34 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 13:18:24 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 13:19:00 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 13:20:00 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 13:20:41 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 13:21:25 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:22:16 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 13:22:55 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 13:23:27 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 13:24:15 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 13:24:27 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000022_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:24:28 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 13:24:39 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 13:24:54 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 13:25:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000006_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:25:11 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 13:25:21 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 13:25:33 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 13:25:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000029_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000029_0/part-00029 (inode 3605486): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000029_0_627543408_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:25:49 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 13:25:52 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 13:25:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000031_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000031_0/part-00031 (inode 3605480): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000031_0_2049425875_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:25:55 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 13:25:59 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:26:01 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 13:26:05 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 13:26:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000013_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000013_0/part-00013 (inode 3605484): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000013_0_-463237092_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:26:08 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:26:17 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 13:26:18 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 13:26:33 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 13:27:27 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 13:27:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000025_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000025_0/part-00025 (inode 3605488): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000025_0_464444729_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:27:35 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 13:27:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000039_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000039_0/part-00039 (inode 3605492): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000039_0_1001363761_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:27:38 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 13:27:45 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:27:48 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 13:27:51 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 13:28:00 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 13:28:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000009_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000009_0/part-00009 (inode 3605490): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000009_0_-860529109_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:28:04 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:28:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000028_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:28:11 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 13:28:14 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 13:28:17 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:28:22 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 13:28:35 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 13:29:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000027_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000027_0/part-00027 (inode 3605496): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000027_0_1314626146_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:29:03 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:29:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000017_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000017_0/part-00017 (inode 3605494): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000017_0_291745910_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:29:04 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 13:29:07 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 13:29:13 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 13:29:14 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:29:23 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 13:29:23 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000034_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000034_0/part-00034 (inode 3605504): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000034_0_-1825985625_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:29:24 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 13:29:28 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 13:29:34 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:29:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000005_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:29:43 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 13:29:54 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 13:29:57 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:30:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000008_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:30:09 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 13:30:20 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 13:30:23 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:30:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000021_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000021_0/part-00021 (inode 3605500): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000021_0_536106578_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:30:26 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 13:30:34 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 13:30:36 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 13:30:48 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:30:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000037_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:30:55 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 13:31:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000010_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000010_0/part-00010 (inode 3605502): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000010_0_-267104097_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:31:05 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 13:31:09 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 13:31:14 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 13:31:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000030_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000030_0/part-00030 (inode 3605498): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000030_0_1948827822_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:31:15 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 13:31:18 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 13:31:25 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 13:31:28 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 13:31:51 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 13:32:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000020_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000020_0/part-00020 (inode 3605508): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000020_0_-93552694_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:32:04 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 13:32:14 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 13:32:17 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 13:32:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000007_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000007_0/part-00007 (inode 3605506): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000007_0_-1177809086_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:32:20 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 13:32:23 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 13:32:29 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 13:32:38 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 13:32:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000015_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000015_0/part-00015 (inode 3605510): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000015_0_-35696700_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:32:55 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 13:32:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000038_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:33:00 INFO mapreduce.Job:  map 100% reduce 71%
15/04/11 13:33:07 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 13:33:10 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 13:33:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000018_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000018_0/part-00018 (inode 3605512): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000018_0_1814854434_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:33:12 INFO mapreduce.Job:  map 100% reduce 71%
15/04/11 13:33:16 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 13:33:22 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 13:33:28 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 13:33:39 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 13:34:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000033_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:34:55 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 13:35:00 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 13:35:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000011_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000011_0/part-00011 (inode 3605516): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000011_0_719819477_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:35:07 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 13:35:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000016_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000016_0/part-00016 (inode 3605514): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000016_0_1186894050_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:35:17 INFO mapreduce.Job:  map 100% reduce 71%
15/04/11 13:35:25 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 13:35:28 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 13:35:37 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 13:36:03 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 13:37:05 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 13:37:59 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:38:57 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 13:39:46 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 13:40:06 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 13:40:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000019_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(java.io.IOException): BP-1272212113-129.114.57.132-1408108439175:blk_1077936077_4195418 does not exist or is not under Constructionnull
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkUCBlock(FSNamesystem.java:5956)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updateBlockForPipeline(FSNamesystem.java:6023)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updateBlockForPipeline(NameNodeRpcServer.java:645)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:874)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:826)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:924)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:486)

15/04/11 13:40:19 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:40:28 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 13:40:34 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 13:40:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000036_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000036_0/part-00036 (inode 3605526): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000036_0_1764415685_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:40:45 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 13:40:56 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 13:41:00 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 13:41:07 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 13:41:38 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 13:42:12 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 13:43:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000004_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:43:01 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 13:43:11 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 13:43:25 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 13:43:43 INFO mapreduce.Job:  map 100% reduce 83%
15/04/11 13:44:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000014_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000014_0/part-00014 (inode 3605534): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000014_0_792165931_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:44:16 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 13:44:26 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 13:44:41 INFO mapreduce.Job:  map 100% reduce 83%
15/04/11 13:45:09 INFO mapreduce.Job:  map 100% reduce 84%
15/04/11 13:45:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000023_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000023_0/part-00023 (inode 3605536): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000023_0_-264391302_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:45:58 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 13:45:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000035_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:46:00 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 13:46:03 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 13:46:10 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 13:46:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000003_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:46:17 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 13:46:26 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 13:46:28 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 13:47:01 INFO mapreduce.Job:  map 100% reduce 83%
15/04/11 13:47:13 INFO mapreduce.Job:  map 100% reduce 84%
15/04/11 13:48:07 INFO mapreduce.Job:  map 100% reduce 85%
15/04/11 13:49:13 INFO mapreduce.Job:  map 100% reduce 86%
15/04/11 13:50:33 INFO mapreduce.Job:  map 100% reduce 87%
15/04/11 13:51:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000024_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(java.io.IOException): BP-1272212113-129.114.57.132-1408108439175:blk_1077936067_4195408 does not exist or is not under Constructionnull
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkUCBlock(FSNamesystem.java:5956)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updateBlockForPipeline(FSNamesystem.java:6023)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updateBlockForPipeline(NameNodeRpcServer.java:645)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:874)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:826)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:924)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:486)

15/04/11 13:51:47 INFO mapreduce.Job:  map 100% reduce 85%
15/04/11 13:51:58 INFO mapreduce.Job:  map 100% reduce 86%
15/04/11 13:52:14 INFO mapreduce.Job:  map 100% reduce 87%
15/04/11 13:52:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000012_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000012_0/part-00012 (inode 3605476): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000012_0_-1795391172_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:52:56 INFO mapreduce.Job:  map 100% reduce 85%
15/04/11 13:53:07 INFO mapreduce.Job:  map 100% reduce 86%
15/04/11 13:53:31 INFO mapreduce.Job:  map 100% reduce 87%
15/04/11 13:54:48 INFO mapreduce.Job:  map 100% reduce 88%
15/04/11 13:56:40 INFO mapreduce.Job:  map 100% reduce 89%
15/04/11 13:57:39 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 13:58:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000002_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 13:58:40 INFO mapreduce.Job:  map 100% reduce 89%
15/04/11 13:58:43 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 14:00:58 INFO mapreduce.Job:  map 100% reduce 91%
15/04/11 14:01:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000032_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4470_r_000032_0/part-00032 (inode 3605482): File does not exist. Holder DFSClient_attempt_1422482982071_4470_r_000032_0_149582667_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 14:01:30 INFO mapreduce.Job:  map 100% reduce 88%
15/04/11 14:01:41 INFO mapreduce.Job:  map 100% reduce 89%
15/04/11 14:02:07 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 14:03:09 INFO mapreduce.Job:  map 100% reduce 91%
15/04/11 14:04:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000026_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 14:04:26 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 14:04:55 INFO mapreduce.Job:  map 100% reduce 91%
15/04/11 14:09:57 INFO mapreduce.Job:  map 100% reduce 92%
15/04/11 14:12:58 INFO mapreduce.Job:  map 100% reduce 93%
15/04/11 14:16:18 INFO mapreduce.Job:  map 100% reduce 94%
15/04/11 14:19:34 INFO mapreduce.Job:  map 100% reduce 95%
15/04/11 14:24:48 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 14:29:12 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 14:30:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000001_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 14:30:26 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 14:31:13 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 14:37:42 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 15:09:33 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 15:24:02 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 15:33:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4470_r_000000_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 15:33:12 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 15:52:57 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 16:11:54 INFO mapreduce.Job: Job job_1422482982071_4470 completed successfully
15/04/11 16:11:54 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=30424216087
		FILE: Number of bytes written=60865113102
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=522
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Failed map tasks=15
		Failed reduce tasks=40
		Killed reduce tasks=8
		Launched map tasks=149
		Launched reduce tasks=88
		Other local map tasks=15
		Data-local map tasks=65
		Rack-local map tasks=69
		Total time spent by all maps in occupied slots (ms)=122833234
		Total time spent by all reduces in occupied slots (ms)=348048742
		Total time spent by all map tasks (ms)=61416617
		Total time spent by all reduce tasks (ms)=174024371
		Total vcore-seconds taken by all map tasks=61416617
		Total vcore-seconds taken by all reduce tasks=174024371
		Total megabyte-seconds taken by all map tasks=497228931232
		Total megabyte-seconds taken by all reduce tasks=2088292452000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424247953
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424247953
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =5360
		Failed Shuffles=0
		Merged Map outputs=5360
		GC time elapsed (ms)=266537
		CPU time spent (ms)=169553250
		Physical memory (bytes) snapshot=300300599296
		Virtual memory (bytes) snapshot=1764221677568
		Total committed heap usage (bytes)=455345467392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/11 16:11:54 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st

real	188m48.957s
user	0m38.859s
sys	0m7.709s
15/04/11 16:11:56 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 30
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-30-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3679225770893965416.jar tmpDir=null
15/04/11 16:11:59 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 16:11:59 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 16:12:00 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/11 16:12:00 INFO mapreduce.JobSubmitter: number of splits:134
15/04/11 16:12:01 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4472
15/04/11 16:12:01 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4472
15/04/11 16:12:01 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4472/
15/04/11 16:12:01 INFO mapreduce.Job: Running job: job_1422482982071_4472
15/04/11 16:12:08 INFO mapreduce.Job: Job job_1422482982071_4472 running in uber mode : false
15/04/11 16:12:08 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 16:12:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000028_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000001_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000066_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000051_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000125_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000015_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000082_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000060_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000076_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000023_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000093_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000086_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000101_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000133_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000121_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000112_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000114_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000066_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4472_m_000133_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 16:12:20 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 16:12:26 INFO mapreduce.Job:  map 2% reduce 0%
15/04/11 16:12:33 INFO mapreduce.Job:  map 3% reduce 0%
15/04/11 16:12:40 INFO mapreduce.Job:  map 4% reduce 0%
15/04/11 16:12:46 INFO mapreduce.Job:  map 5% reduce 0%
15/04/11 16:12:53 INFO mapreduce.Job:  map 6% reduce 0%
15/04/11 16:12:59 INFO mapreduce.Job:  map 7% reduce 0%
15/04/11 16:13:05 INFO mapreduce.Job:  map 8% reduce 0%
15/04/11 16:13:12 INFO mapreduce.Job:  map 9% reduce 0%
15/04/11 16:13:18 INFO mapreduce.Job:  map 10% reduce 0%
15/04/11 16:13:25 INFO mapreduce.Job:  map 11% reduce 0%
15/04/11 16:13:31 INFO mapreduce.Job:  map 12% reduce 0%
15/04/11 16:13:38 INFO mapreduce.Job:  map 13% reduce 0%
15/04/11 16:13:44 INFO mapreduce.Job:  map 14% reduce 0%
15/04/11 16:13:50 INFO mapreduce.Job:  map 15% reduce 0%
15/04/11 16:13:56 INFO mapreduce.Job:  map 16% reduce 0%
15/04/11 16:14:05 INFO mapreduce.Job:  map 17% reduce 0%
15/04/11 16:14:11 INFO mapreduce.Job:  map 18% reduce 0%
15/04/11 16:14:18 INFO mapreduce.Job:  map 19% reduce 0%
15/04/11 16:14:24 INFO mapreduce.Job:  map 20% reduce 0%
15/04/11 16:14:30 INFO mapreduce.Job:  map 21% reduce 0%
15/04/11 16:14:36 INFO mapreduce.Job:  map 22% reduce 0%
15/04/11 16:14:43 INFO mapreduce.Job:  map 23% reduce 0%
15/04/11 16:14:50 INFO mapreduce.Job:  map 24% reduce 0%
15/04/11 16:14:56 INFO mapreduce.Job:  map 25% reduce 0%
15/04/11 16:15:03 INFO mapreduce.Job:  map 26% reduce 0%
15/04/11 16:15:09 INFO mapreduce.Job:  map 27% reduce 0%
15/04/11 16:15:15 INFO mapreduce.Job:  map 28% reduce 0%
15/04/11 16:15:22 INFO mapreduce.Job:  map 29% reduce 0%
15/04/11 16:15:28 INFO mapreduce.Job:  map 30% reduce 0%
15/04/11 16:15:33 INFO mapreduce.Job:  map 31% reduce 0%
15/04/11 16:15:40 INFO mapreduce.Job:  map 32% reduce 0%
15/04/11 16:15:47 INFO mapreduce.Job:  map 33% reduce 0%
15/04/11 16:15:54 INFO mapreduce.Job:  map 34% reduce 0%
15/04/11 16:16:00 INFO mapreduce.Job:  map 35% reduce 0%
15/04/11 16:16:06 INFO mapreduce.Job:  map 36% reduce 0%
15/04/11 16:16:12 INFO mapreduce.Job:  map 37% reduce 0%
15/04/11 16:16:19 INFO mapreduce.Job:  map 38% reduce 0%
15/04/11 16:16:27 INFO mapreduce.Job:  map 39% reduce 0%
15/04/11 16:16:33 INFO mapreduce.Job:  map 40% reduce 0%
15/04/11 16:16:39 INFO mapreduce.Job:  map 41% reduce 0%
15/04/11 16:16:45 INFO mapreduce.Job:  map 42% reduce 0%
15/04/11 16:16:52 INFO mapreduce.Job:  map 43% reduce 0%
15/04/11 16:16:59 INFO mapreduce.Job:  map 44% reduce 0%
15/04/11 16:17:06 INFO mapreduce.Job:  map 45% reduce 0%
15/04/11 16:17:12 INFO mapreduce.Job:  map 46% reduce 0%
15/04/11 16:17:19 INFO mapreduce.Job:  map 47% reduce 0%
15/04/11 16:17:26 INFO mapreduce.Job:  map 48% reduce 0%
15/04/11 16:17:33 INFO mapreduce.Job:  map 49% reduce 0%
15/04/11 16:17:40 INFO mapreduce.Job:  map 50% reduce 0%
15/04/11 16:17:46 INFO mapreduce.Job:  map 51% reduce 0%
15/04/11 16:17:52 INFO mapreduce.Job:  map 52% reduce 0%
15/04/11 16:17:59 INFO mapreduce.Job:  map 53% reduce 0%
15/04/11 16:18:05 INFO mapreduce.Job:  map 54% reduce 0%
15/04/11 16:18:13 INFO mapreduce.Job:  map 55% reduce 0%
15/04/11 16:18:19 INFO mapreduce.Job:  map 56% reduce 0%
15/04/11 16:18:25 INFO mapreduce.Job:  map 57% reduce 0%
15/04/11 16:18:32 INFO mapreduce.Job:  map 58% reduce 0%
15/04/11 16:18:38 INFO mapreduce.Job:  map 59% reduce 0%
15/04/11 16:18:45 INFO mapreduce.Job:  map 60% reduce 0%
15/04/11 16:18:52 INFO mapreduce.Job:  map 61% reduce 0%
15/04/11 16:18:58 INFO mapreduce.Job:  map 62% reduce 0%
15/04/11 16:19:06 INFO mapreduce.Job:  map 63% reduce 0%
15/04/11 16:19:10 INFO mapreduce.Job:  map 64% reduce 0%
15/04/11 16:19:12 INFO mapreduce.Job:  map 65% reduce 0%
15/04/11 16:19:13 INFO mapreduce.Job:  map 66% reduce 0%
15/04/11 16:19:17 INFO mapreduce.Job:  map 67% reduce 0%
15/04/11 16:19:19 INFO mapreduce.Job:  map 68% reduce 0%
15/04/11 16:19:20 INFO mapreduce.Job:  map 70% reduce 0%
15/04/11 16:19:21 INFO mapreduce.Job:  map 71% reduce 0%
15/04/11 16:19:22 INFO mapreduce.Job:  map 72% reduce 6%
15/04/11 16:19:23 INFO mapreduce.Job:  map 73% reduce 7%
15/04/11 16:19:25 INFO mapreduce.Job:  map 74% reduce 9%
15/04/11 16:19:26 INFO mapreduce.Job:  map 75% reduce 9%
15/04/11 16:19:27 INFO mapreduce.Job:  map 75% reduce 10%
15/04/11 16:19:28 INFO mapreduce.Job:  map 76% reduce 11%
15/04/11 16:19:29 INFO mapreduce.Job:  map 77% reduce 11%
15/04/11 16:19:30 INFO mapreduce.Job:  map 78% reduce 12%
15/04/11 16:19:31 INFO mapreduce.Job:  map 78% reduce 13%
15/04/11 16:19:32 INFO mapreduce.Job:  map 79% reduce 14%
15/04/11 16:19:33 INFO mapreduce.Job:  map 80% reduce 14%
15/04/11 16:19:34 INFO mapreduce.Job:  map 80% reduce 15%
15/04/11 16:19:37 INFO mapreduce.Job:  map 81% reduce 15%
15/04/11 16:19:38 INFO mapreduce.Job:  map 81% reduce 16%
15/04/11 16:19:39 INFO mapreduce.Job:  map 82% reduce 16%
15/04/11 16:19:41 INFO mapreduce.Job:  map 82% reduce 17%
15/04/11 16:19:46 INFO mapreduce.Job:  map 83% reduce 17%
15/04/11 16:19:56 INFO mapreduce.Job:  map 84% reduce 17%
15/04/11 16:20:02 INFO mapreduce.Job:  map 84% reduce 18%
15/04/11 16:20:04 INFO mapreduce.Job:  map 85% reduce 18%
15/04/11 16:20:07 INFO mapreduce.Job:  map 86% reduce 19%
15/04/11 16:20:10 INFO mapreduce.Job:  map 87% reduce 20%
15/04/11 16:20:12 INFO mapreduce.Job:  map 89% reduce 21%
15/04/11 16:20:14 INFO mapreduce.Job:  map 89% reduce 22%
15/04/11 16:20:15 INFO mapreduce.Job:  map 90% reduce 22%
15/04/11 16:20:16 INFO mapreduce.Job:  map 91% reduce 22%
15/04/11 16:20:17 INFO mapreduce.Job:  map 92% reduce 23%
15/04/11 16:20:18 INFO mapreduce.Job:  map 93% reduce 24%
15/04/11 16:20:20 INFO mapreduce.Job:  map 94% reduce 25%
15/04/11 16:20:21 INFO mapreduce.Job:  map 94% reduce 26%
15/04/11 16:20:22 INFO mapreduce.Job:  map 95% reduce 26%
15/04/11 16:20:24 INFO mapreduce.Job:  map 95% reduce 27%
15/04/11 16:20:27 INFO mapreduce.Job:  map 96% reduce 28%
15/04/11 16:20:30 INFO mapreduce.Job:  map 97% reduce 28%
15/04/11 16:20:33 INFO mapreduce.Job:  map 98% reduce 29%
15/04/11 16:20:35 INFO mapreduce.Job:  map 99% reduce 30%
15/04/11 16:20:37 INFO mapreduce.Job:  map 99% reduce 31%
15/04/11 16:20:38 INFO mapreduce.Job:  map 100% reduce 31%
15/04/11 16:20:42 INFO mapreduce.Job:  map 100% reduce 32%
15/04/11 16:20:46 INFO mapreduce.Job:  map 100% reduce 33%
15/04/11 16:20:52 INFO mapreduce.Job:  map 100% reduce 34%
15/04/11 16:20:54 INFO mapreduce.Job:  map 100% reduce 36%
15/04/11 16:20:55 INFO mapreduce.Job:  map 100% reduce 39%
15/04/11 16:20:56 INFO mapreduce.Job:  map 100% reduce 40%
15/04/11 16:20:57 INFO mapreduce.Job:  map 100% reduce 42%
15/04/11 16:20:58 INFO mapreduce.Job:  map 100% reduce 45%
15/04/11 16:21:00 INFO mapreduce.Job:  map 100% reduce 47%
15/04/11 16:21:01 INFO mapreduce.Job:  map 100% reduce 51%
15/04/11 16:21:03 INFO mapreduce.Job:  map 100% reduce 53%
15/04/11 16:21:04 INFO mapreduce.Job:  map 100% reduce 57%
15/04/11 16:21:05 INFO mapreduce.Job:  map 100% reduce 58%
15/04/11 16:21:06 INFO mapreduce.Job:  map 100% reduce 59%
15/04/11 16:21:07 INFO mapreduce.Job:  map 100% reduce 62%
15/04/11 16:21:09 INFO mapreduce.Job:  map 100% reduce 63%
15/04/11 16:21:10 INFO mapreduce.Job:  map 100% reduce 65%
15/04/11 16:21:13 INFO mapreduce.Job:  map 100% reduce 66%
15/04/11 16:21:17 INFO mapreduce.Job:  map 100% reduce 67%
15/04/11 16:23:00 INFO mapreduce.Job:  map 100% reduce 68%
15/04/11 16:24:14 INFO mapreduce.Job:  map 100% reduce 69%
15/04/11 16:25:40 INFO mapreduce.Job:  map 100% reduce 70%
15/04/11 16:27:12 INFO mapreduce.Job:  map 100% reduce 71%
15/04/11 16:28:35 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 16:30:03 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 16:31:15 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 16:32:11 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 16:33:02 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 16:34:12 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 16:35:17 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 16:36:08 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 16:37:20 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 16:38:06 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 16:39:14 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 16:40:02 INFO mapreduce.Job:  map 100% reduce 83%
15/04/11 16:41:28 INFO mapreduce.Job:  map 100% reduce 84%
15/04/11 16:42:04 INFO mapreduce.Job:  map 100% reduce 85%
15/04/11 16:42:57 INFO mapreduce.Job:  map 100% reduce 86%
15/04/11 16:43:50 INFO mapreduce.Job:  map 100% reduce 87%
15/04/11 16:45:26 INFO mapreduce.Job:  map 100% reduce 88%
15/04/11 16:46:56 INFO mapreduce.Job:  map 100% reduce 89%
15/04/11 16:48:15 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 16:49:03 INFO mapreduce.Job:  map 100% reduce 91%
15/04/11 16:50:09 INFO mapreduce.Job:  map 100% reduce 92%
15/04/11 16:52:21 INFO mapreduce.Job:  map 100% reduce 93%
15/04/11 16:58:11 INFO mapreduce.Job:  map 100% reduce 94%
15/04/11 17:02:27 INFO mapreduce.Job:  map 100% reduce 95%
15/04/11 17:07:35 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 17:24:25 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 17:28:32 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 17:50:41 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 18:30:19 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 18:53:17 INFO mapreduce.Job: Job job_1422482982071_4472 completed successfully
15/04/11 18:53:17 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=30424216039
		FILE: Number of bytes written=60864123644
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4732772
		HDFS: Number of read operations=492
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Failed map tasks=22
		Killed reduce tasks=2
		Launched map tasks=156
		Launched reduce tasks=32
		Other local map tasks=22
		Data-local map tasks=67
		Rack-local map tasks=67
		Total time spent by all maps in occupied slots (ms)=122851666
		Total time spent by all reduces in occupied slots (ms)=173650520
		Total time spent by all map tasks (ms)=61425833
		Total time spent by all reduce tasks (ms)=86825260
		Total vcore-seconds taken by all map tasks=61425833
		Total vcore-seconds taken by all reduce tasks=86825260
		Total megabyte-seconds taken by all map tasks=497303543968
		Total megabyte-seconds taken by all reduce tasks=1041903120000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130842760
		Map output bytes=24162530273
		Map output materialized bytes=30424239913
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=325361
		Reduce shuffle bytes=30424239913
		Reduce input records=3130842760
		Reduce output records=325361
		Spilled Records=6261685520
		Shuffled Maps =4020
		Failed Shuffles=0
		Merged Map outputs=4020
		GC time elapsed (ms)=347042
		CPU time spent (ms)=164822600
		Physical memory (bytes) snapshot=297748414464
		Virtual memory (bytes) snapshot=1632380067840
		Total committed heap usage (bytes)=434293575680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4732772
15/04/11 18:53:17 INFO streaming.StreamJob: Output directory: ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st

real	161m23.339s
user	0m36.275s
sys	0m6.698s
15/04/11 18:53:20 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 30
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-30-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7860273577664970729.jar tmpDir=null
15/04/11 18:53:23 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 18:53:23 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 18:53:24 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/11 18:53:24 INFO mapreduce.JobSubmitter: number of splits:134
15/04/11 18:53:25 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4473
15/04/11 18:53:25 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4473
15/04/11 18:53:25 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4473/
15/04/11 18:53:25 INFO mapreduce.Job: Running job: job_1422482982071_4473
15/04/11 18:53:31 INFO mapreduce.Job: Job job_1422482982071_4473 running in uber mode : false
15/04/11 18:53:31 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 18:53:36 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 18:53:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000082_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000025_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000007_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000041_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000017_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000056_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000031_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000050_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000046_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:38 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 18:53:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000093_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000059_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000066_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/11 18:53:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000104_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000071_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000067_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000080_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000069_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000090_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000114_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000015_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/11 18:53:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000056_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000031_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000114_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:43 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 18:53:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4473_m_000031_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:53:49 INFO mapreduce.Job:  map 2% reduce 0%
15/04/11 18:53:51 INFO mapreduce.Job:  map 85% reduce 100%
15/04/11 18:53:52 INFO mapreduce.Job:  map 100% reduce 100%
15/04/11 18:53:52 INFO mapreduce.Job: Job job_1422482982071_4473 failed with state FAILED due to: Task failed task_1422482982071_4473_m_000031
Job failed as tasks failed. failedMaps:1 failedReduces:0

15/04/11 18:53:52 INFO mapreduce.Job: Counters: 14
	Job Counters 
		Failed map tasks=26
		Killed map tasks=133
		Launched map tasks=159
		Other local map tasks=25
		Data-local map tasks=65
		Rack-local map tasks=69
		Total time spent by all maps in occupied slots (ms)=4530090
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=2265045
		Total vcore-seconds taken by all map tasks=2265045
		Total megabyte-seconds taken by all map tasks=18337804320
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
15/04/11 18:53:52 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	0m34.509s
user	0m12.229s
sys	0m0.689s
15/04/11 18:53:54 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 30
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-30-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=30 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4480768136743433463.jar tmpDir=null
15/04/11 18:53:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 18:53:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/11 18:53:57 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/11 18:53:58 INFO mapreduce.JobSubmitter: number of splits:134
15/04/11 18:53:58 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4474
15/04/11 18:53:58 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4474
15/04/11 18:53:58 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4474/
15/04/11 18:53:58 INFO mapreduce.Job: Running job: job_1422482982071_4474
15/04/11 18:54:05 INFO mapreduce.Job: Job job_1422482982071_4474 running in uber mode : false
15/04/11 18:54:05 INFO mapreduce.Job:  map 0% reduce 0%
15/04/11 18:54:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_m_000048_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:54:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_m_000044_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:54:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_m_000062_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:54:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_m_000090_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:54:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_m_000021_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:54:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_m_000033_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:54:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_m_000079_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:54:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_m_000119_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:54:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_m_000124_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:54:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_m_000130_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:54:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_m_000114_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:54:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_m_000130_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:54:17 INFO mapreduce.Job:  map 1% reduce 0%
15/04/11 18:54:23 INFO mapreduce.Job:  map 2% reduce 0%
15/04/11 18:54:29 INFO mapreduce.Job:  map 3% reduce 0%
15/04/11 18:54:35 INFO mapreduce.Job:  map 4% reduce 0%
15/04/11 18:54:43 INFO mapreduce.Job:  map 5% reduce 0%
15/04/11 18:54:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_m_000083_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 18:54:49 INFO mapreduce.Job:  map 6% reduce 0%
15/04/11 18:54:56 INFO mapreduce.Job:  map 7% reduce 0%
15/04/11 18:55:02 INFO mapreduce.Job:  map 8% reduce 0%
15/04/11 18:55:08 INFO mapreduce.Job:  map 9% reduce 0%
15/04/11 18:55:15 INFO mapreduce.Job:  map 10% reduce 0%
15/04/11 18:55:21 INFO mapreduce.Job:  map 11% reduce 0%
15/04/11 18:55:28 INFO mapreduce.Job:  map 12% reduce 0%
15/04/11 18:55:35 INFO mapreduce.Job:  map 13% reduce 0%
15/04/11 18:55:42 INFO mapreduce.Job:  map 14% reduce 0%
15/04/11 18:55:48 INFO mapreduce.Job:  map 15% reduce 0%
15/04/11 18:55:54 INFO mapreduce.Job:  map 16% reduce 0%
15/04/11 18:56:01 INFO mapreduce.Job:  map 17% reduce 0%
15/04/11 18:56:08 INFO mapreduce.Job:  map 18% reduce 0%
15/04/11 18:56:15 INFO mapreduce.Job:  map 19% reduce 0%
15/04/11 18:56:21 INFO mapreduce.Job:  map 20% reduce 0%
15/04/11 18:56:27 INFO mapreduce.Job:  map 21% reduce 0%
15/04/11 18:56:33 INFO mapreduce.Job:  map 22% reduce 0%
15/04/11 18:56:39 INFO mapreduce.Job:  map 23% reduce 0%
15/04/11 18:56:46 INFO mapreduce.Job:  map 24% reduce 0%
15/04/11 18:56:51 INFO mapreduce.Job:  map 25% reduce 0%
15/04/11 18:56:57 INFO mapreduce.Job:  map 26% reduce 0%
15/04/11 18:57:04 INFO mapreduce.Job:  map 27% reduce 0%
15/04/11 18:57:12 INFO mapreduce.Job:  map 28% reduce 0%
15/04/11 18:57:18 INFO mapreduce.Job:  map 29% reduce 0%
15/04/11 18:57:24 INFO mapreduce.Job:  map 30% reduce 0%
15/04/11 18:57:30 INFO mapreduce.Job:  map 31% reduce 0%
15/04/11 18:57:37 INFO mapreduce.Job:  map 32% reduce 0%
15/04/11 18:57:45 INFO mapreduce.Job:  map 33% reduce 0%
15/04/11 18:57:51 INFO mapreduce.Job:  map 34% reduce 0%
15/04/11 18:57:57 INFO mapreduce.Job:  map 35% reduce 0%
15/04/11 18:58:03 INFO mapreduce.Job:  map 36% reduce 0%
15/04/11 18:58:10 INFO mapreduce.Job:  map 37% reduce 0%
15/04/11 18:58:18 INFO mapreduce.Job:  map 38% reduce 0%
15/04/11 18:58:24 INFO mapreduce.Job:  map 39% reduce 0%
15/04/11 18:58:30 INFO mapreduce.Job:  map 40% reduce 0%
15/04/11 18:58:37 INFO mapreduce.Job:  map 41% reduce 0%
15/04/11 18:58:44 INFO mapreduce.Job:  map 42% reduce 0%
15/04/11 18:58:52 INFO mapreduce.Job:  map 43% reduce 0%
15/04/11 18:58:58 INFO mapreduce.Job:  map 44% reduce 0%
15/04/11 18:59:04 INFO mapreduce.Job:  map 45% reduce 0%
15/04/11 18:59:11 INFO mapreduce.Job:  map 46% reduce 0%
15/04/11 18:59:17 INFO mapreduce.Job:  map 47% reduce 0%
15/04/11 18:59:25 INFO mapreduce.Job:  map 48% reduce 0%
15/04/11 18:59:31 INFO mapreduce.Job:  map 49% reduce 0%
15/04/11 18:59:37 INFO mapreduce.Job:  map 50% reduce 0%
15/04/11 18:59:43 INFO mapreduce.Job:  map 51% reduce 0%
15/04/11 18:59:50 INFO mapreduce.Job:  map 52% reduce 0%
15/04/11 18:59:57 INFO mapreduce.Job:  map 53% reduce 0%
15/04/11 19:00:04 INFO mapreduce.Job:  map 54% reduce 0%
15/04/11 19:00:10 INFO mapreduce.Job:  map 55% reduce 0%
15/04/11 19:00:16 INFO mapreduce.Job:  map 56% reduce 0%
15/04/11 19:00:23 INFO mapreduce.Job:  map 57% reduce 0%
15/04/11 19:00:31 INFO mapreduce.Job:  map 58% reduce 0%
15/04/11 19:00:37 INFO mapreduce.Job:  map 59% reduce 0%
15/04/11 19:00:43 INFO mapreduce.Job:  map 60% reduce 0%
15/04/11 19:00:50 INFO mapreduce.Job:  map 61% reduce 0%
15/04/11 19:00:56 INFO mapreduce.Job:  map 62% reduce 0%
15/04/11 19:01:04 INFO mapreduce.Job:  map 63% reduce 0%
15/04/11 19:01:08 INFO mapreduce.Job:  map 64% reduce 0%
15/04/11 19:01:11 INFO mapreduce.Job:  map 65% reduce 0%
15/04/11 19:01:12 INFO mapreduce.Job:  map 66% reduce 0%
15/04/11 19:01:16 INFO mapreduce.Job:  map 68% reduce 0%
15/04/11 19:01:17 INFO mapreduce.Job:  map 69% reduce 0%
15/04/11 19:01:18 INFO mapreduce.Job:  map 70% reduce 0%
15/04/11 19:01:19 INFO mapreduce.Job:  map 71% reduce 0%
15/04/11 19:01:20 INFO mapreduce.Job:  map 72% reduce 0%
15/04/11 19:01:21 INFO mapreduce.Job:  map 72% reduce 6%
15/04/11 19:01:22 INFO mapreduce.Job:  map 73% reduce 8%
15/04/11 19:01:23 INFO mapreduce.Job:  map 74% reduce 8%
15/04/11 19:01:24 INFO mapreduce.Job:  map 75% reduce 9%
15/04/11 19:01:25 INFO mapreduce.Job:  map 76% reduce 10%
15/04/11 19:01:26 INFO mapreduce.Job:  map 76% reduce 11%
15/04/11 19:01:27 INFO mapreduce.Job:  map 77% reduce 12%
15/04/11 19:01:28 INFO mapreduce.Job:  map 78% reduce 13%
15/04/11 19:01:30 INFO mapreduce.Job:  map 79% reduce 14%
15/04/11 19:01:34 INFO mapreduce.Job:  map 80% reduce 15%
15/04/11 19:01:35 INFO mapreduce.Job:  map 81% reduce 15%
15/04/11 19:01:36 INFO mapreduce.Job:  map 81% reduce 16%
15/04/11 19:01:40 INFO mapreduce.Job:  map 82% reduce 16%
15/04/11 19:01:46 INFO mapreduce.Job:  map 82% reduce 17%
15/04/11 19:01:51 INFO mapreduce.Job:  map 83% reduce 17%
15/04/11 19:02:00 INFO mapreduce.Job:  map 84% reduce 17%
15/04/11 19:02:03 INFO mapreduce.Job:  map 85% reduce 18%
15/04/11 19:02:07 INFO mapreduce.Job:  map 86% reduce 19%
15/04/11 19:02:09 INFO mapreduce.Job:  map 87% reduce 19%
15/04/11 19:02:10 INFO mapreduce.Job:  map 88% reduce 20%
15/04/11 19:02:12 INFO mapreduce.Job:  map 89% reduce 21%
15/04/11 19:02:13 INFO mapreduce.Job:  map 90% reduce 21%
15/04/11 19:02:14 INFO mapreduce.Job:  map 91% reduce 22%
15/04/11 19:02:15 INFO mapreduce.Job:  map 92% reduce 24%
15/04/11 19:02:17 INFO mapreduce.Job:  map 93% reduce 25%
15/04/11 19:02:19 INFO mapreduce.Job:  map 94% reduce 25%
15/04/11 19:02:20 INFO mapreduce.Job:  map 94% reduce 26%
15/04/11 19:02:21 INFO mapreduce.Job:  map 95% reduce 27%
15/04/11 19:02:24 INFO mapreduce.Job:  map 96% reduce 27%
15/04/11 19:02:25 INFO mapreduce.Job:  map 96% reduce 28%
15/04/11 19:02:27 INFO mapreduce.Job:  map 97% reduce 28%
15/04/11 19:02:29 INFO mapreduce.Job:  map 97% reduce 29%
15/04/11 19:02:32 INFO mapreduce.Job:  map 98% reduce 29%
15/04/11 19:02:34 INFO mapreduce.Job:  map 98% reduce 30%
15/04/11 19:02:40 INFO mapreduce.Job:  map 98% reduce 31%
15/04/11 19:02:41 INFO mapreduce.Job:  map 99% reduce 31%
15/04/11 19:02:42 INFO mapreduce.Job:  map 99% reduce 32%
15/04/11 19:02:47 INFO mapreduce.Job:  map 100% reduce 33%
15/04/11 19:03:07 INFO mapreduce.Job:  map 100% reduce 34%
15/04/11 19:03:08 INFO mapreduce.Job:  map 100% reduce 35%
15/04/11 19:03:09 INFO mapreduce.Job:  map 100% reduce 37%
15/04/11 19:03:10 INFO mapreduce.Job:  map 100% reduce 39%
15/04/11 19:03:11 INFO mapreduce.Job:  map 100% reduce 42%
15/04/11 19:03:12 INFO mapreduce.Job:  map 100% reduce 43%
15/04/11 19:03:13 INFO mapreduce.Job:  map 100% reduce 44%
15/04/11 19:03:14 INFO mapreduce.Job:  map 100% reduce 47%
15/04/11 19:03:15 INFO mapreduce.Job:  map 100% reduce 48%
15/04/11 19:03:16 INFO mapreduce.Job:  map 100% reduce 50%
15/04/11 19:03:17 INFO mapreduce.Job:  map 100% reduce 53%
15/04/11 19:03:18 INFO mapreduce.Job:  map 100% reduce 54%
15/04/11 19:03:19 INFO mapreduce.Job:  map 100% reduce 56%
15/04/11 19:03:20 INFO mapreduce.Job:  map 100% reduce 58%
15/04/11 19:03:21 INFO mapreduce.Job:  map 100% reduce 59%
15/04/11 19:03:22 INFO mapreduce.Job:  map 100% reduce 61%
15/04/11 19:03:23 INFO mapreduce.Job:  map 100% reduce 62%
15/04/11 19:03:24 INFO mapreduce.Job:  map 100% reduce 63%
15/04/11 19:03:25 INFO mapreduce.Job:  map 100% reduce 64%
15/04/11 19:03:26 INFO mapreduce.Job:  map 100% reduce 65%
15/04/11 19:03:27 INFO mapreduce.Job:  map 100% reduce 66%
15/04/11 19:03:32 INFO mapreduce.Job:  map 100% reduce 67%
15/04/11 19:05:16 INFO mapreduce.Job:  map 100% reduce 68%
15/04/11 19:06:33 INFO mapreduce.Job:  map 100% reduce 69%
15/04/11 19:08:00 INFO mapreduce.Job:  map 100% reduce 70%
15/04/11 19:09:29 INFO mapreduce.Job:  map 100% reduce 71%
15/04/11 19:11:00 INFO mapreduce.Job:  map 100% reduce 72%
15/04/11 19:12:03 INFO mapreduce.Job:  map 100% reduce 73%
15/04/11 19:13:29 INFO mapreduce.Job:  map 100% reduce 74%
15/04/11 19:14:24 INFO mapreduce.Job:  map 100% reduce 75%
15/04/11 19:15:25 INFO mapreduce.Job:  map 100% reduce 76%
15/04/11 19:16:29 INFO mapreduce.Job:  map 100% reduce 77%
15/04/11 19:17:40 INFO mapreduce.Job:  map 100% reduce 78%
15/04/11 19:18:26 INFO mapreduce.Job:  map 100% reduce 79%
15/04/11 19:19:36 INFO mapreduce.Job:  map 100% reduce 80%
15/04/11 19:20:22 INFO mapreduce.Job:  map 100% reduce 81%
15/04/11 19:21:15 INFO mapreduce.Job:  map 100% reduce 82%
15/04/11 19:22:21 INFO mapreduce.Job:  map 100% reduce 83%
15/04/11 19:23:23 INFO mapreduce.Job:  map 100% reduce 84%
15/04/11 19:24:19 INFO mapreduce.Job:  map 100% reduce 85%
15/04/11 19:25:20 INFO mapreduce.Job:  map 100% reduce 86%
15/04/11 19:26:16 INFO mapreduce.Job:  map 100% reduce 87%
15/04/11 19:27:29 INFO mapreduce.Job:  map 100% reduce 88%
15/04/11 19:28:56 INFO mapreduce.Job:  map 100% reduce 89%
15/04/11 19:30:02 INFO mapreduce.Job:  map 100% reduce 90%
15/04/11 19:30:58 INFO mapreduce.Job:  map 100% reduce 91%
15/04/11 19:32:25 INFO mapreduce.Job:  map 100% reduce 92%
15/04/11 19:34:45 INFO mapreduce.Job:  map 100% reduce 93%
15/04/11 19:39:26 INFO mapreduce.Job:  map 100% reduce 94%
15/04/11 19:44:13 INFO mapreduce.Job:  map 100% reduce 95%
15/04/11 19:48:49 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 20:05:52 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 20:11:47 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 20:34:20 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 20:47:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_r_000022_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4474_r_000022_0/part-00022 (inode 3606059): File does not exist. Holder DFSClient_attempt_1422482982071_4474_r_000022_0_-1643154682_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 20:47:32 INFO mapreduce.Job:  map 100% reduce 96%
15/04/11 20:48:14 INFO mapreduce.Job:  map 100% reduce 97%
15/04/11 20:48:48 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 21:13:29 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 21:18:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_r_000020_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 21:18:25 INFO mapreduce.Job:  map 100% reduce 98%
15/04/11 22:07:01 INFO mapreduce.Job:  map 100% reduce 99%
15/04/11 22:22:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_r_000020_1, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:237)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/11 23:38:44 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 00:02:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4474_r_000020_2, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/dotcz12/out/stream-r-0-googlebooks-eng-all-5gram-20120701-st/_temporary/1/_temporary/attempt_1422482982071_4474_r_000020_2/part-00020 (inode 3606223): File does not exist. Holder DFSClient_attempt_1422482982071_4474_r_000020_2_-1181554128_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2991)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3077)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3047)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:628)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1362)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:406)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:108)
	at org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.close(ReduceTask.java:502)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:456)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 00:02:51 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 00:57:21 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 01:02:37 INFO mapreduce.Job: Job job_1422482982071_4474 failed with state FAILED due to: Task failed task_1422482982071_4474_r_000020
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 01:02:37 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=27870737975
		FILE: Number of bytes written=58310515005
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=4575386
		HDFS: Number of read operations=489
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=58
	Job Counters 
		Failed map tasks=13
		Failed reduce tasks=5
		Killed reduce tasks=2
		Launched map tasks=147
		Launched reduce tasks=36
		Other local map tasks=13
		Data-local map tasks=61
		Rack-local map tasks=73
		Total time spent by all maps in occupied slots (ms)=123249668
		Total time spent by all reduces in occupied slots (ms)=231990572
		Total time spent by all map tasks (ms)=61624834
		Total time spent by all reduce tasks (ms)=115995286
		Total vcore-seconds taken by all map tasks=61624834
		Total vcore-seconds taken by all reduce tasks=115995286
		Total megabyte-seconds taken by all map tasks=498914656064
		Total megabyte-seconds taken by all reduce tasks=1391943432000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=3130839696
		Map output bytes=24162500747
		Map output materialized bytes=30424204259
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=314584
		Reduce shuffle bytes=27870761063
		Reduce input records=2755769769
		Reduce output records=314584
		Spilled Records=5886609465
		Shuffled Maps =3886
		Failed Shuffles=0
		Merged Map outputs=3886
		GC time elapsed (ms)=312784
		CPU time spent (ms)=154965750
		Physical memory (bytes) snapshot=295373176832
		Virtual memory (bytes) snapshot=1616476569600
		Total committed heap usage (bytes)=432187441152
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=4575386
15/04/12 01:02:37 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	368m45.314s
user	0m52.306s
sys	0m15.121s
15/04/12 01:02:39 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 20
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-20-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2239159799889263793.jar tmpDir=null
15/04/12 01:02:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:02:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:02:43 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 01:02:46 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 01:02:46 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4477
15/04/12 01:02:47 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4477
15/04/12 01:02:47 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4477/
15/04/12 01:02:47 INFO mapreduce.Job: Running job: job_1422482982071_4477
15/04/12 01:02:53 INFO mapreduce.Job: Job job_1422482982071_4477 running in uber mode : false
15/04/12 01:02:53 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 01:02:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000044_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000051_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000097_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000026_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000084_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000096_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000001_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000053_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000031_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000060_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000007_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000092_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000125_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000027_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 01:02:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000113_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000059_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:02:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000111_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000090_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000010_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000104_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000082_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000094_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:05 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 01:03:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000096_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000001_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000010_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000000_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000125_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:12 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 01:03:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000125_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000009_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000069_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000019_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000121_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000091_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000041_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000070_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000052_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000017_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000120_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:20 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 01:03:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000111_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000060_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000070_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000019_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000090_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:29 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 01:03:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000057_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000112_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000057_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000097_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000062_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000021_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:39 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:03:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000098_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000106_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000068_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000110_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4477_m_000094_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:03:44 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 01:03:48 INFO mapreduce.Job: Job job_1422482982071_4477 failed with state FAILED due to: Task failed task_1422482982071_4477_m_000125
Job failed as tasks failed. failedMaps:1 failedReduces:0

15/04/12 01:03:48 INFO mapreduce.Job: Counters: 14
	Job Counters 
		Failed map tasks=61
		Killed map tasks=131
		Launched map tasks=192
		Other local map tasks=58
		Data-local map tasks=62
		Rack-local map tasks=72
		Total time spent by all maps in occupied slots (ms)=12653224
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=6326612
		Total vcore-seconds taken by all map tasks=6326612
		Total megabyte-seconds taken by all map tasks=51220250752
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
15/04/12 01:03:48 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	1m10.556s
user	0m10.116s
sys	0m0.722s
15/04/12 01:03:50 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 20
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-20-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5372491901240494785.jar tmpDir=null
15/04/12 01:03:52 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:03:53 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:03:53 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 01:03:55 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 01:03:55 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4478
15/04/12 01:03:56 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4478
15/04/12 01:03:56 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4478/
15/04/12 01:03:56 INFO mapreduce.Job: Running job: job_1422482982071_4478
15/04/12 01:04:07 INFO mapreduce.Job: Job job_1422482982071_4478 running in uber mode : false
15/04/12 01:04:07 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 01:04:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000005_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 01:04:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000010_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000068_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000047_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000090_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000094_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000125_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000058_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000083_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000054_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000075_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000118_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000133_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000018_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000128_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000096_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000078_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000050_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000112_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:16 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 01:04:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000001_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000053_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000063_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000030_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000115_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000079_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:17 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 01:04:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000017_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000106_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000114_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000042_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000108_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000052_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 01:04:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000120_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000073_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000102_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000061_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000075_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000108_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:22 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 01:04:23 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000073_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000075_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000073_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000057_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:29 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 01:04:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000000_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000005_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000056_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000100_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:36 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 01:04:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000050_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000043_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000042_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000053_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:46 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 01:04:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000023_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000116_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000072_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:55 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:04:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000063_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000117_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000125_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000020_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:04:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000050_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:01 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 01:05:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000067_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000113_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000081_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000069_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000015_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000090_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:12 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 01:05:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000065_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:14 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 01:05:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000017_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000081_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:15 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 01:05:19 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 01:05:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000082_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000007_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000113_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:28 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 01:05:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000132_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000030_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:31 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 01:05:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000042_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000053_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000028_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:33 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 01:05:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000123_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:37 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 01:05:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000049_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000117_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000000_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000054_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000090_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000113_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:47 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 01:05:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000000_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4478_m_000030_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:05:52 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 01:05:56 INFO mapreduce.Job: Job job_1422482982071_4478 failed with state FAILED due to: Task failed task_1422482982071_4478_m_000042
Job failed as tasks failed. failedMaps:1 failedReduces:0

15/04/12 01:05:56 INFO mapreduce.Job: Counters: 14
	Job Counters 
		Failed map tasks=90
		Killed map tasks=132
		Launched map tasks=222
		Other local map tasks=88
		Data-local map tasks=68
		Rack-local map tasks=66
		Total time spent by all maps in occupied slots (ms)=26937080
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=13468540
		Total vcore-seconds taken by all map tasks=13468540
		Total megabyte-seconds taken by all map tasks=109041299840
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
15/04/12 01:05:56 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	2m8.557s
user	0m11.559s
sys	0m0.657s
15/04/12 01:05:59 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 20
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-20-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=20 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2948707934737317650.jar tmpDir=null
15/04/12 01:06:01 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:06:02 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:06:04 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 01:06:15 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 01:06:15 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4479
15/04/12 01:06:16 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4479
15/04/12 01:06:16 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4479/
15/04/12 01:06:16 INFO mapreduce.Job: Running job: job_1422482982071_4479
15/04/12 01:06:23 INFO mapreduce.Job: Job job_1422482982071_4479 running in uber mode : false
15/04/12 01:06:23 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 01:06:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000049_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000009_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000059_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000053_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000004_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000051_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000086_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 01:06:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000035_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 01:06:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000033_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000077_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 01:06:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000126_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000042_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000107_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000092_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000017_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000093_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000038_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000099_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000117_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000030_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000079_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000027_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000059_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:36 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 01:06:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000009_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000126_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000035_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000012_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000092_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000059_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000036_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000079_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4479_m_000009_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:06:43 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 01:06:52 INFO mapreduce.Job: Job job_1422482982071_4479 failed with state FAILED due to: Task failed task_1422482982071_4479_m_000059
Job failed as tasks failed. failedMaps:1 failedReduces:0

15/04/12 01:06:54 INFO mapreduce.Job: Counters: 14
	Job Counters 
		Failed map tasks=36
		Killed map tasks=130
		Launched map tasks=166
		Other local map tasks=32
		Data-local map tasks=62
		Rack-local map tasks=72
		Total time spent by all maps in occupied slots (ms)=4329394
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=2164697
		Total vcore-seconds taken by all map tasks=2164697
		Total megabyte-seconds taken by all map tasks=17525386912
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
15/04/12 01:06:54 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	0m57.727s
user	0m11.075s
sys	0m0.643s
15/04/12 01:06:57 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 10
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-10-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5121529985198165027.jar tmpDir=null
15/04/12 01:07:00 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:07:00 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:07:01 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 01:07:03 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 01:07:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4480
15/04/12 01:07:08 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4480
15/04/12 01:07:08 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4480/
15/04/12 01:07:08 INFO mapreduce.Job: Running job: job_1422482982071_4480
15/04/12 01:07:14 INFO mapreduce.Job: Job job_1422482982071_4480 running in uber mode : false
15/04/12 01:07:14 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 01:07:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000036_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000027_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000044_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000037_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000093_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000105_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000098_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000104_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000120_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000109_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000024_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000045_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000054_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000113_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000048_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000123_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000092_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000082_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000021_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000111_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000036_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:31 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 01:07:34 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 01:07:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000048_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000113_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000111_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000009_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000047_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000023_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000121_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000081_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000107_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000108_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000011_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000014_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000099_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000097_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000049_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:44 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 01:07:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000111_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000123_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000082_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000024_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000040_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000017_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000007_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000101_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:53 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 01:07:53 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000021_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:53 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000060_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000086_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000028_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000133_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:07:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000066_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000072_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000058_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000022_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000050_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000094_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000056_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000107_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000121_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:04 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:08:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000096_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000052_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000088_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4480_m_000132_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:10 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 01:08:14 INFO mapreduce.Job: Job job_1422482982071_4480 failed with state FAILED due to: Task failed task_1422482982071_4480_m_000111
Job failed as tasks failed. failedMaps:1 failedReduces:0

15/04/12 01:08:14 INFO mapreduce.Job: Counters: 14
	Job Counters 
		Failed map tasks=67
		Killed map tasks=130
		Launched map tasks=197
		Other local map tasks=63
		Data-local map tasks=62
		Rack-local map tasks=72
		Total time spent by all maps in occupied slots (ms)=13679568
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=6839784
		Total vcore-seconds taken by all map tasks=6839784
		Total megabyte-seconds taken by all map tasks=55374891264
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
15/04/12 01:08:14 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	1m20.237s
user	0m11.377s
sys	0m0.811s
15/04/12 01:08:17 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 10
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-10-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7435277114732398063.jar tmpDir=null
15/04/12 01:08:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:08:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:08:24 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 01:08:25 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 01:08:25 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4481
15/04/12 01:08:26 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4481
15/04/12 01:08:26 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4481/
15/04/12 01:08:26 INFO mapreduce.Job: Running job: job_1422482982071_4481
15/04/12 01:08:35 INFO mapreduce.Job: Job job_1422482982071_4481 running in uber mode : false
15/04/12 01:08:35 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 01:08:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000071_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000097_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000051_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000122_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000100_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000075_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000128_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000044_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000064_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000008_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000101_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000063_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000021_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:49 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 01:08:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000071_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000008_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000063_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:56 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 01:08:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000079_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000037_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000076_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000001_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000090_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000129_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000028_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000066_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000117_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000019_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000062_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000096_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000086_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:08:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000041_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000037_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000103_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000053_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000027_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000117_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000090_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000044_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000122_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000051_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:07 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 01:09:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000053_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000041_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000125_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000027_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:13 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 01:09:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000053_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000017_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000057_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000074_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000054_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:19 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:09:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000112_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:20 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 01:09:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000114_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000131_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000116_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:23 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:09:23 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000066_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:23 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000076_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:23 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000019_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000055_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000102_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:25 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 01:09:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000103_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:26 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:09:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000037_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000002_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:29 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 01:09:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000093_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:30 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:09:30 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000130_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000016_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000108_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000049_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:35 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 01:09:36 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 01:09:36 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000016_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000092_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000079_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:38 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 01:09:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000040_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:42 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 01:09:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000104_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000129_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:44 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 01:09:45 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 01:09:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000020_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000051_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:48 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 01:09:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000126_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000052_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000122_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000033_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000111_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000090_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000050_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000060_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000031_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000121_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000127_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000083_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:50 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 01:09:51 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 01:09:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000133_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000089_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000133_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000038_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:09:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000015_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000118_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:02 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 01:10:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000070_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000102_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000040_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:04 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 01:10:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000015_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:05 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 01:10:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000034_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000129_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000120_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000068_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:06 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 01:10:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000109_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000026_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000035_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000026_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000005_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000010_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000049_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000117_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000060_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000101_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000039_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000049_2, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:17 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 01:10:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000098_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000008_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000108_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000022_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:22 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000069_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000102_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4481_m_000059_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:10:26 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 01:10:32 INFO mapreduce.Job: Job job_1422482982071_4481 failed with state FAILED due to: Task failed task_1422482982071_4481_m_000051
Job failed as tasks failed. failedMaps:1 failedReduces:0

15/04/12 01:10:32 INFO mapreduce.Job: Counters: 14
	Job Counters 
		Failed map tasks=127
		Killed map tasks=130
		Launched map tasks=257
		Other local map tasks=124
		Data-local map tasks=60
		Rack-local map tasks=74
		Total time spent by all maps in occupied slots (ms)=28053884
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=14026942
		Total vcore-seconds taken by all map tasks=14026942
		Total megabyte-seconds taken by all map tasks=113562122432
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
15/04/12 01:10:32 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	2m18.021s
user	0m13.165s
sys	0m0.907s
15/04/12 01:10:35 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 10
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-10-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=10 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob297597280802445974.jar tmpDir=null
15/04/12 01:10:37 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:10:38 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:10:39 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 01:10:44 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 01:10:48 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4482
15/04/12 01:10:48 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4482
15/04/12 01:10:48 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4482/
15/04/12 01:10:48 INFO mapreduce.Job: Running job: job_1422482982071_4482
15/04/12 01:10:54 INFO mapreduce.Job: Job job_1422482982071_4482 running in uber mode : false
15/04/12 01:10:54 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 01:11:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000032_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000009_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000066_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000008_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000118_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000014_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000067_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000133_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000089_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000021_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000106_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000077_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000098_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000031_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000124_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000096_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000047_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:05 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 01:11:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000085_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000099_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000089_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000008_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000031_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000118_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:16 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 01:11:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000083_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000027_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000059_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000000_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000088_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000044_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000132_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000028_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000022_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000113_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000089_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000058_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:20 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 01:11:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000126_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 01:11:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000076_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 01:11:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000092_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000095_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000082_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000001_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000110_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000011_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000060_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:21 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 01:11:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000066_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:26 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:11:27 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000013_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:27 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000070_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:28 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 01:11:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000119_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:28 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000020_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:31 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 01:11:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000079_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000082_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000000_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000075_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000092_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000027_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000037_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000093_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:34 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 01:11:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000039_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000007_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000108_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000128_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000079_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000101_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:35 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 01:11:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000000_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:37 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 01:11:38 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:11:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000090_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000073_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:39 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 01:11:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000055_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000116_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000069_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000067_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000077_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000073_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000067_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:45 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:11:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000099_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:46 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 01:11:47 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:11:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000008_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000025_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000065_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000105_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000107_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000056_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000013_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000033_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000119_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:53 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000119_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000065_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000083_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:11:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000068_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:00 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 01:12:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000001_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000055_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 01:12:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000090_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000031_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4482_m_000126_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:06 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 01:12:15 INFO mapreduce.Job: Job job_1422482982071_4482 failed with state FAILED due to: Task failed task_1422482982071_4482_m_000119
Job failed as tasks failed. failedMaps:1 failedReduces:0

15/04/12 01:12:15 INFO mapreduce.Job: Counters: 14
	Job Counters 
		Failed map tasks=98
		Killed map tasks=132
		Launched map tasks=230
		Other local map tasks=96
		Data-local map tasks=61
		Rack-local map tasks=73
		Total time spent by all maps in occupied slots (ms)=17685254
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=8842627
		Total vcore-seconds taken by all map tasks=8842627
		Total megabyte-seconds taken by all map tasks=71589908192
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
15/04/12 01:12:15 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	1m42.454s
user	0m10.249s
sys	0m0.678s
15/04/12 01:12:17 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 5
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-5-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3729819662755859929.jar tmpDir=null
15/04/12 01:12:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:12:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:12:27 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 01:12:29 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 01:12:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4483
15/04/12 01:12:30 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4483
15/04/12 01:12:30 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4483/
15/04/12 01:12:30 INFO mapreduce.Job: Running job: job_1422482982071_4483
15/04/12 01:12:37 INFO mapreduce.Job: Job job_1422482982071_4483 running in uber mode : false
15/04/12 01:12:37 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 01:12:46 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 01:12:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000046_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000070_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000006_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000010_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000099_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000100_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000005_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000013_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:46 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000018_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:47 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 01:12:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000064_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000104_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000059_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000119_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000118_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000076_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000127_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000052_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000054_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:52 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 01:12:53 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000080_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:53 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000060_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000045_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 01:12:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000038_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000072_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000006_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000021_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000102_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000067_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000018_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000010_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000070_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000034_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000119_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:12:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000127_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000055_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000067_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:01 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 01:13:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000105_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000016_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000119_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000072_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000010_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000077_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000101_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000028_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000033_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000096_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000086_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000095_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000009_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 01:13:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000063_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4483_m_000065_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:07 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 01:13:12 INFO mapreduce.Job: Job job_1422482982071_4483 failed with state FAILED due to: Task failed task_1422482982071_4483_m_000010
Job failed as tasks failed. failedMaps:1 failedReduces:0

15/04/12 01:13:12 INFO mapreduce.Job: Counters: 14
	Job Counters 
		Failed map tasks=54
		Killed map tasks=130
		Launched map tasks=184
		Other local map tasks=50
		Data-local map tasks=67
		Rack-local map tasks=67
		Total time spent by all maps in occupied slots (ms)=6694680
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=3347340
		Total vcore-seconds taken by all map tasks=3347340
		Total megabyte-seconds taken by all map tasks=27100064640
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
15/04/12 01:13:12 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	0m57.087s
user	0m11.488s
sys	0m0.827s
15/04/12 01:13:14 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 5
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-5-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7959335576017459256.jar tmpDir=null
15/04/12 01:13:16 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:13:17 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:13:18 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 01:13:18 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 01:13:19 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4484
15/04/12 01:13:20 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4484
15/04/12 01:13:20 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4484/
15/04/12 01:13:20 INFO mapreduce.Job: Running job: job_1422482982071_4484
15/04/12 01:13:28 INFO mapreduce.Job: Job job_1422482982071_4484 running in uber mode : false
15/04/12 01:13:28 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 01:13:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000043_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000041_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000045_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000074_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000064_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000053_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000054_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000002_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000118_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000127_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000133_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000115_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000072_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000049_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000051_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000010_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000015_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000035_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000114_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000061_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000057_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000070_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000051_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:40 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 01:13:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000121_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:47 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 01:13:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000095_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000014_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000071_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000093_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000066_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000037_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000090_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000094_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000040_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000028_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000077_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000020_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000025_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000079_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000075_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000105_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000081_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000045_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000102_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000106_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000053_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000106_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000094_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:57 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 01:13:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000049_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000074_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000041_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:13:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000118_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000106_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 01:14:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000094_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000039_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000024_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:05 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 01:14:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000052_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000018_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000084_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000039_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:10 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:14:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000042_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000129_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000095_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000021_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000117_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:11 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 01:14:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000122_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000028_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000008_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:16 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:14:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000047_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000042_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000044_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000091_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000062_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000129_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000047_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:22 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000099_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:23 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000091_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000107_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:27 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 01:14:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000037_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000064_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:34 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 01:14:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000054_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:41 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 01:14:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000073_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000090_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000030_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:45 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000127_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:50 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 01:14:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000029_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000063_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000029_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:14:58 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 01:14:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000059_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000029_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000002_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:07 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 01:15:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000000_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000128_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000003_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000076_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000006_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000129_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000022_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000055_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000019_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000038_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000057_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000067_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000025_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:22 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000038_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:24 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 01:15:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4484_m_000025_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:29 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 01:15:31 INFO mapreduce.Job: Job job_1422482982071_4484 failed with state FAILED due to: Task failed task_1422482982071_4484_m_000025
Job failed as tasks failed. failedMaps:1 failedReduces:0

15/04/12 01:15:31 INFO mapreduce.Job: Counters: 14
	Job Counters 
		Failed map tasks=108
		Killed map tasks=133
		Launched map tasks=241
		Other local map tasks=107
		Data-local map tasks=61
		Rack-local map tasks=73
		Total time spent by all maps in occupied slots (ms)=31500414
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=15750207
		Total vcore-seconds taken by all map tasks=15750207
		Total megabyte-seconds taken by all map tasks=127513675872
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
15/04/12 01:15:31 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	2m19.331s
user	0m9.476s
sys	0m0.618s
15/04/12 01:15:33 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
50 5
r googlebooks-eng-all-5gram-20120701-st mapper.R reducer.R
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -Dmapreduce.job.name=r-50-5-googlebooks-eng-all-5gram-20120701-st -Dmapreduce.job.maps=50 -Dmapreduce.job.reduces=5 -Dmapreduce.map.java.opts=-Xmx12000M -Dmapreduce.reduce.java.opts=-Xmx12000M  -files ./mapper.R,./reducer.R  -mapper ./mapper.R -reducer ./reducer.R -input ./data/googletxt/googlebooks-eng-all-5gram-20120701-st -output ./out/stream-r-0-googlebooks-eng-all-5gram-20120701-st
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2353763501180978627.jar tmpDir=null
15/04/12 01:15:36 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:15:36 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:15:37 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 01:15:37 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 01:15:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4485
15/04/12 01:15:40 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4485
15/04/12 01:15:40 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4485/
15/04/12 01:15:40 INFO mapreduce.Job: Running job: job_1422482982071_4485
15/04/12 01:15:48 INFO mapreduce.Job: Job job_1422482982071_4485 running in uber mode : false
15/04/12 01:15:48 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 01:15:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000001_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000054_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000048_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000091_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000065_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000033_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000060_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000108_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000117_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000114_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000045_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000097_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000115_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000064_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000132_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000010_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000096_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000035_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 01:15:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000100_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:15:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000079_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000085_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000098_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:03 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 01:16:03 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000117_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000114_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000097_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000108_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000001_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:06 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 01:16:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000024_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000124_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000044_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:09 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 01:16:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000108_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000037_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000011_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000034_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000025_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000035_1, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000062_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000119_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000007_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000120_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000119_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000025_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:18 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 01:16:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000064_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000096_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000085_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:22 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000003_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:26 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 01:16:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000090_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000083_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000105_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000063_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:33 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:16:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000066_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000035_2, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:345)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000119_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000088_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000009_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000001_2, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:44 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 01:16:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000090_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:50 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 01:16:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000115_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:53 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000063_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:56 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 01:16:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000093_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000056_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:16:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000116_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:95)
	at java.io.DataOutputStream.write(DataOutputStream.java:88)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:52)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:17:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000012_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:17:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000130_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:17:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000059_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:17:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000003_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:17:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000048_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:17:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000012_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:17:09 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 01:17:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000100_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:17:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000130_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:17:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000071_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:17:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000084_0, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:17:13 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 01:17:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000105_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:17:14 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 01:17:18 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 01:17:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4485_m_000066_1, Status : FAILED
Error: java.io.IOException: Stream closed
	at java.lang.ProcessBuilder$NullOutputStream.write(ProcessBuilder.java:434)
	at java.io.OutputStream.write(OutputStream.java:116)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

15/04/12 01:17:24 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 01:17:25 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 01:17:27 INFO mapreduce.Job: Job job_1422482982071_4485 failed with state FAILED due to: Task failed task_1422482982071_4485_m_000119
Job failed as tasks failed. failedMaps:1 failedReduces:0

15/04/12 01:17:27 INFO mapreduce.Job: Counters: 14
	Job Counters 
		Failed map tasks=75
		Killed map tasks=133
		Launched map tasks=208
		Other local map tasks=74
		Data-local map tasks=67
		Rack-local map tasks=67
		Total time spent by all maps in occupied slots (ms)=24706456
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=12353228
		Total vcore-seconds taken by all map tasks=12353228
		Total megabyte-seconds taken by all map tasks=100011733888
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
15/04/12 01:17:27 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!

real	1m55.844s
user	0m10.386s
sys	0m0.588s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-40-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=40"


15/04/12 01:17:33 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 01:17:33 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5072637223764203739.jar tmpDir=null
15/04/12 01:17:34 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:17:34 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:17:35 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 01:17:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 01:17:36 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 01:17:36 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4486
15/04/12 01:17:36 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4486
15/04/12 01:17:37 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4486/
15/04/12 01:17:37 INFO mapreduce.Job: Running job: job_1422482982071_4486
15/04/12 01:17:45 INFO mapreduce.Job: Job job_1422482982071_4486 running in uber mode : false
15/04/12 01:17:45 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 01:18:00 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 01:18:03 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 01:18:06 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 01:18:09 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 01:18:12 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 01:18:15 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 01:18:18 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 01:18:21 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 01:18:25 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 01:18:28 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 01:18:31 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 01:18:34 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 01:18:35 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 01:18:37 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 01:18:38 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 01:18:40 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 01:18:41 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 01:18:44 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 01:18:46 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 01:18:47 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 01:18:48 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 01:18:49 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 01:18:50 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 01:18:51 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 01:18:52 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 01:18:53 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 01:18:54 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 01:18:55 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 01:18:56 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 01:18:57 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 01:18:58 INFO mapreduce.Job:  map 84% reduce 9%
15/04/12 01:18:59 INFO mapreduce.Job:  map 86% reduce 19%
15/04/12 01:19:02 INFO mapreduce.Job:  map 87% reduce 21%
15/04/12 01:19:03 INFO mapreduce.Job:  map 88% reduce 22%
15/04/12 01:19:05 INFO mapreduce.Job:  map 88% reduce 23%
15/04/12 01:19:06 INFO mapreduce.Job:  map 89% reduce 23%
15/04/12 01:19:07 INFO mapreduce.Job:  map 90% reduce 23%
15/04/12 01:19:08 INFO mapreduce.Job:  map 90% reduce 24%
15/04/12 01:19:09 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 01:19:11 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 01:19:14 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 01:19:16 INFO mapreduce.Job:  map 95% reduce 26%
15/04/12 01:19:18 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 01:19:19 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 01:19:20 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 01:19:21 INFO mapreduce.Job:  map 97% reduce 30%
15/04/12 01:19:22 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 01:19:24 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 01:19:25 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 01:19:26 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 01:19:27 INFO mapreduce.Job:  map 100% reduce 45%
15/04/12 01:19:28 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 01:19:29 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 01:19:30 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 01:19:31 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 01:19:33 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 01:19:36 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 01:19:37 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 01:19:39 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 01:19:40 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 01:19:41 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 01:19:42 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 01:19:43 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 01:19:45 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 01:19:46 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 01:19:48 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 01:19:50 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 01:19:52 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 01:19:55 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 01:19:58 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 01:20:01 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 01:20:06 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 01:20:07 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 01:20:12 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 01:20:15 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 01:20:20 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 01:20:23 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 01:20:28 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 01:20:34 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 01:20:42 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 01:20:44 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 01:20:52 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 01:20:57 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 01:21:10 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 01:21:27 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 01:24:53 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 01:27:34 INFO mapreduce.Job: Job job_1422482982071_4486 completed successfully
15/04/12 01:27:34 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10607087362
		FILE: Number of bytes written=21222905894
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109358026
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=51
		Launched reduce tasks=41
		Data-local map tasks=31
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=7321412
		Total time spent by all reduces in occupied slots (ms)=14025938
		Total time spent by all map tasks (ms)=3660706
		Total time spent by all reduce tasks (ms)=7012969
		Total vcore-seconds taken by all map tasks=3660706
		Total vcore-seconds taken by all reduce tasks=7012969
		Total megabyte-seconds taken by all map tasks=29637075776
		Total megabyte-seconds taken by all reduce tasks=84155628000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985414
		Map output bytes=10355538279
		Map output materialized bytes=10607099122
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623881
		Reduce shuffle bytes=10607099122
		Reduce input records=121985414
		Reduce output records=18700175
		Spilled Records=243970828
		Shuffled Maps =2000
		Failed Shuffles=0
		Merged Map outputs=2000
		GC time elapsed (ms)=64520
		CPU time spent (ms)=9052980
		Physical memory (bytes) snapshot=115920355328
		Virtual memory (bytes) snapshot=993316585472
		Total committed heap usage (bytes)=222689722368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109358026
	rmr
		reduce calls=18623881
15/04/12 01:27:34 INFO streaming.StreamJob: Output directory: /tmp/file5e1e4b79ecfc
function () 
{
    fname
}
<bytecode: 0x2514080>
<environment: 0x2513448>
15/04/12 01:27:40 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file5e1e4b79ecfc

real	10m12.692s
user	0m24.409s
sys	0m1.662s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-40-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=40"


15/04/12 01:27:44 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 01:27:44 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6046962562219615937.jar tmpDir=null
15/04/12 01:27:45 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:27:45 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:27:46 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 01:27:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 01:27:47 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 01:27:49 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4487
15/04/12 01:27:49 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4487
15/04/12 01:27:49 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4487/
15/04/12 01:27:49 INFO mapreduce.Job: Running job: job_1422482982071_4487
15/04/12 01:27:56 INFO mapreduce.Job: Job job_1422482982071_4487 running in uber mode : false
15/04/12 01:27:56 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 01:28:07 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 01:28:08 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 01:28:10 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:28:11 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 01:28:12 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 01:28:14 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 01:28:15 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 01:28:17 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 01:28:18 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 01:28:20 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 01:28:21 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 01:28:23 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 01:28:24 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 01:28:26 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 01:28:27 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 01:28:28 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 01:28:29 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 01:28:30 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 01:28:31 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 01:28:33 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 01:28:34 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 01:28:35 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 01:28:36 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 01:28:37 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 01:28:38 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 01:28:39 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 01:28:40 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 01:28:41 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 01:28:42 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 01:28:43 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 01:28:44 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 01:28:45 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 01:28:46 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 01:28:47 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 01:28:48 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 01:28:49 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 01:28:50 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 01:28:51 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 01:28:52 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 01:28:53 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 01:28:54 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 01:28:55 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 01:28:56 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 01:28:57 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 01:28:58 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 01:29:00 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 01:29:01 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 01:29:02 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 01:29:04 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 01:29:06 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 01:29:07 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 01:29:09 INFO mapreduce.Job:  map 85% reduce 2%
15/04/12 01:29:10 INFO mapreduce.Job:  map 87% reduce 18%
15/04/12 01:29:11 INFO mapreduce.Job:  map 91% reduce 19%
15/04/12 01:29:12 INFO mapreduce.Job:  map 91% reduce 20%
15/04/12 01:29:13 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 01:29:14 INFO mapreduce.Job:  map 91% reduce 26%
15/04/12 01:29:16 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 01:29:18 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 01:29:19 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 01:29:31 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 01:29:32 INFO mapreduce.Job:  map 96% reduce 27%
15/04/12 01:29:33 INFO mapreduce.Job:  map 97% reduce 27%
15/04/12 01:29:34 INFO mapreduce.Job:  map 99% reduce 29%
15/04/12 01:29:35 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 01:29:37 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 01:29:38 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 01:29:40 INFO mapreduce.Job:  map 100% reduce 40%
15/04/12 01:29:41 INFO mapreduce.Job:  map 100% reduce 52%
15/04/12 01:29:42 INFO mapreduce.Job:  map 100% reduce 54%
15/04/12 01:29:43 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 01:29:44 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 01:29:45 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 01:29:47 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 01:29:49 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 01:29:50 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 01:29:52 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 01:29:53 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 01:29:54 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 01:29:56 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 01:29:59 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 01:30:01 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 01:30:02 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 01:30:05 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 01:30:06 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 01:30:08 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 01:30:11 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 01:30:14 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 01:30:17 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 01:30:23 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 01:30:26 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 01:30:30 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 01:30:35 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 01:30:39 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 01:30:42 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 01:30:49 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 01:30:54 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 01:30:58 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 01:31:05 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 01:31:13 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 01:31:23 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 01:31:46 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 01:35:06 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 01:37:49 INFO mapreduce.Job: Job job_1422482982071_4487 completed successfully
15/04/12 01:37:49 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10607082067
		FILE: Number of bytes written=21222895304
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109339908
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=51
		Launched reduce tasks=41
		Data-local map tasks=31
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=7347330
		Total time spent by all reduces in occupied slots (ms)=14198102
		Total time spent by all map tasks (ms)=3673665
		Total time spent by all reduce tasks (ms)=7099051
		Total vcore-seconds taken by all map tasks=3673665
		Total vcore-seconds taken by all reduce tasks=7099051
		Total megabyte-seconds taken by all map tasks=29741991840
		Total megabyte-seconds taken by all reduce tasks=85188612000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985413
		Map output bytes=10355532987
		Map output materialized bytes=10607093827
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623886
		Reduce shuffle bytes=10607093827
		Reduce input records=121985413
		Reduce output records=18700060
		Spilled Records=243970826
		Shuffled Maps =2000
		Failed Shuffles=0
		Merged Map outputs=2000
		GC time elapsed (ms)=64237
		CPU time spent (ms)=9130930
		Physical memory (bytes) snapshot=115943813120
		Virtual memory (bytes) snapshot=993511165952
		Total committed heap usage (bytes)=222689579008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109339908
	rmr
		reduce calls=18623886
15/04/12 01:37:49 INFO streaming.StreamJob: Output directory: /tmp/file5f9713311c13
function () 
{
    fname
}
<bytecode: 0x22b6080>
<environment: 0x22b5448>
15/04/12 01:37:55 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file5f9713311c13

real	10m15.556s
user	0m22.616s
sys	0m1.480s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-40-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=40"


15/04/12 01:38:01 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 01:38:01 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4406421425519051514.jar tmpDir=null
15/04/12 01:38:01 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:38:01 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:38:02 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 01:38:02 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 01:38:02 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 01:38:03 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4488
15/04/12 01:38:04 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4488
15/04/12 01:38:04 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4488/
15/04/12 01:38:04 INFO mapreduce.Job: Running job: job_1422482982071_4488
15/04/12 01:38:10 INFO mapreduce.Job: Job job_1422482982071_4488 running in uber mode : false
15/04/12 01:38:10 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 01:38:21 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 01:38:22 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:38:24 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 01:38:25 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 01:38:27 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 01:38:28 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 01:38:29 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 01:38:30 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 01:38:31 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 01:38:33 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 01:38:34 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 01:38:36 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 01:38:37 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 01:38:39 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 01:38:40 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 01:38:42 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 01:38:43 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 01:38:45 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 01:38:46 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 01:38:48 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 01:38:49 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 01:38:51 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 01:38:52 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 01:38:53 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 01:38:54 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 01:38:55 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 01:38:56 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 01:38:57 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 01:38:58 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 01:38:59 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 01:39:00 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 01:39:01 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 01:39:02 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 01:39:04 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 01:39:05 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 01:39:06 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 01:39:07 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 01:39:09 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 01:39:11 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 01:39:12 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 01:39:14 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 01:39:15 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 01:39:17 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 01:39:18 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 01:39:19 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 01:39:20 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 01:39:21 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 01:39:22 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 01:39:23 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 01:39:24 INFO mapreduce.Job:  map 86% reduce 3%
15/04/12 01:39:25 INFO mapreduce.Job:  map 88% reduce 19%
15/04/12 01:39:26 INFO mapreduce.Job:  map 89% reduce 20%
15/04/12 01:39:27 INFO mapreduce.Job:  map 89% reduce 21%
15/04/12 01:39:28 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 01:39:31 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 01:39:34 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 01:39:44 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 01:39:46 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 01:39:47 INFO mapreduce.Job:  map 96% reduce 29%
15/04/12 01:39:48 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 01:39:49 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 01:39:50 INFO mapreduce.Job:  map 98% reduce 31%
15/04/12 01:39:51 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 01:39:52 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 01:39:54 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 01:39:55 INFO mapreduce.Job:  map 100% reduce 37%
15/04/12 01:39:56 INFO mapreduce.Job:  map 100% reduce 43%
15/04/12 01:39:57 INFO mapreduce.Job:  map 100% reduce 46%
15/04/12 01:39:58 INFO mapreduce.Job:  map 100% reduce 56%
15/04/12 01:39:59 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 01:40:01 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 01:40:02 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 01:40:04 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 01:40:05 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 01:40:06 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 01:40:08 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 01:40:11 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 01:40:14 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 01:40:16 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 01:40:17 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 01:40:20 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 01:40:23 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 01:40:26 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 01:40:28 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 01:40:32 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 01:40:35 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 01:40:38 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 01:40:41 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 01:40:44 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 01:40:50 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 01:40:54 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 01:40:59 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 01:41:05 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 01:41:11 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 01:41:15 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 01:41:22 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 01:41:29 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 01:41:42 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 01:42:03 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 01:45:23 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 01:47:47 INFO mapreduce.Job: Job job_1422482982071_4488 completed successfully
15/04/12 01:47:47 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=10607089286
		FILE: Number of bytes written=21222909742
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109341500
		HDFS: Number of read operations=270
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=51
		Launched reduce tasks=41
		Data-local map tasks=30
		Rack-local map tasks=21
		Total time spent by all maps in occupied slots (ms)=7422290
		Total time spent by all reduces in occupied slots (ms)=14625900
		Total time spent by all map tasks (ms)=3711145
		Total time spent by all reduce tasks (ms)=7312950
		Total vcore-seconds taken by all map tasks=3711145
		Total vcore-seconds taken by all reduce tasks=7312950
		Total megabyte-seconds taken by all map tasks=30045429920
		Total megabyte-seconds taken by all reduce tasks=87755400000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985430
		Map output bytes=10355540165
		Map output materialized bytes=10607101046
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623930
		Reduce shuffle bytes=10607101046
		Reduce input records=121985430
		Reduce output records=18700099
		Spilled Records=243970860
		Shuffled Maps =2000
		Failed Shuffles=0
		Merged Map outputs=2000
		GC time elapsed (ms)=64087
		CPU time spent (ms)=9342740
		Physical memory (bytes) snapshot=115966816256
		Virtual memory (bytes) snapshot=993901690880
		Total committed heap usage (bytes)=222689832960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109341500
	rmr
		reduce calls=18623930
15/04/12 01:47:47 INFO streaming.StreamJob: Output directory: /tmp/file6113520e2106
function () 
{
    fname
}
<bytecode: 0x276d080>
<environment: 0x276c448>
15/04/12 01:47:52 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file6113520e2106

real	9m57.186s
user	0m21.101s
sys	0m1.612s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-30-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=30"


15/04/12 01:47:57 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 01:47:57 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5113399041853794465.jar tmpDir=null
15/04/12 01:47:58 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:47:58 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:47:59 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 01:47:59 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 01:47:59 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 01:48:00 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4489
15/04/12 01:48:00 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4489
15/04/12 01:48:00 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4489/
15/04/12 01:48:00 INFO mapreduce.Job: Running job: job_1422482982071_4489
15/04/12 01:48:06 INFO mapreduce.Job: Job job_1422482982071_4489 running in uber mode : false
15/04/12 01:48:06 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 01:48:17 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 01:48:18 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 01:48:20 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 01:48:21 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 01:48:23 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 01:48:24 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 01:48:26 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 01:48:27 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 01:48:30 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 01:48:31 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 01:48:32 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 01:48:34 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 01:48:36 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 01:48:37 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 01:48:39 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 01:48:40 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 01:48:42 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 01:48:43 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 01:48:44 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 01:48:45 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 01:48:46 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 01:48:47 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 01:48:49 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 01:48:50 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 01:48:52 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 01:48:53 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 01:48:55 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 01:48:56 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 01:48:57 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 01:48:58 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 01:48:59 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 01:49:01 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 01:49:02 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 01:49:03 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 01:49:04 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 01:49:05 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 01:49:06 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 01:49:08 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 01:49:09 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 01:49:10 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 01:49:11 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 01:49:12 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 01:49:13 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 01:49:14 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 01:49:15 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 01:49:16 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 01:49:17 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 01:49:18 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 01:49:19 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 01:49:20 INFO mapreduce.Job:  map 87% reduce 1%
15/04/12 01:49:21 INFO mapreduce.Job:  map 89% reduce 2%
15/04/12 01:49:22 INFO mapreduce.Job:  map 90% reduce 20%
15/04/12 01:49:23 INFO mapreduce.Job:  map 91% reduce 24%
15/04/12 01:49:25 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 01:49:28 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 01:49:39 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 01:49:41 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 01:49:42 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 01:49:43 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 01:49:44 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 01:49:45 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 01:49:46 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 01:49:47 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 01:49:50 INFO mapreduce.Job:  map 99% reduce 33%
15/04/12 01:49:53 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 01:49:55 INFO mapreduce.Job:  map 100% reduce 36%
15/04/12 01:49:56 INFO mapreduce.Job:  map 100% reduce 49%
15/04/12 01:49:57 INFO mapreduce.Job:  map 100% reduce 53%
15/04/12 01:49:58 INFO mapreduce.Job:  map 100% reduce 58%
15/04/12 01:49:59 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 01:50:00 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 01:50:01 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 01:50:03 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 01:50:05 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 01:50:08 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 01:50:11 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 01:50:13 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 01:50:14 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 01:50:17 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 01:50:20 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 01:50:23 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 01:50:26 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 01:50:29 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 01:50:31 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 01:50:35 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 01:50:38 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 01:50:41 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 01:50:47 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 01:50:51 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 01:50:55 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 01:51:00 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 01:51:06 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 01:51:11 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 01:51:16 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 01:51:23 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 01:51:32 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 01:51:41 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 01:51:52 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 01:52:03 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 01:52:15 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 01:52:46 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 01:56:45 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 01:59:37 INFO mapreduce.Job: Job job_1422482982071_4489 completed successfully
15/04/12 01:59:37 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607088162
		FILE: Number of bytes written=21221928274
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109301406
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=30
		Data-local map tasks=30
		Rack-local map tasks=21
		Total time spent by all maps in occupied slots (ms)=7435376
		Total time spent by all reduces in occupied slots (ms)=13597040
		Total time spent by all map tasks (ms)=3717688
		Total time spent by all reduce tasks (ms)=6798520
		Total vcore-seconds taken by all map tasks=3717688
		Total vcore-seconds taken by all reduce tasks=6798520
		Total megabyte-seconds taken by all map tasks=30098402048
		Total megabyte-seconds taken by all reduce tasks=81582240000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985421
		Map output bytes=10355539127
		Map output materialized bytes=10607096982
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623819
		Reduce shuffle bytes=10607096982
		Reduce input records=121985421
		Reduce output records=18699734
		Spilled Records=243970842
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=62418
		CPU time spent (ms)=9378710
		Physical memory (bytes) snapshot=113990324224
		Virtual memory (bytes) snapshot=860067803136
		Total committed heap usage (bytes)=201638400000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109301406
	rmr
		reduce calls=18623819
15/04/12 01:59:37 INFO streaming.StreamJob: Output directory: /tmp/file628e580d77b3
function () 
{
    fname
}
<bytecode: 0x3919080>
<environment: 0x3918448>
15/04/12 01:59:43 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file628e580d77b3

real	11m50.354s
user	0m21.828s
sys	0m1.644s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-30-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=30"


15/04/12 01:59:48 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 01:59:48 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob743268090842889451.jar tmpDir=null
15/04/12 01:59:48 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:59:49 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 01:59:49 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 01:59:49 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 01:59:50 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 01:59:50 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4490
15/04/12 01:59:51 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4490
15/04/12 01:59:51 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4490/
15/04/12 01:59:51 INFO mapreduce.Job: Running job: job_1422482982071_4490
15/04/12 01:59:57 INFO mapreduce.Job: Job job_1422482982071_4490 running in uber mode : false
15/04/12 01:59:57 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 02:00:08 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 02:00:09 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 02:00:11 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 02:00:12 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 02:00:13 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 02:00:15 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 02:00:16 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 02:00:17 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 02:00:18 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 02:00:19 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 02:00:20 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 02:00:21 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 02:00:22 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 02:00:23 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 02:00:24 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 02:00:25 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 02:00:27 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 02:00:28 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 02:00:30 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 02:00:31 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 02:00:33 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 02:00:34 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 02:00:35 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 02:00:36 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 02:00:37 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 02:00:39 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 02:00:40 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 02:00:42 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 02:00:43 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 02:00:45 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 02:00:46 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 02:00:48 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 02:00:49 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 02:00:52 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 02:00:54 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 02:00:55 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 02:00:57 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 02:00:58 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 02:01:01 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 02:01:02 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 02:01:04 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 02:01:06 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 02:01:07 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 02:01:08 INFO mapreduce.Job:  map 80% reduce 1%
15/04/12 02:01:09 INFO mapreduce.Job:  map 83% reduce 10%
15/04/12 02:01:10 INFO mapreduce.Job:  map 86% reduce 16%
15/04/12 02:01:12 INFO mapreduce.Job:  map 89% reduce 16%
15/04/12 02:01:13 INFO mapreduce.Job:  map 89% reduce 21%
15/04/12 02:01:14 INFO mapreduce.Job:  map 92% reduce 24%
15/04/12 02:01:16 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 02:01:17 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 02:01:19 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 02:01:31 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 02:01:32 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 02:01:33 INFO mapreduce.Job:  map 97% reduce 27%
15/04/12 02:01:34 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 02:01:35 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 02:01:37 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 02:01:38 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 02:01:40 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 02:01:41 INFO mapreduce.Job:  map 100% reduce 37%
15/04/12 02:01:42 INFO mapreduce.Job:  map 100% reduce 41%
15/04/12 02:01:43 INFO mapreduce.Job:  map 100% reduce 45%
15/04/12 02:01:44 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 02:01:45 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 02:01:46 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 02:01:47 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 02:01:48 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 02:01:50 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 02:01:51 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 02:01:53 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 02:01:56 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 02:01:57 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 02:01:59 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 02:02:02 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 02:02:03 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 02:02:05 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 02:02:07 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 02:02:09 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 02:02:12 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 02:02:15 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 02:02:17 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 02:02:21 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 02:02:24 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 02:02:28 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 02:02:31 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 02:02:36 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 02:02:41 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 02:02:45 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 02:02:49 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 02:02:56 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 02:03:03 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 02:03:08 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 02:03:17 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 02:03:25 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 02:03:37 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 02:03:47 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 02:03:59 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 02:04:31 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 02:08:34 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 02:11:00 INFO mapreduce.Job: Job job_1422482982071_4490 completed successfully
15/04/12 02:11:00 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607081263
		FILE: Number of bytes written=21221915356
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109305518
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=30
		Data-local map tasks=31
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=7358754
		Total time spent by all reduces in occupied slots (ms)=13191820
		Total time spent by all map tasks (ms)=3679377
		Total time spent by all reduce tasks (ms)=6595910
		Total vcore-seconds taken by all map tasks=3679377
		Total vcore-seconds taken by all reduce tasks=6595910
		Total megabyte-seconds taken by all map tasks=29788236192
		Total megabyte-seconds taken by all reduce tasks=79150920000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985391
		Map output bytes=10355532285
		Map output materialized bytes=10607090083
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623890
		Reduce shuffle bytes=10607090083
		Reduce input records=121985391
		Reduce output records=18699805
		Spilled Records=243970782
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=62520
		CPU time spent (ms)=9182770
		Physical memory (bytes) snapshot=113997434880
		Virtual memory (bytes) snapshot=859665592320
		Total committed heap usage (bytes)=201638715392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109305518
	rmr
		reduce calls=18623890
15/04/12 02:11:00 INFO streaming.StreamJob: Output directory: /tmp/file6498d947914
function () 
{
    fname
}
<bytecode: 0x328e080>
<environment: 0x328d448>
15/04/12 02:11:06 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file6498d947914

real	11m23.520s
user	0m23.000s
sys	0m1.509s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-30-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=30"


15/04/12 02:11:11 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 02:11:11 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4000399792721243938.jar tmpDir=null
15/04/12 02:11:12 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 02:11:12 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 02:11:13 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 02:11:13 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 02:11:13 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 02:11:14 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4491
15/04/12 02:11:14 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4491
15/04/12 02:11:14 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4491/
15/04/12 02:11:14 INFO mapreduce.Job: Running job: job_1422482982071_4491
15/04/12 02:11:21 INFO mapreduce.Job: Job job_1422482982071_4491 running in uber mode : false
15/04/12 02:11:21 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 02:11:32 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 02:11:33 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 02:11:35 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 02:11:36 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 02:11:39 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 02:11:41 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 02:11:42 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 02:11:44 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 02:11:45 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 02:11:47 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 02:11:48 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 02:11:49 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 02:11:50 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 02:11:51 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 02:11:52 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 02:11:53 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 02:11:54 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 02:11:55 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 02:11:56 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 02:11:57 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 02:11:58 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 02:11:59 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 02:12:00 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 02:12:01 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 02:12:02 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 02:12:03 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 02:12:04 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 02:12:05 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 02:12:06 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 02:12:07 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 02:12:09 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 02:12:10 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 02:12:12 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 02:12:13 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 02:12:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_4491_m_000045_0, Status : FAILED
Error: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:334)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRawBytes(TypedBytesInput.java:218)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRaw(TypedBytesInput.java:152)
	at org.apache.hadoop.streaming.io.TypedBytesOutputReader.readKeyValue(TypedBytesOutputReader.java:56)
	at org.apache.hadoop.streaming.PipeMapRed$MROutputThread.run(PipeMapRed.java:376)

15/04/12 02:12:16 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 02:12:18 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 02:12:19 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 02:12:20 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 02:12:21 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 02:12:22 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 02:12:24 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 02:12:25 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 02:12:26 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 02:12:27 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 02:12:29 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 02:12:30 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 02:12:31 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 02:12:32 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 02:12:33 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 02:12:34 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 02:12:35 INFO mapreduce.Job:  map 86% reduce 17%
15/04/12 02:12:36 INFO mapreduce.Job:  map 88% reduce 22%
15/04/12 02:12:37 INFO mapreduce.Job:  map 90% reduce 22%
15/04/12 02:12:38 INFO mapreduce.Job:  map 90% reduce 25%
15/04/12 02:12:39 INFO mapreduce.Job:  map 90% reduce 26%
15/04/12 02:12:40 INFO mapreduce.Job:  map 91% reduce 26%
15/04/12 02:12:46 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 02:12:53 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 02:12:54 INFO mapreduce.Job:  map 94% reduce 26%
15/04/12 02:12:55 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 02:12:57 INFO mapreduce.Job:  map 96% reduce 29%
15/04/12 02:12:59 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 02:13:00 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 02:13:01 INFO mapreduce.Job:  map 98% reduce 31%
15/04/12 02:13:03 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 02:13:06 INFO mapreduce.Job:  map 99% reduce 33%
15/04/12 02:13:29 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 02:13:30 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 02:13:31 INFO mapreduce.Job:  map 100% reduce 43%
15/04/12 02:13:32 INFO mapreduce.Job:  map 100% reduce 55%
15/04/12 02:13:33 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 02:13:34 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 02:13:35 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 02:13:37 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 02:13:38 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 02:13:40 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 02:13:42 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 02:13:44 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 02:13:46 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 02:13:48 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 02:13:50 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 02:13:52 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 02:13:54 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 02:13:56 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 02:13:59 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 02:14:00 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 02:14:03 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 02:14:06 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 02:14:10 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 02:14:14 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 02:14:17 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 02:14:20 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 02:14:25 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 02:14:30 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 02:14:35 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 02:14:40 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 02:14:45 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 02:14:50 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 02:14:57 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 02:15:07 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 02:15:15 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 02:15:25 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 02:15:35 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 02:15:50 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 02:16:15 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 02:20:22 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 02:23:04 INFO mapreduce.Job: Job job_1422482982071_4491 completed successfully
15/04/12 02:23:04 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=10607084471
		FILE: Number of bytes written=21221920972
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109304476
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Failed map tasks=1
		Killed map tasks=1
		Launched map tasks=52
		Launched reduce tasks=30
		Other local map tasks=2
		Data-local map tasks=32
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=7515654
		Total time spent by all reduces in occupied slots (ms)=14538902
		Total time spent by all map tasks (ms)=3757827
		Total time spent by all reduce tasks (ms)=7269451
		Total vcore-seconds taken by all map tasks=3757827
		Total vcore-seconds taken by all reduce tasks=7269451
		Total megabyte-seconds taken by all map tasks=30423367392
		Total megabyte-seconds taken by all reduce tasks=87233412000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985414
		Map output bytes=10355535445
		Map output materialized bytes=10607093291
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623842
		Reduce shuffle bytes=10607093291
		Reduce input records=121985414
		Reduce output records=18699769
		Spilled Records=243970828
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=64228
		CPU time spent (ms)=9245980
		Physical memory (bytes) snapshot=113922560000
		Virtual memory (bytes) snapshot=859796410368
		Total committed heap usage (bytes)=201637924864
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109304476
	rmr
		reduce calls=18623842
15/04/12 02:23:04 INFO streaming.StreamJob: Output directory: /tmp/file6639f06a739
function () 
{
    fname
}
<bytecode: 0x28a8080>
<environment: 0x28a7448>
15/04/12 02:23:11 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file6639f06a739

real	12m4.287s
user	0m22.927s
sys	0m1.680s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-20-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=20"


15/04/12 02:23:16 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 02:23:16 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5730428846800983301.jar tmpDir=null
15/04/12 02:23:16 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 02:23:17 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 02:23:18 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 02:23:18 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 02:23:18 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 02:23:18 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4492
15/04/12 02:23:19 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4492
15/04/12 02:23:19 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4492/
15/04/12 02:23:19 INFO mapreduce.Job: Running job: job_1422482982071_4492
15/04/12 02:23:25 INFO mapreduce.Job: Job job_1422482982071_4492 running in uber mode : false
15/04/12 02:23:25 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 02:23:35 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 02:23:36 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 02:23:38 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 02:23:40 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 02:23:41 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 02:23:43 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 02:23:44 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 02:23:46 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 02:23:47 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 02:23:48 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 02:23:49 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 02:23:50 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 02:23:52 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 02:23:53 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 02:23:55 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 02:23:56 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 02:23:58 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 02:23:59 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 02:24:01 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 02:24:02 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 02:24:04 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 02:24:05 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 02:24:07 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 02:24:08 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 02:24:10 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 02:24:11 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 02:24:13 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 02:24:14 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 02:24:16 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 02:24:17 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 02:24:19 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 02:24:20 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 02:24:22 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 02:24:23 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 02:24:25 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 02:24:26 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 02:24:27 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 02:24:29 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 02:24:30 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 02:24:31 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 02:24:32 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 02:24:33 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 02:24:34 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 02:24:35 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 02:24:36 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 02:24:37 INFO mapreduce.Job:  map 84% reduce 1%
15/04/12 02:24:38 INFO mapreduce.Job:  map 85% reduce 13%
15/04/12 02:24:39 INFO mapreduce.Job:  map 88% reduce 19%
15/04/12 02:24:40 INFO mapreduce.Job:  map 90% reduce 19%
15/04/12 02:24:41 INFO mapreduce.Job:  map 91% reduce 23%
15/04/12 02:24:42 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 02:24:43 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 02:24:44 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 02:24:48 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 02:24:57 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 02:24:59 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 02:25:00 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 02:25:01 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 02:25:02 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 02:25:03 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 02:25:06 INFO mapreduce.Job:  map 99% reduce 33%
15/04/12 02:25:07 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 02:25:09 INFO mapreduce.Job:  map 100% reduce 37%
15/04/12 02:25:10 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 02:25:11 INFO mapreduce.Job:  map 100% reduce 45%
15/04/12 02:25:12 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 02:25:13 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 02:25:14 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 02:25:15 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 02:25:16 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 02:25:18 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 02:25:21 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 02:25:24 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 02:25:27 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 02:25:30 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 02:25:33 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 02:25:36 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 02:25:39 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 02:25:42 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 02:25:45 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 02:25:49 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 02:25:54 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 02:25:59 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 02:26:06 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 02:26:13 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 02:26:18 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 02:26:23 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 02:26:30 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 02:26:34 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 02:26:40 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 02:26:45 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 02:26:52 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 02:27:01 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 02:27:09 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 02:27:18 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 02:27:27 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 02:27:39 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 02:27:52 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 02:28:09 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 02:28:30 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 02:28:53 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 02:30:33 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 02:31:34 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 02:34:19 INFO mapreduce.Job: Job job_1422482982071_4492 completed successfully
15/04/12 02:34:19 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607082167
		FILE: Number of bytes written=21220938984
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109174645
		HDFS: Number of read operations=210
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=20
		Data-local map tasks=31
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=7322378
		Total time spent by all reduces in occupied slots (ms)=12324472
		Total time spent by all map tasks (ms)=3661189
		Total time spent by all reduce tasks (ms)=6162236
		Total vcore-seconds taken by all map tasks=3661189
		Total vcore-seconds taken by all reduce tasks=6162236
		Total megabyte-seconds taken by all map tasks=29640986144
		Total megabyte-seconds taken by all reduce tasks=73946832000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985407
		Map output bytes=10355533208
		Map output materialized bytes=10607088047
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623844
		Reduce shuffle bytes=10607088047
		Reduce input records=121985407
		Reduce output records=18698955
		Spilled Records=243970814
		Shuffled Maps =1000
		Failed Shuffles=0
		Merged Map outputs=1000
		GC time elapsed (ms)=59081
		CPU time spent (ms)=9154590
		Physical memory (bytes) snapshot=111949778944
		Virtual memory (bytes) snapshot=726413406208
		Total committed heap usage (bytes)=180588072960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109174645
	rmr
		reduce calls=18623844
15/04/12 02:34:19 INFO streaming.StreamJob: Output directory: /tmp/file67bc3d8486b7
function () 
{
    fname
}
<bytecode: 0x37fa080>
<environment: 0x37f9448>
15/04/12 02:34:25 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file67bc3d8486b7

real	11m14.581s
user	0m24.863s
sys	0m1.766s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-20-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=20"


15/04/12 02:34:30 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 02:34:30 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob3384726115929203328.jar tmpDir=null
15/04/12 02:34:31 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 02:34:31 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 02:34:32 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 02:34:32 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 02:34:32 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 02:34:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4493
15/04/12 02:34:33 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4493
15/04/12 02:34:33 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4493/
15/04/12 02:34:33 INFO mapreduce.Job: Running job: job_1422482982071_4493
15/04/12 02:34:39 INFO mapreduce.Job: Job job_1422482982071_4493 running in uber mode : false
15/04/12 02:34:39 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 02:34:50 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 02:34:51 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 02:34:53 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 02:34:54 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 02:34:55 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 02:34:56 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 02:34:57 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 02:34:59 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 02:35:00 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 02:35:02 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 02:35:03 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 02:35:05 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 02:35:06 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 02:35:09 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 02:35:12 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 02:35:15 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 02:35:16 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 02:35:18 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 02:35:19 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 02:35:21 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 02:35:22 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 02:35:24 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 02:35:26 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 02:35:28 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 02:35:29 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 02:35:31 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 02:35:32 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 02:35:34 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 02:35:35 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 02:35:36 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 02:35:37 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 02:35:38 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 02:35:40 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 02:35:41 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 02:35:43 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 02:35:44 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 02:35:46 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 02:35:47 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 02:35:48 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 02:35:49 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 02:35:50 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 02:35:51 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 02:35:52 INFO mapreduce.Job:  map 90% reduce 0%
15/04/12 02:35:53 INFO mapreduce.Job:  map 91% reduce 0%
15/04/12 02:35:54 INFO mapreduce.Job:  map 92% reduce 1%
15/04/12 02:35:55 INFO mapreduce.Job:  map 92% reduce 8%
15/04/12 02:35:56 INFO mapreduce.Job:  map 93% reduce 24%
15/04/12 02:35:57 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 02:36:02 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 02:36:11 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 02:36:13 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 02:36:15 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 02:36:16 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 02:36:17 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 02:36:18 INFO mapreduce.Job:  map 98% reduce 31%
15/04/12 02:36:19 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 02:36:20 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 02:36:21 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 02:36:22 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 02:36:23 INFO mapreduce.Job:  map 100% reduce 40%
15/04/12 02:36:24 INFO mapreduce.Job:  map 100% reduce 50%
15/04/12 02:36:25 INFO mapreduce.Job:  map 100% reduce 53%
15/04/12 02:36:26 INFO mapreduce.Job:  map 100% reduce 58%
15/04/12 02:36:27 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 02:36:28 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 02:36:29 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 02:36:31 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 02:36:34 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 02:36:37 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 02:36:41 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 02:36:43 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 02:36:46 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 02:36:48 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 02:36:51 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 02:36:55 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 02:36:58 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 02:37:02 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 02:37:06 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 02:37:12 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 02:37:18 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 02:37:25 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 02:37:30 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 02:37:36 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 02:37:42 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 02:37:49 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 02:37:53 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 02:37:58 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 02:38:04 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 02:38:12 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 02:38:22 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 02:38:31 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 02:38:41 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 02:38:53 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 02:39:08 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 02:39:23 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 02:39:44 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 02:40:14 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 02:41:55 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 02:42:55 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 02:45:44 INFO mapreduce.Job: Job job_1422482982071_4493 completed successfully
15/04/12 02:45:44 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607085199
		FILE: Number of bytes written=21220945048
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109176867
		HDFS: Number of read operations=210
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=20
		Data-local map tasks=33
		Rack-local map tasks=18
		Total time spent by all maps in occupied slots (ms)=7276206
		Total time spent by all reduces in occupied slots (ms)=12459550
		Total time spent by all map tasks (ms)=3638103
		Total time spent by all reduce tasks (ms)=6229775
		Total vcore-seconds taken by all map tasks=3638103
		Total vcore-seconds taken by all reduce tasks=6229775
		Total megabyte-seconds taken by all map tasks=29454081888
		Total megabyte-seconds taken by all reduce tasks=74757300000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985426
		Map output bytes=10355536208
		Map output materialized bytes=10607091079
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623888
		Reduce shuffle bytes=10607091079
		Reduce input records=121985426
		Reduce output records=18699004
		Spilled Records=243970852
		Shuffled Maps =1000
		Failed Shuffles=0
		Merged Map outputs=1000
		GC time elapsed (ms)=60810
		CPU time spent (ms)=9264930
		Physical memory (bytes) snapshot=111920418816
		Virtual memory (bytes) snapshot=726217236480
		Total committed heap usage (bytes)=180587819008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109176867
	rmr
		reduce calls=18623888
15/04/12 02:45:44 INFO streaming.StreamJob: Output directory: /tmp/file69404d51c7e4
function () 
{
    fname
}
<bytecode: 0x3101080>
<environment: 0x3100448>
15/04/12 02:45:51 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file69404d51c7e4

real	11m25.604s
user	0m24.695s
sys	0m1.614s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-20-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=20"


15/04/12 02:45:56 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 02:45:56 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2526002720542013913.jar tmpDir=null
15/04/12 02:45:56 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 02:45:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 02:45:57 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 02:45:57 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 02:45:57 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 02:45:58 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4494
15/04/12 02:45:58 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4494
15/04/12 02:45:58 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4494/
15/04/12 02:45:58 INFO mapreduce.Job: Running job: job_1422482982071_4494
15/04/12 02:46:05 INFO mapreduce.Job: Job job_1422482982071_4494 running in uber mode : false
15/04/12 02:46:05 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 02:46:16 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 02:46:17 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 02:46:19 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 02:46:20 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 02:46:22 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 02:46:23 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 02:46:26 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 02:46:29 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 02:46:30 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 02:46:32 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 02:46:33 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 02:46:35 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 02:46:36 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 02:46:38 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 02:46:39 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 02:46:41 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 02:46:42 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 02:46:44 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 02:46:45 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 02:46:47 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 02:46:48 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 02:46:49 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 02:46:50 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 02:46:51 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 02:46:52 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 02:46:53 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 02:46:54 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 02:46:55 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 02:46:56 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 02:46:57 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 02:46:59 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 02:47:00 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 02:47:02 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 02:47:03 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 02:47:06 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 02:47:08 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 02:47:09 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 02:47:10 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 02:47:11 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 02:47:12 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 02:47:13 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 02:47:14 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 02:47:15 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 02:47:17 INFO mapreduce.Job:  map 85% reduce 2%
15/04/12 02:47:18 INFO mapreduce.Job:  map 88% reduce 14%
15/04/12 02:47:19 INFO mapreduce.Job:  map 90% reduce 19%
15/04/12 02:47:20 INFO mapreduce.Job:  map 90% reduce 20%
15/04/12 02:47:21 INFO mapreduce.Job:  map 93% reduce 24%
15/04/12 02:47:22 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 02:47:23 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 02:47:27 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 02:47:40 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 02:47:41 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 02:47:42 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 02:47:43 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 02:47:44 INFO mapreduce.Job:  map 98% reduce 31%
15/04/12 02:47:45 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 02:47:47 INFO mapreduce.Job:  map 100% reduce 37%
15/04/12 02:47:48 INFO mapreduce.Job:  map 100% reduce 39%
15/04/12 02:47:49 INFO mapreduce.Job:  map 100% reduce 44%
15/04/12 02:47:50 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 02:47:51 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 02:47:52 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 02:47:53 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 02:47:56 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 02:47:59 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 02:48:02 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 02:48:05 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 02:48:08 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 02:48:11 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 02:48:14 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 02:48:16 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 02:48:20 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 02:48:21 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 02:48:25 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 02:48:30 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 02:48:34 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 02:48:42 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 02:48:48 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 02:48:52 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 02:48:59 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 02:49:06 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 02:49:12 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 02:49:15 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 02:49:20 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 02:49:27 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 02:49:34 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 02:49:45 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 02:49:54 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 02:50:04 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 02:50:16 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 02:50:29 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 02:50:46 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 02:51:05 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 02:51:36 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 02:53:13 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 02:54:19 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 02:57:32 INFO mapreduce.Job: Job job_1422482982071_4494 completed successfully
15/04/12 02:57:32 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607082850
		FILE: Number of bytes written=21220940350
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109173378
		HDFS: Number of read operations=210
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=20
		Data-local map tasks=30
		Rack-local map tasks=21
		Total time spent by all maps in occupied slots (ms)=7280362
		Total time spent by all reduces in occupied slots (ms)=12293924
		Total time spent by all map tasks (ms)=3640181
		Total time spent by all reduce tasks (ms)=6146962
		Total vcore-seconds taken by all map tasks=3640181
		Total vcore-seconds taken by all reduce tasks=6146962
		Total megabyte-seconds taken by all map tasks=29470905376
		Total megabyte-seconds taken by all reduce tasks=73763544000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985427
		Map output bytes=10355533858
		Map output materialized bytes=10607088730
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623883
		Reduce shuffle bytes=10607088730
		Reduce input records=121985427
		Reduce output records=18698967
		Spilled Records=243970854
		Shuffled Maps =1000
		Failed Shuffles=0
		Merged Map outputs=1000
		GC time elapsed (ms)=60197
		CPU time spent (ms)=9205160
		Physical memory (bytes) snapshot=111887327232
		Virtual memory (bytes) snapshot=726219481088
		Total committed heap usage (bytes)=180587868160
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109173378
	rmr
		reduce calls=18623883
15/04/12 02:57:32 INFO streaming.StreamJob: Output directory: /tmp/file6ac563cbabf0
function () 
{
    fname
}
<bytecode: 0x3142080>
<environment: 0x3141448>
15/04/12 02:57:39 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file6ac563cbabf0

real	11m47.980s
user	0m23.071s
sys	0m1.632s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-10-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=10"


15/04/12 02:57:44 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 02:57:44 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8561102221439982977.jar tmpDir=null
15/04/12 02:57:45 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 02:57:45 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 02:57:46 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 02:57:46 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 02:57:46 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 02:57:47 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4495
15/04/12 02:57:47 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4495
15/04/12 02:57:47 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4495/
15/04/12 02:57:47 INFO mapreduce.Job: Running job: job_1422482982071_4495
15/04/12 02:57:53 INFO mapreduce.Job: Job job_1422482982071_4495 running in uber mode : false
15/04/12 02:57:53 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 02:58:04 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 02:58:05 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 02:58:07 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 02:58:08 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 02:58:10 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 02:58:11 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 02:58:14 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 02:58:17 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 02:58:19 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 02:58:20 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 02:58:22 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 02:58:24 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 02:58:26 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 02:58:27 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 02:58:29 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 02:58:30 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 02:58:31 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 02:58:33 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 02:58:34 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 02:58:36 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 02:58:37 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 02:58:39 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 02:58:40 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 02:58:42 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 02:58:43 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 02:58:45 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 02:58:46 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 02:58:47 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 02:58:48 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 02:58:49 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 02:58:50 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 02:58:52 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 02:58:54 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 02:58:55 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 02:58:57 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 02:59:01 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 02:59:02 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 02:59:03 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 02:59:04 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 02:59:05 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 02:59:06 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 02:59:07 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 02:59:08 INFO mapreduce.Job:  map 90% reduce 0%
15/04/12 02:59:10 INFO mapreduce.Job:  map 92% reduce 0%
15/04/12 02:59:12 INFO mapreduce.Job:  map 93% reduce 3%
15/04/12 02:59:13 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 02:59:17 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 02:59:29 INFO mapreduce.Job:  map 96% reduce 27%
15/04/12 02:59:30 INFO mapreduce.Job:  map 97% reduce 27%
15/04/12 02:59:31 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 02:59:32 INFO mapreduce.Job:  map 97% reduce 31%
15/04/12 02:59:33 INFO mapreduce.Job:  map 98% reduce 31%
15/04/12 02:59:34 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 02:59:35 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 02:59:37 INFO mapreduce.Job:  map 99% reduce 33%
15/04/12 02:59:38 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 02:59:40 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 02:59:41 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 02:59:43 INFO mapreduce.Job:  map 100% reduce 45%
15/04/12 02:59:44 INFO mapreduce.Job:  map 100% reduce 48%
15/04/12 02:59:46 INFO mapreduce.Job:  map 100% reduce 53%
15/04/12 02:59:47 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 02:59:49 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 02:59:50 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 02:59:52 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 02:59:56 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 03:00:01 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 03:00:07 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 03:00:11 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 03:00:18 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 03:00:22 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 03:00:30 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 03:00:36 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 03:00:44 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 03:00:50 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 03:01:00 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 03:01:08 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 03:01:16 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 03:01:25 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 03:01:33 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 03:01:45 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 03:01:58 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 03:02:13 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 03:02:25 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 03:02:42 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 03:02:54 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 03:03:08 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 03:03:24 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 03:03:46 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 03:04:09 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 03:04:34 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 03:05:07 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 03:05:13 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 03:05:45 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 03:06:11 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 03:07:03 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 03:07:39 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 03:09:50 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 03:13:45 INFO mapreduce.Job: Job job_1422482982071_4495 completed successfully
15/04/12 03:13:45 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607083176
		FILE: Number of bytes written=21219962112
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109007276
		HDFS: Number of read operations=180
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=10
		Data-local map tasks=32
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=7444070
		Total time spent by all reduces in occupied slots (ms)=11115292
		Total time spent by all map tasks (ms)=3722035
		Total time spent by all reduce tasks (ms)=5557646
		Total vcore-seconds taken by all map tasks=3722035
		Total vcore-seconds taken by all reduce tasks=5557646
		Total megabyte-seconds taken by all map tasks=30133595360
		Total megabyte-seconds taken by all reduce tasks=66691752000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985388
		Map output bytes=10355534297
		Map output materialized bytes=10607086086
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623797
		Reduce shuffle bytes=10607086086
		Reduce input records=121985388
		Reduce output records=18697782
		Spilled Records=243970776
		Shuffled Maps =500
		Failed Shuffles=0
		Merged Map outputs=500
		GC time elapsed (ms)=56220
		CPU time spent (ms)=9165620
		Physical memory (bytes) snapshot=110696120320
		Virtual memory (bytes) snapshot=592779427840
		Total committed heap usage (bytes)=159536996352
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109007276
	rmr
		reduce calls=18623797
15/04/12 03:13:45 INFO streaming.StreamJob: Output directory: /tmp/file6cb4919c7c5
function () 
{
    fname
}
<bytecode: 0x336c080>
<environment: 0x336b448>
15/04/12 03:13:51 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file6cb4919c7c5

real	16m12.373s
user	0m24.743s
sys	0m1.885s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-10-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=10"


15/04/12 03:13:56 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 03:13:56 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7138388022337012724.jar tmpDir=null
15/04/12 03:13:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 03:13:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 03:13:58 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 03:13:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 03:13:58 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 03:13:58 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4496
15/04/12 03:13:59 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4496
15/04/12 03:13:59 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4496/
15/04/12 03:13:59 INFO mapreduce.Job: Running job: job_1422482982071_4496
15/04/12 03:14:05 INFO mapreduce.Job: Job job_1422482982071_4496 running in uber mode : false
15/04/12 03:14:05 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 03:14:16 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 03:14:17 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 03:14:19 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 03:14:20 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 03:14:23 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 03:14:25 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 03:14:26 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 03:14:28 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 03:14:29 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 03:14:32 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 03:14:33 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 03:14:35 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 03:14:36 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 03:14:38 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 03:14:39 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 03:14:40 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 03:14:41 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 03:14:42 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 03:14:44 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 03:14:45 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 03:14:47 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 03:14:48 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 03:14:50 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 03:14:51 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 03:14:53 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 03:14:54 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 03:14:55 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 03:14:56 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 03:14:57 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 03:14:58 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 03:14:59 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 03:15:00 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 03:15:02 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 03:15:03 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 03:15:05 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 03:15:06 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 03:15:07 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 03:15:08 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 03:15:10 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 03:15:11 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 03:15:12 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 03:15:13 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 03:15:14 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 03:15:15 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 03:15:16 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 03:15:17 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 03:15:18 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 03:15:19 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 03:15:21 INFO mapreduce.Job:  map 90% reduce 2%
15/04/12 03:15:22 INFO mapreduce.Job:  map 92% reduce 20%
15/04/12 03:15:23 INFO mapreduce.Job:  map 92% reduce 22%
15/04/12 03:15:24 INFO mapreduce.Job:  map 92% reduce 23%
15/04/12 03:15:25 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 03:15:29 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 03:15:32 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 03:15:35 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 03:15:36 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 03:15:38 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 03:15:41 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 03:15:42 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 03:15:43 INFO mapreduce.Job:  map 100% reduce 30%
15/04/12 03:15:44 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 03:15:45 INFO mapreduce.Job:  map 100% reduce 37%
15/04/12 03:15:47 INFO mapreduce.Job:  map 100% reduce 41%
15/04/12 03:15:48 INFO mapreduce.Job:  map 100% reduce 47%
15/04/12 03:15:51 INFO mapreduce.Job:  map 100% reduce 50%
15/04/12 03:15:54 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 03:15:56 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 03:15:57 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 03:16:03 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 03:16:09 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 03:16:12 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 03:16:18 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 03:16:26 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 03:16:29 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 03:16:36 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 03:16:44 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 03:16:50 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 03:16:57 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 03:17:06 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 03:17:14 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 03:17:23 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 03:17:30 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 03:17:44 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 03:17:53 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 03:18:06 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 03:18:18 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 03:18:34 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 03:18:48 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 03:19:03 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 03:19:16 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 03:19:30 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 03:19:48 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 03:20:10 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 03:20:39 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 03:21:09 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 03:21:16 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 03:21:48 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 03:22:15 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 03:23:13 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 03:24:02 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 03:26:30 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 03:30:24 INFO mapreduce.Job: Job job_1422482982071_4496 completed successfully
15/04/12 03:30:25 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607077775
		FILE: Number of bytes written=21219951610
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109008947
		HDFS: Number of read operations=180
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=10
		Data-local map tasks=32
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=7486134
		Total time spent by all reduces in occupied slots (ms)=11254642
		Total time spent by all map tasks (ms)=3743067
		Total time spent by all reduce tasks (ms)=5627321
		Total vcore-seconds taken by all map tasks=3743067
		Total vcore-seconds taken by all reduce tasks=5627321
		Total megabyte-seconds taken by all map tasks=30303870432
		Total megabyte-seconds taken by all reduce tasks=67527852000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985388
		Map output bytes=10355528896
		Map output materialized bytes=10607080685
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623832
		Reduce shuffle bytes=10607080685
		Reduce input records=121985388
		Reduce output records=18697817
		Spilled Records=243970776
		Shuffled Maps =500
		Failed Shuffles=0
		Merged Map outputs=500
		GC time elapsed (ms)=58693
		CPU time spent (ms)=9346950
		Physical memory (bytes) snapshot=110862438400
		Virtual memory (bytes) snapshot=592569757696
		Total committed heap usage (bytes)=159537430528
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109008947
	rmr
		reduce calls=18623832
15/04/12 03:30:25 INFO streaming.StreamJob: Output directory: /tmp/file6e8f3aa2fe4f
function () 
{
    fname
}
<bytecode: 0x2976080>
<environment: 0x2975448>
15/04/12 03:30:30 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file6e8f3aa2fe4f

real	16m39.206s
user	0m23.502s
sys	0m1.939s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-10-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=10"


15/04/12 03:30:37 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 03:30:37 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7726670101887608250.jar tmpDir=null
15/04/12 03:30:37 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 03:30:37 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 03:30:38 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 03:30:38 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 03:30:38 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 03:30:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4497
15/04/12 03:30:39 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4497
15/04/12 03:30:39 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4497/
15/04/12 03:30:39 INFO mapreduce.Job: Running job: job_1422482982071_4497
15/04/12 03:30:46 INFO mapreduce.Job: Job job_1422482982071_4497 running in uber mode : false
15/04/12 03:30:46 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 03:30:57 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 03:30:58 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 03:31:00 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 03:31:01 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 03:31:04 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 03:31:07 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 03:31:09 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 03:31:10 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 03:31:12 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 03:31:13 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 03:31:15 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 03:31:16 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 03:31:17 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 03:31:18 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 03:31:19 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 03:31:20 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 03:31:21 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 03:31:22 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 03:31:23 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 03:31:24 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 03:31:25 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 03:31:26 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 03:31:27 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 03:31:28 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 03:31:29 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 03:31:30 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 03:31:31 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 03:31:32 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 03:31:33 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 03:31:34 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 03:31:35 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 03:31:36 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 03:31:37 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 03:31:38 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 03:31:40 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 03:31:41 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 03:31:43 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 03:31:44 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 03:31:46 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 03:31:47 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 03:31:48 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 03:31:50 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 03:31:52 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 03:31:53 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 03:31:54 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 03:31:55 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 03:31:56 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 03:31:57 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 03:31:58 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 03:31:59 INFO mapreduce.Job:  map 87% reduce 2%
15/04/12 03:32:00 INFO mapreduce.Job:  map 88% reduce 17%
15/04/12 03:32:01 INFO mapreduce.Job:  map 90% reduce 22%
15/04/12 03:32:02 INFO mapreduce.Job:  map 91% reduce 22%
15/04/12 03:32:03 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 03:32:04 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 03:32:06 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 03:32:08 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 03:32:17 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 03:32:18 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 03:32:21 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 03:32:22 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 03:32:25 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 03:32:28 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 03:32:30 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 03:32:31 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 03:32:32 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 03:32:33 INFO mapreduce.Job:  map 100% reduce 36%
15/04/12 03:32:34 INFO mapreduce.Job:  map 100% reduce 43%
15/04/12 03:32:36 INFO mapreduce.Job:  map 100% reduce 45%
15/04/12 03:32:38 INFO mapreduce.Job:  map 100% reduce 56%
15/04/12 03:32:41 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 03:32:44 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 03:32:46 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 03:32:50 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 03:32:55 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 03:32:59 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 03:33:05 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 03:33:12 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 03:33:19 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 03:33:26 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 03:33:32 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 03:33:38 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 03:33:45 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 03:33:54 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 03:34:03 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 03:34:10 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 03:34:20 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 03:34:29 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 03:34:42 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 03:34:57 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 03:35:08 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 03:35:24 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 03:35:40 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 03:35:55 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 03:36:09 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 03:36:25 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 03:36:46 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 03:37:10 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 03:37:38 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 03:37:58 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 03:38:18 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 03:38:47 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 03:39:23 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 03:40:01 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 03:40:45 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 03:43:03 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 03:48:21 INFO mapreduce.Job: Job job_1422482982071_4497 completed successfully
15/04/12 03:48:21 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607074354
		FILE: Number of bytes written=21219945068
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1109008280
		HDFS: Number of read operations=180
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=10
		Data-local map tasks=32
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=7394944
		Total time spent by all reduces in occupied slots (ms)=12023476
		Total time spent by all map tasks (ms)=3697472
		Total time spent by all reduce tasks (ms)=6011738
		Total vcore-seconds taken by all map tasks=3697472
		Total vcore-seconds taken by all reduce tasks=6011738
		Total megabyte-seconds taken by all map tasks=29934733312
		Total megabyte-seconds taken by all reduce tasks=72140856000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985392
		Map output bytes=10355525459
		Map output materialized bytes=10607077264
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623810
		Reduce shuffle bytes=10607077264
		Reduce input records=121985392
		Reduce output records=18697797
		Spilled Records=243970784
		Shuffled Maps =500
		Failed Shuffles=0
		Merged Map outputs=500
		GC time elapsed (ms)=60489
		CPU time spent (ms)=9562880
		Physical memory (bytes) snapshot=110702292992
		Virtual memory (bytes) snapshot=592970846208
		Total committed heap usage (bytes)=159536742400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1109008280
	rmr
		reduce calls=18623810
15/04/12 03:48:21 INFO streaming.StreamJob: Output directory: /tmp/file71426e7fc403
function () 
{
    fname
}
<bytecode: 0x2158080>
<environment: 0x2157448>
15/04/12 03:48:28 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file71426e7fc403

real	17m57.507s
user	0m27.359s
sys	0m2.401s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-5-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=5"


15/04/12 03:48:33 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 03:48:33 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6368859310310985792.jar tmpDir=null
15/04/12 03:48:34 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 03:48:34 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 03:48:35 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 03:48:35 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 03:48:35 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 03:48:36 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4498
15/04/12 03:48:36 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4498
15/04/12 03:48:36 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4498/
15/04/12 03:48:36 INFO mapreduce.Job: Running job: job_1422482982071_4498
15/04/12 03:48:41 INFO mapreduce.Job: Job job_1422482982071_4498 running in uber mode : false
15/04/12 03:48:41 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 03:48:52 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 03:48:53 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 03:48:55 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 03:48:56 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 03:48:59 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 03:49:01 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 03:49:02 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 03:49:05 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 03:49:06 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 03:49:08 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 03:49:09 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 03:49:11 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 03:49:12 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 03:49:14 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 03:49:15 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 03:49:17 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 03:49:18 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 03:49:20 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 03:49:21 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 03:49:22 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 03:49:23 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 03:49:24 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 03:49:25 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 03:49:26 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 03:49:27 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 03:49:29 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 03:49:30 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 03:49:32 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 03:49:33 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 03:49:35 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 03:49:36 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 03:49:38 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 03:49:39 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 03:49:42 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 03:49:43 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 03:49:44 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 03:49:46 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 03:49:48 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 03:49:49 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 03:49:50 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 03:49:51 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 03:49:52 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 03:49:53 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 03:49:54 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 03:49:55 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 03:49:56 INFO mapreduce.Job:  map 90% reduce 18%
15/04/12 03:49:57 INFO mapreduce.Job:  map 91% reduce 18%
15/04/12 03:50:00 INFO mapreduce.Job:  map 92% reduce 18%
15/04/12 03:50:02 INFO mapreduce.Job:  map 92% reduce 19%
15/04/12 03:50:03 INFO mapreduce.Job:  map 93% reduce 19%
15/04/12 03:50:05 INFO mapreduce.Job:  map 93% reduce 24%
15/04/12 03:50:06 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 03:50:09 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 03:50:15 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 03:50:16 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 03:50:18 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 03:50:19 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 03:50:20 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 03:50:21 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 03:50:22 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 03:50:24 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 03:50:27 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 03:50:30 INFO mapreduce.Job:  map 100% reduce 56%
15/04/12 03:50:33 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 03:50:36 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 03:50:55 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 03:51:05 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 03:51:19 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 03:51:32 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 03:51:47 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 03:51:56 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 03:52:12 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 03:52:33 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 03:53:02 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 03:53:15 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 03:53:28 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 03:53:58 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 03:54:10 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 03:54:30 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 03:54:58 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 03:55:19 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 03:55:49 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 03:55:59 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 03:56:29 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 03:56:47 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 03:57:15 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 03:57:42 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 03:58:00 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 03:58:57 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 03:59:18 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 03:59:49 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 04:00:25 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 04:01:05 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 04:01:58 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 04:02:53 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 04:04:09 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 04:05:29 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 04:08:52 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 04:14:46 INFO mapreduce.Job: Job job_1422482982071_4498 completed successfully
15/04/12 04:14:46 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607084539
		FILE: Number of bytes written=21219476191
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1108681676
		HDFS: Number of read operations=165
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=5
		Data-local map tasks=31
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=7516196
		Total time spent by all reduces in occupied slots (ms)=11157594
		Total time spent by all map tasks (ms)=3758098
		Total time spent by all reduce tasks (ms)=5578797
		Total vcore-seconds taken by all map tasks=3758098
		Total vcore-seconds taken by all reduce tasks=5578797
		Total megabyte-seconds taken by all map tasks=30425561408
		Total megabyte-seconds taken by all reduce tasks=66945564000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985413
		Map output bytes=10355535627
		Map output materialized bytes=10607085967
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623823
		Reduce shuffle bytes=10607085967
		Reduce input records=121985413
		Reduce output records=18695506
		Spilled Records=243970826
		Shuffled Maps =250
		Failed Shuffles=0
		Merged Map outputs=250
		GC time elapsed (ms)=60381
		CPU time spent (ms)=9412000
		Physical memory (bytes) snapshot=108140892160
		Virtual memory (bytes) snapshot=525948485632
		Total committed heap usage (bytes)=149122609152
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1108681676
	rmr
		reduce calls=18623823
15/04/12 04:14:46 INFO streaming.StreamJob: Output directory: /tmp/file72ea35a32d50
function () 
{
    fname
}
<bytecode: 0x275b080>
<environment: 0x275a448>
15/04/12 04:14:52 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file72ea35a32d50

real	26m24.053s
user	0m26.446s
sys	0m1.951s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-5-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=5"


15/04/12 04:14:57 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 04:14:57 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob333421044874858194.jar tmpDir=null
15/04/12 04:14:58 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 04:14:58 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 04:14:58 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 04:14:58 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 04:14:59 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 04:14:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4499
15/04/12 04:14:59 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4499
15/04/12 04:14:59 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4499/
15/04/12 04:14:59 INFO mapreduce.Job: Running job: job_1422482982071_4499
15/04/12 04:15:06 INFO mapreduce.Job: Job job_1422482982071_4499 running in uber mode : false
15/04/12 04:15:06 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 04:15:17 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 04:15:18 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 04:15:20 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 04:15:21 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 04:15:23 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 04:15:24 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 04:15:25 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 04:15:26 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 04:15:27 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 04:15:29 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 04:15:30 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 04:15:32 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 04:15:33 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 04:15:35 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 04:15:36 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 04:15:38 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 04:15:39 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 04:15:41 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 04:15:42 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 04:15:44 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 04:15:45 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 04:15:47 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 04:15:48 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 04:15:50 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 04:15:51 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 04:15:52 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 04:15:53 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 04:15:54 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 04:15:55 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 04:15:57 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 04:15:58 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 04:16:00 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 04:16:01 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 04:16:02 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 04:16:03 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 04:16:04 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 04:16:06 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 04:16:07 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 04:16:08 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 04:16:11 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 04:16:12 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 04:16:13 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 04:16:14 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 04:16:15 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 04:16:16 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 04:16:17 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 04:16:18 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 04:16:19 INFO mapreduce.Job:  map 85% reduce 10%
15/04/12 04:16:20 INFO mapreduce.Job:  map 87% reduce 17%
15/04/12 04:16:21 INFO mapreduce.Job:  map 88% reduce 17%
15/04/12 04:16:22 INFO mapreduce.Job:  map 89% reduce 18%
15/04/12 04:16:23 INFO mapreduce.Job:  map 90% reduce 19%
15/04/12 04:16:24 INFO mapreduce.Job:  map 92% reduce 19%
15/04/12 04:16:25 INFO mapreduce.Job:  map 93% reduce 19%
15/04/12 04:16:28 INFO mapreduce.Job:  map 93% reduce 21%
15/04/12 04:16:29 INFO mapreduce.Job:  map 94% reduce 22%
15/04/12 04:16:30 INFO mapreduce.Job:  map 94% reduce 23%
15/04/12 04:16:32 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 04:16:35 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 04:16:38 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 04:16:43 INFO mapreduce.Job:  map 96% reduce 29%
15/04/12 04:16:45 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 04:16:46 INFO mapreduce.Job:  map 99% reduce 29%
15/04/12 04:16:48 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 04:16:49 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 04:16:51 INFO mapreduce.Job:  map 100% reduce 39%
15/04/12 04:16:54 INFO mapreduce.Job:  map 100% reduce 55%
15/04/12 04:16:57 INFO mapreduce.Job:  map 100% reduce 58%
15/04/12 04:17:00 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 04:17:01 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 04:17:15 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 04:17:27 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 04:17:39 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 04:17:54 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 04:18:07 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 04:18:18 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 04:18:33 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 04:18:53 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 04:19:21 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 04:19:34 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 04:19:56 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 04:20:20 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 04:20:36 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 04:20:55 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 04:21:21 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 04:21:44 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 04:22:11 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 04:22:32 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 04:22:46 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 04:23:11 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 04:23:35 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 04:23:59 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 04:24:27 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 04:24:59 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 04:25:33 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 04:26:04 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 04:26:35 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 04:27:14 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 04:28:10 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 04:29:09 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 04:30:21 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 04:31:46 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 04:34:27 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 04:39:12 INFO mapreduce.Job: Job job_1422482982071_4499 completed successfully
15/04/12 04:39:12 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607083278
		FILE: Number of bytes written=21219473394
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1108690819
		HDFS: Number of read operations=165
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=5
		Data-local map tasks=32
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=7497742
		Total time spent by all reduces in occupied slots (ms)=10821632
		Total time spent by all map tasks (ms)=3748871
		Total time spent by all reduce tasks (ms)=5410816
		Total vcore-seconds taken by all map tasks=3748871
		Total vcore-seconds taken by all reduce tasks=5410816
		Total megabyte-seconds taken by all map tasks=30350859616
		Total megabyte-seconds taken by all reduce tasks=64929792000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985403
		Map output bytes=10355534382
		Map output materialized bytes=10607084706
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623908
		Reduce shuffle bytes=10607084706
		Reduce input records=121985403
		Reduce output records=18695618
		Spilled Records=243970806
		Shuffled Maps =250
		Failed Shuffles=0
		Merged Map outputs=250
		GC time elapsed (ms)=56276
		CPU time spent (ms)=9261080
		Physical memory (bytes) snapshot=107641004032
		Virtual memory (bytes) snapshot=525553954816
		Total committed heap usage (bytes)=149011890176
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1108690819
	rmr
		reduce calls=18623908
15/04/12 04:39:12 INFO streaming.StreamJob: Output directory: /tmp/file74e0598d5382
function () 
{
    fname
}
<bytecode: 0x1a59080>
<environment: 0x1a58448>
15/04/12 04:39:18 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file74e0598d5382

real	24m26.256s
user	0m26.332s
sys	0m1.982s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-5-false-googlebooks-eng-all-5gram-20120701-ta"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=5"


15/04/12 04:39:24 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 04:39:24 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6959260910159634561.jar tmpDir=null
15/04/12 04:39:24 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 04:39:25 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 04:39:25 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/12 04:39:25 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/12 04:39:26 INFO mapreduce.JobSubmitter: number of splits:50
15/04/12 04:39:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4500
15/04/12 04:39:26 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4500
15/04/12 04:39:26 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4500/
15/04/12 04:39:26 INFO mapreduce.Job: Running job: job_1422482982071_4500
15/04/12 04:39:32 INFO mapreduce.Job: Job job_1422482982071_4500 running in uber mode : false
15/04/12 04:39:32 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 04:39:43 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 04:39:44 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 04:39:46 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 04:39:47 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 04:39:50 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 04:39:52 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 04:39:53 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 04:39:55 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 04:39:56 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 04:39:59 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 04:40:02 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 04:40:03 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 04:40:05 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 04:40:06 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 04:40:08 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 04:40:09 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 04:40:10 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 04:40:11 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 04:40:12 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 04:40:14 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 04:40:15 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 04:40:17 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 04:40:18 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 04:40:20 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 04:40:21 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 04:40:23 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 04:40:24 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 04:40:26 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 04:40:27 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 04:40:28 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 04:40:29 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 04:40:30 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 04:40:31 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 04:40:33 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 04:40:34 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 04:40:36 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 04:40:37 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 04:40:39 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 04:40:40 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 04:40:41 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 04:40:42 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 04:40:43 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 04:40:44 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 04:40:45 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 04:40:46 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 04:40:47 INFO mapreduce.Job:  map 87% reduce 4%
15/04/12 04:40:48 INFO mapreduce.Job:  map 89% reduce 15%
15/04/12 04:40:49 INFO mapreduce.Job:  map 92% reduce 18%
15/04/12 04:40:50 INFO mapreduce.Job:  map 92% reduce 19%
15/04/12 04:40:54 INFO mapreduce.Job:  map 93% reduce 19%
15/04/12 04:40:55 INFO mapreduce.Job:  map 93% reduce 20%
15/04/12 04:40:57 INFO mapreduce.Job:  map 93% reduce 22%
15/04/12 04:40:58 INFO mapreduce.Job:  map 93% reduce 25%
15/04/12 04:41:01 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 04:41:06 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 04:41:07 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 04:41:08 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 04:41:09 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 04:41:10 INFO mapreduce.Job:  map 99% reduce 29%
15/04/12 04:41:11 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 04:41:13 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 04:41:14 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 04:41:16 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 04:41:17 INFO mapreduce.Job:  map 100% reduce 43%
15/04/12 04:41:19 INFO mapreduce.Job:  map 100% reduce 48%
15/04/12 04:41:20 INFO mapreduce.Job:  map 100% reduce 51%
15/04/12 04:41:22 INFO mapreduce.Job:  map 100% reduce 58%
15/04/12 04:41:23 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 04:41:25 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 04:41:26 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 04:41:45 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 04:41:55 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 04:42:08 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 04:42:22 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 04:42:37 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 04:42:47 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 04:43:01 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 04:43:19 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 04:43:47 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 04:44:02 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 04:44:20 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 04:44:42 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 04:44:59 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 04:45:21 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 04:45:48 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 04:46:09 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 04:46:37 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 04:46:40 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 04:47:09 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 04:47:34 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 04:47:52 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 04:48:19 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 04:48:41 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 04:49:25 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 04:49:50 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 04:50:19 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 04:50:49 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 04:51:28 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 04:52:31 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 04:53:23 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 04:54:40 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 04:55:57 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 04:58:58 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 05:04:17 INFO mapreduce.Job: Job job_1422482982071_4500 completed successfully
15/04/12 05:04:17 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=10607073247
		FILE: Number of bytes written=21219453057
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6039990689
		HDFS: Number of bytes written=1108689880
		HDFS: Number of read operations=165
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Killed map tasks=1
		Launched map tasks=51
		Launched reduce tasks=5
		Data-local map tasks=32
		Rack-local map tasks=19
		Total time spent by all maps in occupied slots (ms)=7558752
		Total time spent by all reduces in occupied slots (ms)=10969654
		Total time spent by all map tasks (ms)=3779376
		Total time spent by all reduce tasks (ms)=5484827
		Total vcore-seconds taken by all map tasks=3779376
		Total vcore-seconds taken by all reduce tasks=5484827
		Total megabyte-seconds taken by all map tasks=30597828096
		Total megabyte-seconds taken by all reduce tasks=65817924000
	Map-Reduce Framework
		Map input records=135697574
		Map output records=121985439
		Map output bytes=10355524275
		Map output materialized bytes=10607074675
		Input split bytes=7900
		Combine input records=0
		Combine output records=0
		Reduce input groups=18623887
		Reduce shuffle bytes=10607074675
		Reduce input records=121985439
		Reduce output records=18695602
		Spilled Records=243970878
		Shuffled Maps =250
		Failed Shuffles=0
		Merged Map outputs=250
		GC time elapsed (ms)=54232
		CPU time spent (ms)=9369180
		Physical memory (bytes) snapshot=107786739712
		Virtual memory (bytes) snapshot=525753872384
		Total committed heap usage (bytes)=149123301376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6039982789
	File Output Format Counters 
		Bytes Written=1108689880
	rmr
		reduce calls=18623887
15/04/12 05:04:17 INFO streaming.StreamJob: Output directory: /tmp/file76b068ce07d
function () 
{
    fname
}
<bytecode: 0x2b0e080>
<environment: 0x2b0d448>
15/04/12 05:04:22 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file76b068ce07d

real	25m4.041s
user	0m26.128s
sys	0m2.171s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-40-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=40"


15/04/12 05:04:28 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 05:04:28 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob438783651315500067.jar tmpDir=null
15/04/12 05:04:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 05:04:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 05:04:29 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 05:04:29 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 05:04:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4502
15/04/12 05:04:30 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4502
15/04/12 05:04:30 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4502/
15/04/12 05:04:30 INFO mapreduce.Job: Running job: job_1422482982071_4502
15/04/12 05:04:36 INFO mapreduce.Job: Job job_1422482982071_4502 running in uber mode : false
15/04/12 05:04:36 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 05:04:47 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 05:04:48 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 05:04:51 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 05:04:52 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 05:04:54 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 05:04:55 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 05:04:57 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 05:04:58 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 05:04:59 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 05:05:00 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 05:05:01 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 05:05:03 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 05:05:04 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 05:05:06 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 05:05:07 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 05:05:08 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 05:05:09 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 05:05:10 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 05:05:12 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 05:05:13 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 05:05:14 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 05:05:15 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 05:05:16 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 05:05:17 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 05:05:19 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 05:05:20 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 05:05:21 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 05:05:22 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 05:05:23 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 05:05:24 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 05:05:25 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 05:05:26 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 05:05:27 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 05:05:28 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 05:05:29 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 05:05:30 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 05:05:31 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 05:05:32 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 05:05:34 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 05:05:35 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 05:05:36 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 05:05:37 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 05:05:38 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 05:05:40 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 05:05:42 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 05:05:44 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 05:05:45 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 05:05:46 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 05:05:47 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 05:05:48 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 05:05:49 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 05:05:50 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 05:05:51 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 05:05:52 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 05:05:53 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 05:05:54 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 05:05:55 INFO mapreduce.Job:  map 90% reduce 2%
15/04/12 05:05:56 INFO mapreduce.Job:  map 91% reduce 19%
15/04/12 05:05:57 INFO mapreduce.Job:  map 91% reduce 23%
15/04/12 05:05:58 INFO mapreduce.Job:  map 92% reduce 24%
15/04/12 05:05:59 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 05:06:05 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 05:06:10 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 05:06:17 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 05:06:19 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 05:06:21 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 05:06:23 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 05:06:24 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 05:06:26 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 05:06:27 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 05:06:29 INFO mapreduce.Job:  map 100% reduce 36%
15/04/12 05:06:30 INFO mapreduce.Job:  map 100% reduce 47%
15/04/12 05:06:31 INFO mapreduce.Job:  map 100% reduce 52%
15/04/12 05:06:32 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 05:06:33 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 05:06:34 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 05:06:35 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 05:06:36 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 05:06:38 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 05:06:39 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 05:06:42 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 05:06:45 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 05:06:47 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 05:06:50 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 05:06:52 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 05:06:54 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 05:06:57 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 05:07:00 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 05:07:04 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 05:07:07 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 05:07:12 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 05:07:18 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 05:07:22 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 05:07:27 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 05:07:34 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 05:07:39 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 05:07:43 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 05:07:49 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 05:07:55 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 05:08:03 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 05:08:10 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 05:08:17 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 05:08:26 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 05:08:34 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 05:08:44 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 05:08:58 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 05:09:13 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 05:09:27 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 05:10:10 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 05:23:08 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 05:26:30 INFO mapreduce.Job: Job job_1422482982071_4502 completed successfully
15/04/12 05:26:30 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559776973
		FILE: Number of bytes written=33130723041
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1697197382
		HDFS: Number of read operations=345
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=41
		Data-local map tasks=52
		Rack-local map tasks=24
		Total time spent by all maps in occupied slots (ms)=11590108
		Total time spent by all reduces in occupied slots (ms)=22862834
		Total time spent by all map tasks (ms)=5795054
		Total time spent by all reduce tasks (ms)=11431417
		Total vcore-seconds taken by all map tasks=5795054
		Total vcore-seconds taken by all reduce tasks=11431417
		Total megabyte-seconds taken by all map tasks=46916757184
		Total megabyte-seconds taken by all reduce tasks=137177004000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167277
		Map output bytes=16164692416
		Map output materialized bytes=16559794733
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462497
		Reduce shuffle bytes=16559794733
		Reduce input records=191167277
		Reduce output records=28580442
		Spilled Records=382334554
		Shuffled Maps =3000
		Failed Shuffles=0
		Merged Map outputs=3000
		GC time elapsed (ms)=84515
		CPU time spent (ms)=15018400
		Physical memory (bytes) snapshot=170511712256
		Virtual memory (bytes) snapshot=1223270907904
		Total committed heap usage (bytes)=291932708864
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1697197382
	rmr
		reduce calls=28462497
15/04/12 05:26:30 INFO streaming.StreamJob: Output directory: /tmp/file7924399483f3
function () 
{
    fname
}
<bytecode: 0x32cf080>
<environment: 0x32ce448>
15/04/12 05:26:35 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file7924399483f3

real	22m13.109s
user	0m25.949s
sys	0m1.938s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-40-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=40"


15/04/12 05:26:41 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 05:26:41 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4363271715916690238.jar tmpDir=null
15/04/12 05:26:41 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 05:26:41 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 05:26:42 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 05:26:42 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 05:26:43 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4503
15/04/12 05:26:43 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4503
15/04/12 05:26:43 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4503/
15/04/12 05:26:43 INFO mapreduce.Job: Running job: job_1422482982071_4503
15/04/12 05:26:50 INFO mapreduce.Job: Job job_1422482982071_4503 running in uber mode : false
15/04/12 05:26:50 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 05:27:01 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 05:27:02 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 05:27:04 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 05:27:05 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 05:27:07 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 05:27:08 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 05:27:10 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 05:27:11 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 05:27:13 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 05:27:14 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 05:27:15 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 05:27:16 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 05:27:17 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 05:27:19 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 05:27:20 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 05:27:22 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 05:27:23 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 05:27:25 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 05:27:26 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 05:27:28 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 05:27:29 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 05:27:30 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 05:27:31 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 05:27:32 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 05:27:34 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 05:27:35 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 05:27:36 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 05:27:37 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 05:27:38 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 05:27:39 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 05:27:40 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 05:27:41 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 05:27:43 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 05:27:44 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 05:27:45 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 05:27:47 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 05:27:48 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 05:27:49 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 05:27:50 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 05:27:51 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 05:27:53 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 05:27:54 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 05:27:55 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 05:27:56 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 05:27:57 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 05:27:58 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 05:27:59 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 05:28:00 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 05:28:01 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 05:28:02 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 05:28:03 INFO mapreduce.Job:  map 81% reduce 5%
15/04/12 05:28:04 INFO mapreduce.Job:  map 83% reduce 14%
15/04/12 05:28:05 INFO mapreduce.Job:  map 85% reduce 16%
15/04/12 05:28:06 INFO mapreduce.Job:  map 86% reduce 18%
15/04/12 05:28:07 INFO mapreduce.Job:  map 87% reduce 21%
15/04/12 05:28:08 INFO mapreduce.Job:  map 87% reduce 22%
15/04/12 05:28:09 INFO mapreduce.Job:  map 87% reduce 23%
15/04/12 05:28:10 INFO mapreduce.Job:  map 89% reduce 23%
15/04/12 05:28:11 INFO mapreduce.Job:  map 90% reduce 24%
15/04/12 05:28:13 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 05:28:15 INFO mapreduce.Job:  map 91% reduce 26%
15/04/12 05:28:17 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 05:28:23 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 05:28:32 INFO mapreduce.Job:  map 94% reduce 26%
15/04/12 05:28:33 INFO mapreduce.Job:  map 95% reduce 26%
15/04/12 05:28:34 INFO mapreduce.Job:  map 96% reduce 27%
15/04/12 05:28:35 INFO mapreduce.Job:  map 96% reduce 29%
15/04/12 05:28:36 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 05:28:37 INFO mapreduce.Job:  map 100% reduce 30%
15/04/12 05:28:38 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 05:28:40 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 05:28:43 INFO mapreduce.Job:  map 100% reduce 40%
15/04/12 05:28:44 INFO mapreduce.Job:  map 100% reduce 50%
15/04/12 05:28:45 INFO mapreduce.Job:  map 100% reduce 52%
15/04/12 05:28:46 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 05:28:47 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 05:28:49 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 05:28:50 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 05:28:52 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 05:28:53 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 05:28:57 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 05:29:00 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 05:29:02 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 05:29:05 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 05:29:07 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 05:29:09 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 05:29:12 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 05:29:14 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 05:29:18 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 05:29:23 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 05:29:27 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 05:29:32 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 05:29:37 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 05:29:42 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 05:29:48 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 05:29:53 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 05:29:57 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 05:30:02 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 05:30:10 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 05:30:17 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 05:30:24 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 05:30:32 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 05:30:39 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 05:30:48 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 05:30:59 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 05:31:13 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 05:31:26 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 05:31:44 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 05:32:23 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 05:45:21 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 05:48:46 INFO mapreduce.Job: Job job_1422482982071_4503 completed successfully
15/04/12 05:48:46 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559778142
		FILE: Number of bytes written=33130726529
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1697193836
		HDFS: Number of read operations=345
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=41
		Data-local map tasks=51
		Rack-local map tasks=25
		Total time spent by all maps in occupied slots (ms)=11639764
		Total time spent by all reduces in occupied slots (ms)=23526440
		Total time spent by all map tasks (ms)=5819882
		Total time spent by all reduce tasks (ms)=11763220
		Total vcore-seconds taken by all map tasks=5819882
		Total vcore-seconds taken by all reduce tasks=11763220
		Total megabyte-seconds taken by all map tasks=47117764672
		Total megabyte-seconds taken by all reduce tasks=141158640000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167321
		Map output bytes=16164693483
		Map output materialized bytes=16559795902
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462407
		Reduce shuffle bytes=16559795902
		Reduce input records=191167321
		Reduce output records=28580351
		Spilled Records=382334642
		Shuffled Maps =3000
		Failed Shuffles=0
		Merged Map outputs=3000
		GC time elapsed (ms)=82714
		CPU time spent (ms)=15114130
		Physical memory (bytes) snapshot=170937282560
		Virtual memory (bytes) snapshot=1223075946496
		Total committed heap usage (bytes)=291932172288
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1697193836
	rmr
		reduce calls=28462407
15/04/12 05:48:46 INFO streaming.StreamJob: Output directory: /tmp/file7ae952e92385
function () 
{
    fname
}
<bytecode: 0x1dfc080>
<environment: 0x1dfb448>
15/04/12 05:48:53 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file7ae952e92385

real	22m17.296s
user	0m26.310s
sys	0m1.971s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-40-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=40"


15/04/12 05:48:58 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 05:48:58 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5513588242166834469.jar tmpDir=null
15/04/12 05:48:59 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 05:48:59 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 05:49:00 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 05:49:00 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 05:49:00 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4504
15/04/12 05:49:01 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4504
15/04/12 05:49:01 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4504/
15/04/12 05:49:01 INFO mapreduce.Job: Running job: job_1422482982071_4504
15/04/12 05:49:07 INFO mapreduce.Job: Job job_1422482982071_4504 running in uber mode : false
15/04/12 05:49:07 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 05:49:18 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 05:49:19 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 05:49:21 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 05:49:22 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 05:49:24 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 05:49:25 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 05:49:27 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 05:49:28 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 05:49:30 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 05:49:31 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 05:49:33 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 05:49:34 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 05:49:36 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 05:49:37 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 05:49:39 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 05:49:40 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 05:49:42 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 05:49:43 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 05:49:45 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 05:49:46 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 05:49:49 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 05:49:50 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 05:49:51 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 05:49:52 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 05:49:53 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 05:49:55 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 05:49:56 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 05:49:58 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 05:49:59 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 05:50:00 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 05:50:01 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 05:50:02 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 05:50:04 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 05:50:05 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 05:50:06 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 05:50:07 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 05:50:08 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 05:50:09 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 05:50:11 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 05:50:12 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 05:50:14 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 05:50:16 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 05:50:17 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 05:50:19 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 05:50:20 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 05:50:21 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 05:50:22 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 05:50:23 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 05:50:24 INFO mapreduce.Job:  map 87% reduce 8%
15/04/12 05:50:25 INFO mapreduce.Job:  map 88% reduce 22%
15/04/12 05:50:26 INFO mapreduce.Job:  map 90% reduce 22%
15/04/12 05:50:27 INFO mapreduce.Job:  map 90% reduce 24%
15/04/12 05:50:28 INFO mapreduce.Job:  map 90% reduce 26%
15/04/12 05:50:29 INFO mapreduce.Job:  map 91% reduce 26%
15/04/12 05:50:32 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 05:50:38 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 05:50:46 INFO mapreduce.Job:  map 94% reduce 26%
15/04/12 05:50:47 INFO mapreduce.Job:  map 95% reduce 26%
15/04/12 05:50:49 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 05:50:51 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 05:50:52 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 05:50:53 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 05:50:54 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 05:50:55 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 05:50:56 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 05:50:58 INFO mapreduce.Job:  map 100% reduce 36%
15/04/12 05:50:59 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 05:51:00 INFO mapreduce.Job:  map 100% reduce 43%
15/04/12 05:51:01 INFO mapreduce.Job:  map 100% reduce 56%
15/04/12 05:51:02 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 05:51:04 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 05:51:05 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 05:51:08 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 05:51:10 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 05:51:11 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 05:51:14 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 05:51:17 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 05:51:19 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 05:51:22 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 05:51:24 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 05:51:27 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 05:51:30 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 05:51:33 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 05:51:38 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 05:51:41 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 05:51:46 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 05:51:50 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 05:51:55 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 05:52:02 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 05:52:07 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 05:52:11 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 05:52:18 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 05:52:25 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 05:52:32 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 05:52:39 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 05:52:45 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 05:52:52 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 05:53:01 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 05:53:12 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 05:53:27 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 05:53:44 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 05:53:57 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 05:54:39 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 06:08:27 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 06:11:57 INFO mapreduce.Job: Job job_1422482982071_4504 completed successfully
15/04/12 06:11:57 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559773104
		FILE: Number of bytes written=33130716453
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1697193314
		HDFS: Number of read operations=345
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=80
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=41
		Data-local map tasks=52
		Rack-local map tasks=24
		Total time spent by all maps in occupied slots (ms)=11624926
		Total time spent by all reduces in occupied slots (ms)=23109294
		Total time spent by all map tasks (ms)=5812463
		Total time spent by all reduce tasks (ms)=11554647
		Total vcore-seconds taken by all map tasks=5812463
		Total vcore-seconds taken by all reduce tasks=11554647
		Total megabyte-seconds taken by all map tasks=47057700448
		Total megabyte-seconds taken by all reduce tasks=138655764000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167269
		Map output bytes=16164688536
		Map output materialized bytes=16559790864
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462434
		Reduce shuffle bytes=16559790864
		Reduce input records=191167269
		Reduce output records=28580365
		Spilled Records=382334538
		Shuffled Maps =3000
		Failed Shuffles=0
		Merged Map outputs=3000
		GC time elapsed (ms)=83128
		CPU time spent (ms)=15048420
		Physical memory (bytes) snapshot=170577551360
		Virtual memory (bytes) snapshot=1223045005312
		Total committed heap usage (bytes)=291932336128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1697193314
	rmr
		reduce calls=28462434
15/04/12 06:11:57 INFO streaming.StreamJob: Output directory: /tmp/file7caa58311bcd
function () 
{
    fname
}
<bytecode: 0x234e080>
<environment: 0x234d448>
15/04/12 06:12:03 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file7caa58311bcd

real	23m10.559s
user	0m25.629s
sys	0m2.142s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-30-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=30"


15/04/12 06:12:09 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 06:12:09 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8005338622421044178.jar tmpDir=null
15/04/12 06:12:09 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 06:12:10 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 06:12:10 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 06:12:11 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 06:12:11 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4505
15/04/12 06:12:12 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4505
15/04/12 06:12:12 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4505/
15/04/12 06:12:12 INFO mapreduce.Job: Running job: job_1422482982071_4505
15/04/12 06:12:17 INFO mapreduce.Job: Job job_1422482982071_4505 running in uber mode : false
15/04/12 06:12:17 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 06:12:28 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 06:12:29 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 06:12:31 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 06:12:33 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 06:12:34 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 06:12:35 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 06:12:37 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 06:12:38 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 06:12:39 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 06:12:40 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 06:12:41 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 06:12:43 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 06:12:44 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 06:12:46 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 06:12:47 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 06:12:49 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 06:12:50 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 06:12:52 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 06:12:53 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 06:12:55 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 06:12:56 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 06:12:58 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 06:12:59 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 06:13:01 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 06:13:02 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 06:13:04 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 06:13:05 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 06:13:07 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 06:13:08 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 06:13:10 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 06:13:11 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 06:13:13 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 06:13:14 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 06:13:16 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 06:13:17 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 06:13:19 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 06:13:20 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 06:13:22 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 06:13:23 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 06:13:25 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 06:13:26 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 06:13:27 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 06:13:28 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 06:13:29 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 06:13:30 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 06:13:31 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 06:13:32 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 06:13:33 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 06:13:35 INFO mapreduce.Job:  map 88% reduce 0%
15/04/12 06:13:36 INFO mapreduce.Job:  map 90% reduce 14%
15/04/12 06:13:37 INFO mapreduce.Job:  map 91% reduce 22%
15/04/12 06:13:38 INFO mapreduce.Job:  map 91% reduce 24%
15/04/12 06:13:39 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 06:13:41 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 06:13:44 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 06:13:53 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 06:13:58 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 06:13:59 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 06:14:00 INFO mapreduce.Job:  map 98% reduce 28%
15/04/12 06:14:01 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 06:14:02 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 06:14:04 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 06:14:05 INFO mapreduce.Job:  map 100% reduce 38%
15/04/12 06:14:06 INFO mapreduce.Job:  map 100% reduce 40%
15/04/12 06:14:07 INFO mapreduce.Job:  map 100% reduce 54%
15/04/12 06:14:08 INFO mapreduce.Job:  map 100% reduce 58%
15/04/12 06:14:09 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 06:14:10 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 06:14:11 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 06:14:14 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 06:14:17 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 06:14:19 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 06:14:22 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 06:14:26 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 06:14:29 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 06:14:34 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 06:14:37 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 06:14:41 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 06:14:44 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 06:14:48 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 06:14:53 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 06:14:59 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 06:15:04 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 06:15:11 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 06:15:16 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 06:15:23 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 06:15:28 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 06:15:35 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 06:15:43 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 06:15:50 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 06:15:57 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 06:16:07 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 06:16:14 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 06:16:24 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 06:16:35 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 06:16:48 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 06:17:00 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 06:17:15 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 06:17:30 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 06:17:56 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 06:18:44 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 06:33:47 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 06:37:10 INFO mapreduce.Job: Job job_1422482982071_4505 completed successfully
15/04/12 06:37:10 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559775205
		FILE: Number of bytes written=33129734889
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1697120857
		HDFS: Number of read operations=315
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=31
		Data-local map tasks=52
		Rack-local map tasks=24
		Total time spent by all maps in occupied slots (ms)=11671168
		Total time spent by all reduces in occupied slots (ms)=22094248
		Total time spent by all map tasks (ms)=5835584
		Total time spent by all reduce tasks (ms)=11047124
		Total vcore-seconds taken by all map tasks=5835584
		Total vcore-seconds taken by all reduce tasks=11047124
		Total megabyte-seconds taken by all map tasks=47244888064
		Total megabyte-seconds taken by all reduce tasks=132565488000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167285
		Map output bytes=16164690672
		Map output materialized bytes=16559788519
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462429
		Reduce shuffle bytes=16559788519
		Reduce input records=191167285
		Reduce output records=28579917
		Spilled Records=382334570
		Shuffled Maps =2250
		Failed Shuffles=0
		Merged Map outputs=2250
		GC time elapsed (ms)=87295
		CPU time spent (ms)=15283040
		Physical memory (bytes) snapshot=168753004544
		Virtual memory (bytes) snapshot=1089615847424
		Total committed heap usage (bytes)=270882136064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1697120857
	rmr
		reduce calls=28462429
15/04/12 06:37:10 INFO streaming.StreamJob: Output directory: /tmp/file7e8e78d67660
function () 
{
    fname
}
<bytecode: 0x1fec080>
<environment: 0x1feb448>
15/04/12 06:37:16 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file7e8e78d67660

real	25m12.578s
user	0m27.386s
sys	0m2.272s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-30-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=30"


15/04/12 06:37:21 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 06:37:21 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1837369942045275809.jar tmpDir=null
15/04/12 06:37:21 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 06:37:21 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 06:37:22 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 06:37:22 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 06:37:23 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4506
15/04/12 06:37:23 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4506
15/04/12 06:37:23 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4506/
15/04/12 06:37:23 INFO mapreduce.Job: Running job: job_1422482982071_4506
15/04/12 06:37:29 INFO mapreduce.Job: Job job_1422482982071_4506 running in uber mode : false
15/04/12 06:37:29 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 06:37:41 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 06:37:42 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 06:37:44 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 06:37:45 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 06:37:47 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 06:37:48 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 06:37:50 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 06:37:51 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 06:37:53 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 06:37:54 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 06:37:56 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 06:37:57 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 06:37:59 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 06:38:00 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 06:38:02 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 06:38:03 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 06:38:05 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 06:38:06 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 06:38:07 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 06:38:08 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 06:38:09 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 06:38:11 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 06:38:12 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 06:38:14 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 06:38:15 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 06:38:16 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 06:38:17 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 06:38:18 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 06:38:19 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 06:38:20 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 06:38:21 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 06:38:22 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 06:38:23 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 06:38:24 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 06:38:25 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 06:38:26 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 06:38:27 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 06:38:29 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 06:38:30 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 06:38:31 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 06:38:32 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 06:38:33 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 06:38:35 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 06:38:38 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 06:38:40 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 06:38:41 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 06:38:42 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 06:38:43 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 06:38:44 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 06:38:45 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 06:38:47 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 06:38:48 INFO mapreduce.Job:  map 88% reduce 0%
15/04/12 06:38:49 INFO mapreduce.Job:  map 90% reduce 8%
15/04/12 06:38:50 INFO mapreduce.Job:  map 91% reduce 22%
15/04/12 06:38:51 INFO mapreduce.Job:  map 91% reduce 24%
15/04/12 06:38:52 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 06:38:53 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 06:38:55 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 06:38:56 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 06:38:59 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 06:39:08 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 06:39:09 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 06:39:11 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 06:39:12 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 06:39:13 INFO mapreduce.Job:  map 99% reduce 29%
15/04/12 06:39:14 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 06:39:15 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 06:39:16 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 06:39:17 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 06:39:18 INFO mapreduce.Job:  map 100% reduce 36%
15/04/12 06:39:19 INFO mapreduce.Job:  map 100% reduce 37%
15/04/12 06:39:20 INFO mapreduce.Job:  map 100% reduce 47%
15/04/12 06:39:21 INFO mapreduce.Job:  map 100% reduce 56%
15/04/12 06:39:23 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 06:39:24 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 06:39:25 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 06:39:27 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 06:39:30 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 06:39:33 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 06:39:36 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 06:39:40 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 06:39:45 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 06:39:48 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 06:39:52 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 06:39:55 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 06:39:58 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 06:40:04 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 06:40:07 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 06:40:13 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 06:40:19 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 06:40:26 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 06:40:34 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 06:40:38 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 06:40:43 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 06:40:50 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 06:40:58 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 06:41:04 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 06:41:11 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 06:41:22 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 06:41:28 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 06:41:37 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 06:41:49 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 06:42:00 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 06:42:12 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 06:42:25 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 06:42:40 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 06:43:00 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 06:43:58 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 06:59:08 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 07:03:20 INFO mapreduce.Job: Job job_1422482982071_4506 completed successfully
15/04/12 07:03:20 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559768042
		FILE: Number of bytes written=33129720563
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1697106104
		HDFS: Number of read operations=315
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=31
		Data-local map tasks=51
		Rack-local map tasks=25
		Total time spent by all maps in occupied slots (ms)=11652750
		Total time spent by all reduces in occupied slots (ms)=22090594
		Total time spent by all map tasks (ms)=5826375
		Total time spent by all reduce tasks (ms)=11045297
		Total vcore-seconds taken by all map tasks=5826375
		Total vcore-seconds taken by all reduce tasks=11045297
		Total megabyte-seconds taken by all map tasks=47170332000
		Total megabyte-seconds taken by all reduce tasks=132543564000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167230
		Map output bytes=16164683617
		Map output materialized bytes=16559781356
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462181
		Reduce shuffle bytes=16559781356
		Reduce input records=191167230
		Reduce output records=28579666
		Spilled Records=382334460
		Shuffled Maps =2250
		Failed Shuffles=0
		Merged Map outputs=2250
		GC time elapsed (ms)=89129
		CPU time spent (ms)=15143580
		Physical memory (bytes) snapshot=168717520896
		Virtual memory (bytes) snapshot=1089039093760
		Total committed heap usage (bytes)=270882390016
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1697106104
	rmr
		reduce calls=28462181
15/04/12 07:03:20 INFO streaming.StreamJob: Output directory: /tmp/file80bf707078e6
function () 
{
    fname
}
<bytecode: 0x361d080>
<environment: 0x361c448>
15/04/12 07:03:26 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file80bf707078e6

real	26m10.541s
user	0m26.624s
sys	0m2.077s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-30-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=30"


15/04/12 07:03:31 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 07:03:31 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4498211123920249848.jar tmpDir=null
15/04/12 07:03:32 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 07:03:32 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 07:03:32 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 07:03:32 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 07:03:33 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4507
15/04/12 07:03:33 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4507
15/04/12 07:03:33 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4507/
15/04/12 07:03:33 INFO mapreduce.Job: Running job: job_1422482982071_4507
15/04/12 07:03:40 INFO mapreduce.Job: Job job_1422482982071_4507 running in uber mode : false
15/04/12 07:03:40 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 07:03:51 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 07:03:54 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 07:03:57 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 07:03:58 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 07:04:00 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 07:04:01 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 07:04:03 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 07:04:04 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 07:04:06 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 07:04:07 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 07:04:09 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 07:04:10 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 07:04:12 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 07:04:13 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 07:04:15 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 07:04:16 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 07:04:18 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 07:04:19 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 07:04:20 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 07:04:21 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 07:04:22 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 07:04:24 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 07:04:25 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 07:04:27 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 07:04:28 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 07:04:29 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 07:04:30 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 07:04:31 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 07:04:33 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 07:04:34 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 07:04:35 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 07:04:36 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 07:04:37 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 07:04:39 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 07:04:40 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 07:04:42 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 07:04:43 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 07:04:44 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 07:04:46 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 07:04:48 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 07:04:49 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 07:04:50 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 07:04:51 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 07:04:52 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 07:04:53 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 07:04:54 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 07:04:55 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 07:04:56 INFO mapreduce.Job:  map 86% reduce 1%
15/04/12 07:04:57 INFO mapreduce.Job:  map 88% reduce 11%
15/04/12 07:04:58 INFO mapreduce.Job:  map 88% reduce 21%
15/04/12 07:04:59 INFO mapreduce.Job:  map 88% reduce 22%
15/04/12 07:05:00 INFO mapreduce.Job:  map 90% reduce 23%
15/04/12 07:05:01 INFO mapreduce.Job:  map 90% reduce 24%
15/04/12 07:05:02 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 07:05:03 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 07:05:04 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 07:05:06 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 07:05:18 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 07:05:21 INFO mapreduce.Job:  map 96% reduce 27%
15/04/12 07:05:22 INFO mapreduce.Job:  map 97% reduce 27%
15/04/12 07:05:23 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 07:05:24 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 07:05:25 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 07:05:26 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 07:05:27 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 07:05:29 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 07:05:30 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 07:05:32 INFO mapreduce.Job:  map 100% reduce 39%
15/04/12 07:05:33 INFO mapreduce.Job:  map 100% reduce 49%
15/04/12 07:05:34 INFO mapreduce.Job:  map 100% reduce 51%
15/04/12 07:05:35 INFO mapreduce.Job:  map 100% reduce 58%
15/04/12 07:05:36 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 07:05:38 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 07:05:41 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 07:05:44 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 07:05:47 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 07:05:50 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 07:05:54 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 07:05:57 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 07:06:00 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 07:06:04 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 07:06:08 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 07:06:12 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 07:06:15 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 07:06:20 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 07:06:27 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 07:06:31 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 07:06:39 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 07:06:44 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 07:06:48 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 07:06:56 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 07:07:02 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 07:07:09 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 07:07:15 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 07:07:24 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 07:07:33 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 07:07:39 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 07:07:50 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 07:08:01 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 07:08:14 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 07:08:26 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 07:08:41 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 07:08:55 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 07:09:19 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 07:10:11 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 07:26:13 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 07:29:57 INFO mapreduce.Job: Job job_1422482982071_4507 completed successfully
15/04/12 07:29:58 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559783296
		FILE: Number of bytes written=33129750651
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1697116538
		HDFS: Number of read operations=315
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=60
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=31
		Data-local map tasks=51
		Rack-local map tasks=25
		Total time spent by all maps in occupied slots (ms)=11645612
		Total time spent by all reduces in occupied slots (ms)=22579244
		Total time spent by all map tasks (ms)=5822806
		Total time spent by all reduce tasks (ms)=11289622
		Total vcore-seconds taken by all map tasks=5822806
		Total vcore-seconds taken by all reduce tasks=11289622
		Total megabyte-seconds taken by all map tasks=47141437376
		Total megabyte-seconds taken by all reduce tasks=135475464000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167244
		Map output bytes=16164698855
		Map output materialized bytes=16559796610
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462339
		Reduce shuffle bytes=16559796610
		Reduce input records=191167244
		Reduce output records=28579819
		Spilled Records=382334488
		Shuffled Maps =2250
		Failed Shuffles=0
		Merged Map outputs=2250
		GC time elapsed (ms)=90164
		CPU time spent (ms)=15265430
		Physical memory (bytes) snapshot=168773992448
		Virtual memory (bytes) snapshot=1089429417984
		Total committed heap usage (bytes)=270881390592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1697116538
	rmr
		reduce calls=28462339
15/04/12 07:29:58 INFO streaming.StreamJob: Output directory: /tmp/file82b77df891d3
function () 
{
    fname
}
<bytecode: 0x2801080>
<environment: 0x2800448>
15/04/12 07:30:03 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file82b77df891d3

real	26m36.900s
user	0m25.555s
sys	0m2.033s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-20-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=20"


15/04/12 07:30:08 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 07:30:08 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5214463384902977028.jar tmpDir=null
15/04/12 07:30:09 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 07:30:09 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 07:30:10 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 07:30:10 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 07:30:10 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4508
15/04/12 07:30:11 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4508
15/04/12 07:30:11 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4508/
15/04/12 07:30:11 INFO mapreduce.Job: Running job: job_1422482982071_4508
15/04/12 07:30:16 INFO mapreduce.Job: Job job_1422482982071_4508 running in uber mode : false
15/04/12 07:30:16 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 07:30:27 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 07:30:28 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 07:30:30 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 07:30:31 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 07:30:33 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 07:30:34 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 07:30:37 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 07:30:39 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 07:30:40 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 07:30:43 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 07:30:45 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 07:30:46 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 07:30:47 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 07:30:49 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 07:30:51 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 07:30:52 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 07:30:53 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 07:30:55 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 07:30:56 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 07:30:58 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 07:31:00 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 07:31:01 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 07:31:02 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 07:31:04 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 07:31:05 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 07:31:07 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 07:31:08 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 07:31:09 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 07:31:10 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 07:31:11 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 07:31:13 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 07:31:14 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 07:31:16 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 07:31:17 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 07:31:19 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 07:31:21 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 07:31:23 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 07:31:24 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 07:31:25 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 07:31:26 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 07:31:27 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 07:31:28 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 07:31:29 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 07:31:30 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 07:31:31 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 07:31:32 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 07:31:33 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 07:31:34 INFO mapreduce.Job:  map 86% reduce 3%
15/04/12 07:31:35 INFO mapreduce.Job:  map 87% reduce 20%
15/04/12 07:31:36 INFO mapreduce.Job:  map 89% reduce 20%
15/04/12 07:31:37 INFO mapreduce.Job:  map 90% reduce 20%
15/04/12 07:31:38 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 07:31:39 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 07:31:41 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 07:31:46 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 07:31:58 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 07:32:00 INFO mapreduce.Job:  map 94% reduce 28%
15/04/12 07:32:01 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 07:32:02 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 07:32:03 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 07:32:04 INFO mapreduce.Job:  map 98% reduce 28%
15/04/12 07:32:05 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 07:32:06 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 07:32:08 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 07:32:09 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 07:32:11 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 07:32:20 INFO mapreduce.Job:  map 100% reduce 38%
15/04/12 07:32:21 INFO mapreduce.Job:  map 100% reduce 48%
15/04/12 07:32:23 INFO mapreduce.Job:  map 100% reduce 51%
15/04/12 07:32:24 INFO mapreduce.Job:  map 100% reduce 58%
15/04/12 07:32:26 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 07:32:27 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 07:32:28 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 07:32:30 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 07:32:33 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 07:32:39 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 07:32:42 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 07:32:48 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 07:32:54 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 07:33:00 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 07:33:04 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 07:33:09 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 07:33:16 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 07:33:24 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 07:33:36 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 07:33:44 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 07:33:49 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 07:33:58 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 07:34:08 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 07:34:16 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 07:34:26 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 07:34:37 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 07:34:47 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 07:34:57 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 07:35:05 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 07:35:18 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 07:35:29 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 07:35:41 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 07:35:56 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 07:36:14 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 07:36:37 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 07:37:04 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 07:37:24 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 07:37:57 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 07:38:57 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 07:48:41 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 07:50:10 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 07:54:48 INFO mapreduce.Job: Job job_1422482982071_4508 completed successfully
15/04/12 07:54:48 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559774633
		FILE: Number of bytes written=33128747979
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1696970552
		HDFS: Number of read operations=285
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=21
		Data-local map tasks=50
		Rack-local map tasks=26
		Total time spent by all maps in occupied slots (ms)=11878646
		Total time spent by all reduces in occupied slots (ms)=21262846
		Total time spent by all map tasks (ms)=5939323
		Total time spent by all reduce tasks (ms)=10631423
		Total vcore-seconds taken by all map tasks=5939323
		Total vcore-seconds taken by all reduce tasks=10631423
		Total megabyte-seconds taken by all map tasks=48084759008
		Total megabyte-seconds taken by all reduce tasks=127577076000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167252
		Map output bytes=16164690222
		Map output materialized bytes=16559783501
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462378
		Reduce shuffle bytes=16559783501
		Reduce input records=191167252
		Reduce output records=28578861
		Spilled Records=382334504
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=84497
		CPU time spent (ms)=15367450
		Physical memory (bytes) snapshot=166945136640
		Virtual memory (bytes) snapshot=956179660800
		Total committed heap usage (bytes)=249831051264
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1696970552
	rmr
		reduce calls=28462378
15/04/12 07:54:48 INFO streaming.StreamJob: Output directory: /tmp/file849546ffd4a9
function () 
{
    fname
}
<bytecode: 0x2d13080>
<environment: 0x2d12448>
15/04/12 07:54:54 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file849546ffd4a9

real	24m50.659s
user	0m25.395s
sys	0m1.926s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-20-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=20"


15/04/12 07:54:59 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 07:54:59 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8848911059297615727.jar tmpDir=null
15/04/12 07:55:00 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 07:55:00 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 07:55:00 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 07:55:01 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 07:55:01 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4509
15/04/12 07:55:02 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4509
15/04/12 07:55:02 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4509/
15/04/12 07:55:02 INFO mapreduce.Job: Running job: job_1422482982071_4509
15/04/12 07:55:08 INFO mapreduce.Job: Job job_1422482982071_4509 running in uber mode : false
15/04/12 07:55:08 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 07:55:19 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 07:55:20 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 07:55:22 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 07:55:23 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 07:55:25 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 07:55:26 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 07:55:28 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 07:55:29 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 07:55:31 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 07:55:32 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 07:55:34 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 07:55:35 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 07:55:37 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 07:55:38 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 07:55:40 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 07:55:41 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 07:55:43 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 07:55:44 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 07:55:46 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 07:55:47 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 07:55:49 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 07:55:50 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 07:55:52 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 07:55:53 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 07:55:55 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 07:55:56 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 07:55:58 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 07:55:59 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 07:56:00 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 07:56:01 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 07:56:02 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 07:56:03 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 07:56:05 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 07:56:07 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 07:56:08 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 07:56:11 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 07:56:12 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 07:56:16 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 07:56:17 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 07:56:18 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 07:56:19 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 07:56:20 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 07:56:21 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 07:56:22 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 07:56:24 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 07:56:25 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 07:56:26 INFO mapreduce.Job:  map 88% reduce 0%
15/04/12 07:56:27 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 07:56:28 INFO mapreduce.Job:  map 90% reduce 1%
15/04/12 07:56:29 INFO mapreduce.Job:  map 91% reduce 9%
15/04/12 07:56:30 INFO mapreduce.Job:  map 92% reduce 24%
15/04/12 07:56:32 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 07:56:33 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 07:56:39 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 07:56:49 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 07:56:50 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 07:56:52 INFO mapreduce.Job:  map 96% reduce 29%
15/04/12 07:56:53 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 07:56:54 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 07:56:55 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 07:56:57 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 07:56:58 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 07:56:59 INFO mapreduce.Job:  map 100% reduce 38%
15/04/12 07:57:00 INFO mapreduce.Job:  map 100% reduce 44%
15/04/12 07:57:01 INFO mapreduce.Job:  map 100% reduce 51%
15/04/12 07:57:02 INFO mapreduce.Job:  map 100% reduce 53%
15/04/12 07:57:03 INFO mapreduce.Job:  map 100% reduce 56%
15/04/12 07:57:04 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 07:57:05 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 07:57:06 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 07:57:07 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 07:57:08 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 07:57:12 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 07:57:16 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 07:57:21 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 07:57:27 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 07:57:32 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 07:57:37 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 07:57:43 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 07:57:48 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 07:57:54 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 07:58:03 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 07:58:13 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 07:58:17 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 07:58:26 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 07:58:36 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 07:58:43 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 07:58:52 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 07:59:02 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 07:59:11 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 07:59:23 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 07:59:35 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 07:59:44 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 07:59:57 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 08:00:04 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 08:00:20 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 08:00:32 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 08:00:51 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 08:01:14 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 08:01:36 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 08:02:00 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 08:02:31 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 08:03:31 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 08:13:18 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 08:14:57 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 08:20:14 INFO mapreduce.Job: Job job_1422482982071_4509 completed successfully
15/04/12 08:20:14 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559775340
		FILE: Number of bytes written=33128748918
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1696972043
		HDFS: Number of read operations=285
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=21
		Data-local map tasks=56
		Rack-local map tasks=20
		Total time spent by all maps in occupied slots (ms)=11692776
		Total time spent by all reduces in occupied slots (ms)=20749776
		Total time spent by all map tasks (ms)=5846388
		Total time spent by all reduce tasks (ms)=10374888
		Total vcore-seconds taken by all map tasks=5846388
		Total vcore-seconds taken by all reduce tasks=10374888
		Total megabyte-seconds taken by all map tasks=47332357248
		Total megabyte-seconds taken by all reduce tasks=124498656000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167269
		Map output bytes=16164690895
		Map output materialized bytes=16559784208
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462391
		Reduce shuffle bytes=16559784208
		Reduce input records=191167269
		Reduce output records=28578883
		Spilled Records=382334538
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=78251
		CPU time spent (ms)=15234090
		Physical memory (bytes) snapshot=166910976000
		Virtual memory (bytes) snapshot=955576725504
		Total committed heap usage (bytes)=249831047168
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1696972043
	rmr
		reduce calls=28462391
15/04/12 08:20:14 INFO streaming.StreamJob: Output directory: /tmp/file8682da4a680
function () 
{
    fname
}
<bytecode: 0x1bfb080>
<environment: 0x1bfa448>
15/04/12 08:20:20 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file8682da4a680

real	25m25.698s
user	0m25.602s
sys	0m1.877s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-20-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=20"


15/04/12 08:20:25 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 08:20:25 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8292357204185870352.jar tmpDir=null
15/04/12 08:20:25 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 08:20:25 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 08:20:26 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 08:20:27 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 08:20:27 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4513
15/04/12 08:20:28 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4513
15/04/12 08:20:28 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4513/
15/04/12 08:20:28 INFO mapreduce.Job: Running job: job_1422482982071_4513
15/04/12 08:20:32 INFO mapreduce.Job: Job job_1422482982071_4513 running in uber mode : false
15/04/12 08:20:32 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 08:20:42 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 08:20:43 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 08:20:44 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 08:20:46 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 08:20:47 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 08:20:48 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 08:20:49 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 08:20:50 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 08:20:52 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 08:20:53 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 08:20:55 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 08:20:56 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 08:20:57 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 08:20:58 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 08:20:59 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 08:21:01 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 08:21:02 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 08:21:04 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 08:21:05 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 08:21:06 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 08:21:07 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 08:21:08 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 08:21:10 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 08:21:11 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 08:21:13 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 08:21:14 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 08:21:15 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 08:21:16 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 08:21:17 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 08:21:19 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 08:21:20 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 08:21:21 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 08:21:22 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 08:21:23 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 08:21:24 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 08:21:25 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 08:21:26 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 08:21:28 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 08:21:29 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 08:21:31 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 08:21:32 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 08:21:35 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 08:21:37 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 08:21:38 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 08:21:40 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 08:21:41 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 08:21:42 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 08:21:43 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 08:21:44 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 08:21:45 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 08:21:46 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 08:21:47 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 08:21:48 INFO mapreduce.Job:  map 86% reduce 16%
15/04/12 08:21:49 INFO mapreduce.Job:  map 89% reduce 21%
15/04/12 08:21:50 INFO mapreduce.Job:  map 91% reduce 21%
15/04/12 08:21:51 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 08:21:52 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 08:21:54 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 08:21:55 INFO mapreduce.Job:  map 94% reduce 28%
15/04/12 08:22:06 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 08:22:14 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 08:22:15 INFO mapreduce.Job:  map 96% reduce 29%
15/04/12 08:22:17 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 08:22:18 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 08:22:19 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 08:22:20 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 08:22:22 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 08:22:23 INFO mapreduce.Job:  map 100% reduce 38%
15/04/12 08:22:25 INFO mapreduce.Job:  map 100% reduce 39%
15/04/12 08:22:26 INFO mapreduce.Job:  map 100% reduce 51%
15/04/12 08:22:27 INFO mapreduce.Job:  map 100% reduce 54%
15/04/12 08:22:29 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 08:22:31 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 08:22:32 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 08:22:33 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 08:22:37 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 08:22:41 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 08:22:47 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 08:22:51 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 08:22:58 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 08:23:03 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 08:23:08 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 08:23:14 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 08:23:20 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 08:23:30 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 08:23:38 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 08:23:47 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 08:23:54 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 08:24:03 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 08:24:14 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 08:24:18 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 08:24:30 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 08:24:39 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 08:24:51 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 08:25:04 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 08:25:12 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 08:25:24 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 08:25:37 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 08:25:48 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 08:26:04 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 08:26:24 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 08:26:44 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 08:27:17 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 08:27:37 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 08:28:05 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 08:28:58 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 08:38:43 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 08:40:17 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 08:45:44 INFO mapreduce.Job: Job job_1422482982071_4513 completed successfully
15/04/12 08:45:44 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=16559771432
		FILE: Number of bytes written=33128741577
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1696964183
		HDFS: Number of read operations=285
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=76
		Launched reduce tasks=21
		Data-local map tasks=53
		Rack-local map tasks=23
		Total time spent by all maps in occupied slots (ms)=11368962
		Total time spent by all reduces in occupied slots (ms)=21379458
		Total time spent by all map tasks (ms)=5684481
		Total time spent by all reduce tasks (ms)=10689729
		Total vcore-seconds taken by all map tasks=5684481
		Total vcore-seconds taken by all reduce tasks=10689729
		Total megabyte-seconds taken by all map tasks=46021558176
		Total megabyte-seconds taken by all reduce tasks=128276748000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167325
		Map output bytes=16164686889
		Map output materialized bytes=16559780300
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462283
		Reduce shuffle bytes=16559780300
		Reduce input records=191167325
		Reduce output records=28578776
		Spilled Records=382334650
		Shuffled Maps =1500
		Failed Shuffles=0
		Merged Map outputs=1500
		GC time elapsed (ms)=75343
		CPU time spent (ms)=15311340
		Physical memory (bytes) snapshot=166975700992
		Virtual memory (bytes) snapshot=955193704448
		Total committed heap usage (bytes)=249829629952
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1696964183
	rmr
		reduce calls=28462283
15/04/12 08:45:44 INFO streaming.StreamJob: Output directory: /tmp/file8bc07667d1bb
function () 
{
    fname
}
<bytecode: 0x2be3080>
<environment: 0x2be2448>
15/04/12 08:45:51 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file8bc07667d1bb

real	25m31.366s
user	0m27.042s
sys	0m2.089s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-10-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=10"


15/04/12 08:45:56 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 08:45:56 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2178897184158690185.jar tmpDir=null
15/04/12 08:45:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 08:45:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 08:45:58 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 08:45:58 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 08:45:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4516
15/04/12 08:45:59 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4516
15/04/12 08:45:59 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4516/
15/04/12 08:45:59 INFO mapreduce.Job: Running job: job_1422482982071_4516
15/04/12 08:46:06 INFO mapreduce.Job: Job job_1422482982071_4516 running in uber mode : false
15/04/12 08:46:06 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 08:46:17 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 08:46:18 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 08:46:20 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 08:46:21 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 08:46:23 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 08:46:24 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 08:46:26 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 08:46:27 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 08:46:29 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 08:46:30 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 08:46:32 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 08:46:33 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 08:46:35 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 08:46:36 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 08:46:38 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 08:46:39 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 08:46:41 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 08:46:42 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 08:46:44 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 08:46:45 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 08:46:46 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 08:46:48 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 08:46:50 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 08:46:51 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 08:46:53 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 08:46:54 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 08:46:56 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 08:46:57 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 08:46:59 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 08:47:00 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 08:47:01 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 08:47:03 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 08:47:06 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 08:47:09 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 08:47:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4516_m_000011_0, Status : FAILED
Error: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:334)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRawBytes(TypedBytesInput.java:211)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRaw(TypedBytesInput.java:152)
	at org.apache.hadoop.streaming.io.TypedBytesOutputReader.readKeyValue(TypedBytesOutputReader.java:56)
	at org.apache.hadoop.streaming.PipeMapRed$MROutputThread.run(PipeMapRed.java:376)

15/04/12 08:47:14 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 08:47:15 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 08:47:16 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 08:47:17 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 08:47:18 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 08:47:19 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 08:47:20 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 08:47:21 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 08:47:22 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 08:47:23 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 08:47:24 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 08:47:25 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 08:47:26 INFO mapreduce.Job:  map 87% reduce 4%
15/04/12 08:47:27 INFO mapreduce.Job:  map 88% reduce 12%
15/04/12 08:47:28 INFO mapreduce.Job:  map 89% reduce 19%
15/04/12 08:47:29 INFO mapreduce.Job:  map 89% reduce 21%
15/04/12 08:47:30 INFO mapreduce.Job:  map 89% reduce 22%
15/04/12 08:47:31 INFO mapreduce.Job:  map 90% reduce 22%
15/04/12 08:47:32 INFO mapreduce.Job:  map 91% reduce 23%
15/04/12 08:47:35 INFO mapreduce.Job:  map 91% reduce 24%
15/04/12 08:47:36 INFO mapreduce.Job:  map 92% reduce 24%
15/04/12 08:47:37 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 08:47:39 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 08:47:46 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 08:47:47 INFO mapreduce.Job:  map 94% reduce 26%
15/04/12 08:47:48 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 08:47:49 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 08:47:50 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 08:47:51 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 08:47:52 INFO mapreduce.Job:  map 97% reduce 30%
15/04/12 08:47:53 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 08:47:54 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 08:47:55 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 08:47:59 INFO mapreduce.Job:  map 99% reduce 33%
15/04/12 08:48:11 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 08:48:31 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 08:48:32 INFO mapreduce.Job:  map 100% reduce 41%
15/04/12 08:48:33 INFO mapreduce.Job:  map 100% reduce 46%
15/04/12 08:48:34 INFO mapreduce.Job:  map 100% reduce 49%
15/04/12 08:48:35 INFO mapreduce.Job:  map 100% reduce 58%
15/04/12 08:48:36 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 08:48:37 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 08:48:38 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 08:48:39 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 08:48:47 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 08:48:59 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 08:49:09 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 08:49:21 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 08:49:33 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 08:49:50 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 08:49:55 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 08:50:08 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 08:50:24 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 08:50:35 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 08:50:49 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 08:51:00 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 08:51:16 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 08:51:31 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 08:51:50 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 08:52:12 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 08:52:30 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 08:52:46 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 08:53:07 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 08:53:29 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 08:53:56 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 08:54:26 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 08:54:58 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 08:55:24 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 08:55:58 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 08:56:37 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 08:57:23 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 08:58:18 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 08:59:25 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 09:02:12 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 09:04:57 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 09:09:19 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 09:14:20 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 09:20:06 INFO mapreduce.Job: Job job_1422482982071_4516 completed successfully
15/04/12 09:20:07 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=16559781137
		FILE: Number of bytes written=33127775173
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1696831715
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Failed map tasks=1
		Killed map tasks=2
		Launched map tasks=78
		Launched reduce tasks=10
		Other local map tasks=2
		Data-local map tasks=51
		Rack-local map tasks=25
		Total time spent by all maps in occupied slots (ms)=12237414
		Total time spent by all reduces in occupied slots (ms)=18764254
		Total time spent by all map tasks (ms)=6118707
		Total time spent by all reduce tasks (ms)=9382127
		Total vcore-seconds taken by all map tasks=6118707
		Total vcore-seconds taken by all reduce tasks=9382127
		Total megabyte-seconds taken by all map tasks=49537051872
		Total megabyte-seconds taken by all reduce tasks=112585524000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167325
		Map output bytes=16164696574
		Map output materialized bytes=16559785511
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462616
		Reduce shuffle bytes=16559785511
		Reduce input records=191167325
		Reduce output records=28578087
		Spilled Records=382334650
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=70921
		CPU time spent (ms)=15035120
		Physical memory (bytes) snapshot=165861363712
		Virtual memory (bytes) snapshot=822723485696
		Total committed heap usage (bytes)=228779995136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1696831715
	rmr
		reduce calls=28462616
15/04/12 09:20:07 INFO streaming.StreamJob: Output directory: /tmp/file90127ff23172
function () 
{
    fname
}
<bytecode: 0x239b080>
<environment: 0x239a448>
15/04/12 09:20:12 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file90127ff23172

real	34m20.791s
user	0m28.439s
sys	0m2.405s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-10-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=10"


15/04/12 09:20:17 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 09:20:17 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2690191803095271795.jar tmpDir=null
15/04/12 09:20:18 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 09:20:18 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 09:20:19 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 09:20:19 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 09:20:20 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4520
15/04/12 09:20:20 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4520
15/04/12 09:20:20 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4520/
15/04/12 09:20:20 INFO mapreduce.Job: Running job: job_1422482982071_4520
15/04/12 09:20:27 INFO mapreduce.Job: Job job_1422482982071_4520 running in uber mode : false
15/04/12 09:20:27 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 09:20:38 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 09:20:39 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 09:20:42 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 09:20:45 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 09:20:47 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 09:20:48 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 09:20:49 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 09:20:51 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 09:20:53 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 09:20:54 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 09:20:55 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 09:20:56 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 09:20:57 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 09:20:58 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 09:20:59 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 09:21:00 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 09:21:01 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 09:21:03 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 09:21:05 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 09:21:06 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 09:21:07 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 09:21:08 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 09:21:09 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 09:21:10 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 09:21:12 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 09:21:13 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 09:21:14 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 09:21:15 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 09:21:16 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 09:21:18 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 09:21:19 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 09:21:21 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 09:21:22 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 09:21:24 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 09:21:25 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 09:21:26 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 09:21:27 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 09:21:28 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 09:21:30 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 09:21:31 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 09:21:33 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 09:21:35 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 09:21:36 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 09:21:37 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 09:21:38 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 09:21:39 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 09:21:40 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 09:21:41 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 09:21:42 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 09:21:43 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 09:21:44 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 09:21:45 INFO mapreduce.Job:  map 90% reduce 18%
15/04/12 09:21:46 INFO mapreduce.Job:  map 90% reduce 20%
15/04/12 09:21:47 INFO mapreduce.Job:  map 91% reduce 20%
15/04/12 09:21:48 INFO mapreduce.Job:  map 91% reduce 22%
15/04/12 09:21:49 INFO mapreduce.Job:  map 92% reduce 22%
15/04/12 09:21:51 INFO mapreduce.Job:  map 92% reduce 23%
15/04/12 09:21:52 INFO mapreduce.Job:  map 93% reduce 23%
15/04/12 09:21:54 INFO mapreduce.Job:  map 93% reduce 25%
15/04/12 09:21:57 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 09:21:58 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 09:22:00 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 09:22:08 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 09:22:10 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 09:22:11 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 09:22:12 INFO mapreduce.Job:  map 97% reduce 30%
15/04/12 09:22:13 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 09:22:14 INFO mapreduce.Job:  map 98% reduce 31%
15/04/12 09:22:17 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 09:22:18 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 09:22:24 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 09:22:31 INFO mapreduce.Job:  map 100% reduce 50%
15/04/12 09:22:32 INFO mapreduce.Job:  map 100% reduce 52%
15/04/12 09:22:34 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 09:22:35 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 09:22:38 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 09:22:47 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 09:22:58 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 09:23:08 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 09:23:20 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 09:23:33 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 09:23:49 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 09:23:56 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 09:24:09 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 09:24:23 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 09:24:32 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 09:24:44 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 09:24:59 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 09:25:12 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 09:25:33 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 09:25:51 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 09:26:12 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 09:26:31 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 09:26:49 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 09:27:12 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 09:27:30 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 09:27:56 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 09:28:31 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 09:28:58 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 09:29:29 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 09:30:06 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 09:30:53 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 09:31:47 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 09:32:47 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 09:34:06 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 09:36:33 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 09:38:55 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 09:43:29 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 09:48:05 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 09:54:14 INFO mapreduce.Job: Job job_1422482982071_4520 completed successfully
15/04/12 09:54:14 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=16559775922
		FILE: Number of bytes written=33127764743
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1696814014
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Killed map tasks=1
		Launched map tasks=76
		Launched reduce tasks=10
		Data-local map tasks=53
		Rack-local map tasks=23
		Total time spent by all maps in occupied slots (ms)=11752190
		Total time spent by all reduces in occupied slots (ms)=19159938
		Total time spent by all map tasks (ms)=5876095
		Total time spent by all reduce tasks (ms)=9579969
		Total vcore-seconds taken by all map tasks=5876095
		Total vcore-seconds taken by all reduce tasks=9579969
		Total megabyte-seconds taken by all map tasks=47572865120
		Total megabyte-seconds taken by all reduce tasks=114959628000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167241
		Map output bytes=16164691544
		Map output materialized bytes=16559780296
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462342
		Reduce shuffle bytes=16559780296
		Reduce input records=191167241
		Reduce output records=28577807
		Spilled Records=382334482
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=69924
		CPU time spent (ms)=15331250
		Physical memory (bytes) snapshot=165913223168
		Virtual memory (bytes) snapshot=821921894400
		Total committed heap usage (bytes)=228779868160
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1696814014
	rmr
		reduce calls=28462342
15/04/12 09:54:14 INFO streaming.StreamJob: Output directory: /tmp/file96196cc998aa
function () 
{
    fname
}
<bytecode: 0x1dac080>
<environment: 0x1dab448>
15/04/12 09:54:21 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file96196cc998aa

real	34m9.267s
user	0m31.829s
sys	0m2.668s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-10-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=10"


15/04/12 09:54:26 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 09:54:26 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2770558742827113898.jar tmpDir=null
15/04/12 09:54:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 09:54:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 09:54:28 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 09:54:28 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 09:54:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4529
15/04/12 09:54:29 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4529
15/04/12 09:54:29 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4529/
15/04/12 09:54:29 INFO mapreduce.Job: Running job: job_1422482982071_4529
15/04/12 09:54:34 INFO mapreduce.Job: Job job_1422482982071_4529 running in uber mode : false
15/04/12 09:54:34 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 09:54:46 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 09:54:48 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 09:54:49 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 09:54:52 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 09:54:54 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 09:54:55 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 09:54:56 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 09:54:58 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 09:54:59 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 09:55:00 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 09:55:01 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 09:55:02 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 09:55:04 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 09:55:05 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 09:55:06 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 09:55:07 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 09:55:08 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 09:55:10 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 09:55:11 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 09:55:13 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 09:55:14 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 09:55:16 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 09:55:17 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 09:55:19 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 09:55:20 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 09:55:21 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 09:55:22 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 09:55:23 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 09:55:25 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 09:55:26 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 09:55:28 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 09:55:29 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 09:55:31 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 09:55:32 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 09:55:34 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 09:55:35 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 09:55:37 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 09:55:38 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 09:55:39 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 09:55:41 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 09:55:43 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 09:55:44 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 09:55:45 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 09:55:46 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 09:55:47 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 09:55:48 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 09:55:49 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 09:55:50 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 09:55:51 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 09:55:52 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 09:55:53 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 09:55:54 INFO mapreduce.Job:  map 87% reduce 4%
15/04/12 09:55:55 INFO mapreduce.Job:  map 89% reduce 19%
15/04/12 09:55:57 INFO mapreduce.Job:  map 91% reduce 22%
15/04/12 09:55:59 INFO mapreduce.Job:  map 92% reduce 22%
15/04/12 09:56:01 INFO mapreduce.Job:  map 92% reduce 23%
15/04/12 09:56:03 INFO mapreduce.Job:  map 93% reduce 23%
15/04/12 09:56:04 INFO mapreduce.Job:  map 93% reduce 24%
15/04/12 09:56:07 INFO mapreduce.Job:  map 93% reduce 25%
15/04/12 09:56:08 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 09:56:14 INFO mapreduce.Job:  map 94% reduce 26%
15/04/12 09:56:16 INFO mapreduce.Job:  map 95% reduce 26%
15/04/12 09:56:17 INFO mapreduce.Job:  map 96% reduce 27%
15/04/12 09:56:18 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 09:56:19 INFO mapreduce.Job:  map 98% reduce 28%
15/04/12 09:56:20 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 09:56:22 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 09:56:23 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 09:56:24 INFO mapreduce.Job:  map 100% reduce 36%
15/04/12 09:56:25 INFO mapreduce.Job:  map 100% reduce 40%
15/04/12 09:56:26 INFO mapreduce.Job:  map 100% reduce 53%
15/04/12 09:56:27 INFO mapreduce.Job:  map 100% reduce 55%
15/04/12 09:56:28 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 09:56:33 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 09:56:36 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 09:56:42 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 09:56:51 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 09:57:02 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 09:57:14 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 09:57:26 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 09:57:42 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 09:57:53 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 09:58:06 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 09:58:18 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 09:58:26 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 09:58:41 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 09:58:54 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 09:59:12 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 09:59:24 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 09:59:46 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 10:00:07 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 10:00:34 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 10:00:48 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 10:01:07 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 10:01:28 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 10:01:49 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 10:02:22 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 10:03:03 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 10:03:32 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 10:04:10 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 10:04:58 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 10:05:46 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 10:06:47 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 10:07:54 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 10:10:57 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 10:13:07 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 10:17:20 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 10:22:22 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 10:27:50 INFO mapreduce.Job: Job job_1422482982071_4529 completed successfully
15/04/12 10:27:50 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=16559762438
		FILE: Number of bytes written=33127737775
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1696811020
		HDFS: Number of read operations=255
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Killed map tasks=1
		Launched map tasks=76
		Launched reduce tasks=10
		Data-local map tasks=51
		Rack-local map tasks=25
		Total time spent by all maps in occupied slots (ms)=12028372
		Total time spent by all reduces in occupied slots (ms)=18734060
		Total time spent by all map tasks (ms)=6014186
		Total time spent by all reduce tasks (ms)=9367030
		Total vcore-seconds taken by all map tasks=6014186
		Total vcore-seconds taken by all reduce tasks=9367030
		Total megabyte-seconds taken by all map tasks=48690849856
		Total megabyte-seconds taken by all reduce tasks=112404360000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167281
		Map output bytes=16164677964
		Map output materialized bytes=16559766812
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462393
		Reduce shuffle bytes=16559766812
		Reduce input records=191167281
		Reduce output records=28577819
		Spilled Records=382334562
		Shuffled Maps =750
		Failed Shuffles=0
		Merged Map outputs=750
		GC time elapsed (ms)=66060
		CPU time spent (ms)=15397850
		Physical memory (bytes) snapshot=165763330048
		Virtual memory (bytes) snapshot=822130839552
		Total committed heap usage (bytes)=228780122112
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1696811020
	rmr
		reduce calls=28462393
15/04/12 10:27:50 INFO streaming.StreamJob: Output directory: /tmp/file9d6f5e0f552f
function () 
{
    fname
}
<bytecode: 0x2d1f080>
<environment: 0x2d1e448>
15/04/12 10:27:56 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file9d6f5e0f552f

real	33m34.923s
user	0m29.952s
sys	0m2.576s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-5-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=5"


15/04/12 10:28:01 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 10:28:01 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8404620168221914631.jar tmpDir=null
15/04/12 10:28:01 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 10:28:01 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 10:28:02 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 10:28:03 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 10:28:03 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4537
15/04/12 10:28:03 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4537
15/04/12 10:28:03 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4537/
15/04/12 10:28:03 INFO mapreduce.Job: Running job: job_1422482982071_4537
15/04/12 10:28:10 INFO mapreduce.Job: Job job_1422482982071_4537 running in uber mode : false
15/04/12 10:28:10 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 10:28:21 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 10:28:24 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 10:28:27 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 10:28:29 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 10:28:30 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 10:28:31 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 10:28:33 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 10:28:34 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 10:28:35 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 10:28:36 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 10:28:37 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 10:28:39 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 10:28:40 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 10:28:41 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 10:28:42 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 10:28:43 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 10:28:45 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 10:28:46 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 10:28:48 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 10:28:49 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 10:28:51 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 10:28:52 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 10:28:54 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 10:28:55 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 10:28:57 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 10:28:58 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 10:29:00 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 10:29:01 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 10:29:03 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 10:29:04 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 10:29:06 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 10:29:07 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 10:29:09 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 10:29:10 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 10:29:12 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 10:29:13 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 10:29:15 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 10:29:18 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 10:29:20 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 10:29:21 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 10:29:23 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 10:29:24 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 10:29:25 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 10:29:26 INFO mapreduce.Job:  map 71% reduce 0%
15/04/12 10:29:27 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 10:29:28 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 10:29:29 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 10:29:30 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 10:29:31 INFO mapreduce.Job:  map 86% reduce 9%
15/04/12 10:29:32 INFO mapreduce.Job:  map 89% reduce 12%
15/04/12 10:29:33 INFO mapreduce.Job:  map 90% reduce 12%
15/04/12 10:29:36 INFO mapreduce.Job:  map 92% reduce 12%
15/04/12 10:29:37 INFO mapreduce.Job:  map 92% reduce 14%
15/04/12 10:29:40 INFO mapreduce.Job:  map 92% reduce 17%
15/04/12 10:29:41 INFO mapreduce.Job:  map 92% reduce 23%
15/04/12 10:29:43 INFO mapreduce.Job:  map 93% reduce 23%
15/04/12 10:29:47 INFO mapreduce.Job:  map 93% reduce 24%
15/04/12 10:29:51 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 10:29:55 INFO mapreduce.Job:  map 94% reduce 26%
15/04/12 10:29:56 INFO mapreduce.Job:  map 95% reduce 26%
15/04/12 10:29:57 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 10:29:58 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 10:30:00 INFO mapreduce.Job:  map 96% reduce 29%
15/04/12 10:30:01 INFO mapreduce.Job:  map 99% reduce 29%
15/04/12 10:30:02 INFO mapreduce.Job:  map 100% reduce 29%
15/04/12 10:30:03 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 10:30:06 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 10:30:09 INFO mapreduce.Job:  map 100% reduce 45%
15/04/12 10:30:12 INFO mapreduce.Job:  map 100% reduce 51%
15/04/12 10:30:15 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 10:30:16 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 10:30:19 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 10:30:43 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 10:31:04 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 10:31:24 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 10:31:58 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 10:32:44 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 10:33:02 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 10:33:28 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 10:33:59 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 10:34:16 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 10:34:59 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 10:35:35 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 10:36:07 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 10:36:41 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 10:37:26 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 10:37:56 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 10:39:14 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 10:39:47 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 10:40:35 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 10:41:31 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 10:42:36 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 10:43:54 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 10:45:20 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 10:46:44 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 10:46:53 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 10:48:03 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 10:49:02 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 10:50:26 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 10:52:16 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 10:53:20 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 10:54:34 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 10:57:06 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 11:00:14 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 11:07:29 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 11:14:56 INFO mapreduce.Job: Job job_1422482982071_4537 completed successfully
15/04/12 11:14:57 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=16559768359
		FILE: Number of bytes written=33127256570
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1696513365
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Killed map tasks=1
		Launched map tasks=76
		Launched reduce tasks=5
		Data-local map tasks=52
		Rack-local map tasks=24
		Total time spent by all maps in occupied slots (ms)=12481916
		Total time spent by all reduces in occupied slots (ms)=18687138
		Total time spent by all map tasks (ms)=6240958
		Total time spent by all reduce tasks (ms)=9343569
		Total vcore-seconds taken by all map tasks=6240958
		Total vcore-seconds taken by all reduce tasks=9343569
		Total megabyte-seconds taken by all map tasks=50526795968
		Total megabyte-seconds taken by all reduce tasks=112122828000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167310
		Map output bytes=16164683848
		Map output materialized bytes=16559770501
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462441
		Reduce shuffle bytes=16559770501
		Reduce input records=191167310
		Reduce output records=28575735
		Spilled Records=382334620
		Shuffled Maps =375
		Failed Shuffles=0
		Merged Map outputs=375
		GC time elapsed (ms)=66283
		CPU time spent (ms)=15727810
		Physical memory (bytes) snapshot=158194544640
		Virtual memory (bytes) snapshot=755923255296
		Total committed heap usage (bytes)=218339135488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1696513365
	rmr
		reduce calls=28462441
15/04/12 11:14:57 INFO streaming.StreamJob: Output directory: /tmp/filea39c58b67b8d
function () 
{
    fname
}
<bytecode: 0x1de3080>
<environment: 0x1de2448>
15/04/12 11:15:03 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/filea39c58b67b8d

real	47m7.045s
user	0m31.479s
sys	0m3.027s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-5-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=5"


15/04/12 11:15:08 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 11:15:08 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8148890117302176372.jar tmpDir=null
15/04/12 11:15:09 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 11:15:09 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 11:15:10 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 11:15:10 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 11:15:11 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4550
15/04/12 11:15:11 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4550
15/04/12 11:15:11 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4550/
15/04/12 11:15:11 INFO mapreduce.Job: Running job: job_1422482982071_4550
15/04/12 11:15:18 INFO mapreduce.Job: Job job_1422482982071_4550 running in uber mode : false
15/04/12 11:15:18 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 11:15:29 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 11:15:32 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 11:15:33 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 11:15:35 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 11:15:38 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 11:15:41 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 11:15:44 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 11:15:45 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 11:15:47 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 11:15:48 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 11:15:51 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 11:15:52 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 11:15:54 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 11:15:55 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 11:15:57 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 11:15:58 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 11:16:00 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 11:16:01 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 11:16:03 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 11:16:04 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 11:16:06 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 11:16:07 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 11:16:09 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 11:16:10 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 11:16:12 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 11:16:13 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 11:16:15 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 11:16:16 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 11:16:18 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 11:16:19 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 11:16:21 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 11:16:22 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 11:16:24 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 11:16:26 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 11:16:27 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 11:16:30 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 11:16:32 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 11:16:33 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 11:16:34 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 11:16:35 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 11:16:36 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 11:16:37 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 11:16:38 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 11:16:39 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 11:16:40 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 11:16:41 INFO mapreduce.Job:  map 88% reduce 0%
15/04/12 11:16:42 INFO mapreduce.Job:  map 90% reduce 5%
15/04/12 11:16:43 INFO mapreduce.Job:  map 92% reduce 12%
15/04/12 11:16:44 INFO mapreduce.Job:  map 93% reduce 12%
15/04/12 11:16:49 INFO mapreduce.Job:  map 93% reduce 14%
15/04/12 11:16:50 INFO mapreduce.Job:  map 93% reduce 15%
15/04/12 11:16:51 INFO mapreduce.Job:  map 94% reduce 15%
15/04/12 11:16:52 INFO mapreduce.Job:  map 94% reduce 18%
15/04/12 11:16:53 INFO mapreduce.Job:  map 94% reduce 21%
15/04/12 11:16:59 INFO mapreduce.Job:  map 94% reduce 23%
15/04/12 11:17:00 INFO mapreduce.Job:  map 94% reduce 25%
15/04/12 11:17:01 INFO mapreduce.Job:  map 94% reduce 26%
15/04/12 11:17:02 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 11:17:03 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 11:17:06 INFO mapreduce.Job:  map 96% reduce 27%
15/04/12 11:17:07 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 11:17:08 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 11:17:10 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 11:17:11 INFO mapreduce.Job:  map 98% reduce 31%
15/04/12 11:17:13 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 11:17:14 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 11:17:17 INFO mapreduce.Job:  map 100% reduce 37%
15/04/12 11:17:19 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 11:17:20 INFO mapreduce.Job:  map 100% reduce 47%
15/04/12 11:17:22 INFO mapreduce.Job:  map 100% reduce 49%
15/04/12 11:17:23 INFO mapreduce.Job:  map 100% reduce 53%
15/04/12 11:17:25 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 11:17:26 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 11:17:29 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 11:17:32 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 11:17:56 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 11:18:14 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 11:18:36 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 11:19:04 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 11:19:48 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 11:20:09 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 11:20:36 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 11:21:01 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 11:21:27 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 11:21:54 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 11:22:37 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 11:23:06 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 11:23:41 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 11:24:12 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 11:24:52 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 11:26:03 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 11:26:37 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 11:27:26 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 11:28:28 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 11:29:29 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 11:30:33 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 11:31:54 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 11:33:24 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 11:34:19 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 11:35:00 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 11:35:57 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 11:37:07 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 11:38:49 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 11:40:12 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 11:41:25 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 11:43:43 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 11:47:31 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 11:55:16 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 12:03:29 INFO mapreduce.Job: Job job_1422482982071_4550 completed successfully
15/04/12 12:03:29 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=16559770040
		FILE: Number of bytes written=33127259532
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1696506327
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Killed map tasks=1
		Launched map tasks=76
		Launched reduce tasks=5
		Data-local map tasks=53
		Rack-local map tasks=23
		Total time spent by all maps in occupied slots (ms)=12377744
		Total time spent by all reduces in occupied slots (ms)=18026360
		Total time spent by all map tasks (ms)=6188872
		Total time spent by all reduce tasks (ms)=9013180
		Total vcore-seconds taken by all map tasks=6188872
		Total vcore-seconds taken by all reduce tasks=9013180
		Total megabyte-seconds taken by all map tasks=50105107712
		Total megabyte-seconds taken by all reduce tasks=108158160000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167243
		Map output bytes=16164685677
		Map output materialized bytes=16559772182
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462320
		Reduce shuffle bytes=16559772182
		Reduce input records=191167243
		Reduce output records=28575625
		Spilled Records=382334486
		Shuffled Maps =375
		Failed Shuffles=0
		Merged Map outputs=375
		GC time elapsed (ms)=60434
		CPU time spent (ms)=15352000
		Physical memory (bytes) snapshot=157984661504
		Virtual memory (bytes) snapshot=755313487872
		Total committed heap usage (bytes)=218307313664
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1696506327
	rmr
		reduce calls=28462320
15/04/12 12:03:29 INFO streaming.StreamJob: Output directory: /tmp/filead3f71b70568
function () 
{
    fname
}
<bytecode: 0x33a9080>
<environment: 0x33a8448>
15/04/12 12:03:35 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/filead3f71b70568

real	48m32.509s
user	0m32.189s
sys	0m3.128s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-5-false-googlebooks-eng-all-5gram-20120701-un"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=5"


15/04/12 12:03:41 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 12:03:41 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6335980292283188023.jar tmpDir=null
15/04/12 12:03:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 12:03:42 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 12:03:43 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 12:03:43 INFO mapreduce.JobSubmitter: number of splits:75
15/04/12 12:03:44 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4564
15/04/12 12:03:44 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4564
15/04/12 12:03:44 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4564/
15/04/12 12:03:44 INFO mapreduce.Job: Running job: job_1422482982071_4564
15/04/12 12:03:49 INFO mapreduce.Job: Job job_1422482982071_4564 running in uber mode : false
15/04/12 12:03:49 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 12:04:00 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 12:04:01 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 12:04:03 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 12:04:04 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 12:04:06 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 12:04:07 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 12:04:09 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 12:04:10 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 12:04:12 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 12:04:13 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 12:04:15 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 12:04:16 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 12:04:18 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 12:04:19 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 12:04:21 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 12:04:22 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 12:04:24 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 12:04:25 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 12:04:27 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 12:04:28 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 12:04:30 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 12:04:31 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 12:04:33 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 12:04:34 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 12:04:36 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 12:04:37 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 12:04:39 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 12:04:40 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 12:04:42 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 12:04:43 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 12:04:45 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 12:04:46 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 12:04:48 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 12:04:49 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 12:04:52 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 12:04:56 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 12:04:57 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 12:04:58 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 12:04:59 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 12:05:00 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 12:05:01 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 12:05:02 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 12:05:03 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 12:05:04 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 12:05:06 INFO mapreduce.Job:  map 88% reduce 0%
15/04/12 12:05:07 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 12:05:08 INFO mapreduce.Job:  map 89% reduce 10%
15/04/12 12:05:09 INFO mapreduce.Job:  map 91% reduce 12%
15/04/12 12:05:12 INFO mapreduce.Job:  map 92% reduce 12%
15/04/12 12:05:15 INFO mapreduce.Job:  map 93% reduce 14%
15/04/12 12:05:17 INFO mapreduce.Job:  map 93% reduce 16%
15/04/12 12:05:18 INFO mapreduce.Job:  map 93% reduce 17%
15/04/12 12:05:23 INFO mapreduce.Job:  map 93% reduce 19%
15/04/12 12:05:24 INFO mapreduce.Job:  map 93% reduce 20%
15/04/12 12:05:26 INFO mapreduce.Job:  map 93% reduce 23%
15/04/12 12:05:29 INFO mapreduce.Job:  map 93% reduce 24%
15/04/12 12:05:31 INFO mapreduce.Job:  map 94% reduce 24%
15/04/12 12:05:32 INFO mapreduce.Job:  map 96% reduce 26%
15/04/12 12:05:33 INFO mapreduce.Job:  map 98% reduce 27%
15/04/12 12:05:34 INFO mapreduce.Job:  map 98% reduce 28%
15/04/12 12:05:35 INFO mapreduce.Job:  map 99% reduce 28%
15/04/12 12:05:36 INFO mapreduce.Job:  map 100% reduce 29%
15/04/12 12:05:38 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 12:05:39 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 12:05:41 INFO mapreduce.Job:  map 100% reduce 37%
15/04/12 12:05:42 INFO mapreduce.Job:  map 100% reduce 39%
15/04/12 12:05:43 INFO mapreduce.Job:  map 100% reduce 41%
15/04/12 12:05:44 INFO mapreduce.Job:  map 100% reduce 43%
15/04/12 12:05:45 INFO mapreduce.Job:  map 100% reduce 45%
15/04/12 12:05:46 INFO mapreduce.Job:  map 100% reduce 48%
15/04/12 12:05:47 INFO mapreduce.Job:  map 100% reduce 54%
15/04/12 12:05:48 INFO mapreduce.Job:  map 100% reduce 55%
15/04/12 12:05:49 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 12:05:50 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 12:05:52 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 12:06:22 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 12:06:41 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 12:07:06 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 12:07:34 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 12:08:19 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 12:08:37 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 12:09:05 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 12:09:37 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 12:09:55 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 12:10:47 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 12:11:21 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 12:11:57 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 12:12:21 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 12:13:01 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 12:13:39 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 12:14:53 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 12:15:26 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 12:16:17 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 12:17:17 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 12:18:22 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 12:19:37 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 12:21:05 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 12:22:10 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 12:22:24 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 12:23:25 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 12:24:21 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 12:25:37 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 12:27:46 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 12:28:43 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 12:30:01 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 12:32:32 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 12:36:24 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 12:44:17 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 12:51:44 INFO mapreduce.Job: Job job_1422482982071_4564 completed successfully
15/04/12 12:51:44 INFO mapreduce.Job: Counters: 52
	File System Counters
		FILE: Number of bytes read=16559774588
		FILE: Number of bytes written=33127268708
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10040556145
		HDFS: Number of bytes written=1696518376
		HDFS: Number of read operations=240
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Killed map tasks=1
		Launched map tasks=76
		Launched reduce tasks=5
		Data-local map tasks=53
		Rack-local map tasks=23
		Total time spent by all maps in occupied slots (ms)=11572752
		Total time spent by all reduces in occupied slots (ms)=18453906
		Total time spent by all map tasks (ms)=5786376
		Total time spent by all reduce tasks (ms)=9226953
		Total vcore-seconds taken by all map tasks=5786376
		Total vcore-seconds taken by all reduce tasks=9226953
		Total megabyte-seconds taken by all map tasks=46846500096
		Total megabyte-seconds taken by all reduce tasks=110723436000
	Map-Reduce Framework
		Map input records=210858101
		Map output records=191167247
		Map output bytes=16164690212
		Map output materialized bytes=16559776730
		Input split bytes=11850
		Combine input records=0
		Combine output records=0
		Reduce input groups=28462534
		Reduce shuffle bytes=16559776730
		Reduce input records=191167247
		Reduce output records=28575838
		Spilled Records=382334494
		Shuffled Maps =375
		Failed Shuffles=0
		Merged Map outputs=375
		GC time elapsed (ms)=64713
		CPU time spent (ms)=15194430
		Physical memory (bytes) snapshot=158245781504
		Virtual memory (bytes) snapshot=755323334656
		Total committed heap usage (bytes)=218500464640
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10040544295
	File Output Format Counters 
		Bytes Written=1696518376
	rmr
		reduce calls=28462534
15/04/12 12:51:44 INFO streaming.StreamJob: Output directory: /tmp/fileb7ad788ef4c2
function () 
{
    fname
}
<bytecode: 0x1e89080>
<environment: 0x1e88448>
15/04/12 12:51:50 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/fileb7ad788ef4c2

real	48m14.741s
user	0m34.007s
sys	0m3.130s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-40-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=40"


15/04/12 12:51:56 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 12:51:56 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1944003895806647029.jar tmpDir=null
15/04/12 12:51:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 12:51:57 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 12:51:58 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 12:51:58 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 12:51:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4576
15/04/12 12:51:59 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4576
15/04/12 12:51:59 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4576/
15/04/12 12:51:59 INFO mapreduce.Job: Running job: job_1422482982071_4576
15/04/12 12:52:06 INFO mapreduce.Job: Job job_1422482982071_4576 running in uber mode : false
15/04/12 12:52:06 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 12:52:17 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 12:52:18 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 12:52:19 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 12:52:20 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 12:52:21 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 12:52:23 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 12:52:24 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 12:52:26 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 12:52:27 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 12:52:28 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 12:52:29 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 12:52:30 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 12:52:32 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 12:52:33 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 12:52:34 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 12:52:35 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 12:52:36 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 12:52:38 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 12:52:39 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 12:52:40 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 12:52:41 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 12:52:42 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 12:52:43 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 12:52:45 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 12:52:47 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 12:52:48 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 12:52:49 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 12:52:51 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 12:52:53 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 12:52:54 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 12:52:55 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 12:52:57 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 12:52:59 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 12:53:00 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 12:53:01 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 12:53:03 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 12:53:06 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 12:53:07 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 12:53:09 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 12:53:10 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 12:53:13 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 12:53:14 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 12:53:15 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 12:53:16 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 12:53:17 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 12:53:18 INFO mapreduce.Job:  map 74% reduce 0%
15/04/12 12:53:19 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 12:53:20 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 12:53:21 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 12:53:22 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 12:53:23 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 12:53:24 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 12:53:25 INFO mapreduce.Job:  map 89% reduce 9%
15/04/12 12:53:27 INFO mapreduce.Job:  map 91% reduce 24%
15/04/12 12:53:30 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 12:53:31 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 12:53:36 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 12:53:48 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 12:53:49 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 12:53:50 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 12:53:51 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 12:53:52 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 12:53:53 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 12:53:54 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 12:53:55 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 12:53:57 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 12:53:58 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 12:54:05 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 12:54:06 INFO mapreduce.Job:  map 100% reduce 47%
15/04/12 12:54:07 INFO mapreduce.Job:  map 100% reduce 48%
15/04/12 12:54:08 INFO mapreduce.Job:  map 100% reduce 55%
15/04/12 12:54:09 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 12:54:11 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 12:54:12 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 12:54:14 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 12:54:17 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 12:54:21 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 12:54:26 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 12:54:29 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 12:54:33 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 12:54:38 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 12:54:42 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 12:54:45 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 12:54:51 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 12:54:54 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 12:55:00 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 12:55:06 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 12:55:12 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 12:55:20 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 12:55:26 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 12:55:32 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 12:55:39 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 12:55:47 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 12:55:54 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 12:56:02 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 12:56:08 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 12:56:17 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 12:56:27 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 12:56:39 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 12:56:52 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 12:57:07 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 12:57:25 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 12:57:48 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 12:58:01 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 12:58:34 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 12:59:34 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 13:01:04 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 13:17:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4576_r_000012_0, Status : FAILED
Container [pid=42859,containerID=container_1422482982071_4576_01_000199] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4576_01_000199 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 42868 42859 42859 42859 (java) 3412 702 13312589824 554882 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4576/container_1422482982071_4576_01_000199/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4576/container_1422482982071_4576_01_000199 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 59965 attempt_1422482982071_4576_r_000012_0 199 
	|- 42859 9971 42859 42859 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4576/container_1422482982071_4576_01_000199/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4576/container_1422482982071_4576_01_000199 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 59965 attempt_1422482982071_4576_r_000012_0 199 1>/var/log/hadoop-yarn/containers/application_1422482982071_4576/container_1422482982071_4576_01_000199/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4576/container_1422482982071_4576_01_000199/stderr  
	|- 42923 42912 42859 42859 (cat) 0 26 4231168 142 cat 
	|- 42925 42912 42859 42859 (cat) 0 0 4231168 134 cat 
	|- 42912 42868 42859 42859 (R) 114744 23954 10603749376 2565714 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce2865b449f76 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 13:26:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_4576_r_000012_1, Status : FAILED
Container [pid=43007,containerID=container_1422482982071_4576_01_000228] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4576_01_000228 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 43072 43016 43007 43007 (R) 107022 18046 10587222016 2537570 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce2865b449f76 
	|- 43016 43007 43007 43007 (java) 2972 619 13411983360 564249 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4576/container_1422482982071_4576_01_000228/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4576/container_1422482982071_4576_01_000228 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 59965 attempt_1422482982071_4576_r_000012_1 228 
	|- 43140 43072 43007 43007 (cat) 0 26 103391232 159 cat 
	|- 43152 43072 43007 43007 (cat) 0 0 103391232 151 cat 
	|- 43007 3828 43007 43007 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4576/container_1422482982071_4576_01_000228/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4576/container_1422482982071_4576_01_000228 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 59965 attempt_1422482982071_4576_r_000012_1 228 1>/var/log/hadoop-yarn/containers/application_1422482982071_4576/container_1422482982071_4576_01_000228/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4576/container_1422482982071_4576_01_000228/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 13:40:53 INFO mapreduce.Job: Task Id : attempt_1422482982071_4576_r_000012_2, Status : FAILED
Container [pid=10361,containerID=container_1422482982071_4576_01_000229] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 23.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4576_01_000229 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 10413 10371 10361 10361 (R) 118523 20504 11151876096 2675458 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce2865b449f76 
	|- 10424 10413 10361 10361 (cat) 0 28 103391232 159 cat 
	|- 10371 10361 10361 10361 (java) 2647 496 13411835904 440663 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4576/container_1422482982071_4576_01_000229/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4576/container_1422482982071_4576_01_000229 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 59965 attempt_1422482982071_4576_r_000012_2 229 
	|- 10361 3817 10361 10361 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4576/container_1422482982071_4576_01_000229/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4576/container_1422482982071_4576_01_000229 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 59965 attempt_1422482982071_4576_r_000012_2 229 1>/var/log/hadoop-yarn/containers/application_1422482982071_4576/container_1422482982071_4576_01_000229/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4576/container_1422482982071_4576_01_000229/stderr  
	|- 10426 10413 10361 10361 (cat) 0 0 103391232 151 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 13:50:13 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 13:50:14 INFO mapreduce.Job: Job job_1422482982071_4576 failed with state FAILED due to: Task failed task_1422482982071_4576_r_000012
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 13:50:14 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=28108814575
		FILE: Number of bytes written=58329675746
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2126405165
		HDFS: Number of read operations=519
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=78
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=135
		Launched reduce tasks=44
		Data-local map tasks=62
		Rack-local map tasks=73
		Total time spent by all maps in occupied slots (ms)=20838726
		Total time spent by all reduces in occupied slots (ms)=39015530
		Total time spent by all map tasks (ms)=10419363
		Total time spent by all reduce tasks (ms)=19507765
		Total vcore-seconds taken by all map tasks=10419363
		Total vcore-seconds taken by all reduce tasks=19507765
		Total megabyte-seconds taken by all map tasks=84355162848
		Total megabyte-seconds taken by all reduce tasks=234093180000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141593
		Map output bytes=29491527666
		Map output materialized bytes=30204066041
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=35498339
		Reduce shuffle bytes=28108845685
		Reduce input records=335444581
		Reduce output records=35696328
		Spilled Records=679586174
		Shuffled Maps =5226
		Failed Shuffles=0
		Merged Map outputs=5226
		GC time elapsed (ms)=125039
		CPU time spent (ms)=22716930
		Physical memory (bytes) snapshot=297120952320
		Virtual memory (bytes) snapshot=1751729983488
		Total committed heap usage (bytes)=453240500224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2126405165
	rmr
		reduce calls=35498339
15/04/12 13:50:14 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 13:50:21 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file2861c33de21

real	58m30.566s
user	0m37.669s
sys	0m3.721s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-40-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=40"


15/04/12 13:50:26 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 13:50:26 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1670347542230005496.jar tmpDir=null
15/04/12 13:50:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 13:50:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 13:50:28 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 13:50:28 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 13:50:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4590
15/04/12 13:50:29 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4590
15/04/12 13:50:29 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4590/
15/04/12 13:50:29 INFO mapreduce.Job: Running job: job_1422482982071_4590
15/04/12 13:50:35 INFO mapreduce.Job: Job job_1422482982071_4590 running in uber mode : false
15/04/12 13:50:35 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 13:50:45 INFO mapreduce.Job:  map 2% reduce 0%
15/04/12 13:50:46 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 13:50:47 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 13:50:48 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 13:50:49 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 13:50:52 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 13:50:54 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 13:50:55 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 13:50:58 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 13:51:00 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 13:51:01 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 13:51:04 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 13:51:05 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 13:51:07 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 13:51:09 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 13:51:10 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 13:51:11 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 13:51:13 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 13:51:15 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 13:51:16 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 13:51:17 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 13:51:19 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 13:51:21 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 13:51:22 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 13:51:23 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 13:51:25 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 13:51:27 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 13:51:28 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 13:51:29 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 13:51:31 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 13:51:32 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 13:51:34 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 13:51:35 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 13:51:37 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 13:51:38 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 13:51:40 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 13:51:42 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 13:51:43 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 13:51:44 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 13:51:45 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 13:51:46 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 13:51:47 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 13:51:48 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 13:51:49 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 13:51:50 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 13:51:51 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 13:51:52 INFO mapreduce.Job:  map 89% reduce 0%
15/04/12 13:51:53 INFO mapreduce.Job:  map 90% reduce 21%
15/04/12 13:51:54 INFO mapreduce.Job:  map 91% reduce 23%
15/04/12 13:51:56 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 13:51:57 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 13:52:01 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 13:52:11 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 13:52:16 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 13:52:17 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 13:52:18 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 13:52:19 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 13:52:20 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 13:52:21 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 13:52:23 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 13:52:24 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 13:52:30 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 13:52:31 INFO mapreduce.Job:  map 100% reduce 46%
15/04/12 13:52:32 INFO mapreduce.Job:  map 100% reduce 48%
15/04/12 13:52:33 INFO mapreduce.Job:  map 100% reduce 50%
15/04/12 13:52:34 INFO mapreduce.Job:  map 100% reduce 58%
15/04/12 13:52:35 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 13:52:36 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 13:52:37 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 13:52:38 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 13:52:43 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 13:52:45 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 13:52:48 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 13:52:52 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 13:52:55 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 13:53:00 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 13:53:07 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 13:53:10 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 13:53:13 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 13:53:16 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 13:53:22 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 13:53:28 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 13:53:31 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 13:53:37 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 13:53:46 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 13:53:52 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 13:53:58 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 13:54:04 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 13:54:13 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 13:54:19 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 13:54:25 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 13:54:34 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 13:54:43 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 13:54:52 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 13:55:04 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 13:55:17 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 13:55:32 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 13:55:50 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 13:56:14 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 13:56:26 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 13:56:59 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 13:58:03 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 13:59:18 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 14:13:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_4590_r_000012_0, Status : FAILED
Container [pid=10908,containerID=container_1422482982071_4590_01_000199] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4590_01_000199 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 10922 10908 10908 10908 (java) 2634 548 13312049152 577700 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4590/container_1422482982071_4590_01_000199/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4590/container_1422482982071_4590_01_000199 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.186 34511 attempt_1422482982071_4590_r_000012_0 199 
	|- 11047 11031 10908 10908 (cat) 0 0 4231168 134 cat 
	|- 10908 9550 10908 10908 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4590/container_1422482982071_4590_01_000199/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4590/container_1422482982071_4590_01_000199 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.186 34511 attempt_1422482982071_4590_r_000012_0 199 1>/var/log/hadoop-yarn/containers/application_1422482982071_4590/container_1422482982071_4590_01_000199/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4590/container_1422482982071_4590_01_000199/stderr  
	|- 11031 10922 10908 10908 (R) 107286 18502 10488291328 2537527 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduced7a7b8988b6 
	|- 11045 11031 10908 10908 (cat) 1 26 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 14:24:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4590_r_000012_1, Status : FAILED
Container [pid=30756,containerID=container_1422482982071_4590_01_000228] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4590_01_000228 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 30820 30807 30756 30756 (cat) 0 0 4231168 134 cat 
	|- 30756 8968 30756 30756 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4590/container_1422482982071_4590_01_000228/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4590/container_1422482982071_4590_01_000228 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.186 34511 attempt_1422482982071_4590_r_000012_1 228 1>/var/log/hadoop-yarn/containers/application_1422482982071_4590/container_1422482982071_4590_01_000228/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4590/container_1422482982071_4590_01_000228/stderr  
	|- 30766 30756 30756 30756 (java) 3038 632 13312143360 565703 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4590/container_1422482982071_4590_01_000228/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4590/container_1422482982071_4590_01_000228 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.186 34511 attempt_1422482982071_4590_r_000012_1 228 
	|- 30818 30807 30756 30756 (cat) 0 25 4231168 142 cat 
	|- 30807 30766 30756 30756 (R) 106296 18195 10488606720 2537603 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduced7a7b8988b6 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 14:36:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4590_r_000012_2, Status : FAILED
Container [pid=30388,containerID=container_1422482982071_4590_01_000229] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4590_01_000229 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 30450 30439 30388 30388 (cat) 0 26 4231168 142 cat 
	|- 30452 30439 30388 30388 (cat) 0 0 4231168 134 cat 
	|- 30388 10433 30388 30388 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4590/container_1422482982071_4590_01_000229/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4590/container_1422482982071_4590_01_000229 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.186 34511 attempt_1422482982071_4590_r_000012_2 229 1>/var/log/hadoop-yarn/containers/application_1422482982071_4590/container_1422482982071_4590_01_000229/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4590/container_1422482982071_4590_01_000229/stderr  
	|- 30439 30398 30388 30388 (R) 107822 19171 10488303616 2529307 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduced7a7b8988b6 
	|- 30398 30388 30388 30388 (java) 2640 531 13311889408 568308 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4590/container_1422482982071_4590_01_000229/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4590/container_1422482982071_4590_01_000229 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.186 34511 attempt_1422482982071_4590_r_000012_2 229 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 14:49:54 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 14:49:54 INFO mapreduce.Job: Job job_1422482982071_4590 failed with state FAILED due to: Task failed task_1422482982071_4590_r_000012
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 14:49:54 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=28108860259
		FILE: Number of bytes written=58329732795
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2126423537
		HDFS: Number of read operations=519
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=78
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=135
		Launched reduce tasks=44
		Data-local map tasks=62
		Rack-local map tasks=73
		Total time spent by all maps in occupied slots (ms)=20742430
		Total time spent by all reduces in occupied slots (ms)=39017950
		Total time spent by all map tasks (ms)=10371215
		Total time spent by all reduce tasks (ms)=19508975
		Total vcore-seconds taken by all map tasks=10371215
		Total vcore-seconds taken by all reduce tasks=19508975
		Total megabyte-seconds taken by all map tasks=83965356640
		Total megabyte-seconds taken by all reduce tasks=234107700000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141566
		Map output bytes=29491540122
		Map output materialized bytes=30204078444
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=35498319
		Reduce shuffle bytes=28108891369
		Reduce input records=335444819
		Reduce output records=35696437
		Spilled Records=679586385
		Shuffled Maps =5226
		Failed Shuffles=0
		Merged Map outputs=5226
		GC time elapsed (ms)=120239
		CPU time spent (ms)=22713100
		Physical memory (bytes) snapshot=297213771776
		Virtual memory (bytes) snapshot=1751747645440
		Total committed heap usage (bytes)=453241016320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2126423537
	rmr
		reduce calls=35498319
15/04/12 14:49:54 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 14:50:00 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/filed7a43c41a7

real	59m39.522s
user	0m37.381s
sys	0m3.356s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-40-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=40"


15/04/12 14:50:06 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 14:50:06 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1979001925654188038.jar tmpDir=null
15/04/12 14:50:07 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 14:50:07 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 14:50:08 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 14:50:08 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 14:50:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4604
15/04/12 14:50:09 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4604
15/04/12 14:50:09 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4604/
15/04/12 14:50:09 INFO mapreduce.Job: Running job: job_1422482982071_4604
15/04/12 14:50:15 INFO mapreduce.Job: Job job_1422482982071_4604 running in uber mode : false
15/04/12 14:50:15 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 14:50:26 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 14:50:27 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 14:50:29 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 14:50:30 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 14:50:32 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 14:50:33 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 14:50:35 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 14:50:36 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 14:50:38 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 14:50:39 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 14:50:41 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 14:50:42 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 14:50:44 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 14:50:45 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 14:50:47 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 14:50:49 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 14:50:51 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 14:50:52 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 14:50:53 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 14:50:54 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 14:50:55 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 14:50:57 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 14:50:58 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 14:50:59 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 14:51:00 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 14:51:01 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 14:51:03 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 14:51:04 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 14:51:06 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 14:51:07 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 14:51:09 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 14:51:10 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 14:51:12 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 14:51:13 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 14:51:15 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 14:51:16 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 14:51:19 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 14:51:20 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 14:51:22 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 14:51:23 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 14:51:24 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 14:51:25 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 14:51:26 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 14:51:27 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 14:51:28 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 14:51:29 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 14:51:30 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 14:51:31 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 14:51:32 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 14:51:33 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 14:51:34 INFO mapreduce.Job:  map 89% reduce 2%
15/04/12 14:51:35 INFO mapreduce.Job:  map 91% reduce 8%
15/04/12 14:51:36 INFO mapreduce.Job:  map 91% reduce 24%
15/04/12 14:51:37 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 14:51:39 INFO mapreduce.Job:  map 91% reduce 27%
15/04/12 14:51:40 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 14:51:46 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 14:51:56 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 14:52:00 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 14:52:01 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 14:52:02 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 14:52:03 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 14:52:04 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 14:52:05 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 14:52:06 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 14:52:07 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 14:52:09 INFO mapreduce.Job:  map 100% reduce 39%
15/04/12 14:52:10 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 14:52:11 INFO mapreduce.Job:  map 100% reduce 44%
15/04/12 14:52:12 INFO mapreduce.Job:  map 100% reduce 51%
15/04/12 14:52:13 INFO mapreduce.Job:  map 100% reduce 56%
15/04/12 14:52:14 INFO mapreduce.Job:  map 100% reduce 58%
15/04/12 14:52:15 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 14:52:16 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 14:52:17 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 14:52:18 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 14:52:22 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 14:52:25 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 14:52:30 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 14:52:34 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 14:52:37 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 14:52:42 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 14:52:46 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 14:52:51 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 14:52:55 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 14:53:00 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 14:53:05 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 14:53:11 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 14:53:17 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 14:53:23 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 14:53:30 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 14:53:35 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 14:53:44 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 14:53:50 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 14:53:58 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 14:54:04 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 14:54:12 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 14:54:20 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 14:54:29 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 14:54:40 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 14:54:53 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 14:55:05 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 14:55:25 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 14:55:45 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 14:56:07 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 14:56:41 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 14:57:39 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 14:58:57 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 15:15:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_4604_r_000012_0, Status : FAILED
Container [pid=594,containerID=container_1422482982071_4604_01_000204] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4604_01_000204 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 594 9971 594 594 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4604/container_1422482982071_4604_01_000204/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4604/container_1422482982071_4604_01_000204 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.191 49043 attempt_1422482982071_4604_r_000012_0 204 1>/var/log/hadoop-yarn/containers/application_1422482982071_4604/container_1422482982071_4604_01_000204/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4604/container_1422482982071_4604_01_000204/stderr  
	|- 753 703 594 594 (cat) 0 0 4231168 134 cat 
	|- 740 703 594 594 (cat) 1 27 4231168 142 cat 
	|- 703 604 594 594 (R) 115755 23931 10603552768 2565667 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce16f23621883c 
	|- 604 594 594 594 (java) 2759 623 13312872448 562676 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4604/container_1422482982071_4604_01_000204/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4604/container_1422482982071_4604_01_000204 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.191 49043 attempt_1422482982071_4604_r_000012_0 204 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 15:24:54 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 15:24:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_4604_r_000012_1, Status : FAILED
Container [pid=44643,containerID=container_1422482982071_4604_01_000272] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4604_01_000272 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 44712 44699 44643 44643 (cat) 0 0 4231168 134 cat 
	|- 44699 44653 44643 44643 (R) 111782 20059 10567704576 2556914 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce16f23621883c 
	|- 44653 44643 44643 44643 (java) 2857 584 13312704512 562261 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4604/container_1422482982071_4604_01_000272/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4604/container_1422482982071_4604_01_000272 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.191 49043 attempt_1422482982071_4604_r_000012_1 272 
	|- 44710 44699 44643 44643 (cat) 0 27 4231168 142 cat 
	|- 44643 10211 44643 44643 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4604/container_1422482982071_4604_01_000272/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4604/container_1422482982071_4604_01_000272 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.191 49043 attempt_1422482982071_4604_r_000012_1 272 1>/var/log/hadoop-yarn/containers/application_1422482982071_4604/container_1422482982071_4604_01_000272/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4604/container_1422482982071_4604_01_000272/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 15:24:55 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 15:36:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4604_r_000012_2, Status : FAILED
Container [pid=12879,containerID=container_1422482982071_4604_01_000273] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4604_01_000273 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 12879 9261 12879 12879 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4604/container_1422482982071_4604_01_000273/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4604/container_1422482982071_4604_01_000273 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.191 49043 attempt_1422482982071_4604_r_000012_2 273 1>/var/log/hadoop-yarn/containers/application_1422482982071_4604/container_1422482982071_4604_01_000273/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4604/container_1422482982071_4604_01_000273/stderr  
	|- 12952 12941 12879 12879 (cat) 0 27 4231168 142 cat 
	|- 12888 12879 12879 12879 (java) 2967 616 13312217088 567730 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4604/container_1422482982071_4604_01_000273/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4604/container_1422482982071_4604_01_000273 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.191 49043 attempt_1422482982071_4604_r_000012_2 273 
	|- 12954 12941 12879 12879 (cat) 0 0 4231168 134 cat 
	|- 12941 12888 12879 12879 (R) 105440 18534 10552655872 2553273 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce16f23621883c 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 15:48:05 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 15:48:05 INFO mapreduce.Job: Job job_1422482982071_4604 failed with state FAILED due to: Task failed task_1422482982071_4604_r_000012
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 15:48:05 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=28108853418
		FILE: Number of bytes written=58329720745
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2126425005
		HDFS: Number of read operations=519
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=78
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=135
		Launched reduce tasks=44
		Data-local map tasks=63
		Rack-local map tasks=72
		Total time spent by all maps in occupied slots (ms)=20786326
		Total time spent by all reduces in occupied slots (ms)=38019398
		Total time spent by all map tasks (ms)=10393163
		Total time spent by all reduce tasks (ms)=19009699
		Total vcore-seconds taken by all map tasks=10393163
		Total vcore-seconds taken by all reduce tasks=19009699
		Total megabyte-seconds taken by all map tasks=84143047648
		Total megabyte-seconds taken by all reduce tasks=228116388000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141567
		Map output bytes=29491530586
		Map output materialized bytes=30204068910
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=35498309
		Reduce shuffle bytes=28108884528
		Reduce input records=335444836
		Reduce output records=35696441
		Spilled Records=679586403
		Shuffled Maps =5226
		Failed Shuffles=0
		Merged Map outputs=5226
		GC time elapsed (ms)=115866
		CPU time spent (ms)=22389390
		Physical memory (bytes) snapshot=297050320896
		Virtual memory (bytes) snapshot=1751539838976
		Total committed heap usage (bytes)=453240541184
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2126425005
	rmr
		reduce calls=35498309
15/04/12 15:48:05 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 15:48:11 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file16f22fe9ad95

real	58m10.469s
user	0m36.694s
sys	0m3.523s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-30-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=30"


15/04/12 15:48:17 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 15:48:17 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8759918130484980776.jar tmpDir=null
15/04/12 15:48:17 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 15:48:17 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 15:48:18 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 15:48:19 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 15:48:19 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4618
15/04/12 15:48:19 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4618
15/04/12 15:48:19 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4618/
15/04/12 15:48:19 INFO mapreduce.Job: Running job: job_1422482982071_4618
15/04/12 15:48:24 INFO mapreduce.Job: Job job_1422482982071_4618 running in uber mode : false
15/04/12 15:48:24 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 15:48:35 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 15:48:36 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 15:48:38 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 15:48:39 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 15:48:40 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 15:48:41 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 15:48:42 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 15:48:44 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 15:48:45 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 15:48:46 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 15:48:47 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 15:48:48 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 15:48:50 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 15:48:51 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 15:48:52 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 15:48:53 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 15:48:54 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 15:48:56 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 15:48:57 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 15:48:58 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 15:48:59 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 15:49:00 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 15:49:01 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 15:49:02 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 15:49:03 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 15:49:05 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 15:49:06 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 15:49:07 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 15:49:08 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 15:49:09 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 15:49:11 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 15:49:12 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 15:49:13 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 15:49:14 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 15:49:15 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 15:49:16 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 15:49:17 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 15:49:18 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 15:49:20 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 15:49:21 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 15:49:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4618_m_000126_0, Status : FAILED
Error: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:334)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRawBytes(TypedBytesInput.java:218)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRaw(TypedBytesInput.java:152)
	at org.apache.hadoop.streaming.io.TypedBytesOutputReader.readKeyValue(TypedBytesOutputReader.java:51)
	at org.apache.hadoop.streaming.PipeMapRed$MROutputThread.run(PipeMapRed.java:376)

15/04/12 15:49:23 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 15:49:24 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 15:49:26 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 15:49:27 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 15:49:30 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 15:49:31 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 15:49:32 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 15:49:33 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 15:49:34 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 15:49:35 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 15:49:36 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 15:49:37 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 15:49:38 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 15:49:39 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 15:49:40 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 15:49:41 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 15:49:42 INFO mapreduce.Job:  map 88% reduce 22%
15/04/12 15:49:43 INFO mapreduce.Job:  map 90% reduce 22%
15/04/12 15:49:44 INFO mapreduce.Job:  map 92% reduce 22%
15/04/12 15:49:45 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 15:49:48 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 15:49:49 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 15:49:57 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 15:50:05 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 15:50:06 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 15:50:08 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 15:50:09 INFO mapreduce.Job:  map 96% reduce 29%
15/04/12 15:50:10 INFO mapreduce.Job:  map 98% reduce 29%
15/04/12 15:50:12 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 15:50:13 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 15:50:16 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 15:51:06 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 15:51:07 INFO mapreduce.Job:  map 100% reduce 39%
15/04/12 15:51:08 INFO mapreduce.Job:  map 100% reduce 51%
15/04/12 15:51:09 INFO mapreduce.Job:  map 100% reduce 52%
15/04/12 15:51:10 INFO mapreduce.Job:  map 100% reduce 55%
15/04/12 15:51:11 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 15:51:12 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 15:51:13 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 15:51:14 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 15:51:15 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 15:51:16 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 15:51:17 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 15:51:18 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 15:51:22 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 15:51:28 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 15:51:35 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 15:51:41 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 15:51:48 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 15:51:55 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 15:52:01 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 15:52:06 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 15:52:12 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 15:52:19 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 15:52:26 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 15:52:33 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 15:52:40 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 15:52:47 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 15:52:56 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 15:53:04 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 15:53:11 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 15:53:20 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 15:53:30 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 15:53:40 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 15:53:50 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 15:54:04 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 15:54:18 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 15:54:33 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 15:54:51 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 15:55:06 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 15:55:20 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 15:55:42 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 15:56:05 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 15:56:42 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 15:57:19 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 15:59:17 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 16:13:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4618_r_000012_0, Status : FAILED
Container [pid=11803,containerID=container_1422482982071_4618_01_000201] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4618_01_000201 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 11910 11899 11803 11803 (cat) 0 26 4231168 142 cat 
	|- 11803 40699 11803 11803 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4618/container_1422482982071_4618_01_000201/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4618/container_1422482982071_4618_01_000201 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.199 36877 attempt_1422482982071_4618_r_000012_0 201 1>/var/log/hadoop-yarn/containers/application_1422482982071_4618/container_1422482982071_4618_01_000201/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4618/container_1422482982071_4618_01_000201/stderr  
	|- 11912 11899 11803 11803 (cat) 0 0 4231168 134 cat 
	|- 11899 11813 11803 11803 (R) 111308 19919 10908327936 2640107 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce1f91740c432c 
	|- 11813 11803 11803 11803 (java) 3144 683 13312671744 486384 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4618/container_1422482982071_4618_01_000201/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4618/container_1422482982071_4618_01_000201 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.199 36877 attempt_1422482982071_4618_r_000012_0 201 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 16:27:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4618_r_000012_1, Status : FAILED
Container [pid=12140,containerID=container_1422482982071_4618_01_000219] is running beyond physical memory limits. Current usage: 12.1 GB of 11.7 GB physical memory used; 22.8 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4618_01_000219 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 12140 3817 12140 12140 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4618/container_1422482982071_4618_01_000219/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4618/container_1422482982071_4618_01_000219 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.199 36877 attempt_1422482982071_4618_r_000012_1 219 1>/var/log/hadoop-yarn/containers/application_1422482982071_4618/container_1422482982071_4618_01_000219/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4618/container_1422482982071_4618_01_000219/stderr  
	|- 12150 12140 12140 12140 (java) 3753 796 13411078144 585879 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4618/container_1422482982071_4618_01_000219/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4618/container_1422482982071_4618_01_000219 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.199 36877 attempt_1422482982071_4618_r_000012_1 219 
	|- 12204 12193 12140 12140 (cat) 0 26 103391232 159 cat 
	|- 12193 12150 12140 12140 (R) 106830 18395 10783543296 2584835 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce1f91740c432c 
	|- 12206 12193 12140 12140 (cat) 0 0 103391232 151 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 16:43:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4618_r_000012_2, Status : FAILED
Container [pid=1083,containerID=container_1422482982071_4618_01_000220] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4618_01_000220 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 1167 1093 1083 1083 (R) 107762 20034 10587082752 2537536 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce1f91740c432c 
	|- 1180 1167 1083 1083 (cat) 0 0 103391232 151 cat 
	|- 1093 1083 1083 1083 (java) 2628 532 13411229696 586362 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4618/container_1422482982071_4618_01_000220/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4618/container_1422482982071_4618_01_000220 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.199 36877 attempt_1422482982071_4618_r_000012_2 220 
	|- 1083 3946 1083 1083 (bash) 0 0 108650496 297 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4618/container_1422482982071_4618_01_000220/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4618/container_1422482982071_4618_01_000220 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.199 36877 attempt_1422482982071_4618_r_000012_2 220 1>/var/log/hadoop-yarn/containers/application_1422482982071_4618/container_1422482982071_4618_01_000220/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4618/container_1422482982071_4618_01_000220/stderr  
	|- 1178 1167 1083 1083 (cat) 0 26 103391232 159 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 16:59:19 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 16:59:19 INFO mapreduce.Job: Job job_1422482982071_4618 failed with state FAILED due to: Task failed task_1422482982071_4618_r_000012
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 16:59:19 INFO mapreduce.Job: Counters: 56
	File System Counters
		FILE: Number of bytes read=27616956657
		FILE: Number of bytes written=57836841818
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2107412284
		HDFS: Number of read operations=489
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=58
	Job Counters 
		Failed map tasks=1
		Failed reduce tasks=4
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=136
		Launched reduce tasks=34
		Other local map tasks=2
		Data-local map tasks=62
		Rack-local map tasks=72
		Total time spent by all maps in occupied slots (ms)=20744376
		Total time spent by all reduces in occupied slots (ms)=38964974
		Total time spent by all map tasks (ms)=10372188
		Total time spent by all reduce tasks (ms)=19482487
		Total vcore-seconds taken by all map tasks=10372188
		Total vcore-seconds taken by all reduce tasks=19482487
		Total megabyte-seconds taken by all map tasks=83973234048
		Total megabyte-seconds taken by all reduce tasks=233789844000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141614
		Map output bytes=29491551859
		Map output materialized bytes=30204082234
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=35198028
		Reduce shuffle bytes=27616979745
		Reduce input records=332529973
		Reduce output records=35387248
		Spilled Records=676671587
		Shuffled Maps =3886
		Failed Shuffles=0
		Merged Map outputs=3886
		GC time elapsed (ms)=114958
		CPU time spent (ms)=22087350
		Physical memory (bytes) snapshot=295549145088
		Virtual memory (bytes) snapshot=1616908541952
		Total committed heap usage (bytes)=432189333504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2107412284
	rmr
		reduce calls=35198028
15/04/12 16:59:19 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 16:59:25 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file1f9111ab3c11

real	71m14.001s
user	0m37.902s
sys	0m3.902s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-30-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=30"


15/04/12 16:59:30 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 16:59:30 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1026420851546747685.jar tmpDir=null
15/04/12 16:59:31 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 16:59:31 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 16:59:32 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 16:59:32 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 16:59:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4631
15/04/12 16:59:32 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4631
15/04/12 16:59:32 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4631/
15/04/12 16:59:32 INFO mapreduce.Job: Running job: job_1422482982071_4631
15/04/12 16:59:38 INFO mapreduce.Job: Job job_1422482982071_4631 running in uber mode : false
15/04/12 16:59:38 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 16:59:48 INFO mapreduce.Job:  map 1% reduce 0%
15/04/12 16:59:49 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 16:59:50 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 16:59:51 INFO mapreduce.Job:  map 6% reduce 0%
15/04/12 16:59:52 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 16:59:53 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 16:59:54 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 16:59:55 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 16:59:56 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 16:59:58 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 16:59:59 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 17:00:00 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 17:00:01 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 17:00:02 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 17:00:04 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 17:00:05 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 17:00:06 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 17:00:07 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 17:00:08 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 17:00:10 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 17:00:11 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 17:00:13 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 17:00:14 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 17:00:16 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 17:00:17 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 17:00:19 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 17:00:20 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 17:00:22 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 17:00:23 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 17:00:25 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 17:00:28 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 17:00:29 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 17:00:31 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 17:00:32 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 17:00:34 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 17:00:35 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 17:00:37 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 17:00:38 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 17:00:40 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 17:00:43 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 17:00:44 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 17:00:45 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 17:00:46 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 17:00:47 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 17:00:48 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 17:00:49 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 17:00:50 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 17:00:51 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 17:00:52 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 17:00:53 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 17:00:54 INFO mapreduce.Job:  map 87% reduce 0%
15/04/12 17:00:55 INFO mapreduce.Job:  map 88% reduce 21%
15/04/12 17:00:56 INFO mapreduce.Job:  map 90% reduce 21%
15/04/12 17:00:57 INFO mapreduce.Job:  map 91% reduce 21%
15/04/12 17:00:58 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 17:01:01 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 17:01:04 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 17:01:11 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 17:01:20 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 17:01:22 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 17:01:23 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 17:01:24 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 17:01:25 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 17:01:27 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 17:01:28 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 17:01:29 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 17:01:31 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 17:01:34 INFO mapreduce.Job:  map 100% reduce 47%
15/04/12 17:01:37 INFO mapreduce.Job:  map 100% reduce 57%
15/04/12 17:01:41 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 17:01:44 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 17:01:50 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 17:01:53 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 17:02:02 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 17:02:08 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 17:02:14 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 17:02:23 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 17:02:29 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 17:02:35 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 17:02:41 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 17:02:47 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 17:02:56 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 17:03:02 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 17:03:09 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 17:03:18 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 17:03:24 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 17:03:33 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 17:03:39 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 17:03:50 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 17:03:59 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 17:04:09 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 17:04:20 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 17:04:33 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 17:04:46 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 17:05:01 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 17:05:21 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 17:05:39 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 17:05:57 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 17:06:15 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 17:06:40 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 17:07:18 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 17:07:58 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 17:10:01 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 17:22:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_4631_r_000012_0, Status : FAILED
Container [pid=28484,containerID=container_1422482982071_4631_01_000199] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4631_01_000199 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 28560 28547 28484 28484 (cat) 0 0 4231168 134 cat 
	|- 28493 28484 28484 28484 (java) 2503 566 13311864832 588446 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4631/container_1422482982071_4631_01_000199/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4631/container_1422482982071_4631_01_000199 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.177 35106 attempt_1422482982071_4631_r_000012_0 199 
	|- 28547 28493 28484 28484 (R) 105790 18190 10339328000 2501191 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce27e243f80e76 
	|- 28484 8938 28484 28484 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4631/container_1422482982071_4631_01_000199/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4631/container_1422482982071_4631_01_000199 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.177 35106 attempt_1422482982071_4631_r_000012_0 199 1>/var/log/hadoop-yarn/containers/application_1422482982071_4631/container_1422482982071_4631_01_000199/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4631/container_1422482982071_4631_01_000199/stderr  
	|- 28558 28547 28484 28484 (cat) 0 26 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 17:37:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_4631_r_000012_1, Status : FAILED
Container [pid=43237,containerID=container_1422482982071_4631_01_000218] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4631_01_000218 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 43472 43461 43237 43237 (cat) 0 27 4231168 142 cat 
	|- 43247 43237 43237 43237 (java) 3410 758 13312458752 587970 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4631/container_1422482982071_4631_01_000218/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4631/container_1422482982071_4631_01_000218 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.177 35106 attempt_1422482982071_4631_r_000012_1 218 
	|- 43474 43461 43237 43237 (cat) 0 0 4231168 134 cat 
	|- 43461 43247 43237 43237 (R) 106961 19902 10569191424 2557310 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce27e243f80e76 
	|- 43237 8824 43237 43237 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4631/container_1422482982071_4631_01_000218/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4631/container_1422482982071_4631_01_000218 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.177 35106 attempt_1422482982071_4631_r_000012_1 218 1>/var/log/hadoop-yarn/containers/application_1422482982071_4631/container_1422482982071_4631_01_000218/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4631/container_1422482982071_4631_01_000218/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 17:52:53 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 17:52:53 INFO mapreduce.Job: Task Id : attempt_1422482982071_4631_r_000012_2, Status : FAILED
Container [pid=30039,containerID=container_1422482982071_4631_01_000219] is running beyond physical memory limits. Current usage: 12.2 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4631_01_000219 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 30039 9412 30039 30039 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4631/container_1422482982071_4631_01_000219/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4631/container_1422482982071_4631_01_000219 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.177 35106 attempt_1422482982071_4631_r_000012_2 219 1>/var/log/hadoop-yarn/containers/application_1422482982071_4631/container_1422482982071_4631_01_000219/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4631/container_1422482982071_4631_01_000219/stderr  
	|- 30049 30039 30039 30039 (java) 2632 621 13311942656 586251 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4631/container_1422482982071_4631_01_000219/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4631/container_1422482982071_4631_01_000219 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.177 35106 attempt_1422482982071_4631_r_000012_2 219 
	|- 30186 30173 30039 30039 (cat) 0 0 4231168 134 cat 
	|- 30173 30049 30039 30039 (R) 112692 19803 10789101568 2610998 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce27e243f80e76 
	|- 30184 30173 30039 30039 (cat) 0 26 4231168 143 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 17:52:54 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 18:02:49 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 18:02:50 INFO mapreduce.Job: Job job_1422482982071_4631 failed with state FAILED due to: Task failed task_1422482982071_4631_r_000012
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 18:02:50 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=27616826830
		FILE: Number of bytes written=57836699824
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2107442053
		HDFS: Number of read operations=489
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=58
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=135
		Launched reduce tasks=34
		Data-local map tasks=60
		Rack-local map tasks=75
		Total time spent by all maps in occupied slots (ms)=20537588
		Total time spent by all reduces in occupied slots (ms)=35686590
		Total time spent by all map tasks (ms)=10268794
		Total time spent by all reduce tasks (ms)=17843295
		Total vcore-seconds taken by all map tasks=10268794
		Total vcore-seconds taken by all reduce tasks=17843295
		Total megabyte-seconds taken by all map tasks=83136156224
		Total megabyte-seconds taken by all reduce tasks=214119540000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141606
		Map output bytes=29491539707
		Map output materialized bytes=30204070067
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=35198139
		Reduce shuffle bytes=27616849918
		Reduce input records=332529097
		Reduce output records=35387513
		Spilled Records=676670703
		Shuffled Maps =3886
		Failed Shuffles=0
		Merged Map outputs=3886
		GC time elapsed (ms)=97436
		CPU time spent (ms)=22058890
		Physical memory (bytes) snapshot=295343370240
		Virtual memory (bytes) snapshot=1617725476864
		Total committed heap usage (bytes)=432187052032
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2107442053
	rmr
		reduce calls=35198139
15/04/12 18:02:50 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 18:02:57 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file27e2124fee8b

real	63m31.642s
user	0m36.109s
sys	0m3.725s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-30-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=30"


15/04/12 18:03:03 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 18:03:03 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2030347263253782501.jar tmpDir=null
15/04/12 18:03:03 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 18:03:03 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 18:03:04 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 18:03:05 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 18:03:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4641
15/04/12 18:03:06 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4641
15/04/12 18:03:06 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4641/
15/04/12 18:03:06 INFO mapreduce.Job: Running job: job_1422482982071_4641
15/04/12 18:03:12 INFO mapreduce.Job: Job job_1422482982071_4641 running in uber mode : false
15/04/12 18:03:12 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 18:03:23 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 18:03:24 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 18:03:26 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 18:03:29 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 18:03:30 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 18:03:32 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 18:03:33 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 18:03:35 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 18:03:36 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 18:03:38 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 18:03:39 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 18:03:41 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 18:03:42 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 18:03:44 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 18:03:45 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 18:03:47 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 18:03:48 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 18:03:50 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 18:03:51 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 18:03:53 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 18:03:54 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 18:03:56 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 18:03:57 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 18:03:59 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 18:04:00 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 18:04:02 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 18:04:03 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 18:04:05 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 18:04:06 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 18:04:08 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 18:04:09 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 18:04:11 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 18:04:12 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 18:04:14 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 18:04:15 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 18:04:17 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 18:04:18 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 18:04:20 INFO mapreduce.Job:  map 64% reduce 0%
15/04/12 18:04:21 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 18:04:23 INFO mapreduce.Job:  map 70% reduce 0%
15/04/12 18:04:24 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 18:04:25 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 18:04:26 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 18:04:27 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 18:04:28 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 18:04:30 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 18:04:31 INFO mapreduce.Job:  map 86% reduce 15%
15/04/12 18:04:32 INFO mapreduce.Job:  map 89% reduce 19%
15/04/12 18:04:33 INFO mapreduce.Job:  map 90% reduce 20%
15/04/12 18:04:34 INFO mapreduce.Job:  map 91% reduce 25%
15/04/12 18:04:35 INFO mapreduce.Job:  map 91% reduce 26%
15/04/12 18:04:36 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 18:04:37 INFO mapreduce.Job:  map 92% reduce 27%
15/04/12 18:04:42 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 18:04:53 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 18:04:56 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 18:04:59 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 18:05:00 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 18:05:01 INFO mapreduce.Job:  map 99% reduce 29%
15/04/12 18:05:02 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 18:05:03 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 18:05:05 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 18:05:06 INFO mapreduce.Job:  map 100% reduce 36%
15/04/12 18:05:08 INFO mapreduce.Job:  map 100% reduce 46%
15/04/12 18:05:11 INFO mapreduce.Job:  map 100% reduce 54%
15/04/12 18:05:13 INFO mapreduce.Job:  map 100% reduce 56%
15/04/12 18:05:14 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 18:05:15 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 18:05:17 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 18:05:23 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 18:05:28 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 18:05:35 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 18:05:41 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 18:05:47 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 18:05:54 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 18:06:02 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 18:06:08 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 18:06:14 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 18:06:20 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 18:06:29 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 18:06:38 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 18:06:45 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 18:06:54 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 18:07:00 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 18:07:08 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 18:07:14 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 18:07:25 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 18:07:34 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 18:07:45 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 18:07:57 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 18:08:09 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 18:08:22 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 18:08:39 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 18:08:57 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 18:09:16 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 18:09:26 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 18:09:50 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 18:10:16 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 18:10:48 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 18:11:30 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 18:13:27 INFO mapreduce.Job:  map 100% reduce 99%
15/04/12 18:27:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4641_r_000012_0, Status : FAILED
Container [pid=26097,containerID=container_1422482982071_4641_01_000199] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4641_01_000199 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 26382 26369 26097 26097 (cat) 0 0 4231168 134 cat 
	|- 26369 26107 26097 26097 (R) 113181 19520 10792779776 2611896 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce2de44b29228e 
	|- 26107 26097 26097 26097 (java) 2827 621 13312454656 487648 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4641/container_1422482982071_4641_01_000199/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4641/container_1422482982071_4641_01_000199 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.178 40875 attempt_1422482982071_4641_r_000012_0 199 
	|- 26380 26369 26097 26097 (cat) 0 28 4231168 143 cat 
	|- 26097 29409 26097 26097 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4641/container_1422482982071_4641_01_000199/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4641/container_1422482982071_4641_01_000199 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.178 40875 attempt_1422482982071_4641_r_000012_0 199 1>/var/log/hadoop-yarn/containers/application_1422482982071_4641/container_1422482982071_4641_01_000199/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4641/container_1422482982071_4641_01_000199/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 18:40:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4641_r_000012_1, Status : FAILED
Container [pid=48448,containerID=container_1422482982071_4641_01_000218] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4641_01_000218 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 48457 48448 48448 48448 (java) 2913 500 13411246080 586855 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4641/container_1422482982071_4641_01_000218/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4641/container_1422482982071_4641_01_000218 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.178 40875 attempt_1422482982071_4641_r_000012_1 218 
	|- 48448 3801 48448 48448 (bash) 0 0 108650496 297 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4641/container_1422482982071_4641_01_000218/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4641/container_1422482982071_4641_01_000218 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.178 40875 attempt_1422482982071_4641_r_000012_1 218 1>/var/log/hadoop-yarn/containers/application_1422482982071_4641/container_1422482982071_4641_01_000218/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4641/container_1422482982071_4641_01_000218/stderr  
	|- 48511 48498 48448 48448 (cat) 0 0 103391232 151 cat 
	|- 48498 48457 48448 48448 (R) 105569 18553 10402881536 2492598 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce2de44b29228e 
	|- 48509 48498 48448 48448 (cat) 0 26 103391232 159 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 18:55:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_4641_r_000012_2, Status : FAILED
Container [pid=45197,containerID=container_1422482982071_4641_01_000219] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4641_01_000219 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 45207 45197 45197 45197 (java) 3502 717 13311918080 586890 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4641/container_1422482982071_4641_01_000219/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4641/container_1422482982071_4641_01_000219 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.178 40875 attempt_1422482982071_4641_r_000012_2 219 
	|- 45250 45207 45197 45197 (R) 107681 19206 10561085440 2555331 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce2de44b29228e 
	|- 45261 45250 45197 45197 (cat) 1 25 4231168 142 cat 
	|- 45263 45250 45197 45197 (cat) 0 0 4231168 135 cat 
	|- 45197 10269 45197 45197 (bash) 0 1 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4641/container_1422482982071_4641_01_000219/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4641/container_1422482982071_4641_01_000219 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.178 40875 attempt_1422482982071_4641_r_000012_2 219 1>/var/log/hadoop-yarn/containers/application_1422482982071_4641/container_1422482982071_4641_01_000219/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4641/container_1422482982071_4641_01_000219/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 19:09:48 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 19:09:48 INFO mapreduce.Job: Job job_1422482982071_4641 failed with state FAILED due to: Task failed task_1422482982071_4641_r_000012
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 19:09:49 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=27616875026
		FILE: Number of bytes written=57836758908
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2107429556
		HDFS: Number of read operations=489
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=58
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=135
		Launched reduce tasks=34
		Data-local map tasks=65
		Rack-local map tasks=70
		Total time spent by all maps in occupied slots (ms)=21159368
		Total time spent by all reduces in occupied slots (ms)=36716624
		Total time spent by all map tasks (ms)=10579684
		Total time spent by all reduce tasks (ms)=18358312
		Total vcore-seconds taken by all map tasks=10579684
		Total vcore-seconds taken by all reduce tasks=18358312
		Total megabyte-seconds taken by all map tasks=85653121664
		Total megabyte-seconds taken by all reduce tasks=220299744000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141606
		Map output bytes=29491551248
		Map output materialized bytes=30204081607
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=35198018
		Reduce shuffle bytes=27616898114
		Reduce input records=332529351
		Reduce output records=35387362
		Spilled Records=676670957
		Shuffled Maps =3886
		Failed Shuffles=0
		Merged Map outputs=3886
		GC time elapsed (ms)=112993
		CPU time spent (ms)=22624030
		Physical memory (bytes) snapshot=295447793664
		Virtual memory (bytes) snapshot=1618307612672
		Total committed heap usage (bytes)=432189861888
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2107429556
	rmr
		reduce calls=35198018
15/04/12 19:09:49 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 19:09:55 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file2de41c243d22

real	66m58.966s
user	0m38.070s
sys	0m3.943s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-20-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=20"


15/04/12 19:10:01 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 19:10:01 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5786285946250837588.jar tmpDir=null
15/04/12 19:10:01 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 19:10:01 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 19:10:02 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 19:10:03 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 19:10:03 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4658
15/04/12 19:10:04 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4658
15/04/12 19:10:04 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4658/
15/04/12 19:10:04 INFO mapreduce.Job: Running job: job_1422482982071_4658
15/04/12 19:10:08 INFO mapreduce.Job: Job job_1422482982071_4658 running in uber mode : false
15/04/12 19:10:08 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 19:10:19 INFO mapreduce.Job:  map 4% reduce 0%
15/04/12 19:10:20 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 19:10:22 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 19:10:23 INFO mapreduce.Job:  map 9% reduce 0%
15/04/12 19:10:25 INFO mapreduce.Job:  map 12% reduce 0%
15/04/12 19:10:28 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 19:10:29 INFO mapreduce.Job:  map 16% reduce 0%
15/04/12 19:10:31 INFO mapreduce.Job:  map 19% reduce 0%
15/04/12 19:10:34 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 19:10:35 INFO mapreduce.Job:  map 23% reduce 0%
15/04/12 19:10:37 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 19:10:38 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 19:10:40 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 19:10:41 INFO mapreduce.Job:  map 30% reduce 0%
15/04/12 19:10:43 INFO mapreduce.Job:  map 32% reduce 0%
15/04/12 19:10:44 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 19:10:46 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 19:10:47 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 19:10:48 INFO mapreduce.Job:  map 37% reduce 0%
15/04/12 19:10:49 INFO mapreduce.Job:  map 39% reduce 0%
15/04/12 19:10:50 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 19:10:52 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 19:10:53 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 19:10:54 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 19:10:55 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 19:10:56 INFO mapreduce.Job:  map 46% reduce 0%
15/04/12 19:10:57 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 19:10:58 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 19:10:59 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 19:11:00 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 19:11:01 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 19:11:02 INFO mapreduce.Job:  map 53% reduce 0%
15/04/12 19:11:03 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 19:11:04 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 19:11:05 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 19:11:07 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 19:11:08 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 19:11:09 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 19:11:10 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 19:11:12 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 19:11:15 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 19:11:18 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 19:11:19 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 19:11:21 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 19:11:22 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 19:11:23 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 19:11:24 INFO mapreduce.Job:  map 81% reduce 0%
15/04/12 19:11:25 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 19:11:26 INFO mapreduce.Job:  map 83% reduce 0%
15/04/12 19:11:27 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 19:11:28 INFO mapreduce.Job:  map 88% reduce 0%
15/04/12 19:11:29 INFO mapreduce.Job:  map 89% reduce 8%
15/04/12 19:11:30 INFO mapreduce.Job:  map 91% reduce 22%
15/04/12 19:11:32 INFO mapreduce.Job:  map 92% reduce 23%
15/04/12 19:11:33 INFO mapreduce.Job:  map 92% reduce 24%
15/04/12 19:11:37 INFO mapreduce.Job:  map 93% reduce 24%
15/04/12 19:11:39 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 19:11:45 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 19:11:49 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 19:11:51 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 19:11:53 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 19:11:54 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 19:11:55 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 19:11:56 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 19:11:57 INFO mapreduce.Job:  map 97% reduce 30%
15/04/12 19:11:59 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 19:12:00 INFO mapreduce.Job:  map 98% reduce 31%
15/04/12 19:12:02 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 19:12:03 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 19:12:06 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 19:12:07 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 19:12:13 INFO mapreduce.Job:  map 100% reduce 36%
15/04/12 19:12:14 INFO mapreduce.Job:  map 100% reduce 43%
15/04/12 19:12:15 INFO mapreduce.Job:  map 100% reduce 44%
15/04/12 19:12:16 INFO mapreduce.Job:  map 100% reduce 54%
15/04/12 19:12:17 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 19:12:19 INFO mapreduce.Job:  map 100% reduce 62%
15/04/12 19:12:20 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 19:12:23 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 19:12:26 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 19:12:37 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 19:12:47 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 19:12:58 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 19:13:08 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 19:13:20 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 19:13:28 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 19:13:37 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 19:13:48 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 19:14:01 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 19:14:11 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 19:14:23 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 19:14:37 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 19:14:51 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 19:15:08 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 19:15:24 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 19:15:42 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 19:15:59 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 19:16:12 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 19:16:27 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 19:16:47 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 19:17:06 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 19:17:27 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 19:17:54 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 19:18:13 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 19:18:38 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 19:18:59 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 19:19:26 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 19:20:00 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 19:20:48 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 19:22:12 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 19:33:11 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 19:33:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4658_r_000012_0, Status : FAILED
Container [pid=13477,containerID=container_1422482982071_4658_01_000200] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4658_01_000200 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 13477 6181 13477 13477 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4658/container_1422482982071_4658_01_000200/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4658/container_1422482982071_4658_01_000200 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.187 52973 attempt_1422482982071_4658_r_000012_0 200 1>/var/log/hadoop-yarn/containers/application_1422482982071_4658/container_1422482982071_4658_01_000200/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4658/container_1422482982071_4658_01_000200/stderr  
	|- 13701 13689 13477 13477 (cat) 1 25 4231168 142 cat 
	|- 13689 13486 13477 13477 (R) 107389 17940 10553315328 2501589 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3c0a7a8c6f64 
	|- 13486 13477 13477 13477 (java) 3589 577 13312385024 588802 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4658/container_1422482982071_4658_01_000200/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4658/container_1422482982071_4658_01_000200 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.187 52973 attempt_1422482982071_4658_r_000012_0 200 
	|- 13703 13689 13477 13477 (cat) 0 0 4231168 134 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 19:33:12 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 19:33:13 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 19:54:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4658_r_000012_1, Status : FAILED
Container [pid=8591,containerID=container_1422482982071_4658_01_000228] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4658_01_000228 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 8591 9763 8591 8591 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4658/container_1422482982071_4658_01_000228/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4658/container_1422482982071_4658_01_000228 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.187 52973 attempt_1422482982071_4658_r_000012_1 228 1>/var/log/hadoop-yarn/containers/application_1422482982071_4658/container_1422482982071_4658_01_000228/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4658/container_1422482982071_4658_01_000228/stderr  
	|- 8984 8601 8591 8591 (R) 107697 19598 10573221888 2558294 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3c0a7a8c6f64 
	|- 8997 8984 8591 8591 (cat) 0 0 4231168 135 cat 
	|- 8995 8984 8591 8591 (cat) 0 26 4231168 142 cat 
	|- 8601 8591 8591 8591 (java) 3830 747 13311954944 589453 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4658/container_1422482982071_4658_01_000228/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4658/container_1422482982071_4658_01_000228 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.187 52973 attempt_1422482982071_4658_r_000012_1 228 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 19:54:30 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 19:54:40 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 19:54:43 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 20:15:24 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 20:15:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_4658_r_000012_2, Status : FAILED
Container [pid=24930,containerID=container_1422482982071_4658_01_000229] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4658_01_000229 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 24981 24940 24930 24930 (R) 105666 18199 10437668864 2501089 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3c0a7a8c6f64 
	|- 24994 24981 24930 24930 (cat) 0 0 103391232 152 cat 
	|- 24930 3817 24930 24930 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4658/container_1422482982071_4658_01_000229/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4658/container_1422482982071_4658_01_000229 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.187 52973 attempt_1422482982071_4658_r_000012_2 229 1>/var/log/hadoop-yarn/containers/application_1422482982071_4658/container_1422482982071_4658_01_000229/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4658/container_1422482982071_4658_01_000229/stderr  
	|- 24992 24981 24930 24930 (cat) 0 26 103391232 159 cat 
	|- 24940 24930 24930 24930 (java) 2770 520 13411328000 588781 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4658/container_1422482982071_4658_01_000229/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4658/container_1422482982071_4658_01_000229 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.187 52973 attempt_1422482982071_4658_r_000012_2 229 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 20:15:25 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 20:15:36 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 20:15:52 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 20:15:55 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 20:37:16 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 20:37:16 INFO mapreduce.Job: Job job_1422482982071_4658 failed with state FAILED due to: Task failed task_1422482982071_4658_r_000012
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 20:37:16 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=27497406205
		FILE: Number of bytes written=57716290161
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2071206860
		HDFS: Number of read operations=459
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=38
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=135
		Launched reduce tasks=24
		Data-local map tasks=60
		Rack-local map tasks=75
		Total time spent by all maps in occupied slots (ms)=21314872
		Total time spent by all reduces in occupied slots (ms)=34684038
		Total time spent by all map tasks (ms)=10657436
		Total time spent by all reduce tasks (ms)=17342019
		Total vcore-seconds taken by all map tasks=10657436
		Total vcore-seconds taken by all reduce tasks=17342019
		Total megabyte-seconds taken by all map tasks=86282601856
		Total megabyte-seconds taken by all reduce tasks=208104228000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141595
		Map output bytes=29491554222
		Map output materialized bytes=30204076519
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=34588500
		Reduce shuffle bytes=27497421253
		Reduce input records=326864763
		Reduce output records=34776583
		Spilled Records=671006358
		Shuffled Maps =2546
		Failed Shuffles=0
		Merged Map outputs=2546
		GC time elapsed (ms)=95107
		CPU time spent (ms)=22360670
		Physical memory (bytes) snapshot=295210053632
		Virtual memory (bytes) snapshot=1483693940736
		Total committed heap usage (bytes)=411136471040
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2071206860
	rmr
		reduce calls=34588500
15/04/12 20:37:16 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 20:37:22 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file3c0a30c88aab

real	87m26.302s
user	0m40.429s
sys	0m4.581s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-20-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=20"


15/04/12 20:37:27 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 20:37:27 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob177876508176132465.jar tmpDir=null
15/04/12 20:37:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 20:37:28 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 20:37:29 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 20:37:29 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 20:37:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4680
15/04/12 20:37:30 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4680
15/04/12 20:37:30 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4680/
15/04/12 20:37:30 INFO mapreduce.Job: Running job: job_1422482982071_4680
15/04/12 20:37:36 INFO mapreduce.Job: Job job_1422482982071_4680 running in uber mode : false
15/04/12 20:37:36 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 20:37:47 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 20:37:48 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 20:37:50 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 20:37:51 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 20:37:53 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 20:37:54 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 20:37:56 INFO mapreduce.Job:  map 14% reduce 0%
15/04/12 20:37:57 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 20:37:59 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 20:38:00 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 20:38:02 INFO mapreduce.Job:  map 21% reduce 0%
15/04/12 20:38:03 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 20:38:05 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 20:38:06 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 20:38:08 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 20:38:09 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 20:38:11 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 20:38:12 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 20:38:14 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 20:38:15 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 20:38:17 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 20:38:18 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 20:38:20 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 20:38:21 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 20:38:23 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 20:38:24 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 20:38:26 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 20:38:27 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 20:38:30 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 20:38:31 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 20:38:33 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 20:38:33 INFO mapreduce.Job: Task Id : attempt_1422482982071_4680_m_000004_0, Status : FAILED
Error: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:334)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRawBytes(TypedBytesInput.java:218)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRaw(TypedBytesInput.java:152)
	at org.apache.hadoop.streaming.io.TypedBytesOutputReader.readKeyValue(TypedBytesOutputReader.java:56)
	at org.apache.hadoop.streaming.PipeMapRed$MROutputThread.run(PipeMapRed.java:376)

15/04/12 20:38:34 INFO mapreduce.Job:  map 56% reduce 0%
15/04/12 20:38:34 INFO mapreduce.Job: Task Id : attempt_1422482982071_4680_m_000008_0, Status : FAILED
Error: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:334)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRawBytes(TypedBytesInput.java:218)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRaw(TypedBytesInput.java:152)
	at org.apache.hadoop.streaming.io.TypedBytesOutputReader.readKeyValue(TypedBytesOutputReader.java:56)
	at org.apache.hadoop.streaming.PipeMapRed$MROutputThread.run(PipeMapRed.java:376)

15/04/12 20:38:36 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 20:38:37 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 20:38:39 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 20:38:41 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 20:38:43 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 20:38:45 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 20:38:46 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 20:38:47 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 20:38:48 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 20:38:49 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 20:38:50 INFO mapreduce.Job:  map 75% reduce 0%
15/04/12 20:38:51 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 20:38:52 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 20:38:53 INFO mapreduce.Job:  map 80% reduce 0%
15/04/12 20:38:54 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 20:38:55 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 20:38:56 INFO mapreduce.Job:  map 87% reduce 4%
15/04/12 20:38:57 INFO mapreduce.Job:  map 89% reduce 13%
15/04/12 20:38:58 INFO mapreduce.Job:  map 89% reduce 19%
15/04/12 20:38:59 INFO mapreduce.Job:  map 90% reduce 23%
15/04/12 20:39:00 INFO mapreduce.Job:  map 91% reduce 23%
15/04/12 20:39:04 INFO mapreduce.Job:  map 91% reduce 24%
15/04/12 20:39:05 INFO mapreduce.Job:  map 92% reduce 24%
15/04/12 20:39:06 INFO mapreduce.Job:  map 92% reduce 25%
15/04/12 20:39:07 INFO mapreduce.Job:  map 92% reduce 26%
15/04/12 20:39:12 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 20:39:20 INFO mapreduce.Job:  map 94% reduce 26%
15/04/12 20:39:21 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 20:39:22 INFO mapreduce.Job:  map 95% reduce 28%
15/04/12 20:39:23 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 20:39:24 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 20:39:25 INFO mapreduce.Job:  map 97% reduce 30%
15/04/12 20:39:26 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 20:39:28 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 20:39:31 INFO mapreduce.Job:  map 99% reduce 32%
15/04/12 20:39:33 INFO mapreduce.Job:  map 99% reduce 33%
15/04/12 20:39:39 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 20:39:54 INFO mapreduce.Job:  map 100% reduce 34%
15/04/12 20:39:55 INFO mapreduce.Job:  map 100% reduce 42%
15/04/12 20:39:56 INFO mapreduce.Job:  map 100% reduce 49%
15/04/12 20:39:57 INFO mapreduce.Job:  map 100% reduce 54%
15/04/12 20:39:58 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 20:39:59 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 20:40:01 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 20:40:02 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 20:40:08 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 20:40:18 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 20:40:28 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 20:40:39 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 20:40:50 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 20:41:02 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 20:41:10 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 20:41:20 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 20:41:32 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 20:41:43 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 20:41:53 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 20:42:04 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 20:42:17 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 20:42:32 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 20:42:47 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 20:43:02 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 20:43:20 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 20:43:38 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 20:43:54 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 20:44:07 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 20:44:26 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 20:44:44 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 20:45:06 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 20:45:31 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 20:45:49 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 20:46:15 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 20:46:32 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 20:47:01 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 20:47:35 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 20:48:21 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 20:49:45 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 21:01:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_4680_r_000012_0, Status : FAILED
Container [pid=20699,containerID=container_1422482982071_4680_01_000206] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4680_01_000206 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 20699 11693 20699 20699 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4680/container_1422482982071_4680_01_000206/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4680/container_1422482982071_4680_01_000206 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.160 43905 attempt_1422482982071_4680_r_000012_0 206 1>/var/log/hadoop-yarn/containers/application_1422482982071_4680/container_1422482982071_4680_01_000206/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4680/container_1422482982071_4680_01_000206/stderr  
	|- 20817 20801 20699 20699 (cat) 0 0 4231168 135 cat 
	|- 20708 20699 20699 20699 (java) 3639 715 13312577536 589846 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4680/container_1422482982071_4680_01_000206/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4680/container_1422482982071_4680_01_000206 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.160 43905 attempt_1422482982071_4680_r_000012_0 206 
	|- 20812 20801 20699 20699 (cat) 0 25 4231168 142 cat 
	|- 20801 20708 20699 20699 (R) 107158 19276 10305888256 2493026 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4cb43099fded 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 21:22:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4680_r_000012_1, Status : FAILED
Container [pid=25623,containerID=container_1422482982071_4680_01_000234] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4680_01_000234 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 25674 25633 25623 25623 (R) 108399 19854 10439565312 2520135 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4cb43099fded 
	|- 25633 25623 25623 25623 (java) 4199 794 13312040960 589068 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4680/container_1422482982071_4680_01_000234/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4680/container_1422482982071_4680_01_000234 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.160 43905 attempt_1422482982071_4680_r_000012_1 234 
	|- 25623 10523 25623 25623 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4680/container_1422482982071_4680_01_000234/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4680/container_1422482982071_4680_01_000234 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.160 43905 attempt_1422482982071_4680_r_000012_1 234 1>/var/log/hadoop-yarn/containers/application_1422482982071_4680/container_1422482982071_4680_01_000234/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4680/container_1422482982071_4680_01_000234/stderr  
	|- 25685 25674 25623 25623 (cat) 1 26 4231168 142 cat 
	|- 25698 25674 25623 25623 (cat) 0 0 4231168 134 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 21:22:26 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 21:22:34 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 21:22:37 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 21:43:53 INFO mapreduce.Job: Task Id : attempt_1422482982071_4680_r_000012_2, Status : FAILED
Container [pid=6719,containerID=container_1422482982071_4680_01_000235] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4680_01_000235 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 6729 6719 6719 6719 (java) 3358 676 13311881216 589395 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4680/container_1422482982071_4680_01_000235/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4680/container_1422482982071_4680_01_000235 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.160 43905 attempt_1422482982071_4680_r_000012_2 235 
	|- 6779 6729 6719 6719 (R) 107996 19300 10339184640 2501123 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4cb43099fded 
	|- 6792 6779 6719 6719 (cat) 0 0 4231168 134 cat 
	|- 6790 6779 6719 6719 (cat) 0 25 4231168 142 cat 
	|- 6719 11626 6719 6719 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4680/container_1422482982071_4680_01_000235/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4680/container_1422482982071_4680_01_000235 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.160 43905 attempt_1422482982071_4680_r_000012_2 235 1>/var/log/hadoop-yarn/containers/application_1422482982071_4680/container_1422482982071_4680_01_000235/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4680/container_1422482982071_4680_01_000235/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 21:43:54 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 21:44:04 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 21:44:20 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 21:44:23 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 22:05:56 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 22:05:56 INFO mapreduce.Job: Job job_1422482982071_4680 failed with state FAILED due to: Task failed task_1422482982071_4680_r_000012
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 22:05:56 INFO mapreduce.Job: Counters: 56
	File System Counters
		FILE: Number of bytes read=27497388837
		FILE: Number of bytes written=57716259913
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2071199742
		HDFS: Number of read operations=459
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=38
	Job Counters 
		Failed map tasks=2
		Failed reduce tasks=4
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=137
		Launched reduce tasks=24
		Other local map tasks=3
		Data-local map tasks=61
		Rack-local map tasks=73
		Total time spent by all maps in occupied slots (ms)=21344456
		Total time spent by all reduces in occupied slots (ms)=35161440
		Total time spent by all map tasks (ms)=10672228
		Total time spent by all reduce tasks (ms)=17580720
		Total vcore-seconds taken by all map tasks=10672228
		Total vcore-seconds taken by all reduce tasks=17580720
		Total megabyte-seconds taken by all map tasks=86402357888
		Total megabyte-seconds taken by all reduce tasks=210968640000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141583
		Map output bytes=29491542740
		Map output materialized bytes=30204065016
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=34588441
		Reduce shuffle bytes=27497403885
		Reduce input records=326864700
		Reduce output records=34776498
		Spilled Records=671006283
		Shuffled Maps =2546
		Failed Shuffles=0
		Merged Map outputs=2546
		GC time elapsed (ms)=111094
		CPU time spent (ms)=22230300
		Physical memory (bytes) snapshot=294939074560
		Virtual memory (bytes) snapshot=1483670794240
		Total committed heap usage (bytes)=411138998272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2071199742
	rmr
		reduce calls=34588441
15/04/12 22:05:56 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 22:06:02 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file4cb448c34ab4

real	88m40.274s
user	0m41.236s
sys	0m4.513s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-20-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=20"


15/04/12 22:06:08 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 22:06:08 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1755841252765805966.jar tmpDir=null
15/04/12 22:06:09 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 22:06:09 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 22:06:10 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 22:06:10 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 22:06:11 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4693
15/04/12 22:06:11 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4693
15/04/12 22:06:11 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4693/
15/04/12 22:06:11 INFO mapreduce.Job: Running job: job_1422482982071_4693
15/04/12 22:06:17 INFO mapreduce.Job: Job job_1422482982071_4693 running in uber mode : false
15/04/12 22:06:17 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 22:06:28 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 22:06:29 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 22:06:31 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 22:06:32 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 22:06:34 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 22:06:35 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 22:06:37 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 22:06:38 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 22:06:41 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 22:06:42 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 22:06:44 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 22:06:45 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 22:06:47 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 22:06:48 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 22:06:49 INFO mapreduce.Job:  map 26% reduce 0%
15/04/12 22:06:50 INFO mapreduce.Job:  map 28% reduce 0%
15/04/12 22:06:51 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 22:06:53 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 22:06:54 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 22:06:56 INFO mapreduce.Job:  map 35% reduce 0%
15/04/12 22:06:57 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 22:06:59 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 22:07:00 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 22:07:02 INFO mapreduce.Job:  map 42% reduce 0%
15/04/12 22:07:03 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 22:07:04 INFO mapreduce.Job:  map 44% reduce 0%
15/04/12 22:07:05 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 22:07:06 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 22:07:08 INFO mapreduce.Job:  map 49% reduce 0%
15/04/12 22:07:09 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 22:07:10 INFO mapreduce.Job:  map 51% reduce 0%
15/04/12 22:07:11 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 22:07:12 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 22:07:14 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 22:07:15 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 22:07:17 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 22:07:18 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 22:07:20 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 22:07:21 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 22:07:23 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 22:07:26 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 22:07:27 INFO mapreduce.Job:  map 66% reduce 0%
15/04/12 22:07:28 INFO mapreduce.Job:  map 68% reduce 0%
15/04/12 22:07:30 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 22:07:31 INFO mapreduce.Job:  map 73% reduce 0%
15/04/12 22:07:32 INFO mapreduce.Job:  map 77% reduce 0%
15/04/12 22:07:33 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 22:07:34 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 22:07:35 INFO mapreduce.Job:  map 85% reduce 0%
15/04/12 22:07:36 INFO mapreduce.Job:  map 88% reduce 0%
15/04/12 22:07:37 INFO mapreduce.Job:  map 89% reduce 5%
15/04/12 22:07:38 INFO mapreduce.Job:  map 90% reduce 14%
15/04/12 22:07:39 INFO mapreduce.Job:  map 91% reduce 22%
15/04/12 22:07:40 INFO mapreduce.Job:  map 92% reduce 23%
15/04/12 22:07:41 INFO mapreduce.Job:  map 92% reduce 24%
15/04/12 22:07:45 INFO mapreduce.Job:  map 93% reduce 24%
15/04/12 22:07:47 INFO mapreduce.Job:  map 93% reduce 25%
15/04/12 22:07:48 INFO mapreduce.Job:  map 93% reduce 26%
15/04/12 22:07:50 INFO mapreduce.Job:  map 93% reduce 27%
15/04/12 22:07:53 INFO mapreduce.Job:  map 94% reduce 27%
15/04/12 22:08:03 INFO mapreduce.Job:  map 95% reduce 27%
15/04/12 22:08:04 INFO mapreduce.Job:  map 96% reduce 27%
15/04/12 22:08:05 INFO mapreduce.Job:  map 96% reduce 28%
15/04/12 22:08:06 INFO mapreduce.Job:  map 97% reduce 29%
15/04/12 22:08:08 INFO mapreduce.Job:  map 98% reduce 30%
15/04/12 22:08:09 INFO mapreduce.Job:  map 99% reduce 31%
15/04/12 22:08:10 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 22:08:11 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 22:08:12 INFO mapreduce.Job:  map 100% reduce 35%
15/04/12 22:08:13 INFO mapreduce.Job:  map 100% reduce 41%
15/04/12 22:08:14 INFO mapreduce.Job:  map 100% reduce 49%
15/04/12 22:08:15 INFO mapreduce.Job:  map 100% reduce 55%
15/04/12 22:08:16 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 22:08:17 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 22:08:18 INFO mapreduce.Job:  map 100% reduce 64%
15/04/12 22:08:19 INFO mapreduce.Job:  map 100% reduce 65%
15/04/12 22:08:23 INFO mapreduce.Job:  map 100% reduce 66%
15/04/12 22:08:29 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 22:08:36 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 22:08:46 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 22:08:57 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 22:09:08 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 22:09:20 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 22:09:28 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 22:09:39 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 22:09:47 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 22:09:58 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 22:10:09 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 22:10:20 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 22:10:34 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 22:10:46 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 22:11:01 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 22:11:18 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 22:11:34 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 22:11:52 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 22:12:11 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 22:12:25 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 22:12:40 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 22:13:04 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 22:13:22 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 22:13:46 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 22:14:06 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 22:14:35 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 22:14:52 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 22:15:23 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 22:15:55 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 22:16:45 INFO mapreduce.Job:  map 100% reduce 97%
15/04/12 22:18:17 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 22:29:13 INFO mapreduce.Job: Task Id : attempt_1422482982071_4693_r_000012_0, Status : FAILED
Container [pid=38902,containerID=container_1422482982071_4693_01_000204] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4693_01_000204 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 38911 38902 38902 38902 (java) 3915 639 13312577536 589307 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4693/container_1422482982071_4693_01_000204/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4693/container_1422482982071_4693_01_000204 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.176 51386 attempt_1422482982071_4693_r_000012_0 204 
	|- 39020 39009 38902 38902 (cat) 0 27 4231168 142 cat 
	|- 39022 39009 38902 38902 (cat) 0 0 4231168 134 cat 
	|- 38902 29409 38902 38902 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4693/container_1422482982071_4693_01_000204/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4693/container_1422482982071_4693_01_000204 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.176 51386 attempt_1422482982071_4693_r_000012_0 204 1>/var/log/hadoop-yarn/containers/application_1422482982071_4693/container_1422482982071_4693_01_000204/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4693/container_1422482982071_4693_01_000204/stderr  
	|- 39009 38911 38902 38902 (R) 106572 19073 10532814848 2548397 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce75a92cbeea11 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 22:49:38 INFO mapreduce.Job: Task Id : attempt_1422482982071_4693_r_000012_1, Status : FAILED
Container [pid=29092,containerID=container_1422482982071_4693_01_000227] is running beyond physical memory limits. Current usage: 12.1 GB of 11.7 GB physical memory used; 22.4 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4693_01_000227 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 29157 29144 29092 29092 (cat) 0 0 4231168 134 cat 
	|- 29092 9431 29092 29092 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4693/container_1422482982071_4693_01_000227/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4693/container_1422482982071_4693_01_000227 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.176 51386 attempt_1422482982071_4693_r_000012_1 227 1>/var/log/hadoop-yarn/containers/application_1422482982071_4693/container_1422482982071_4693_01_000227/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4693/container_1422482982071_4693_01_000227/stderr  
	|- 29155 29144 29092 29092 (cat) 0 28 4231168 142 cat 
	|- 29144 29102 29092 29092 (R) 107515 17150 10684624896 2585460 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce75a92cbeea11 
	|- 29102 29092 29092 29092 (java) 3852 756 13312802816 589459 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4693/container_1422482982071_4693_01_000227/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4693/container_1422482982071_4693_01_000227 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.176 51386 attempt_1422482982071_4693_r_000012_1 227 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 23:10:23 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 23:10:23 INFO mapreduce.Job: Task Id : attempt_1422482982071_4693_r_000012_2, Status : FAILED
Container [pid=30210,containerID=container_1422482982071_4693_01_000228] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4693_01_000228 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 30210 3817 30210 30210 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4693/container_1422482982071_4693_01_000228/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4693/container_1422482982071_4693_01_000228 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.176 51386 attempt_1422482982071_4693_r_000012_2 228 1>/var/log/hadoop-yarn/containers/application_1422482982071_4693/container_1422482982071_4693_01_000228/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4693/container_1422482982071_4693_01_000228/stderr  
	|- 30260 30219 30210 30210 (R) 107621 16849 10538889216 2483368 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce75a92cbeea11 
	|- 30273 30260 30210 30210 (cat) 0 0 103391232 151 cat 
	|- 30271 30260 30210 30210 (cat) 0 24 103391232 159 cat 
	|- 30219 30210 30210 30210 (java) 3966 738 13412155392 589096 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4693/container_1422482982071_4693_01_000228/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4693/container_1422482982071_4693_01_000228 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.176 51386 attempt_1422482982071_4693_r_000012_2 228 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 23:10:24 INFO mapreduce.Job:  map 100% reduce 98%
15/04/12 23:32:02 INFO mapreduce.Job:  map 100% reduce 100%
15/04/12 23:32:02 INFO mapreduce.Job: Job job_1422482982071_4693 failed with state FAILED due to: Task failed task_1422482982071_4693_r_000012
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/12 23:32:02 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=27497324982
		FILE: Number of bytes written=57716194935
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=2071208988
		HDFS: Number of read operations=459
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=38
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=135
		Launched reduce tasks=24
		Data-local map tasks=64
		Rack-local map tasks=71
		Total time spent by all maps in occupied slots (ms)=21124120
		Total time spent by all reduces in occupied slots (ms)=34071792
		Total time spent by all map tasks (ms)=10562060
		Total time spent by all reduce tasks (ms)=17035896
		Total vcore-seconds taken by all map tasks=10562060
		Total vcore-seconds taken by all reduce tasks=17035896
		Total megabyte-seconds taken by all map tasks=85510437760
		Total megabyte-seconds taken by all reduce tasks=204430752000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141613
		Map output bytes=29491540184
		Map output materialized bytes=30204062516
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=34588439
		Reduce shuffle bytes=27497340030
		Reduce input records=326864300
		Reduce output records=34776564
		Spilled Records=671005913
		Shuffled Maps =2546
		Failed Shuffles=0
		Merged Map outputs=2546
		GC time elapsed (ms)=102110
		CPU time spent (ms)=22091650
		Physical memory (bytes) snapshot=294964445184
		Virtual memory (bytes) snapshot=1483677310976
		Total committed heap usage (bytes)=411138719744
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=2071208988
	rmr
		reduce calls=34588439
15/04/12 23:32:02 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/12 23:32:09 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file75a96f89fb31

real	86m7.419s
user	0m42.210s
sys	0m4.596s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-10-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=10"


15/04/12 23:32:15 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/12 23:32:15 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7080064706402515927.jar tmpDir=null
15/04/12 23:32:16 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 23:32:16 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/12 23:32:17 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/12 23:32:17 INFO mapreduce.JobSubmitter: number of splits:134
15/04/12 23:32:17 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4701
15/04/12 23:32:18 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4701
15/04/12 23:32:18 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4701/
15/04/12 23:32:18 INFO mapreduce.Job: Running job: job_1422482982071_4701
15/04/12 23:32:24 INFO mapreduce.Job: Job job_1422482982071_4701 running in uber mode : false
15/04/12 23:32:24 INFO mapreduce.Job:  map 0% reduce 0%
15/04/12 23:32:35 INFO mapreduce.Job:  map 3% reduce 0%
15/04/12 23:32:36 INFO mapreduce.Job:  map 5% reduce 0%
15/04/12 23:32:38 INFO mapreduce.Job:  map 7% reduce 0%
15/04/12 23:32:39 INFO mapreduce.Job:  map 8% reduce 0%
15/04/12 23:32:41 INFO mapreduce.Job:  map 10% reduce 0%
15/04/12 23:32:42 INFO mapreduce.Job:  map 11% reduce 0%
15/04/12 23:32:44 INFO mapreduce.Job:  map 13% reduce 0%
15/04/12 23:32:45 INFO mapreduce.Job:  map 15% reduce 0%
15/04/12 23:32:47 INFO mapreduce.Job:  map 17% reduce 0%
15/04/12 23:32:48 INFO mapreduce.Job:  map 18% reduce 0%
15/04/12 23:32:50 INFO mapreduce.Job:  map 20% reduce 0%
15/04/12 23:32:51 INFO mapreduce.Job:  map 22% reduce 0%
15/04/12 23:32:53 INFO mapreduce.Job:  map 24% reduce 0%
15/04/12 23:32:54 INFO mapreduce.Job:  map 25% reduce 0%
15/04/12 23:32:56 INFO mapreduce.Job:  map 27% reduce 0%
15/04/12 23:32:57 INFO mapreduce.Job:  map 29% reduce 0%
15/04/12 23:32:59 INFO mapreduce.Job:  map 31% reduce 0%
15/04/12 23:33:00 INFO mapreduce.Job:  map 33% reduce 0%
15/04/12 23:33:03 INFO mapreduce.Job:  map 34% reduce 0%
15/04/12 23:33:04 INFO mapreduce.Job:  map 36% reduce 0%
15/04/12 23:33:06 INFO mapreduce.Job:  map 38% reduce 0%
15/04/12 23:33:07 INFO mapreduce.Job:  map 40% reduce 0%
15/04/12 23:33:09 INFO mapreduce.Job:  map 41% reduce 0%
15/04/12 23:33:10 INFO mapreduce.Job:  map 43% reduce 0%
15/04/12 23:33:12 INFO mapreduce.Job:  map 45% reduce 0%
15/04/12 23:33:13 INFO mapreduce.Job:  map 47% reduce 0%
15/04/12 23:33:15 INFO mapreduce.Job:  map 48% reduce 0%
15/04/12 23:33:16 INFO mapreduce.Job:  map 50% reduce 0%
15/04/12 23:33:18 INFO mapreduce.Job:  map 52% reduce 0%
15/04/12 23:33:19 INFO mapreduce.Job:  map 54% reduce 0%
15/04/12 23:33:21 INFO mapreduce.Job:  map 55% reduce 0%
15/04/12 23:33:21 INFO mapreduce.Job: Task Id : attempt_1422482982071_4701_m_000023_0, Status : FAILED
Error: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:334)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRawBytes(TypedBytesInput.java:218)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRaw(TypedBytesInput.java:152)
	at org.apache.hadoop.streaming.io.TypedBytesOutputReader.readKeyValue(TypedBytesOutputReader.java:51)
	at org.apache.hadoop.streaming.PipeMapRed$MROutputThread.run(PipeMapRed.java:376)

15/04/12 23:33:22 INFO mapreduce.Job:  map 57% reduce 0%
15/04/12 23:33:24 INFO mapreduce.Job:  map 58% reduce 0%
15/04/12 23:33:25 INFO mapreduce.Job:  map 59% reduce 0%
15/04/12 23:33:26 INFO mapreduce.Job:  map 60% reduce 0%
15/04/12 23:33:28 INFO mapreduce.Job:  map 61% reduce 0%
15/04/12 23:33:30 INFO mapreduce.Job:  map 62% reduce 0%
15/04/12 23:33:32 INFO mapreduce.Job:  map 63% reduce 0%
15/04/12 23:33:35 INFO mapreduce.Job:  map 65% reduce 0%
15/04/12 23:33:36 INFO mapreduce.Job:  map 67% reduce 0%
15/04/12 23:33:37 INFO mapreduce.Job:  map 69% reduce 0%
15/04/12 23:33:38 INFO mapreduce.Job:  map 72% reduce 0%
15/04/12 23:33:39 INFO mapreduce.Job:  map 76% reduce 0%
15/04/12 23:33:40 INFO mapreduce.Job:  map 78% reduce 0%
15/04/12 23:33:41 INFO mapreduce.Job:  map 79% reduce 0%
15/04/12 23:33:42 INFO mapreduce.Job:  map 82% reduce 0%
15/04/12 23:33:43 INFO mapreduce.Job:  map 84% reduce 0%
15/04/12 23:33:44 INFO mapreduce.Job:  map 86% reduce 0%
15/04/12 23:33:45 INFO mapreduce.Job:  map 88% reduce 0%
15/04/12 23:33:46 INFO mapreduce.Job:  map 89% reduce 1%
15/04/12 23:33:47 INFO mapreduce.Job:  map 89% reduce 12%
15/04/12 23:33:48 INFO mapreduce.Job:  map 91% reduce 13%
15/04/12 23:33:50 INFO mapreduce.Job:  map 92% reduce 13%
15/04/12 23:33:54 INFO mapreduce.Job:  map 93% reduce 13%
15/04/12 23:33:56 INFO mapreduce.Job:  map 93% reduce 15%
15/04/12 23:33:57 INFO mapreduce.Job:  map 93% reduce 18%
15/04/12 23:33:59 INFO mapreduce.Job:  map 93% reduce 19%
15/04/12 23:34:00 INFO mapreduce.Job:  map 93% reduce 20%
15/04/12 23:34:03 INFO mapreduce.Job:  map 93% reduce 21%
15/04/12 23:34:06 INFO mapreduce.Job:  map 93% reduce 23%
15/04/12 23:34:08 INFO mapreduce.Job:  map 94% reduce 24%
15/04/12 23:34:09 INFO mapreduce.Job:  map 95% reduce 26%
15/04/12 23:34:11 INFO mapreduce.Job:  map 96% reduce 26%
15/04/12 23:34:12 INFO mapreduce.Job:  map 97% reduce 28%
15/04/12 23:34:13 INFO mapreduce.Job:  map 98% reduce 28%
15/04/12 23:34:14 INFO mapreduce.Job:  map 99% reduce 28%
15/04/12 23:34:15 INFO mapreduce.Job:  map 99% reduce 30%
15/04/12 23:34:17 INFO mapreduce.Job:  map 100% reduce 30%
15/04/12 23:34:18 INFO mapreduce.Job:  map 100% reduce 31%
15/04/12 23:34:19 INFO mapreduce.Job:  map 100% reduce 32%
15/04/12 23:34:21 INFO mapreduce.Job:  map 100% reduce 33%
15/04/12 23:34:52 INFO mapreduce.Job:  map 100% reduce 36%
15/04/12 23:34:53 INFO mapreduce.Job:  map 100% reduce 38%
15/04/12 23:34:54 INFO mapreduce.Job:  map 100% reduce 44%
15/04/12 23:34:55 INFO mapreduce.Job:  map 100% reduce 49%
15/04/12 23:34:56 INFO mapreduce.Job:  map 100% reduce 50%
15/04/12 23:34:57 INFO mapreduce.Job:  map 100% reduce 59%
15/04/12 23:34:58 INFO mapreduce.Job:  map 100% reduce 60%
15/04/12 23:34:59 INFO mapreduce.Job:  map 100% reduce 61%
15/04/12 23:35:00 INFO mapreduce.Job:  map 100% reduce 63%
15/04/12 23:35:06 INFO mapreduce.Job:  map 100% reduce 67%
15/04/12 23:35:19 INFO mapreduce.Job:  map 100% reduce 68%
15/04/12 23:35:41 INFO mapreduce.Job:  map 100% reduce 69%
15/04/12 23:36:11 INFO mapreduce.Job:  map 100% reduce 70%
15/04/12 23:36:41 INFO mapreduce.Job:  map 100% reduce 71%
15/04/12 23:37:02 INFO mapreduce.Job:  map 100% reduce 72%
15/04/12 23:37:23 INFO mapreduce.Job:  map 100% reduce 73%
15/04/12 23:37:41 INFO mapreduce.Job:  map 100% reduce 74%
15/04/12 23:38:02 INFO mapreduce.Job:  map 100% reduce 75%
15/04/12 23:38:30 INFO mapreduce.Job:  map 100% reduce 76%
15/04/12 23:38:51 INFO mapreduce.Job:  map 100% reduce 77%
15/04/12 23:39:16 INFO mapreduce.Job:  map 100% reduce 78%
15/04/12 23:39:36 INFO mapreduce.Job:  map 100% reduce 79%
15/04/12 23:39:59 INFO mapreduce.Job:  map 100% reduce 80%
15/04/12 23:40:27 INFO mapreduce.Job:  map 100% reduce 81%
15/04/12 23:40:52 INFO mapreduce.Job:  map 100% reduce 82%
15/04/12 23:41:20 INFO mapreduce.Job:  map 100% reduce 83%
15/04/12 23:41:50 INFO mapreduce.Job:  map 100% reduce 84%
15/04/12 23:42:23 INFO mapreduce.Job:  map 100% reduce 85%
15/04/12 23:43:02 INFO mapreduce.Job:  map 100% reduce 86%
15/04/12 23:43:41 INFO mapreduce.Job:  map 100% reduce 87%
15/04/12 23:44:23 INFO mapreduce.Job:  map 100% reduce 88%
15/04/12 23:44:53 INFO mapreduce.Job:  map 100% reduce 89%
15/04/12 23:45:37 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 23:46:19 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 23:47:12 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 23:48:04 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 23:49:15 INFO mapreduce.Job:  map 100% reduce 94%
15/04/12 23:50:38 INFO mapreduce.Job:  map 100% reduce 95%
15/04/12 23:52:30 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 23:56:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4701_r_000002_0, Status : FAILED
Container [pid=38026,containerID=container_1422482982071_4701_01_000191] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4701_01_000191 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 38224 38213 38026 38026 (cat) 0 26 103391232 159 cat 
	|- 38213 38037 38026 38026 (R) 109457 17857 10587344896 2537600 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce93cf3c84f227 
	|- 38037 38026 38026 38026 (java) 4808 791 13411516416 585403 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4701/container_1422482982071_4701_01_000191/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4701/container_1422482982071_4701_01_000191 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 40764 attempt_1422482982071_4701_r_000002_0 191 
	|- 38225 38213 38026 38026 (cat) 0 0 103391232 151 cat 
	|- 38026 3816 38026 38026 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4701/container_1422482982071_4701_01_000191/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4701/container_1422482982071_4701_01_000191 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 40764 attempt_1422482982071_4701_r_000002_0 191 1>/var/log/hadoop-yarn/containers/application_1422482982071_4701/container_1422482982071_4701_01_000191/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4701/container_1422482982071_4701_01_000191/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/12 23:56:12 INFO mapreduce.Job:  map 100% reduce 90%
15/04/12 23:56:23 INFO mapreduce.Job:  map 100% reduce 91%
15/04/12 23:56:33 INFO mapreduce.Job:  map 100% reduce 92%
15/04/12 23:56:48 INFO mapreduce.Job:  map 100% reduce 93%
15/04/12 23:56:57 INFO mapreduce.Job:  map 100% reduce 96%
15/04/12 23:57:00 INFO mapreduce.Job:  map 100% reduce 97%
15/04/13 00:19:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_4701_r_000002_1, Status : FAILED
Container [pid=48448,containerID=container_1422482982071_4701_01_000208] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4701_01_000208 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 48564 48551 48448 48448 (cat) 0 0 4231168 134 cat 
	|- 48551 48457 48448 48448 (R) 109092 28088 10439593984 2495569 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce93cf3c84f227 
	|- 48562 48551 48448 48448 (cat) 0 25 4231168 142 cat 
	|- 48457 48448 48448 48448 (java) 4534 834 13312274432 586215 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4701/container_1422482982071_4701_01_000208/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4701/container_1422482982071_4701_01_000208 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 40764 attempt_1422482982071_4701_r_000002_1 208 
	|- 48448 9000 48448 48448 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4701/container_1422482982071_4701_01_000208/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4701/container_1422482982071_4701_01_000208 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 40764 attempt_1422482982071_4701_r_000002_1 208 1>/var/log/hadoop-yarn/containers/application_1422482982071_4701/container_1422482982071_4701_01_000208/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4701/container_1422482982071_4701_01_000208/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 00:19:52 INFO mapreduce.Job:  map 100% reduce 90%
15/04/13 00:20:05 INFO mapreduce.Job:  map 100% reduce 91%
15/04/13 00:20:18 INFO mapreduce.Job:  map 100% reduce 92%
15/04/13 00:20:33 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 00:20:42 INFO mapreduce.Job:  map 100% reduce 95%
15/04/13 00:20:46 INFO mapreduce.Job:  map 100% reduce 97%
15/04/13 00:42:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_4701_r_000002_2, Status : FAILED
Container [pid=33953,containerID=container_1422482982071_4701_01_000209] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4701_01_000209 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 34020 34008 33953 33953 (cat) 0 0 4231168 134 cat 
	|- 33962 33953 33953 33953 (java) 6193 1156 13312389120 594004 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4701/container_1422482982071_4701_01_000209/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4701/container_1422482982071_4701_01_000209 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 40764 attempt_1422482982071_4701_r_000002_2 209 
	|- 34008 33962 33953 33953 (R) 108482 19291 10488315904 2537531 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce93cf3c84f227 
	|- 34019 34008 33953 33953 (cat) 0 26 4231168 143 cat 
	|- 33953 10523 33953 33953 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4701/container_1422482982071_4701_01_000209/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4701/container_1422482982071_4701_01_000209 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.192 40764 attempt_1422482982071_4701_r_000002_2 209 1>/var/log/hadoop-yarn/containers/application_1422482982071_4701/container_1422482982071_4701_01_000209/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4701/container_1422482982071_4701_01_000209/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 00:42:06 INFO mapreduce.Job:  map 100% reduce 90%
15/04/13 00:42:19 INFO mapreduce.Job:  map 100% reduce 91%
15/04/13 00:42:31 INFO mapreduce.Job:  map 100% reduce 92%
15/04/13 00:42:47 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 00:42:56 INFO mapreduce.Job:  map 100% reduce 96%
15/04/13 00:42:59 INFO mapreduce.Job:  map 100% reduce 97%
15/04/13 01:03:50 INFO mapreduce.Job:  map 100% reduce 100%
15/04/13 01:03:51 INFO mapreduce.Job: Job job_1422482982071_4701 failed with state FAILED due to: Task failed task_1422482982071_4701_r_000002
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/13 01:03:51 INFO mapreduce.Job: Counters: 55
	File System Counters
		FILE: Number of bytes read=25781338338
		FILE: Number of bytes written=55999200617
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=1961719730
		HDFS: Number of read operations=429
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=18
	Job Counters 
		Failed map tasks=1
		Failed reduce tasks=4
		Killed map tasks=1
		Launched map tasks=136
		Launched reduce tasks=13
		Other local map tasks=2
		Data-local map tasks=64
		Rack-local map tasks=70
		Total time spent by all maps in occupied slots (ms)=21483392
		Total time spent by all reduces in occupied slots (ms)=33580804
		Total time spent by all map tasks (ms)=10741696
		Total time spent by all reduce tasks (ms)=16790402
		Total vcore-seconds taken by all map tasks=10741696
		Total vcore-seconds taken by all reduce tasks=16790402
		Total megabyte-seconds taken by all map tasks=86964770816
		Total megabyte-seconds taken by all reduce tasks=201484824000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141584
		Map output bytes=29491536093
		Map output materialized bytes=30204050331
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=32769503
		Reduce shuffle bytes=25781345394
		Reduce input records=309773571
		Reduce output records=32943679
		Spilled Records=653915155
		Shuffled Maps =1206
		Failed Shuffles=0
		Merged Map outputs=1206
		GC time elapsed (ms)=105172
		CPU time spent (ms)=22131070
		Physical memory (bytes) snapshot=281910304768
		Virtual memory (bytes) snapshot=1350230392832
		Total committed heap usage (bytes)=390101958656
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=1961719730
	rmr
		reduce calls=32769503
15/04/13 01:03:51 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/13 01:03:58 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file93cf51e9098e

real	91m48.617s
user	0m42.104s
sys	0m4.597s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-10-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=10"


15/04/13 01:04:04 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/13 01:04:04 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob155607856536605263.jar tmpDir=null
15/04/13 01:04:04 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/13 01:04:05 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/13 01:04:06 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/13 01:04:06 INFO mapreduce.JobSubmitter: number of splits:134
15/04/13 01:04:07 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4711
15/04/13 01:04:07 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4711
15/04/13 01:04:07 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4711/
15/04/13 01:04:07 INFO mapreduce.Job: Running job: job_1422482982071_4711
15/04/13 01:04:15 INFO mapreduce.Job: Job job_1422482982071_4711 running in uber mode : false
15/04/13 01:04:15 INFO mapreduce.Job:  map 0% reduce 0%
15/04/13 01:04:25 INFO mapreduce.Job:  map 1% reduce 0%
15/04/13 01:04:26 INFO mapreduce.Job:  map 4% reduce 0%
15/04/13 01:04:27 INFO mapreduce.Job:  map 5% reduce 0%
15/04/13 01:04:29 INFO mapreduce.Job:  map 7% reduce 0%
15/04/13 01:04:30 INFO mapreduce.Job:  map 8% reduce 0%
15/04/13 01:04:32 INFO mapreduce.Job:  map 11% reduce 0%
15/04/13 01:04:35 INFO mapreduce.Job:  map 14% reduce 0%
15/04/13 01:04:37 INFO mapreduce.Job:  map 15% reduce 0%
15/04/13 01:04:38 INFO mapreduce.Job:  map 17% reduce 0%
15/04/13 01:04:39 INFO mapreduce.Job:  map 18% reduce 0%
15/04/13 01:04:41 INFO mapreduce.Job:  map 21% reduce 0%
15/04/13 01:04:43 INFO mapreduce.Job:  map 22% reduce 0%
15/04/13 01:04:44 INFO mapreduce.Job:  map 24% reduce 0%
15/04/13 01:04:45 INFO mapreduce.Job:  map 25% reduce 0%
15/04/13 01:04:47 INFO mapreduce.Job:  map 28% reduce 0%
15/04/13 01:04:48 INFO mapreduce.Job:  map 29% reduce 0%
15/04/13 01:04:50 INFO mapreduce.Job:  map 31% reduce 0%
15/04/13 01:04:51 INFO mapreduce.Job:  map 32% reduce 0%
15/04/13 01:04:53 INFO mapreduce.Job:  map 35% reduce 0%
15/04/13 01:04:54 INFO mapreduce.Job:  map 36% reduce 0%
15/04/13 01:04:56 INFO mapreduce.Job:  map 38% reduce 0%
15/04/13 01:04:57 INFO mapreduce.Job:  map 39% reduce 0%
15/04/13 01:04:59 INFO mapreduce.Job:  map 42% reduce 0%
15/04/13 01:05:00 INFO mapreduce.Job:  map 43% reduce 0%
15/04/13 01:05:02 INFO mapreduce.Job:  map 45% reduce 0%
15/04/13 01:05:03 INFO mapreduce.Job:  map 46% reduce 0%
15/04/13 01:05:05 INFO mapreduce.Job:  map 49% reduce 0%
15/04/13 01:05:06 INFO mapreduce.Job:  map 50% reduce 0%
15/04/13 01:05:08 INFO mapreduce.Job:  map 52% reduce 0%
15/04/13 01:05:09 INFO mapreduce.Job:  map 53% reduce 0%
15/04/13 01:05:11 INFO mapreduce.Job:  map 56% reduce 0%
15/04/13 01:05:12 INFO mapreduce.Job:  map 57% reduce 0%
15/04/13 01:05:14 INFO mapreduce.Job:  map 59% reduce 0%
15/04/13 01:05:15 INFO mapreduce.Job:  map 60% reduce 0%
15/04/13 01:05:17 INFO mapreduce.Job:  map 61% reduce 0%
15/04/13 01:05:18 INFO mapreduce.Job:  map 62% reduce 0%
15/04/13 01:05:21 INFO mapreduce.Job:  map 63% reduce 0%
15/04/13 01:05:24 INFO mapreduce.Job:  map 64% reduce 0%
15/04/13 01:05:25 INFO mapreduce.Job:  map 65% reduce 0%
15/04/13 01:05:26 INFO mapreduce.Job:  map 67% reduce 0%
15/04/13 01:05:27 INFO mapreduce.Job:  map 69% reduce 0%
15/04/13 01:05:28 INFO mapreduce.Job:  map 70% reduce 0%
15/04/13 01:05:29 INFO mapreduce.Job:  map 73% reduce 0%
15/04/13 01:05:30 INFO mapreduce.Job:  map 76% reduce 0%
15/04/13 01:05:31 INFO mapreduce.Job:  map 80% reduce 0%
15/04/13 01:05:32 INFO mapreduce.Job:  map 83% reduce 0%
15/04/13 01:05:33 INFO mapreduce.Job:  map 87% reduce 0%
15/04/13 01:05:34 INFO mapreduce.Job:  map 88% reduce 0%
15/04/13 01:05:35 INFO mapreduce.Job:  map 90% reduce 0%
15/04/13 01:05:36 INFO mapreduce.Job:  map 91% reduce 7%
15/04/13 01:05:37 INFO mapreduce.Job:  map 91% reduce 13%
15/04/13 01:05:38 INFO mapreduce.Job:  map 92% reduce 13%
15/04/13 01:05:42 INFO mapreduce.Job:  map 93% reduce 13%
15/04/13 01:05:44 INFO mapreduce.Job:  map 93% reduce 14%
15/04/13 01:05:45 INFO mapreduce.Job:  map 93% reduce 15%
15/04/13 01:05:46 INFO mapreduce.Job:  map 93% reduce 17%
15/04/13 01:05:47 INFO mapreduce.Job:  map 93% reduce 18%
15/04/13 01:05:48 INFO mapreduce.Job:  map 93% reduce 19%
15/04/13 01:05:54 INFO mapreduce.Job:  map 93% reduce 22%
15/04/13 01:05:55 INFO mapreduce.Job:  map 93% reduce 23%
15/04/13 01:05:56 INFO mapreduce.Job:  map 93% reduce 24%
15/04/13 01:05:57 INFO mapreduce.Job:  map 94% reduce 24%
15/04/13 01:05:58 INFO mapreduce.Job:  map 95% reduce 26%
15/04/13 01:05:59 INFO mapreduce.Job:  map 96% reduce 27%
15/04/13 01:06:01 INFO mapreduce.Job:  map 97% reduce 27%
15/04/13 01:06:02 INFO mapreduce.Job:  map 98% reduce 27%
15/04/13 01:06:03 INFO mapreduce.Job:  map 98% reduce 28%
15/04/13 01:06:04 INFO mapreduce.Job:  map 100% reduce 29%
15/04/13 01:06:06 INFO mapreduce.Job:  map 100% reduce 30%
15/04/13 01:06:07 INFO mapreduce.Job:  map 100% reduce 33%
15/04/13 01:06:08 INFO mapreduce.Job:  map 100% reduce 35%
15/04/13 01:06:10 INFO mapreduce.Job:  map 100% reduce 38%
15/04/13 01:06:11 INFO mapreduce.Job:  map 100% reduce 43%
15/04/13 01:06:13 INFO mapreduce.Job:  map 100% reduce 46%
15/04/13 01:06:14 INFO mapreduce.Job:  map 100% reduce 50%
15/04/13 01:06:15 INFO mapreduce.Job:  map 100% reduce 57%
15/04/13 01:06:16 INFO mapreduce.Job:  map 100% reduce 61%
15/04/13 01:06:17 INFO mapreduce.Job:  map 100% reduce 63%
15/04/13 01:06:18 INFO mapreduce.Job:  map 100% reduce 66%
15/04/13 01:06:20 INFO mapreduce.Job:  map 100% reduce 67%
15/04/13 01:06:35 INFO mapreduce.Job:  map 100% reduce 68%
15/04/13 01:06:57 INFO mapreduce.Job:  map 100% reduce 69%
15/04/13 01:07:27 INFO mapreduce.Job:  map 100% reduce 70%
15/04/13 01:08:00 INFO mapreduce.Job:  map 100% reduce 71%
15/04/13 01:08:22 INFO mapreduce.Job:  map 100% reduce 72%
15/04/13 01:08:42 INFO mapreduce.Job:  map 100% reduce 73%
15/04/13 01:09:04 INFO mapreduce.Job:  map 100% reduce 74%
15/04/13 01:09:25 INFO mapreduce.Job:  map 100% reduce 75%
15/04/13 01:09:52 INFO mapreduce.Job:  map 100% reduce 76%
15/04/13 01:10:14 INFO mapreduce.Job:  map 100% reduce 77%
15/04/13 01:10:34 INFO mapreduce.Job:  map 100% reduce 78%
15/04/13 01:10:56 INFO mapreduce.Job:  map 100% reduce 79%
15/04/13 01:11:22 INFO mapreduce.Job:  map 100% reduce 80%
15/04/13 01:11:46 INFO mapreduce.Job:  map 100% reduce 81%
15/04/13 01:12:13 INFO mapreduce.Job:  map 100% reduce 82%
15/04/13 01:12:40 INFO mapreduce.Job:  map 100% reduce 83%
15/04/13 01:13:12 INFO mapreduce.Job:  map 100% reduce 84%
15/04/13 01:13:40 INFO mapreduce.Job:  map 100% reduce 85%
15/04/13 01:14:17 INFO mapreduce.Job:  map 100% reduce 86%
15/04/13 01:14:58 INFO mapreduce.Job:  map 100% reduce 87%
15/04/13 01:15:39 INFO mapreduce.Job:  map 100% reduce 88%
15/04/13 01:16:08 INFO mapreduce.Job:  map 100% reduce 89%
15/04/13 01:16:49 INFO mapreduce.Job:  map 100% reduce 90%
15/04/13 01:17:28 INFO mapreduce.Job:  map 100% reduce 91%
15/04/13 01:18:17 INFO mapreduce.Job:  map 100% reduce 92%
15/04/13 01:19:15 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 01:20:15 INFO mapreduce.Job:  map 100% reduce 94%
15/04/13 01:21:46 INFO mapreduce.Job:  map 100% reduce 95%
15/04/13 01:23:47 INFO mapreduce.Job:  map 100% reduce 96%
15/04/13 01:27:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_4711_r_000002_0, Status : FAILED
Container [pid=21730,containerID=container_1422482982071_4711_01_000190] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4711_01_000190 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 21870 21841 21730 21730 (cat) 0 28 4231168 142 cat 
	|- 21739 21730 21730 21730 (java) 5415 992 13313646592 585080 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4711/container_1422482982071_4711_01_000190/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4711/container_1422482982071_4711_01_000190 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 54149 attempt_1422482982071_4711_r_000002_0 190 
	|- 21841 21739 21730 21730 (R) 110724 18564 10340032512 2488779 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce9f7a6b34ab95 
	|- 21872 21841 21730 21730 (cat) 0 0 4231168 134 cat 
	|- 21730 9793 21730 21730 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4711/container_1422482982071_4711_01_000190/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4711/container_1422482982071_4711_01_000190 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 54149 attempt_1422482982071_4711_r_000002_0 190 1>/var/log/hadoop-yarn/containers/application_1422482982071_4711/container_1422482982071_4711_01_000190/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4711/container_1422482982071_4711_01_000190/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 01:27:49 INFO mapreduce.Job:  map 100% reduce 90%
15/04/13 01:28:01 INFO mapreduce.Job:  map 100% reduce 91%
15/04/13 01:28:21 INFO mapreduce.Job:  map 100% reduce 92%
15/04/13 01:28:34 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 01:28:47 INFO mapreduce.Job:  map 100% reduce 96%
15/04/13 01:29:53 INFO mapreduce.Job:  map 100% reduce 97%
15/04/13 01:51:29 INFO mapreduce.Job:  map 100% reduce 100%
15/04/13 01:51:29 INFO mapreduce.Job: Task Id : attempt_1422482982071_4711_r_000002_1, Status : FAILED
Container [pid=39326,containerID=container_1422482982071_4711_01_000208] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.9 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4711_01_000208 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 39391 39335 39326 39326 (R) 114957 20795 10219048960 2471825 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce9f7a6b34ab95 
	|- 39335 39326 39326 39326 (java) 5853 1021 13312241664 609857 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4711/container_1422482982071_4711_01_000208/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4711/container_1422482982071_4711_01_000208 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 54149 attempt_1422482982071_4711_r_000002_1 208 
	|- 39403 39391 39326 39326 (cat) 0 0 4231168 134 cat 
	|- 39402 39391 39326 39326 (cat) 0 27 4231168 142 cat 
	|- 39326 9261 39326 39326 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4711/container_1422482982071_4711_01_000208/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4711/container_1422482982071_4711_01_000208 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 54149 attempt_1422482982071_4711_r_000002_1 208 1>/var/log/hadoop-yarn/containers/application_1422482982071_4711/container_1422482982071_4711_01_000208/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4711/container_1422482982071_4711_01_000208/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 01:51:30 INFO mapreduce.Job:  map 100% reduce 90%
15/04/13 01:51:42 INFO mapreduce.Job:  map 100% reduce 91%
15/04/13 01:51:55 INFO mapreduce.Job:  map 100% reduce 92%
15/04/13 01:52:14 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 01:52:23 INFO mapreduce.Job:  map 100% reduce 96%
15/04/13 01:52:26 INFO mapreduce.Job:  map 100% reduce 97%
15/04/13 02:14:49 INFO mapreduce.Job: Task Id : attempt_1422482982071_4711_r_000002_2, Status : FAILED
Container [pid=46470,containerID=container_1422482982071_4711_01_000209] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4711_01_000209 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 46480 46470 46470 46470 (java) 6376 1216 13313073152 585659 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4711/container_1422482982071_4711_01_000209/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4711/container_1422482982071_4711_01_000209 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 54149 attempt_1422482982071_4711_r_000002_2 209 
	|- 46470 9043 46470 46470 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4711/container_1422482982071_4711_01_000209/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4711/container_1422482982071_4711_01_000209 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.141 54149 attempt_1422482982071_4711_r_000002_2 209 1>/var/log/hadoop-yarn/containers/application_1422482982071_4711/container_1422482982071_4711_01_000209/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4711/container_1422482982071_4711_01_000209/stderr  
	|- 46536 46523 46470 46470 (cat) 0 0 4231168 134 cat 
	|- 46534 46523 46470 46470 (cat) 0 27 4231168 142 cat 
	|- 46523 46480 46470 46470 (R) 112297 22086 10488164352 2537496 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce9f7a6b34ab95 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 02:14:50 INFO mapreduce.Job:  map 100% reduce 90%
15/04/13 02:15:03 INFO mapreduce.Job:  map 100% reduce 91%
15/04/13 02:15:16 INFO mapreduce.Job:  map 100% reduce 92%
15/04/13 02:15:33 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 02:15:42 INFO mapreduce.Job:  map 100% reduce 95%
15/04/13 02:15:45 INFO mapreduce.Job:  map 100% reduce 97%
15/04/13 02:41:07 INFO mapreduce.Job:  map 100% reduce 100%
15/04/13 02:41:07 INFO mapreduce.Job: Job job_1422482982071_4711 failed with state FAILED due to: Task failed task_1422482982071_4711_r_000002
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/13 02:41:07 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=25781274918
		FILE: Number of bytes written=55999138925
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=1961718845
		HDFS: Number of read operations=429
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=18
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Launched map tasks=135
		Launched reduce tasks=13
		Data-local map tasks=61
		Rack-local map tasks=74
		Total time spent by all maps in occupied slots (ms)=21383442
		Total time spent by all reduces in occupied slots (ms)=33339018
		Total time spent by all map tasks (ms)=10691721
		Total time spent by all reduce tasks (ms)=16669509
		Total vcore-seconds taken by all map tasks=10691721
		Total vcore-seconds taken by all reduce tasks=16669509
		Total megabyte-seconds taken by all map tasks=86560173216
		Total megabyte-seconds taken by all reduce tasks=200034108000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141584
		Map output bytes=29491537823
		Map output materialized bytes=30204052059
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=32769533
		Reduce shuffle bytes=25781281974
		Reduce input records=309773106
		Reduce output records=32943690
		Spilled Records=653914690
		Shuffled Maps =1206
		Failed Shuffles=0
		Merged Map outputs=1206
		GC time elapsed (ms)=103171
		CPU time spent (ms)=22029090
		Physical memory (bytes) snapshot=282572996608
		Virtual memory (bytes) snapshot=1350622920704
		Total committed heap usage (bytes)=390195064832
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=1961718845
	rmr
		reduce calls=32769533
15/04/13 02:41:07 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/13 02:41:14 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file9f7a1be132ba

real	97m15.523s
user	0m42.273s
sys	0m4.717s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-10-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=10"


15/04/13 02:41:19 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/13 02:41:19 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob1728818299959369040.jar tmpDir=null
15/04/13 02:41:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/13 02:41:20 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/13 02:41:21 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/13 02:41:21 INFO mapreduce.JobSubmitter: number of splits:134
15/04/13 02:41:22 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4722
15/04/13 02:41:22 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4722
15/04/13 02:41:22 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4722/
15/04/13 02:41:22 INFO mapreduce.Job: Running job: job_1422482982071_4722
15/04/13 02:41:26 INFO mapreduce.Job: Job job_1422482982071_4722 running in uber mode : false
15/04/13 02:41:26 INFO mapreduce.Job:  map 0% reduce 0%
15/04/13 02:41:38 INFO mapreduce.Job:  map 2% reduce 0%
15/04/13 02:41:39 INFO mapreduce.Job:  map 4% reduce 0%
15/04/13 02:41:40 INFO mapreduce.Job:  map 5% reduce 0%
15/04/13 02:41:41 INFO mapreduce.Job:  map 7% reduce 0%
15/04/13 02:41:42 INFO mapreduce.Job:  map 8% reduce 0%
15/04/13 02:41:43 INFO mapreduce.Job:  map 9% reduce 0%
15/04/13 02:41:44 INFO mapreduce.Job:  map 10% reduce 0%
15/04/13 02:41:45 INFO mapreduce.Job:  map 11% reduce 0%
15/04/13 02:41:46 INFO mapreduce.Job:  map 12% reduce 0%
15/04/13 02:41:47 INFO mapreduce.Job:  map 14% reduce 0%
15/04/13 02:41:48 INFO mapreduce.Job:  map 15% reduce 0%
15/04/13 02:41:49 INFO mapreduce.Job:  map 16% reduce 0%
15/04/13 02:41:50 INFO mapreduce.Job:  map 17% reduce 0%
15/04/13 02:41:51 INFO mapreduce.Job:  map 18% reduce 0%
15/04/13 02:41:52 INFO mapreduce.Job:  map 19% reduce 0%
15/04/13 02:41:53 INFO mapreduce.Job:  map 20% reduce 0%
15/04/13 02:41:54 INFO mapreduce.Job:  map 22% reduce 0%
15/04/13 02:41:55 INFO mapreduce.Job:  map 23% reduce 0%
15/04/13 02:41:56 INFO mapreduce.Job:  map 24% reduce 0%
15/04/13 02:41:57 INFO mapreduce.Job:  map 25% reduce 0%
15/04/13 02:41:58 INFO mapreduce.Job:  map 26% reduce 0%
15/04/13 02:41:59 INFO mapreduce.Job:  map 27% reduce 0%
15/04/13 02:42:00 INFO mapreduce.Job:  map 29% reduce 0%
15/04/13 02:42:01 INFO mapreduce.Job:  map 30% reduce 0%
15/04/13 02:42:02 INFO mapreduce.Job:  map 31% reduce 0%
15/04/13 02:42:03 INFO mapreduce.Job:  map 32% reduce 0%
15/04/13 02:42:04 INFO mapreduce.Job:  map 33% reduce 0%
15/04/13 02:42:05 INFO mapreduce.Job:  map 35% reduce 0%
15/04/13 02:42:06 INFO mapreduce.Job:  map 36% reduce 0%
15/04/13 02:42:07 INFO mapreduce.Job:  map 37% reduce 0%
15/04/13 02:42:08 INFO mapreduce.Job:  map 38% reduce 0%
15/04/13 02:42:09 INFO mapreduce.Job:  map 39% reduce 0%
15/04/13 02:42:10 INFO mapreduce.Job:  map 40% reduce 0%
15/04/13 02:42:11 INFO mapreduce.Job:  map 41% reduce 0%
15/04/13 02:42:12 INFO mapreduce.Job:  map 43% reduce 0%
15/04/13 02:42:13 INFO mapreduce.Job:  map 44% reduce 0%
15/04/13 02:42:14 INFO mapreduce.Job:  map 45% reduce 0%
15/04/13 02:42:15 INFO mapreduce.Job:  map 46% reduce 0%
15/04/13 02:42:16 INFO mapreduce.Job:  map 47% reduce 0%
15/04/13 02:42:17 INFO mapreduce.Job:  map 48% reduce 0%
15/04/13 02:42:18 INFO mapreduce.Job:  map 50% reduce 0%
15/04/13 02:42:20 INFO mapreduce.Job:  map 52% reduce 0%
15/04/13 02:42:21 INFO mapreduce.Job:  map 53% reduce 0%
15/04/13 02:42:22 INFO mapreduce.Job:  map 54% reduce 0%
15/04/13 02:42:23 INFO mapreduce.Job:  map 55% reduce 0%
15/04/13 02:42:24 INFO mapreduce.Job:  map 57% reduce 0%
15/04/13 02:42:26 INFO mapreduce.Job:  map 59% reduce 0%
15/04/13 02:42:27 INFO mapreduce.Job:  map 60% reduce 0%
15/04/13 02:42:29 INFO mapreduce.Job:  map 61% reduce 0%
15/04/13 02:42:30 INFO mapreduce.Job:  map 62% reduce 0%
15/04/13 02:42:33 INFO mapreduce.Job:  map 63% reduce 0%
15/04/13 02:42:37 INFO mapreduce.Job:  map 64% reduce 0%
15/04/13 02:42:38 INFO mapreduce.Job:  map 65% reduce 0%
15/04/13 02:42:39 INFO mapreduce.Job:  map 68% reduce 0%
15/04/13 02:42:40 INFO mapreduce.Job:  map 71% reduce 0%
15/04/13 02:42:41 INFO mapreduce.Job:  map 76% reduce 0%
15/04/13 02:42:42 INFO mapreduce.Job:  map 79% reduce 0%
15/04/13 02:42:43 INFO mapreduce.Job:  map 81% reduce 0%
15/04/13 02:42:44 INFO mapreduce.Job:  map 83% reduce 0%
15/04/13 02:42:45 INFO mapreduce.Job:  map 87% reduce 0%
15/04/13 02:42:46 INFO mapreduce.Job:  map 89% reduce 0%
15/04/13 02:42:48 INFO mapreduce.Job:  map 90% reduce 0%
15/04/13 02:42:49 INFO mapreduce.Job:  map 91% reduce 11%
15/04/13 02:42:50 INFO mapreduce.Job:  map 91% reduce 13%
15/04/13 02:42:51 INFO mapreduce.Job:  map 92% reduce 13%
15/04/13 02:42:53 INFO mapreduce.Job:  map 93% reduce 13%
15/04/13 02:42:56 INFO mapreduce.Job:  map 93% reduce 14%
15/04/13 02:42:58 INFO mapreduce.Job:  map 93% reduce 16%
15/04/13 02:42:59 INFO mapreduce.Job:  map 93% reduce 19%
15/04/13 02:43:00 INFO mapreduce.Job:  map 94% reduce 19%
15/04/13 02:43:01 INFO mapreduce.Job:  map 94% reduce 22%
15/04/13 02:43:06 INFO mapreduce.Job:  map 94% reduce 23%
15/04/13 02:43:07 INFO mapreduce.Job:  map 94% reduce 25%
15/04/13 02:43:09 INFO mapreduce.Job:  map 94% reduce 26%
15/04/13 02:43:12 INFO mapreduce.Job:  map 95% reduce 26%
15/04/13 02:43:13 INFO mapreduce.Job:  map 95% reduce 27%
15/04/13 02:43:15 INFO mapreduce.Job:  map 96% reduce 27%
15/04/13 02:43:16 INFO mapreduce.Job:  map 97% reduce 29%
15/04/13 02:43:17 INFO mapreduce.Job:  map 98% reduce 29%
15/04/13 02:43:18 INFO mapreduce.Job:  map 98% reduce 30%
15/04/13 02:43:19 INFO mapreduce.Job:  map 99% reduce 31%
15/04/13 02:43:20 INFO mapreduce.Job:  map 100% reduce 31%
15/04/13 02:43:22 INFO mapreduce.Job:  map 100% reduce 32%
15/04/13 02:43:23 INFO mapreduce.Job:  map 100% reduce 33%
15/04/13 02:43:30 INFO mapreduce.Job:  map 100% reduce 35%
15/04/13 02:43:31 INFO mapreduce.Job:  map 100% reduce 39%
15/04/13 02:43:32 INFO mapreduce.Job:  map 100% reduce 48%
15/04/13 02:43:33 INFO mapreduce.Job:  map 100% reduce 50%
15/04/13 02:43:34 INFO mapreduce.Job:  map 100% reduce 53%
15/04/13 02:43:35 INFO mapreduce.Job:  map 100% reduce 60%
15/04/13 02:43:37 INFO mapreduce.Job:  map 100% reduce 61%
15/04/13 02:43:38 INFO mapreduce.Job:  map 100% reduce 63%
15/04/13 02:43:41 INFO mapreduce.Job:  map 100% reduce 67%
15/04/13 02:43:59 INFO mapreduce.Job:  map 100% reduce 68%
15/04/13 02:44:22 INFO mapreduce.Job:  map 100% reduce 69%
15/04/13 02:44:52 INFO mapreduce.Job:  map 100% reduce 70%
15/04/13 02:45:22 INFO mapreduce.Job:  map 100% reduce 71%
15/04/13 02:45:43 INFO mapreduce.Job:  map 100% reduce 72%
15/04/13 02:46:01 INFO mapreduce.Job:  map 100% reduce 73%
15/04/13 02:46:18 INFO mapreduce.Job:  map 100% reduce 74%
15/04/13 02:46:43 INFO mapreduce.Job:  map 100% reduce 75%
15/04/13 02:47:12 INFO mapreduce.Job:  map 100% reduce 76%
15/04/13 02:47:32 INFO mapreduce.Job:  map 100% reduce 77%
15/04/13 02:47:55 INFO mapreduce.Job:  map 100% reduce 78%
15/04/13 02:48:19 INFO mapreduce.Job:  map 100% reduce 79%
15/04/13 02:48:39 INFO mapreduce.Job:  map 100% reduce 80%
15/04/13 02:49:03 INFO mapreduce.Job:  map 100% reduce 81%
15/04/13 02:49:29 INFO mapreduce.Job:  map 100% reduce 82%
15/04/13 02:49:55 INFO mapreduce.Job:  map 100% reduce 83%
15/04/13 02:50:30 INFO mapreduce.Job:  map 100% reduce 84%
15/04/13 02:50:58 INFO mapreduce.Job:  map 100% reduce 85%
15/04/13 02:51:34 INFO mapreduce.Job:  map 100% reduce 86%
15/04/13 02:52:14 INFO mapreduce.Job:  map 100% reduce 87%
15/04/13 02:52:54 INFO mapreduce.Job:  map 100% reduce 88%
15/04/13 02:53:30 INFO mapreduce.Job:  map 100% reduce 89%
15/04/13 02:54:08 INFO mapreduce.Job:  map 100% reduce 90%
15/04/13 02:54:53 INFO mapreduce.Job:  map 100% reduce 91%
15/04/13 02:55:42 INFO mapreduce.Job:  map 100% reduce 92%
15/04/13 02:56:45 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 02:57:53 INFO mapreduce.Job:  map 100% reduce 94%
15/04/13 02:59:17 INFO mapreduce.Job:  map 100% reduce 95%
15/04/13 03:01:03 INFO mapreduce.Job:  map 100% reduce 96%
15/04/13 03:06:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4722_r_000002_0, Status : FAILED
Container [pid=16546,containerID=container_1422482982071_4722_01_000222] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4722_01_000222 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 16546 9143 16546 16546 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4722/container_1422482982071_4722_01_000222/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4722/container_1422482982071_4722_01_000222 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.157 52435 attempt_1422482982071_4722_r_000002_0 222 1>/var/log/hadoop-yarn/containers/application_1422482982071_4722/container_1422482982071_4722_01_000222/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4722/container_1422482982071_4722_01_000222/stderr  
	|- 16555 16546 16546 16546 (java) 5574 1003 13312397312 585878 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4722/container_1422482982071_4722_01_000222/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4722/container_1422482982071_4722_01_000222 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.157 52435 attempt_1422482982071_4722_r_000002_0 222 
	|- 16643 16555 16546 16546 (R) 114018 20606 10349961216 2503753 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reducea79519aadcde 
	|- 16654 16643 16546 16546 (cat) 0 29 4231168 142 cat 
	|- 16655 16643 16546 16546 (cat) 0 0 4231168 134 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 03:06:02 INFO mapreduce.Job:  map 100% reduce 90%
15/04/13 03:06:16 INFO mapreduce.Job:  map 100% reduce 91%
15/04/13 03:06:29 INFO mapreduce.Job:  map 100% reduce 92%
15/04/13 03:06:45 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 03:07:03 INFO mapreduce.Job:  map 100% reduce 97%
15/04/13 03:30:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_4722_r_000002_2, Status : FAILED
Container [pid=13025,containerID=container_1422482982071_4722_01_000231] is running beyond physical memory limits. Current usage: 12.1 GB of 11.7 GB physical memory used; 22.4 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4722_01_000231 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 13025 10887 13025 13025 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4722/container_1422482982071_4722_01_000231/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4722/container_1422482982071_4722_01_000231 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.157 52435 attempt_1422482982071_4722_r_000002_2 231 1>/var/log/hadoop-yarn/containers/application_1422482982071_4722/container_1422482982071_4722_01_000231/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4722/container_1422482982071_4722_01_000231/stderr  
	|- 13035 13025 13025 13025 (java) 5580 1095 13312176128 584781 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4722/container_1422482982071_4722_01_000231/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4722/container_1422482982071_4722_01_000231 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.157 52435 attempt_1422482982071_4722_r_000002_2 231 
	|- 13135 13123 13025 13025 (cat) 0 0 4231168 135 cat 
	|- 13134 13123 13025 13025 (cat) 0 24 4231168 142 cat 
	|- 13123 13035 13025 13025 (R) 106580 31155 10686607360 2585976 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reducea79519aadcde 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 03:30:19 INFO mapreduce.Job: Task Id : attempt_1422482982071_4722_r_000002_1, Status : FAILED
Container [pid=12979,containerID=container_1422482982071_4722_01_000230] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 21.9 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4722_01_000230 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 13091 13079 12979 12979 (cat) 0 0 4231168 134 cat 
	|- 13090 13079 12979 12979 (cat) 0 25 4231168 143 cat 
	|- 13079 12989 12979 12979 (R) 107350 32369 10222051328 2472558 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reducea79519aadcde 
	|- 12989 12979 12979 12979 (java) 6085 1181 13312716800 602019 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4722/container_1422482982071_4722_01_000230/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4722/container_1422482982071_4722_01_000230 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.157 52435 attempt_1422482982071_4722_r_000002_1 230 
	|- 12979 10887 12979 12979 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4722/container_1422482982071_4722_01_000230/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4722/container_1422482982071_4722_01_000230 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.157 52435 attempt_1422482982071_4722_r_000002_1 230 1>/var/log/hadoop-yarn/containers/application_1422482982071_4722/container_1422482982071_4722_01_000230/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4722/container_1422482982071_4722_01_000230/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 03:30:20 INFO mapreduce.Job:  map 100% reduce 90%
15/04/13 03:30:33 INFO mapreduce.Job:  map 100% reduce 91%
15/04/13 03:30:47 INFO mapreduce.Job:  map 100% reduce 92%
15/04/13 03:31:03 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 03:31:15 INFO mapreduce.Job:  map 100% reduce 95%
15/04/13 03:31:18 INFO mapreduce.Job:  map 100% reduce 97%
15/04/13 03:52:20 INFO mapreduce.Job:  map 100% reduce 100%
15/04/13 03:52:20 INFO mapreduce.Job: Job job_1422482982071_4722 failed with state FAILED due to: Task failed task_1422482982071_4722_r_000002
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/13 03:52:21 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=25781494140
		FILE: Number of bytes written=55999378981
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=1961712135
		HDFS: Number of read operations=429
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=18
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Launched map tasks=135
		Launched reduce tasks=13
		Data-local map tasks=66
		Rack-local map tasks=69
		Total time spent by all maps in occupied slots (ms)=21157624
		Total time spent by all reduces in occupied slots (ms)=33359760
		Total time spent by all map tasks (ms)=10578812
		Total time spent by all reduce tasks (ms)=16679880
		Total vcore-seconds taken by all map tasks=10578812
		Total vcore-seconds taken by all reduce tasks=16679880
		Total megabyte-seconds taken by all map tasks=85646061952
		Total megabyte-seconds taken by all reduce tasks=200158560000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141563
		Map output bytes=29491558700
		Map output materialized bytes=30204072893
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=32769532
		Reduce shuffle bytes=25781501196
		Reduce input records=309774565
		Reduce output records=32943643
		Spilled Records=653916128
		Shuffled Maps =1206
		Failed Shuffles=0
		Merged Map outputs=1206
		GC time elapsed (ms)=98613
		CPU time spent (ms)=21853960
		Physical memory (bytes) snapshot=282785783808
		Virtual memory (bytes) snapshot=1350246756352
		Total committed heap usage (bytes)=390280003584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=1961712135
	rmr
		reduce calls=32769532
15/04/13 03:52:21 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/13 03:52:27 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/filea7956548bebf

real	71m13.413s
user	0m39.727s
sys	0m4.207s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-5-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=5"


15/04/13 03:52:33 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/13 03:52:33 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob775225567967676001.jar tmpDir=null
15/04/13 03:52:33 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/13 03:52:34 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/13 03:52:34 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/13 03:52:35 INFO mapreduce.JobSubmitter: number of splits:134
15/04/13 03:52:35 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4725
15/04/13 03:52:35 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4725
15/04/13 03:52:36 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4725/
15/04/13 03:52:36 INFO mapreduce.Job: Running job: job_1422482982071_4725
15/04/13 03:52:42 INFO mapreduce.Job: Job job_1422482982071_4725 running in uber mode : false
15/04/13 03:52:42 INFO mapreduce.Job:  map 0% reduce 0%
15/04/13 03:52:53 INFO mapreduce.Job:  map 3% reduce 0%
15/04/13 03:52:54 INFO mapreduce.Job:  map 5% reduce 0%
15/04/13 03:52:56 INFO mapreduce.Job:  map 7% reduce 0%
15/04/13 03:52:57 INFO mapreduce.Job:  map 8% reduce 0%
15/04/13 03:52:59 INFO mapreduce.Job:  map 10% reduce 0%
15/04/13 03:53:00 INFO mapreduce.Job:  map 11% reduce 0%
15/04/13 03:53:02 INFO mapreduce.Job:  map 13% reduce 0%
15/04/13 03:53:03 INFO mapreduce.Job:  map 15% reduce 0%
15/04/13 03:53:05 INFO mapreduce.Job:  map 17% reduce 0%
15/04/13 03:53:06 INFO mapreduce.Job:  map 18% reduce 0%
15/04/13 03:53:08 INFO mapreduce.Job:  map 20% reduce 0%
15/04/13 03:53:09 INFO mapreduce.Job:  map 22% reduce 0%
15/04/13 03:53:11 INFO mapreduce.Job:  map 24% reduce 0%
15/04/13 03:53:12 INFO mapreduce.Job:  map 25% reduce 0%
15/04/13 03:53:13 INFO mapreduce.Job:  map 26% reduce 0%
15/04/13 03:53:14 INFO mapreduce.Job:  map 28% reduce 0%
15/04/13 03:53:15 INFO mapreduce.Job:  map 29% reduce 0%
15/04/13 03:53:17 INFO mapreduce.Job:  map 31% reduce 0%
15/04/13 03:53:18 INFO mapreduce.Job:  map 33% reduce 0%
15/04/13 03:53:20 INFO mapreduce.Job:  map 35% reduce 0%
15/04/13 03:53:21 INFO mapreduce.Job:  map 36% reduce 0%
15/04/13 03:53:23 INFO mapreduce.Job:  map 38% reduce 0%
15/04/13 03:53:24 INFO mapreduce.Job:  map 40% reduce 0%
15/04/13 03:53:26 INFO mapreduce.Job:  map 42% reduce 0%
15/04/13 03:53:27 INFO mapreduce.Job:  map 43% reduce 0%
15/04/13 03:53:29 INFO mapreduce.Job:  map 45% reduce 0%
15/04/13 03:53:30 INFO mapreduce.Job:  map 47% reduce 0%
15/04/13 03:53:32 INFO mapreduce.Job:  map 48% reduce 0%
15/04/13 03:53:33 INFO mapreduce.Job:  map 50% reduce 0%
15/04/13 03:53:35 INFO mapreduce.Job:  map 52% reduce 0%
15/04/13 03:53:36 INFO mapreduce.Job:  map 53% reduce 0%
15/04/13 03:53:38 INFO mapreduce.Job:  map 55% reduce 0%
15/04/13 03:53:39 INFO mapreduce.Job:  map 57% reduce 0%
15/04/13 03:53:41 INFO mapreduce.Job:  map 58% reduce 0%
15/04/13 03:53:42 INFO mapreduce.Job:  map 60% reduce 0%
15/04/13 03:53:44 INFO mapreduce.Job:  map 61% reduce 0%
15/04/13 03:53:45 INFO mapreduce.Job:  map 62% reduce 0%
15/04/13 03:53:48 INFO mapreduce.Job:  map 63% reduce 0%
15/04/13 03:53:52 INFO mapreduce.Job:  map 64% reduce 0%
15/04/13 03:53:53 INFO mapreduce.Job:  map 65% reduce 0%
15/04/13 03:53:54 INFO mapreduce.Job:  map 67% reduce 0%
15/04/13 03:53:55 INFO mapreduce.Job:  map 69% reduce 0%
15/04/13 03:53:56 INFO mapreduce.Job:  map 72% reduce 0%
15/04/13 03:53:57 INFO mapreduce.Job:  map 74% reduce 0%
15/04/13 03:53:58 INFO mapreduce.Job:  map 78% reduce 0%
15/04/13 03:53:59 INFO mapreduce.Job:  map 80% reduce 0%
15/04/13 03:54:00 INFO mapreduce.Job:  map 84% reduce 0%
15/04/13 03:54:01 INFO mapreduce.Job:  map 87% reduce 0%
15/04/13 03:54:02 INFO mapreduce.Job:  map 89% reduce 0%
15/04/13 03:54:03 INFO mapreduce.Job:  map 91% reduce 4%
15/04/13 03:54:04 INFO mapreduce.Job:  map 91% reduce 7%
15/04/13 03:54:05 INFO mapreduce.Job:  map 92% reduce 7%
15/04/13 03:54:09 INFO mapreduce.Job:  map 93% reduce 7%
15/04/13 03:54:10 INFO mapreduce.Job:  map 93% reduce 8%
15/04/13 03:54:14 INFO mapreduce.Job:  map 93% reduce 11%
15/04/13 03:54:17 INFO mapreduce.Job:  map 93% reduce 13%
15/04/13 03:54:20 INFO mapreduce.Job:  map 94% reduce 13%
15/04/13 03:54:23 INFO mapreduce.Job:  map 94% reduce 15%
15/04/13 03:54:26 INFO mapreduce.Job:  map 94% reduce 18%
15/04/13 03:54:28 INFO mapreduce.Job:  map 95% reduce 19%
15/04/13 03:54:29 INFO mapreduce.Job:  map 96% reduce 19%
15/04/13 03:54:31 INFO mapreduce.Job:  map 97% reduce 19%
15/04/13 03:54:32 INFO mapreduce.Job:  map 98% reduce 21%
15/04/13 03:54:34 INFO mapreduce.Job:  map 99% reduce 21%
15/04/13 03:54:35 INFO mapreduce.Job:  map 100% reduce 22%
15/04/13 03:54:37 INFO mapreduce.Job:  map 100% reduce 23%
15/04/13 03:54:38 INFO mapreduce.Job:  map 100% reduce 25%
15/04/13 03:54:41 INFO mapreduce.Job:  map 100% reduce 27%
15/04/13 03:54:46 INFO mapreduce.Job:  map 100% reduce 28%
15/04/13 03:54:47 INFO mapreduce.Job:  map 100% reduce 29%
15/04/13 03:54:50 INFO mapreduce.Job:  map 100% reduce 31%
15/04/13 03:54:57 INFO mapreduce.Job:  map 100% reduce 32%
15/04/13 03:54:58 INFO mapreduce.Job:  map 100% reduce 35%
15/04/13 03:54:59 INFO mapreduce.Job:  map 100% reduce 36%
15/04/13 03:55:00 INFO mapreduce.Job:  map 100% reduce 42%
15/04/13 03:55:02 INFO mapreduce.Job:  map 100% reduce 47%
15/04/13 03:55:03 INFO mapreduce.Job:  map 100% reduce 49%
15/04/13 03:55:04 INFO mapreduce.Job:  map 100% reduce 52%
15/04/13 03:55:06 INFO mapreduce.Job:  map 100% reduce 53%
15/04/13 03:55:07 INFO mapreduce.Job:  map 100% reduce 55%
15/04/13 03:55:09 INFO mapreduce.Job:  map 100% reduce 60%
15/04/13 03:55:11 INFO mapreduce.Job:  map 100% reduce 67%
15/04/13 03:56:18 INFO mapreduce.Job:  map 100% reduce 68%
15/04/13 03:57:10 INFO mapreduce.Job:  map 100% reduce 69%
15/04/13 03:57:56 INFO mapreduce.Job:  map 100% reduce 70%
15/04/13 03:58:44 INFO mapreduce.Job:  map 100% reduce 71%
15/04/13 03:59:15 INFO mapreduce.Job:  map 100% reduce 72%
15/04/13 04:00:04 INFO mapreduce.Job:  map 100% reduce 73%
15/04/13 04:01:01 INFO mapreduce.Job:  map 100% reduce 74%
15/04/13 04:01:49 INFO mapreduce.Job:  map 100% reduce 75%
15/04/13 04:02:39 INFO mapreduce.Job:  map 100% reduce 76%
15/04/13 04:03:38 INFO mapreduce.Job:  map 100% reduce 77%
15/04/13 04:04:36 INFO mapreduce.Job:  map 100% reduce 78%
15/04/13 04:05:24 INFO mapreduce.Job:  map 100% reduce 79%
15/04/13 04:06:37 INFO mapreduce.Job:  map 100% reduce 80%
15/04/13 04:08:11 INFO mapreduce.Job:  map 100% reduce 81%
15/04/13 04:09:27 INFO mapreduce.Job:  map 100% reduce 82%
15/04/13 04:10:15 INFO mapreduce.Job:  map 100% reduce 83%
15/04/13 04:11:29 INFO mapreduce.Job:  map 100% reduce 84%
15/04/13 04:12:34 INFO mapreduce.Job:  map 100% reduce 85%
15/04/13 04:13:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4725_r_000002_0, Status : FAILED
Container [pid=45570,containerID=container_1422482982071_4725_01_000193] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4725_01_000193 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 45668 45580 45570 45570 (R) 93566 16992 9973248000 2387706 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduceacca35fe3fec 
	|- 45679 45668 45570 45570 (cat) 0 23 103391232 159 cat 
	|- 45680 45668 45570 45570 (cat) 0 0 103391232 151 cat 
	|- 45580 45570 45570 45570 (java) 8527 1486 13412188160 699300 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4725/container_1422482982071_4725_01_000193/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4725/container_1422482982071_4725_01_000193 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 48103 attempt_1422482982071_4725_r_000002_0 193 
	|- 45570 3816 45570 45570 (bash) 0 0 108650496 297 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4725/container_1422482982071_4725_01_000193/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4725/container_1422482982071_4725_01_000193 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 48103 attempt_1422482982071_4725_r_000002_0 193 1>/var/log/hadoop-yarn/containers/application_1422482982071_4725/container_1422482982071_4725_01_000193/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4725/container_1422482982071_4725_01_000193/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 04:13:36 INFO mapreduce.Job:  map 100% reduce 72%
15/04/13 04:13:48 INFO mapreduce.Job:  map 100% reduce 74%
15/04/13 04:14:04 INFO mapreduce.Job:  map 100% reduce 75%
15/04/13 04:14:13 INFO mapreduce.Job:  map 100% reduce 76%
15/04/13 04:14:17 INFO mapreduce.Job:  map 100% reduce 77%
15/04/13 04:14:26 INFO mapreduce.Job:  map 100% reduce 78%
15/04/13 04:14:43 INFO mapreduce.Job:  map 100% reduce 79%
15/04/13 04:14:48 INFO mapreduce.Job:  map 100% reduce 80%
15/04/13 04:14:57 INFO mapreduce.Job:  map 100% reduce 86%
15/04/13 04:15:12 INFO mapreduce.Job:  map 100% reduce 87%
15/04/13 04:16:42 INFO mapreduce.Job:  map 100% reduce 88%
15/04/13 04:18:32 INFO mapreduce.Job:  map 100% reduce 89%
15/04/13 04:20:53 INFO mapreduce.Job:  map 100% reduce 90%
15/04/13 04:23:46 INFO mapreduce.Job:  map 100% reduce 91%
15/04/13 04:26:48 INFO mapreduce.Job:  map 100% reduce 92%
15/04/13 04:31:20 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 04:35:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_4725_r_000002_1, Status : FAILED
Container [pid=36639,containerID=container_1422482982071_4725_01_000197] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.8 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4725_01_000197 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 36694 36649 36639 36639 (R) 98380 21829 10108485632 2444801 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduceacca35fe3fec 
	|- 36649 36639 36639 36639 (java) 9041 1876 13313347584 645789 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4725/container_1422482982071_4725_01_000197/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4725/container_1422482982071_4725_01_000197 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 48103 attempt_1422482982071_4725_r_000002_1 197 
	|- 36639 11693 36639 36639 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4725/container_1422482982071_4725_01_000197/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4725/container_1422482982071_4725_01_000197 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 48103 attempt_1422482982071_4725_r_000002_1 197 1>/var/log/hadoop-yarn/containers/application_1422482982071_4725/container_1422482982071_4725_01_000197/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4725/container_1422482982071_4725_01_000197/stderr  
	|- 36705 36694 36639 36639 (cat) 0 23 4231168 143 cat 
	|- 36706 36694 36639 36639 (cat) 0 0 4231168 134 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 04:35:01 INFO mapreduce.Job:  map 100% reduce 80%
15/04/13 04:35:14 INFO mapreduce.Job:  map 100% reduce 81%
15/04/13 04:35:23 INFO mapreduce.Job:  map 100% reduce 82%
15/04/13 04:35:33 INFO mapreduce.Job:  map 100% reduce 83%
15/04/13 04:35:42 INFO mapreduce.Job:  map 100% reduce 84%
15/04/13 04:35:54 INFO mapreduce.Job:  map 100% reduce 85%
15/04/13 04:36:12 INFO mapreduce.Job:  map 100% reduce 86%
15/04/13 04:36:22 INFO mapreduce.Job:  map 100% reduce 90%
15/04/13 04:36:25 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 04:57:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_4725_r_000002_2, Status : FAILED
Container [pid=42609,containerID=container_1422482982071_4725_01_000198] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 21.9 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4725_01_000198 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 42664 42619 42609 42609 (R) 105636 20192 10205913088 2468617 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduceacca35fe3fec 
	|- 42676 42664 42609 42609 (cat) 0 24 4231168 142 cat 
	|- 42609 10523 42609 42609 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4725/container_1422482982071_4725_01_000198/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4725/container_1422482982071_4725_01_000198 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 48103 attempt_1422482982071_4725_r_000002_2 198 1>/var/log/hadoop-yarn/containers/application_1422482982071_4725/container_1422482982071_4725_01_000198/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4725/container_1422482982071_4725_01_000198/stderr  
	|- 42677 42664 42609 42609 (cat) 0 0 4231168 134 cat 
	|- 42619 42609 42609 42609 (java) 9223 1904 13313245184 655702 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4725/container_1422482982071_4725_01_000198/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4725/container_1422482982071_4725_01_000198 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 48103 attempt_1422482982071_4725_r_000002_2 198 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 04:57:26 INFO mapreduce.Job:  map 100% reduce 80%
15/04/13 04:57:38 INFO mapreduce.Job:  map 100% reduce 81%
15/04/13 04:57:47 INFO mapreduce.Job:  map 100% reduce 82%
15/04/13 04:57:56 INFO mapreduce.Job:  map 100% reduce 83%
15/04/13 04:58:05 INFO mapreduce.Job:  map 100% reduce 84%
15/04/13 04:58:16 INFO mapreduce.Job:  map 100% reduce 85%
15/04/13 04:58:28 INFO mapreduce.Job:  map 100% reduce 86%
15/04/13 04:58:37 INFO mapreduce.Job:  map 100% reduce 87%
15/04/13 04:58:46 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 05:17:24 INFO mapreduce.Job:  map 100% reduce 100%
15/04/13 05:17:24 INFO mapreduce.Job: Job job_1422482982071_4725 failed with state FAILED due to: Task failed task_1422482982071_4725_r_000002
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/13 05:17:24 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=22766743706
		FILE: Number of bytes written=52984106681
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=1743478986
		HDFS: Number of read operations=414
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Launched map tasks=135
		Launched reduce tasks=8
		Data-local map tasks=61
		Rack-local map tasks=74
		Total time spent by all maps in occupied slots (ms)=21574002
		Total time spent by all reduces in occupied slots (ms)=29766220
		Total time spent by all map tasks (ms)=10787001
		Total time spent by all reduce tasks (ms)=14883110
		Total vcore-seconds taken by all map tasks=10787001
		Total vcore-seconds taken by all reduce tasks=14883110
		Total megabyte-seconds taken by all map tasks=87331560096
		Total megabyte-seconds taken by all reduce tasks=178597320000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141584
		Map output bytes=29491538826
		Map output materialized bytes=30204049043
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=29130492
		Reduce shuffle bytes=22766746772
		Reduce input records=275297078
		Reduce output records=29282517
		Spilled Records=619438662
		Shuffled Maps =536
		Failed Shuffles=0
		Merged Map outputs=536
		GC time elapsed (ms)=109038
		CPU time spent (ms)=21137780
		Physical memory (bytes) snapshot=271026323456
		Virtual memory (bytes) snapshot=1283797573632
		Total committed heap usage (bytes)=380084318208
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=1743478986
	rmr
		reduce calls=29130492
15/04/13 05:17:24 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/13 05:17:30 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/fileacca6a5833cd

real	85m3.346s
user	0m39.749s
sys	0m4.383s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-5-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=5"


15/04/13 05:17:36 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/13 05:17:36 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob5434640990340939742.jar tmpDir=null
15/04/13 05:17:36 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/13 05:17:36 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/13 05:17:37 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/13 05:17:37 INFO mapreduce.JobSubmitter: number of splits:134
15/04/13 05:17:38 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4726
15/04/13 05:17:38 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4726
15/04/13 05:17:38 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4726/
15/04/13 05:17:38 INFO mapreduce.Job: Running job: job_1422482982071_4726
15/04/13 05:17:44 INFO mapreduce.Job: Job job_1422482982071_4726 running in uber mode : false
15/04/13 05:17:44 INFO mapreduce.Job:  map 0% reduce 0%
15/04/13 05:17:56 INFO mapreduce.Job:  map 3% reduce 0%
15/04/13 05:17:57 INFO mapreduce.Job:  map 4% reduce 0%
15/04/13 05:17:59 INFO mapreduce.Job:  map 7% reduce 0%
15/04/13 05:18:00 INFO mapreduce.Job:  map 8% reduce 0%
15/04/13 05:18:02 INFO mapreduce.Job:  map 10% reduce 0%
15/04/13 05:18:03 INFO mapreduce.Job:  map 11% reduce 0%
15/04/13 05:18:05 INFO mapreduce.Job:  map 13% reduce 0%
15/04/13 05:18:06 INFO mapreduce.Job:  map 14% reduce 0%
15/04/13 05:18:08 INFO mapreduce.Job:  map 17% reduce 0%
15/04/13 05:18:09 INFO mapreduce.Job:  map 18% reduce 0%
15/04/13 05:18:11 INFO mapreduce.Job:  map 20% reduce 0%
15/04/13 05:18:12 INFO mapreduce.Job:  map 22% reduce 0%
15/04/13 05:18:14 INFO mapreduce.Job:  map 24% reduce 0%
15/04/13 05:18:15 INFO mapreduce.Job:  map 25% reduce 0%
15/04/13 05:18:17 INFO mapreduce.Job:  map 27% reduce 0%
15/04/13 05:18:18 INFO mapreduce.Job:  map 29% reduce 0%
15/04/13 05:18:20 INFO mapreduce.Job:  map 31% reduce 0%
15/04/13 05:18:21 INFO mapreduce.Job:  map 32% reduce 0%
15/04/13 05:18:23 INFO mapreduce.Job:  map 34% reduce 0%
15/04/13 05:18:24 INFO mapreduce.Job:  map 36% reduce 0%
15/04/13 05:18:26 INFO mapreduce.Job:  map 38% reduce 0%
15/04/13 05:18:27 INFO mapreduce.Job:  map 39% reduce 0%
15/04/13 05:18:28 INFO mapreduce.Job:  map 40% reduce 0%
15/04/13 05:18:29 INFO mapreduce.Job:  map 41% reduce 0%
15/04/13 05:18:30 INFO mapreduce.Job:  map 43% reduce 0%
15/04/13 05:18:32 INFO mapreduce.Job:  map 45% reduce 0%
15/04/13 05:18:33 INFO mapreduce.Job:  map 47% reduce 0%
15/04/13 05:18:35 INFO mapreduce.Job:  map 48% reduce 0%
15/04/13 05:18:36 INFO mapreduce.Job:  map 50% reduce 0%
15/04/13 05:18:38 INFO mapreduce.Job:  map 52% reduce 0%
15/04/13 05:18:39 INFO mapreduce.Job:  map 54% reduce 0%
15/04/13 05:18:41 INFO mapreduce.Job:  map 55% reduce 0%
15/04/13 05:18:42 INFO mapreduce.Job:  map 57% reduce 0%
15/04/13 05:18:44 INFO mapreduce.Job:  map 58% reduce 0%
15/04/13 05:18:45 INFO mapreduce.Job:  map 60% reduce 0%
15/04/13 05:18:47 INFO mapreduce.Job:  map 61% reduce 0%
15/04/13 05:18:48 INFO mapreduce.Job:  map 62% reduce 0%
15/04/13 05:18:51 INFO mapreduce.Job:  map 63% reduce 0%
15/04/13 05:18:54 INFO mapreduce.Job:  map 64% reduce 0%
15/04/13 05:18:55 INFO mapreduce.Job:  map 65% reduce 0%
15/04/13 05:18:57 INFO mapreduce.Job:  map 67% reduce 0%
15/04/13 05:18:58 INFO mapreduce.Job:  map 69% reduce 0%
15/04/13 05:18:59 INFO mapreduce.Job:  map 73% reduce 0%
15/04/13 05:19:00 INFO mapreduce.Job:  map 75% reduce 0%
15/04/13 05:19:01 INFO mapreduce.Job:  map 77% reduce 0%
15/04/13 05:19:02 INFO mapreduce.Job:  map 81% reduce 0%
15/04/13 05:19:03 INFO mapreduce.Job:  map 84% reduce 0%
15/04/13 05:19:04 INFO mapreduce.Job:  map 87% reduce 0%
15/04/13 05:19:05 INFO mapreduce.Job:  map 89% reduce 0%
15/04/13 05:19:06 INFO mapreduce.Job:  map 90% reduce 0%
15/04/13 05:19:07 INFO mapreduce.Job:  map 91% reduce 6%
15/04/13 05:19:08 INFO mapreduce.Job:  map 92% reduce 7%
15/04/13 05:19:09 INFO mapreduce.Job:  map 93% reduce 7%
15/04/13 05:19:16 INFO mapreduce.Job:  map 94% reduce 7%
15/04/13 05:19:17 INFO mapreduce.Job:  map 94% reduce 9%
15/04/13 05:19:19 INFO mapreduce.Job:  map 94% reduce 10%
15/04/13 05:19:22 INFO mapreduce.Job:  map 94% reduce 12%
15/04/13 05:19:25 INFO mapreduce.Job:  map 94% reduce 13%
15/04/13 05:19:28 INFO mapreduce.Job:  map 95% reduce 14%
15/04/13 05:19:29 INFO mapreduce.Job:  map 96% reduce 15%
15/04/13 05:19:31 INFO mapreduce.Job:  map 98% reduce 16%
15/04/13 05:19:32 INFO mapreduce.Job:  map 98% reduce 18%
15/04/13 05:19:33 INFO mapreduce.Job:  map 99% reduce 18%
15/04/13 05:19:34 INFO mapreduce.Job:  map 100% reduce 19%
15/04/13 05:19:37 INFO mapreduce.Job:  map 100% reduce 20%
15/04/13 05:19:41 INFO mapreduce.Job:  map 100% reduce 21%
15/04/13 05:19:42 INFO mapreduce.Job:  map 100% reduce 22%
15/04/13 05:19:44 INFO mapreduce.Job:  map 100% reduce 23%
15/04/13 05:19:47 INFO mapreduce.Job:  map 100% reduce 25%
15/04/13 05:19:51 INFO mapreduce.Job:  map 100% reduce 26%
15/04/13 05:19:53 INFO mapreduce.Job:  map 100% reduce 27%
15/04/13 05:19:56 INFO mapreduce.Job:  map 100% reduce 30%
15/04/13 05:19:59 INFO mapreduce.Job:  map 100% reduce 31%
15/04/13 05:20:09 INFO mapreduce.Job:  map 100% reduce 33%
15/04/13 05:20:10 INFO mapreduce.Job:  map 100% reduce 36%
15/04/13 05:20:13 INFO mapreduce.Job:  map 100% reduce 40%
15/04/13 05:20:18 INFO mapreduce.Job:  map 100% reduce 47%
15/04/13 05:20:19 INFO mapreduce.Job:  map 100% reduce 53%
15/04/13 05:20:21 INFO mapreduce.Job:  map 100% reduce 64%
15/04/13 05:20:24 INFO mapreduce.Job:  map 100% reduce 67%
15/04/13 05:21:34 INFO mapreduce.Job:  map 100% reduce 68%
15/04/13 05:22:20 INFO mapreduce.Job:  map 100% reduce 69%
15/04/13 05:23:06 INFO mapreduce.Job:  map 100% reduce 70%
15/04/13 05:23:57 INFO mapreduce.Job:  map 100% reduce 71%
15/04/13 05:24:27 INFO mapreduce.Job:  map 100% reduce 72%
15/04/13 05:25:19 INFO mapreduce.Job:  map 100% reduce 73%
15/04/13 05:26:14 INFO mapreduce.Job:  map 100% reduce 74%
15/04/13 05:27:05 INFO mapreduce.Job:  map 100% reduce 75%
15/04/13 05:27:44 INFO mapreduce.Job:  map 100% reduce 76%
15/04/13 05:28:45 INFO mapreduce.Job:  map 100% reduce 77%
15/04/13 05:29:46 INFO mapreduce.Job:  map 100% reduce 78%
15/04/13 05:30:28 INFO mapreduce.Job:  map 100% reduce 79%
15/04/13 05:31:42 INFO mapreduce.Job:  map 100% reduce 80%
15/04/13 05:33:03 INFO mapreduce.Job:  map 100% reduce 81%
15/04/13 05:34:18 INFO mapreduce.Job:  map 100% reduce 82%
15/04/13 05:35:16 INFO mapreduce.Job:  map 100% reduce 83%
15/04/13 05:36:30 INFO mapreduce.Job:  map 100% reduce 84%
15/04/13 05:37:32 INFO mapreduce.Job:  map 100% reduce 85%
15/04/13 05:38:48 INFO mapreduce.Job:  map 100% reduce 86%
15/04/13 05:40:02 INFO mapreduce.Job:  map 100% reduce 87%
15/04/13 05:41:29 INFO mapreduce.Job:  map 100% reduce 88%
15/04/13 05:41:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_4726_r_000002_0, Status : FAILED
Container [pid=21035,containerID=container_1422482982071_4726_01_000191] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4726_01_000191 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 21145 21134 21035 21035 (cat) 1 26 4231168 142 cat 
	|- 21134 21045 21035 21035 (R) 106724 20359 10487963648 2443510 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduceb0d65cbd7aab 
	|- 21146 21134 21035 21035 (cat) 0 0 4231168 134 cat 
	|- 21045 21035 21035 21035 (java) 8813 1790 13312507904 630316 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4726/container_1422482982071_4726_01_000191/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4726/container_1422482982071_4726_01_000191 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.181 39327 attempt_1422482982071_4726_r_000002_0 191 
	|- 21035 8824 21035 21035 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4726/container_1422482982071_4726_01_000191/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4726/container_1422482982071_4726_01_000191 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.181 39327 attempt_1422482982071_4726_r_000002_0 191 1>/var/log/hadoop-yarn/containers/application_1422482982071_4726/container_1422482982071_4726_01_000191/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4726/container_1422482982071_4726_01_000191/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 05:41:36 INFO mapreduce.Job:  map 100% reduce 74%
15/04/13 05:41:48 INFO mapreduce.Job:  map 100% reduce 75%
15/04/13 05:41:49 INFO mapreduce.Job:  map 100% reduce 76%
15/04/13 05:41:57 INFO mapreduce.Job:  map 100% reduce 77%
15/04/13 05:42:07 INFO mapreduce.Job:  map 100% reduce 78%
15/04/13 05:42:16 INFO mapreduce.Job:  map 100% reduce 79%
15/04/13 05:42:25 INFO mapreduce.Job:  map 100% reduce 80%
15/04/13 05:42:37 INFO mapreduce.Job:  map 100% reduce 81%
15/04/13 05:43:05 INFO mapreduce.Job:  map 100% reduce 82%
15/04/13 05:43:20 INFO mapreduce.Job:  map 100% reduce 88%
15/04/13 05:43:35 INFO mapreduce.Job:  map 100% reduce 89%
15/04/13 05:45:50 INFO mapreduce.Job:  map 100% reduce 90%
15/04/13 05:48:42 INFO mapreduce.Job:  map 100% reduce 91%
15/04/13 05:51:46 INFO mapreduce.Job:  map 100% reduce 92%
15/04/13 05:55:48 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 06:05:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_4726_r_000002_1, Status : FAILED
Container [pid=48139,containerID=container_1422482982071_4726_01_000194] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.9 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4726_01_000194 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 48212 48200 48139 48139 (cat) 0 0 4231168 134 cat 
	|- 48211 48200 48139 48139 (cat) 0 28 4231168 142 cat 
	|- 48200 48149 48139 48139 (R) 110901 20066 10161426432 2457756 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduceb0d65cbd7aab 
	|- 48149 48139 48139 48139 (java) 9194 1992 13312389120 646115 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4726/container_1422482982071_4726_01_000194/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4726/container_1422482982071_4726_01_000194 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.181 39327 attempt_1422482982071_4726_r_000002_1 194 
	|- 48139 9754 48139 48139 (bash) 0 1 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4726/container_1422482982071_4726_01_000194/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4726/container_1422482982071_4726_01_000194 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.181 39327 attempt_1422482982071_4726_r_000002_1 194 1>/var/log/hadoop-yarn/containers/application_1422482982071_4726/container_1422482982071_4726_01_000194/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4726/container_1422482982071_4726_01_000194/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 06:05:12 INFO mapreduce.Job:  map 100% reduce 80%
15/04/13 06:05:23 INFO mapreduce.Job:  map 100% reduce 81%
15/04/13 06:05:33 INFO mapreduce.Job:  map 100% reduce 82%
15/04/13 06:05:42 INFO mapreduce.Job:  map 100% reduce 83%
15/04/13 06:05:51 INFO mapreduce.Job:  map 100% reduce 84%
15/04/13 06:06:00 INFO mapreduce.Job:  map 100% reduce 85%
15/04/13 06:06:13 INFO mapreduce.Job:  map 100% reduce 86%
15/04/13 06:06:22 INFO mapreduce.Job:  map 100% reduce 87%
15/04/13 06:06:31 INFO mapreduce.Job:  map 100% reduce 88%
15/04/13 06:06:34 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 06:26:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_4726_r_000002_2, Status : FAILED
Container [pid=46272,containerID=container_1422482982071_4726_01_000195] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4726_01_000195 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 46339 46328 46272 46272 (cat) 0 24 103391232 159 cat 
	|- 46328 46282 46272 46272 (R) 102240 18609 10082230272 2414281 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduceb0d65cbd7aab 
	|- 46282 46272 46272 46272 (java) 9042 1860 13412204544 660030 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4726/container_1422482982071_4726_01_000195/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4726/container_1422482982071_4726_01_000195 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.181 39327 attempt_1422482982071_4726_r_000002_2 195 
	|- 46272 3816 46272 46272 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4726/container_1422482982071_4726_01_000195/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4726/container_1422482982071_4726_01_000195 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.181 39327 attempt_1422482982071_4726_r_000002_2 195 1>/var/log/hadoop-yarn/containers/application_1422482982071_4726/container_1422482982071_4726_01_000195/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4726/container_1422482982071_4726_01_000195/stderr  
	|- 46340 46328 46272 46272 (cat) 0 0 103391232 152 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 06:26:45 INFO mapreduce.Job:  map 100% reduce 80%
15/04/13 06:26:57 INFO mapreduce.Job:  map 100% reduce 81%
15/04/13 06:27:06 INFO mapreduce.Job:  map 100% reduce 82%
15/04/13 06:27:15 INFO mapreduce.Job:  map 100% reduce 83%
15/04/13 06:27:24 INFO mapreduce.Job:  map 100% reduce 84%
15/04/13 06:27:37 INFO mapreduce.Job:  map 100% reduce 85%
15/04/13 06:27:46 INFO mapreduce.Job:  map 100% reduce 86%
15/04/13 06:27:55 INFO mapreduce.Job:  map 100% reduce 87%
15/04/13 06:28:04 INFO mapreduce.Job:  map 100% reduce 89%
15/04/13 06:28:07 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 06:48:49 INFO mapreduce.Job:  map 100% reduce 100%
15/04/13 06:48:49 INFO mapreduce.Job: Job job_1422482982071_4726 failed with state FAILED due to: Task failed task_1422482982071_4726_r_000002
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/13 06:48:49 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=22766845489
		FILE: Number of bytes written=52984219691
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=1743484194
		HDFS: Number of read operations=414
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Launched map tasks=135
		Launched reduce tasks=8
		Data-local map tasks=60
		Rack-local map tasks=75
		Total time spent by all maps in occupied slots (ms)=21398048
		Total time spent by all reduces in occupied slots (ms)=30518762
		Total time spent by all map tasks (ms)=10699024
		Total time spent by all reduce tasks (ms)=15259381
		Total vcore-seconds taken by all map tasks=10699024
		Total vcore-seconds taken by all reduce tasks=15259381
		Total megabyte-seconds taken by all map tasks=86619298304
		Total megabyte-seconds taken by all reduce tasks=183112572000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141673
		Map output bytes=29491549875
		Map output materialized bytes=30204060270
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=29130617
		Reduce shuffle bytes=22766848555
		Reduce input records=275297810
		Reduce output records=29282633
		Spilled Records=619439483
		Shuffled Maps =536
		Failed Shuffles=0
		Merged Map outputs=536
		GC time elapsed (ms)=107672
		CPU time spent (ms)=21027900
		Physical memory (bytes) snapshot=270817902592
		Virtual memory (bytes) snapshot=1283598864384
		Total committed heap usage (bytes)=379836092416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=1743484194
	rmr
		reduce calls=29130617
15/04/13 06:48:49 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/13 06:48:56 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/fileb0d64955bd06

real	91m25.199s
user	0m40.936s
sys	0m4.781s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-50-5-false-googlebooks-eng-all-5gram-20120701-st"

$hadoop$D
[1] "mapreduce.job.maps=50"

$hadoop$D
[1] "mapred.reduce.tasks=5"


15/04/13 06:49:02 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/13 06:49:02 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7647529230591697814.jar tmpDir=null
15/04/13 06:49:03 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/13 06:49:03 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/13 06:49:04 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/13 06:49:04 INFO mapreduce.JobSubmitter: number of splits:134
15/04/13 06:49:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_4727
15/04/13 06:49:05 INFO impl.YarnClientImpl: Submitted application application_1422482982071_4727
15/04/13 06:49:05 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_4727/
15/04/13 06:49:05 INFO mapreduce.Job: Running job: job_1422482982071_4727
15/04/13 06:49:11 INFO mapreduce.Job: Job job_1422482982071_4727 running in uber mode : false
15/04/13 06:49:11 INFO mapreduce.Job:  map 0% reduce 0%
15/04/13 06:49:23 INFO mapreduce.Job:  map 2% reduce 0%
15/04/13 06:49:24 INFO mapreduce.Job:  map 4% reduce 0%
15/04/13 06:49:26 INFO mapreduce.Job:  map 6% reduce 0%
15/04/13 06:49:27 INFO mapreduce.Job:  map 7% reduce 0%
15/04/13 06:49:28 INFO mapreduce.Job:  map 8% reduce 0%
15/04/13 06:49:29 INFO mapreduce.Job:  map 9% reduce 0%
15/04/13 06:49:30 INFO mapreduce.Job:  map 11% reduce 0%
15/04/13 06:49:32 INFO mapreduce.Job:  map 12% reduce 0%
15/04/13 06:49:33 INFO mapreduce.Job:  map 14% reduce 0%
15/04/13 06:49:35 INFO mapreduce.Job:  map 16% reduce 0%
15/04/13 06:49:36 INFO mapreduce.Job:  map 18% reduce 0%
15/04/13 06:49:38 INFO mapreduce.Job:  map 19% reduce 0%
15/04/13 06:49:39 INFO mapreduce.Job:  map 21% reduce 0%
15/04/13 06:49:41 INFO mapreduce.Job:  map 23% reduce 0%
15/04/13 06:49:42 INFO mapreduce.Job:  map 25% reduce 0%
15/04/13 06:49:44 INFO mapreduce.Job:  map 26% reduce 0%
15/04/13 06:49:45 INFO mapreduce.Job:  map 28% reduce 0%
15/04/13 06:49:46 INFO mapreduce.Job:  map 29% reduce 0%
15/04/13 06:49:47 INFO mapreduce.Job:  map 30% reduce 0%
15/04/13 06:49:48 INFO mapreduce.Job:  map 32% reduce 0%
15/04/13 06:49:50 INFO mapreduce.Job:  map 33% reduce 0%
15/04/13 06:49:51 INFO mapreduce.Job:  map 36% reduce 0%
15/04/13 06:49:53 INFO mapreduce.Job:  map 37% reduce 0%
15/04/13 06:49:54 INFO mapreduce.Job:  map 39% reduce 0%
15/04/13 06:49:55 INFO mapreduce.Job:  map 40% reduce 0%
15/04/13 06:49:57 INFO mapreduce.Job:  map 43% reduce 0%
15/04/13 06:49:59 INFO mapreduce.Job:  map 44% reduce 0%
15/04/13 06:50:00 INFO mapreduce.Job:  map 46% reduce 0%
15/04/13 06:50:01 INFO mapreduce.Job:  map 47% reduce 0%
15/04/13 06:50:03 INFO mapreduce.Job:  map 50% reduce 0%
15/04/13 06:50:05 INFO mapreduce.Job:  map 51% reduce 0%
15/04/13 06:50:06 INFO mapreduce.Job:  map 53% reduce 0%
15/04/13 06:50:07 INFO mapreduce.Job:  map 54% reduce 0%
15/04/13 06:50:09 INFO mapreduce.Job:  map 57% reduce 0%
15/04/13 06:50:11 INFO mapreduce.Job:  map 58% reduce 0%
15/04/13 06:50:12 INFO mapreduce.Job:  map 60% reduce 0%
15/04/13 06:50:15 INFO mapreduce.Job:  map 62% reduce 0%
15/04/13 06:50:18 INFO mapreduce.Job:  map 63% reduce 0%
15/04/13 06:50:21 INFO mapreduce.Job:  map 64% reduce 0%
15/04/13 06:50:23 INFO mapreduce.Job:  map 65% reduce 0%
15/04/13 06:50:24 INFO mapreduce.Job:  map 66% reduce 0%
15/04/13 06:50:25 INFO mapreduce.Job:  map 67% reduce 0%
15/04/13 06:50:26 INFO mapreduce.Job:  map 70% reduce 0%
15/04/13 06:50:27 INFO mapreduce.Job:  map 74% reduce 0%
15/04/13 06:50:28 INFO mapreduce.Job:  map 77% reduce 0%
15/04/13 06:50:29 INFO mapreduce.Job:  map 80% reduce 0%
15/04/13 06:50:30 INFO mapreduce.Job:  map 83% reduce 0%
15/04/13 06:50:31 INFO mapreduce.Job:  map 89% reduce 0%
15/04/13 06:50:32 INFO mapreduce.Job:  map 90% reduce 0%
15/04/13 06:50:33 INFO mapreduce.Job:  map 91% reduce 0%
15/04/13 06:50:34 INFO mapreduce.Job:  map 92% reduce 3%
15/04/13 06:50:35 INFO mapreduce.Job:  map 92% reduce 7%
15/04/13 06:50:36 INFO mapreduce.Job:  map 93% reduce 7%
15/04/13 06:50:41 INFO mapreduce.Job:  map 93% reduce 8%
15/04/13 06:50:42 INFO mapreduce.Job:  map 94% reduce 8%
15/04/13 06:50:44 INFO mapreduce.Job:  map 94% reduce 9%
15/04/13 06:50:47 INFO mapreduce.Job:  map 94% reduce 10%
15/04/13 06:50:50 INFO mapreduce.Job:  map 94% reduce 11%
15/04/13 06:50:53 INFO mapreduce.Job:  map 94% reduce 13%
15/04/13 06:50:54 INFO mapreduce.Job:  map 94% reduce 14%
15/04/13 06:50:55 INFO mapreduce.Job:  map 95% reduce 14%
15/04/13 06:50:56 INFO mapreduce.Job:  map 95% reduce 16%
15/04/13 06:50:57 INFO mapreduce.Job:  map 96% reduce 16%
15/04/13 06:50:59 INFO mapreduce.Job:  map 97% reduce 16%
15/04/13 06:51:00 INFO mapreduce.Job:  map 99% reduce 17%
15/04/13 06:51:02 INFO mapreduce.Job:  map 100% reduce 19%
15/04/13 06:51:03 INFO mapreduce.Job:  map 100% reduce 20%
15/04/13 06:51:08 INFO mapreduce.Job:  map 100% reduce 22%
15/04/13 06:51:11 INFO mapreduce.Job:  map 100% reduce 24%
15/04/13 06:51:14 INFO mapreduce.Job:  map 100% reduce 25%
15/04/13 06:51:15 INFO mapreduce.Job:  map 100% reduce 26%
15/04/13 06:51:17 INFO mapreduce.Job:  map 100% reduce 27%
15/04/13 06:51:20 INFO mapreduce.Job:  map 100% reduce 28%
15/04/13 06:51:24 INFO mapreduce.Job:  map 100% reduce 30%
15/04/13 06:51:27 INFO mapreduce.Job:  map 100% reduce 31%
15/04/13 06:51:29 INFO mapreduce.Job:  map 100% reduce 38%
15/04/13 06:51:32 INFO mapreduce.Job:  map 100% reduce 39%
15/04/13 06:51:36 INFO mapreduce.Job:  map 100% reduce 46%
15/04/13 06:51:38 INFO mapreduce.Job:  map 100% reduce 47%
15/04/13 06:51:42 INFO mapreduce.Job:  map 100% reduce 50%
15/04/13 06:51:45 INFO mapreduce.Job:  map 100% reduce 53%
15/04/13 06:51:46 INFO mapreduce.Job:  map 100% reduce 58%
15/04/13 06:51:47 INFO mapreduce.Job:  map 100% reduce 63%
15/04/13 06:51:48 INFO mapreduce.Job:  map 100% reduce 64%
15/04/13 06:51:49 INFO mapreduce.Job:  map 100% reduce 66%
15/04/13 06:51:50 INFO mapreduce.Job:  map 100% reduce 67%
15/04/13 06:52:43 INFO mapreduce.Job:  map 100% reduce 68%
15/04/13 06:53:49 INFO mapreduce.Job:  map 100% reduce 69%
15/04/13 06:54:32 INFO mapreduce.Job:  map 100% reduce 70%
15/04/13 06:55:17 INFO mapreduce.Job:  map 100% reduce 71%
15/04/13 06:55:56 INFO mapreduce.Job:  map 100% reduce 72%
15/04/13 06:56:42 INFO mapreduce.Job:  map 100% reduce 73%
15/04/13 06:57:43 INFO mapreduce.Job:  map 100% reduce 74%
15/04/13 06:58:32 INFO mapreduce.Job:  map 100% reduce 75%
15/04/13 06:59:23 INFO mapreduce.Job:  map 100% reduce 76%
15/04/13 07:00:20 INFO mapreduce.Job:  map 100% reduce 77%
15/04/13 07:01:13 INFO mapreduce.Job:  map 100% reduce 78%
15/04/13 07:02:06 INFO mapreduce.Job:  map 100% reduce 79%
15/04/13 07:03:14 INFO mapreduce.Job:  map 100% reduce 80%
15/04/13 07:04:56 INFO mapreduce.Job:  map 100% reduce 81%
15/04/13 07:06:00 INFO mapreduce.Job:  map 100% reduce 82%
15/04/13 07:06:46 INFO mapreduce.Job:  map 100% reduce 83%
15/04/13 07:08:01 INFO mapreduce.Job:  map 100% reduce 84%
15/04/13 07:09:08 INFO mapreduce.Job:  map 100% reduce 85%
15/04/13 07:10:10 INFO mapreduce.Job:  map 100% reduce 86%
15/04/13 07:11:34 INFO mapreduce.Job:  map 100% reduce 87%
15/04/13 07:13:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_4727_r_000002_0, Status : FAILED
Container [pid=47287,containerID=container_1422482982071_4727_01_000189] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 21.9 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4727_01_000189 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 47297 47287 47287 47287 (java) 9288 1778 13312966656 647717 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4727/container_1422482982071_4727_01_000189/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4727/container_1422482982071_4727_01_000189 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.189 52760 attempt_1422482982071_4727_r_000002_0 189 
	|- 47287 9550 47287 47287 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4727/container_1422482982071_4727_01_000189/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4727/container_1422482982071_4727_01_000189 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.189 52760 attempt_1422482982071_4727_r_000002_0 189 1>/var/log/hadoop-yarn/containers/application_1422482982071_4727/container_1422482982071_4727_01_000189/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4727/container_1422482982071_4727_01_000189/stderr  
	|- 47382 47297 47287 47287 (R) 106187 20962 10227798016 2473961 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduceb3f8173ecacb 
	|- 47394 47382 47287 47287 (cat) 0 0 4231168 134 cat 
	|- 47393 47382 47287 47287 (cat) 0 25 4231168 143 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 07:13:02 INFO mapreduce.Job:  map 100% reduce 74%
15/04/13 07:13:13 INFO mapreduce.Job:  map 100% reduce 76%
15/04/13 07:13:23 INFO mapreduce.Job:  map 100% reduce 77%
15/04/13 07:13:32 INFO mapreduce.Job:  map 100% reduce 78%
15/04/13 07:13:41 INFO mapreduce.Job:  map 100% reduce 79%
15/04/13 07:13:53 INFO mapreduce.Job:  map 100% reduce 80%
15/04/13 07:14:02 INFO mapreduce.Job:  map 100% reduce 81%
15/04/13 07:14:21 INFO mapreduce.Job:  map 100% reduce 84%
15/04/13 07:14:24 INFO mapreduce.Job:  map 100% reduce 88%
15/04/13 07:15:10 INFO mapreduce.Job:  map 100% reduce 89%
15/04/13 07:16:57 INFO mapreduce.Job:  map 100% reduce 90%
15/04/13 07:19:33 INFO mapreduce.Job:  map 100% reduce 91%
15/04/13 07:22:35 INFO mapreduce.Job:  map 100% reduce 92%
15/04/13 07:26:58 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 07:39:02 INFO mapreduce.Job:  map 100% reduce 100%
15/04/13 07:39:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_4727_r_000002_1, Status : FAILED
Container [pid=28282,containerID=container_1422482982071_4727_01_000193] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 21.7 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4727_01_000193 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 28282 9608 28282 28282 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4727/container_1422482982071_4727_01_000193/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4727/container_1422482982071_4727_01_000193 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.189 52760 attempt_1422482982071_4727_r_000002_1 193 1>/var/log/hadoop-yarn/containers/application_1422482982071_4727/container_1422482982071_4727_01_000193/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4727/container_1422482982071_4727_01_000193/stderr  
	|- 28292 28282 28282 28282 (java) 9212 1900 13313081344 659509 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4727/container_1422482982071_4727_01_000193/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4727/container_1422482982071_4727_01_000193 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.189 52760 attempt_1422482982071_4727_r_000002_1 193 
	|- 28340 28292 28282 28282 (R) 114091 33099 9978671104 2413108 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduceb3f8173ecacb 
	|- 28354 28340 28282 28282 (cat) 0 0 4231168 134 cat 
	|- 28353 28340 28282 28282 (cat) 0 26 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 07:39:03 INFO mapreduce.Job:  map 100% reduce 80%
15/04/13 07:39:15 INFO mapreduce.Job:  map 100% reduce 81%
15/04/13 07:39:24 INFO mapreduce.Job:  map 100% reduce 82%
15/04/13 07:39:34 INFO mapreduce.Job:  map 100% reduce 83%
15/04/13 07:39:43 INFO mapreduce.Job:  map 100% reduce 84%
15/04/13 07:39:55 INFO mapreduce.Job:  map 100% reduce 85%
15/04/13 07:40:04 INFO mapreduce.Job:  map 100% reduce 86%
15/04/13 07:40:17 INFO mapreduce.Job:  map 100% reduce 87%
15/04/13 07:40:32 INFO mapreduce.Job:  map 100% reduce 92%
15/04/13 07:40:35 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 08:01:23 INFO mapreduce.Job: Task Id : attempt_1422482982071_4727_r_000002_2, Status : FAILED
Container [pid=24574,containerID=container_1422482982071_4727_01_000194] is running beyond physical memory limits. Current usage: 12.1 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_4727_01_000194 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 24645 24633 24574 24574 (cat) 0 0 103391232 152 cat 
	|- 24584 24574 24574 24574 (java) 9162 1968 13412257792 633089 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4727/container_1422482982071_4727_01_000194/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4727/container_1422482982071_4727_01_000194 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.189 52760 attempt_1422482982071_4727_r_000002_2 194 
	|- 24644 24633 24574 24574 (cat) 0 26 103391232 159 cat 
	|- 24633 24584 24574 24574 (R) 105640 19310 10587287552 2537586 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduceb3f8173ecacb 
	|- 24574 3828 24574 24574 (bash) 1 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_4727/container_1422482982071_4727_01_000194/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_4727/container_1422482982071_4727_01_000194 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.189 52760 attempt_1422482982071_4727_r_000002_2 194 1>/var/log/hadoop-yarn/containers/application_1422482982071_4727/container_1422482982071_4727_01_000194/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_4727/container_1422482982071_4727_01_000194/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/13 08:01:24 INFO mapreduce.Job:  map 100% reduce 80%
15/04/13 08:01:37 INFO mapreduce.Job:  map 100% reduce 81%
15/04/13 08:01:46 INFO mapreduce.Job:  map 100% reduce 82%
15/04/13 08:01:55 INFO mapreduce.Job:  map 100% reduce 83%
15/04/13 08:02:04 INFO mapreduce.Job:  map 100% reduce 84%
15/04/13 08:02:13 INFO mapreduce.Job:  map 100% reduce 85%
15/04/13 08:02:26 INFO mapreduce.Job:  map 100% reduce 86%
15/04/13 08:02:35 INFO mapreduce.Job:  map 100% reduce 87%
15/04/13 08:02:44 INFO mapreduce.Job:  map 100% reduce 92%
15/04/13 08:02:47 INFO mapreduce.Job:  map 100% reduce 93%
15/04/13 08:23:21 INFO mapreduce.Job:  map 100% reduce 100%
15/04/13 08:23:21 INFO mapreduce.Job: Job job_1422482982071_4727 failed with state FAILED due to: Task failed task_1422482982071_4727_r_000002
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/13 08:23:22 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=22766741278
		FILE: Number of bytes written=52984104510
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17901410693
		HDFS: Number of bytes written=1743474457
		HDFS: Number of read operations=414
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Job Counters 
		Failed reduce tasks=4
		Killed map tasks=1
		Launched map tasks=135
		Launched reduce tasks=8
		Data-local map tasks=66
		Rack-local map tasks=69
		Total time spent by all maps in occupied slots (ms)=21368912
		Total time spent by all reduces in occupied slots (ms)=30586330
		Total time spent by all map tasks (ms)=10684456
		Total time spent by all reduce tasks (ms)=15293165
		Total vcore-seconds taken by all map tasks=10684456
		Total vcore-seconds taken by all reduce tasks=15293165
		Total megabyte-seconds taken by all map tasks=86501355776
		Total megabyte-seconds taken by all reduce tasks=183517980000
	Map-Reduce Framework
		Map input records=391355345
		Map output records=344141584
		Map output bytes=29491539084
		Map output materialized bytes=30204049300
		Input split bytes=21172
		Combine input records=0
		Combine output records=0
		Reduce input groups=29130457
		Reduce shuffle bytes=22766744344
		Reduce input records=275297043
		Reduce output records=29282466
		Spilled Records=619438627
		Shuffled Maps =536
		Failed Shuffles=0
		Merged Map outputs=536
		GC time elapsed (ms)=105750
		CPU time spent (ms)=20881100
		Physical memory (bytes) snapshot=270713110528
		Virtual memory (bytes) snapshot=1283384041472
		Total committed heap usage (bytes)=379773186048
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17901389521
	File Output Format Counters 
		Bytes Written=1743474457
	rmr
		reduce calls=29130457
15/04/13 08:23:22 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/13 08:23:28 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/fileb3f83e4ef154

real	94m32.624s
user	0m42.560s
sys	0m4.807s

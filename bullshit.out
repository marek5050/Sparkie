Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-202-25-false-googlebooks-eng-all-5gram-20120701-on"

$hadoop$D
[1] "mapreduce.job.maps=202"

$hadoop$D
[1] "mapred.reduce.tasks=25"


15/04/15 14:47:54 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/15 14:47:54 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4302925746466159187.jar tmpDir=null
15/04/15 14:47:55 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 14:47:55 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 14:47:56 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.149:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.192:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.162:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.163:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.203:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.190:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.199:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/15 14:47:56 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.195:50010
15/04/15 14:47:56 INFO mapreduce.JobSubmitter: number of splits:202
15/04/15 14:47:56 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_5054
15/04/15 14:47:56 INFO impl.YarnClientImpl: Submitted application application_1422482982071_5054
15/04/15 14:47:57 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_5054/
15/04/15 14:47:57 INFO mapreduce.Job: Running job: job_1422482982071_5054
15/04/15 14:48:01 INFO mapreduce.Job: Job job_1422482982071_5054 running in uber mode : false
15/04/15 14:48:01 INFO mapreduce.Job:  map 0% reduce 0%
15/04/15 14:48:11 INFO mapreduce.Job:  map 1% reduce 0%
15/04/15 14:48:12 INFO mapreduce.Job:  map 2% reduce 0%
15/04/15 14:48:13 INFO mapreduce.Job:  map 4% reduce 0%
15/04/15 14:48:14 INFO mapreduce.Job:  map 5% reduce 0%
15/04/15 14:48:15 INFO mapreduce.Job:  map 6% reduce 0%
15/04/15 14:48:16 INFO mapreduce.Job:  map 7% reduce 0%
15/04/15 14:48:17 INFO mapreduce.Job:  map 8% reduce 0%
15/04/15 14:48:18 INFO mapreduce.Job:  map 10% reduce 0%
15/04/15 14:48:20 INFO mapreduce.Job:  map 11% reduce 0%
15/04/15 14:48:21 INFO mapreduce.Job:  map 13% reduce 0%
15/04/15 14:48:22 INFO mapreduce.Job:  map 14% reduce 0%
15/04/15 14:48:24 INFO mapreduce.Job:  map 16% reduce 0%
15/04/15 14:48:25 INFO mapreduce.Job:  map 17% reduce 0%
15/04/15 14:48:26 INFO mapreduce.Job:  map 18% reduce 0%
15/04/15 14:48:27 INFO mapreduce.Job:  map 19% reduce 0%
15/04/15 14:48:28 INFO mapreduce.Job:  map 20% reduce 0%
15/04/15 14:48:29 INFO mapreduce.Job:  map 21% reduce 0%
15/04/15 14:48:30 INFO mapreduce.Job:  map 23% reduce 0%
15/04/15 14:48:32 INFO mapreduce.Job:  map 24% reduce 0%
15/04/15 14:48:33 INFO mapreduce.Job:  map 26% reduce 0%
15/04/15 14:48:34 INFO mapreduce.Job:  map 27% reduce 0%
15/04/15 14:48:36 INFO mapreduce.Job:  map 29% reduce 0%
15/04/15 14:48:37 INFO mapreduce.Job:  map 30% reduce 0%
15/04/15 14:48:38 INFO mapreduce.Job:  map 31% reduce 0%
15/04/15 14:48:39 INFO mapreduce.Job:  map 32% reduce 0%
15/04/15 14:48:40 INFO mapreduce.Job:  map 33% reduce 0%
15/04/15 14:48:41 INFO mapreduce.Job:  map 34% reduce 0%
15/04/15 14:48:42 INFO mapreduce.Job:  map 36% reduce 0%
15/04/15 14:48:44 INFO mapreduce.Job:  map 37% reduce 0%
15/04/15 14:48:45 INFO mapreduce.Job:  map 39% reduce 0%
15/04/15 14:48:46 INFO mapreduce.Job:  map 40% reduce 0%
15/04/15 14:48:48 INFO mapreduce.Job:  map 42% reduce 0%
15/04/15 14:48:49 INFO mapreduce.Job:  map 43% reduce 0%
15/04/15 14:48:50 INFO mapreduce.Job:  map 44% reduce 0%
15/04/15 14:48:51 INFO mapreduce.Job:  map 45% reduce 0%
15/04/15 14:48:52 INFO mapreduce.Job:  map 46% reduce 0%
15/04/15 14:48:53 INFO mapreduce.Job:  map 47% reduce 0%
15/04/15 14:48:54 INFO mapreduce.Job:  map 48% reduce 0%
15/04/15 14:48:55 INFO mapreduce.Job:  map 49% reduce 0%
15/04/15 14:48:56 INFO mapreduce.Job:  map 50% reduce 0%
15/04/15 14:48:57 INFO mapreduce.Job:  map 52% reduce 0%
15/04/15 14:48:58 INFO mapreduce.Job:  map 53% reduce 0%
15/04/15 14:49:00 INFO mapreduce.Job:  map 55% reduce 0%
15/04/15 14:49:01 INFO mapreduce.Job:  map 56% reduce 0%
15/04/15 14:49:02 INFO mapreduce.Job:  map 57% reduce 0%
15/04/15 14:49:03 INFO mapreduce.Job:  map 58% reduce 0%
15/04/15 14:49:04 INFO mapreduce.Job:  map 59% reduce 0%
15/04/15 14:49:06 INFO mapreduce.Job:  map 60% reduce 0%
15/04/15 14:49:07 INFO mapreduce.Job:  map 61% reduce 0%
15/04/15 14:49:09 INFO mapreduce.Job:  map 62% reduce 0%
15/04/15 14:49:12 INFO mapreduce.Job:  map 63% reduce 0%
15/04/15 14:49:15 INFO mapreduce.Job:  map 64% reduce 0%
15/04/15 14:49:16 INFO mapreduce.Job:  map 65% reduce 0%
15/04/15 14:49:17 INFO mapreduce.Job:  map 69% reduce 0%
15/04/15 14:49:18 INFO mapreduce.Job:  map 72% reduce 0%
15/04/15 14:49:19 INFO mapreduce.Job:  map 75% reduce 0%
15/04/15 14:49:20 INFO mapreduce.Job:  map 78% reduce 0%
15/04/15 14:49:21 INFO mapreduce.Job:  map 80% reduce 0%
15/04/15 14:49:22 INFO mapreduce.Job:  map 82% reduce 0%
15/04/15 14:49:23 INFO mapreduce.Job:  map 83% reduce 0%
15/04/15 14:49:24 INFO mapreduce.Job:  map 86% reduce 0%
15/04/15 14:49:25 INFO mapreduce.Job:  map 87% reduce 0%
15/04/15 14:49:26 INFO mapreduce.Job:  map 89% reduce 0%
15/04/15 14:49:27 INFO mapreduce.Job:  map 90% reduce 12%
15/04/15 14:49:28 INFO mapreduce.Job:  map 91% reduce 19%
15/04/15 14:49:30 INFO mapreduce.Job:  map 92% reduce 19%
15/04/15 14:49:36 INFO mapreduce.Job:  map 93% reduce 20%
15/04/15 14:49:39 INFO mapreduce.Job:  map 93% reduce 22%
15/04/15 14:49:42 INFO mapreduce.Job:  map 93% reduce 24%
15/04/15 14:49:42 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_m_000039_0, Status : FAILED
Error: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:334)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRawBytes(TypedBytesInput.java:218)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRaw(TypedBytesInput.java:152)
	at org.apache.hadoop.streaming.io.TypedBytesOutputReader.readKeyValue(TypedBytesOutputReader.java:51)
	at org.apache.hadoop.streaming.PipeMapRed$MROutputThread.run(PipeMapRed.java:376)

15/04/15 14:49:45 INFO mapreduce.Job:  map 93% reduce 25%
15/04/15 14:49:49 INFO mapreduce.Job:  map 93% reduce 26%
15/04/15 14:49:51 INFO mapreduce.Job:  map 93% reduce 27%
15/04/15 14:49:52 INFO mapreduce.Job:  map 94% reduce 27%
15/04/15 14:49:54 INFO mapreduce.Job:  map 95% reduce 28%
15/04/15 14:49:56 INFO mapreduce.Job:  map 96% reduce 28%
15/04/15 14:49:57 INFO mapreduce.Job:  map 96% reduce 29%
15/04/15 14:49:58 INFO mapreduce.Job:  map 97% reduce 29%
15/04/15 14:49:59 INFO mapreduce.Job:  map 98% reduce 30%
15/04/15 14:50:00 INFO mapreduce.Job:  map 98% reduce 31%
15/04/15 14:50:01 INFO mapreduce.Job:  map 99% reduce 31%
15/04/15 14:50:03 INFO mapreduce.Job:  map 99% reduce 32%
15/04/15 14:50:05 INFO mapreduce.Job:  map 99% reduce 33%
15/04/15 14:50:06 INFO mapreduce.Job:  map 100% reduce 33%
15/04/15 14:51:09 INFO mapreduce.Job:  map 100% reduce 37%
15/04/15 14:51:10 INFO mapreduce.Job:  map 100% reduce 40%
15/04/15 14:51:11 INFO mapreduce.Job:  map 100% reduce 48%
15/04/15 14:51:12 INFO mapreduce.Job:  map 100% reduce 54%
15/04/15 14:51:13 INFO mapreduce.Job:  map 100% reduce 56%
15/04/15 14:51:14 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 14:51:15 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 14:51:16 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 14:51:17 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 14:51:18 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 14:51:29 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 14:51:40 INFO mapreduce.Job:  map 100% reduce 69%
15/04/15 14:51:52 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 14:52:05 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 14:52:20 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 14:52:33 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 14:52:47 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 14:52:59 INFO mapreduce.Job:  map 100% reduce 75%
15/04/15 14:53:13 INFO mapreduce.Job:  map 100% reduce 76%
15/04/15 14:53:32 INFO mapreduce.Job:  map 100% reduce 77%
15/04/15 14:53:53 INFO mapreduce.Job:  map 100% reduce 78%
15/04/15 14:54:16 INFO mapreduce.Job:  map 100% reduce 79%
15/04/15 14:54:42 INFO mapreduce.Job:  map 100% reduce 80%
15/04/15 14:55:04 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 14:55:29 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 14:55:54 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 14:56:24 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 14:56:53 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 14:57:19 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 14:57:51 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 14:58:30 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 14:59:19 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 15:00:16 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:01:51 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:03:52 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:10:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000021_0, Status : FAILED
Container [pid=31515,containerID=container_1422482982071_5054_01_000279] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000279 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 31601 31588 31515 31515 (cat) 0 0 4231168 138 cat 
	|- 31599 31588 31515 31515 (cat) 0 26 4231168 142 cat 
	|- 31524 31515 31515 31515 (java) 4324 549 13313757184 587372 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000279/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000279 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000021_0 279 
	|- 31588 31524 31515 31515 (R) 96156 18403 10356391936 2487859 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 31515 11042 31515 31515 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000279/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000279 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000021_0 279 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000279/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000279/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:10:19 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:10:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000015_0, Status : FAILED
Container [pid=40854,containerID=container_1422482982071_5054_01_000273] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000273 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 40863 40854 40854 40854 (java) 4862 767 13312385024 571950 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000273/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000273 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000015_0 273 
	|- 40854 10433 40854 40854 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000273/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000273 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000015_0 273 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000273/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000273/stderr  
	|- 40965 40952 40854 40854 (cat) 0 0 4231168 138 cat 
	|- 40952 40863 40854 40854 (R) 93769 21150 10373296128 2509497 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 40963 40952 40854 40854 (cat) 0 24 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:10:27 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 15:10:30 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 15:10:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000013_0, Status : FAILED
Container [pid=11425,containerID=container_1422482982071_5054_01_000271] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000271 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 11519 11506 11425 11425 (cat) 0 0 4231168 136 cat 
	|- 11506 11434 11425 11425 (R) 100242 15508 10420113408 2520434 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 11517 11506 11425 11425 (cat) 0 22 4231168 142 cat 
	|- 11434 11425 11425 11425 (java) 4322 603 13312053248 587230 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000271/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000271 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000013_0 271 
	|- 11425 10599 11425 11425 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000271/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000271 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000013_0 271 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000271/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000271/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:10:32 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 15:10:41 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 15:10:49 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 15:10:57 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 15:11:00 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 15:11:08 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:11:14 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:11:22 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:12:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000012_0, Status : FAILED
Container [pid=11948,containerID=container_1422482982071_5054_01_000270] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.4 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000270 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 12076 11967 11948 11948 (R) 106770 18247 10721312768 2519488 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 12088 12076 11948 11948 (cat) 0 0 4231168 134 cat 
	|- 11967 11948 11948 11948 (java) 4426 840 13312491520 600604 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000270/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000270 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000012_0 270 
	|- 12087 12076 11948 11948 (cat) 0 26 4231168 142 cat 
	|- 11948 9793 11948 11948 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000270/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000270 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000012_0 270 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000270/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000270/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:12:05 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:12:24 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:12:42 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:13:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000018_0, Status : FAILED
Container [pid=7213,containerID=container_1422482982071_5054_01_000276] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.4 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000276 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 7391 7360 7213 7213 (cat) 0 0 4231168 139 cat 
	|- 7360 7222 7213 7213 (R) 110324 25748 10753667072 2602361 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 7371 7360 7213 7213 (cat) 0 26 4231168 142 cat 
	|- 7222 7213 7213 7213 (java) 4228 714 13315047424 550320 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000276/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000276 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000018_0 276 
	|- 7213 9971 7213 7213 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000276/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000276 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000018_0 276 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000276/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000276/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:13:57 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:14:14 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:14:30 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:16:10 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000017_0, Status : FAILED
Container [pid=45275,containerID=container_1422482982071_5054_01_000275] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000275 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 45275 29409 45275 45275 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000275/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000275 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000017_0 275 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000275/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000275/stderr  
	|- 45401 45385 45275 45275 (cat) 0 0 4231168 140 cat 
	|- 45284 45275 45275 45275 (java) 4653 657 13315002368 591200 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000275/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000275 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000017_0 275 
	|- 45396 45385 45275 45275 (cat) 0 51 4231168 142 cat 
	|- 45385 45284 45275 45275 (R) 125701 23552 10611118080 2505641 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:16:11 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 15:16:22 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:16:32 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:16:41 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:39:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000017_1, Status : FAILED
Container [pid=26676,containerID=container_1422482982071_5054_01_000316] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000316 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 26742 26729 26676 26676 (cat) 0 0 4231168 140 cat 
	|- 26686 26676 26676 26676 (java) 5045 872 13314519040 590050 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000316/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000316 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000017_1 316 
	|- 26676 9754 26676 26676 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000316/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000316 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000017_1 316 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000316/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000316/stderr  
	|- 26729 26686 26676 26676 (R) 111899 22706 10603433984 2565651 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 26740 26729 26676 26676 (cat) 0 47 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:39:15 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 15:39:27 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:39:36 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:39:45 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 15:44:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000012_1, Status : FAILED
Container [pid=39367,containerID=container_1422482982071_5054_01_000314] is running beyond physical memory limits. Current usage: 12.1 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000314 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 39420 39377 39367 39367 (R) 108775 83030 10570829824 2557678 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 39431 39420 39367 39367 (cat) 0 27 4231168 143 cat 
	|- 39432 39420 39367 39367 (cat) 0 0 4231168 134 cat 
	|- 39377 39367 39367 39367 (java) 5127 1033 13314269184 610152 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000314/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000314 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000012_1 314 
	|- 39367 9245 39367 39367 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000314/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000314 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000012_1 314 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000314/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000314/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:45:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000021_1, Status : FAILED
Container [pid=39556,containerID=container_1422482982071_5054_01_000310] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000310 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 39566 39556 39556 39556 (java) 3701 1538 13312327680 589758 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000310/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000310 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000021_1 310 
	|- 39556 10887 39556 39556 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000310/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000310 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000021_1 310 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000310/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000310/stderr  
	|- 39746 39566 39556 39556 (R) 96829 112039 10395729920 2514973 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 39757 39746 39556 39556 (cat) 0 28 4231168 142 cat 
	|- 39759 39746 39556 39556 (cat) 0 0 4231168 138 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:47:05 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000018_1, Status : FAILED
Container [pid=39439,containerID=container_1422482982071_5054_01_000315] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.4 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000315 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 39493 39449 39439 39439 (R) 106895 88150 10716540928 2593298 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 39449 39439 39439 39439 (java) 3906 656 13314826240 531661 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000315/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000315 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000018_1 315 
	|- 39504 39493 39439 39439 (cat) 0 26 4231168 142 cat 
	|- 39506 39493 39439 39439 (cat) 0 0 4231168 139 cat 
	|- 39439 9245 39439 39439 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000315/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000315 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000018_1 315 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000315/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000315/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:49:23 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000013_2, Status : FAILED
Container [pid=39695,containerID=container_1422482982071_5054_01_000313] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000313 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 39787 39705 39695 39695 (R) 110083 117292 10624249856 2570735 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 39798 39787 39695 39695 (cat) 0 25 4231168 143 cat 
	|- 39705 39695 39695 39695 (java) 3646 1402 13312163840 585564 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000313/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000313 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000013_2 313 
	|- 39815 39787 39695 39695 (cat) 0 0 4231168 136 cat 
	|- 39695 10887 39695 39695 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000313/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000313 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000013_2 313 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000313/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000313/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:50:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000015_1, Status : FAILED
Container [pid=39602,containerID=container_1422482982071_5054_01_000311] is running beyond physical memory limits. Current usage: 12.2 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000311 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 39602 10887 39602 39602 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000311/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000311 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000015_1 311 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000311/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000311/stderr  
	|- 39778 39767 39602 39602 (cat) 0 27 4231168 142 cat 
	|- 39612 39602 39602 39602 (java) 3616 1710 13312651264 586898 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000311/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000311 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000015_1 311 
	|- 39767 39612 39602 39602 (R) 114224 118114 10896347136 2604176 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 39780 39767 39602 39602 (cat) 0 0 4231168 138 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:50:09 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000013_1, Status : FAILED
Container [pid=39648,containerID=container_1422482982071_5054_01_000312] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000312 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 39807 39658 39648 39648 (R) 116097 115636 10425339904 2496096 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 39813 39807 39648 39648 (cat) 0 25 4231168 142 cat 
	|- 39648 10887 39648 39648 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000312/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000312 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000013_1 312 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000312/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000312/stderr  
	|- 39821 39807 39648 39648 (cat) 0 0 4231168 135 cat 
	|- 39658 39648 39648 39648 (java) 3557 2581 13312524288 583678 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000312/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000312 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000013_1 312 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:58:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000015_2, Status : FAILED
Container [pid=38308,containerID=container_1422482982071_5054_01_000317] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000317 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 38366 38318 38308 38308 (R) 105211 16332 10342158336 2501894 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 38318 38308 38308 38308 (java) 4594 797 13312942080 588087 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000317/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000317 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000015_2 317 
	|- 38377 38366 38308 38308 (cat) 1 28 4231168 142 cat 
	|- 38379 38366 38308 38308 (cat) 0 0 4231168 138 cat 
	|- 38308 9412 38308 38308 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000317/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000317 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000015_2 317 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000317/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000317/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 15:58:56 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 15:59:13 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 15:59:25 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 16:01:23 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000012_2, Status : FAILED
Container [pid=2018,containerID=container_1422482982071_5054_01_000319] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000319 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 2018 3799 2018 2018 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000319/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000319 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000012_2 319 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000319/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000319/stderr  
	|- 2148 2136 2018 2018 (cat) 0 25 103391232 159 cat 
	|- 2151 2136 2018 2018 (cat) 0 0 103391232 151 cat 
	|- 2028 2018 2018 2018 (java) 4169 852 13411733504 586290 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000319/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000319 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000012_2 319 
	|- 2136 2028 2018 2018 (R) 110959 16987 10585825280 2537230 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:01:24 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 16:01:40 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 16:01:56 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 16:01:57 INFO mapreduce.Job:  map 100% reduce 93%
15/04/15 16:01:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000017_2, Status : FAILED
Container [pid=1971,containerID=container_1422482982071_5054_01_000318] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.7 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000318 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 2069 1981 1971 1971 (R) 116340 16087 10615205888 2512020 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 1971 3799 1971 1971 (bash) 0 0 108650496 295 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000318/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000318 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000017_2 318 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000318/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000318/stderr  
	|- 1981 1971 1971 1971 (java) 4634 795 13413052416 597371 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000318/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000318 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000017_2 318 
	|- 2080 2069 1971 1971 (cat) 0 49 103391232 159 cat 
	|- 2082 2069 1971 1971 (cat) 0 0 103391232 157 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:01:58 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 16:02:08 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 16:02:17 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 16:02:25 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 16:02:25 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000021_2, Status : FAILED
Container [pid=2084,containerID=container_1422482982071_5054_01_000320] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.9 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000320 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 2174 2161 2084 2084 (cat) 0 0 103391232 155 cat 
	|- 2161 2094 2084 2084 (R) 115807 16116 10870583296 2606765 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 2084 3799 2084 2084 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000320/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000320 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000021_2 320 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000320/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000320/stderr  
	|- 2094 2084 2084 2084 (java) 3661 555 13410947072 469825 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000320/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000320 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000021_2 320 
	|- 2172 2161 2084 2084 (cat) 0 28 103391232 159 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:02:26 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 16:02:33 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 16:02:36 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 16:02:46 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 16:02:55 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 16:05:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_5054_r_000018_2, Status : FAILED
Container [pid=42076,containerID=container_1422482982071_5054_01_000321] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5054_01_000321 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 42141 42130 42076 42076 (cat) 1 26 4231168 142 cat 
	|- 42143 42130 42076 42076 (cat) 0 0 4231168 139 cat 
	|- 42130 42086 42076 42076 (R) 107273 30544 10838573056 2544673 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce3e42398495ce 
	|- 42086 42076 42076 42076 (java) 3465 565 13313241088 590297 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000321/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000321 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000018_2 321 
	|- 42076 10433 42076 42076 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5054/container_1422482982071_5054_01_000321/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000321 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.182 45077 attempt_1422482982071_5054_r_000018_2 321 1>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000321/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5054/container_1422482982071_5054_01_000321/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:05:58 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 16:06:19 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 16:06:28 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 16:13:15 INFO mapreduce.Job:  map 100% reduce 100%
15/04/15 16:13:15 INFO mapreduce.Job: Job job_1422482982071_5054 failed with state FAILED due to: Task failed task_1422482982071_5054_r_000013
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/15 16:13:15 INFO mapreduce.Job: Counters: 56
	File System Counters
		FILE: Number of bytes read=31863080732
		FILE: Number of bytes written=81367948034
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=27107640365
		HDFS: Number of bytes written=2698916635
		HDFS: Number of read operations=663
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=38
	Job Counters 
		Failed map tasks=1
		Failed reduce tasks=19
		Killed map tasks=2
		Killed reduce tasks=5
		Launched map tasks=205
		Launched reduce tasks=43
		Other local map tasks=2
		Data-local map tasks=146
		Rack-local map tasks=57
		Total time spent by all maps in occupied slots (ms)=34149386
		Total time spent by all reduces in occupied slots (ms)=99282468
		Total time spent by all map tasks (ms)=17074693
		Total time spent by all reduce tasks (ms)=49641234
		Total vcore-seconds taken by all map tasks=17074693
		Total vcore-seconds taken by all reduce tasks=49641234
		Total megabyte-seconds taken by all map tasks=138236714528
		Total megabyte-seconds taken by all reduce tasks=595694808000
	Map-Reduce Framework
		Map input records=632973453
		Map output records=567321156
		Map output bytes=48319012976
		Map output materialized bytes=49483449944
		Input split bytes=31916
		Combine input records=0
		Combine output records=0
		Reduce input groups=44903888
		Reduce shuffle bytes=31863103526
		Reduce input records=431122863
		Reduce output records=45129891
		Spilled Records=998444019
		Shuffled Maps =3838
		Failed Shuffles=0
		Merged Map outputs=3838
		GC time elapsed (ms)=127006
		CPU time spent (ms)=31238060
		Physical memory (bytes) snapshot=430254395392
		Virtual memory (bytes) snapshot=2108156125184
		Total committed heap usage (bytes)=599726206976
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27107608449
	File Output Format Counters 
		Bytes Written=2698916635
	rmr
		reduce calls=44903888
15/04/15 16:13:15 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/15 16:13:21 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file3e4215a23e3c

real	85m31.402s
user	0m36.172s
sys	0m3.930s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-202-15-false-googlebooks-eng-all-5gram-20120701-on"

$hadoop$D
[1] "mapreduce.job.maps=202"

$hadoop$D
[1] "mapred.reduce.tasks=15"


15/04/15 16:13:27 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/15 16:13:27 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob4272084959970479081.jar tmpDir=null
15/04/15 16:13:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 16:13:27 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 16:13:28 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.149:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.192:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.162:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.163:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.203:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.190:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.199:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/15 16:13:28 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.195:50010
15/04/15 16:13:28 INFO mapreduce.JobSubmitter: number of splits:202
15/04/15 16:13:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_5062
15/04/15 16:13:29 INFO impl.YarnClientImpl: Submitted application application_1422482982071_5062
15/04/15 16:13:29 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_5062/
15/04/15 16:13:29 INFO mapreduce.Job: Running job: job_1422482982071_5062
15/04/15 16:13:34 INFO mapreduce.Job: Job job_1422482982071_5062 running in uber mode : false
15/04/15 16:13:34 INFO mapreduce.Job:  map 0% reduce 0%
15/04/15 16:13:46 INFO mapreduce.Job:  map 2% reduce 0%
15/04/15 16:13:47 INFO mapreduce.Job:  map 3% reduce 0%
15/04/15 16:13:48 INFO mapreduce.Job:  map 4% reduce 0%
15/04/15 16:13:49 INFO mapreduce.Job:  map 5% reduce 0%
15/04/15 16:13:50 INFO mapreduce.Job:  map 6% reduce 0%
15/04/15 16:13:51 INFO mapreduce.Job:  map 7% reduce 0%
15/04/15 16:13:52 INFO mapreduce.Job:  map 8% reduce 0%
15/04/15 16:13:53 INFO mapreduce.Job:  map 9% reduce 0%
15/04/15 16:13:54 INFO mapreduce.Job:  map 10% reduce 0%
15/04/15 16:13:55 INFO mapreduce.Job:  map 11% reduce 0%
15/04/15 16:13:56 INFO mapreduce.Job:  map 13% reduce 0%
15/04/15 16:13:57 INFO mapreduce.Job:  map 14% reduce 0%
15/04/15 16:13:59 INFO mapreduce.Job:  map 16% reduce 0%
15/04/15 16:14:00 INFO mapreduce.Job:  map 17% reduce 0%
15/04/15 16:14:02 INFO mapreduce.Job:  map 19% reduce 0%
15/04/15 16:14:03 INFO mapreduce.Job:  map 20% reduce 0%
15/04/15 16:14:05 INFO mapreduce.Job:  map 22% reduce 0%
15/04/15 16:14:06 INFO mapreduce.Job:  map 23% reduce 0%
15/04/15 16:14:07 INFO mapreduce.Job:  map 24% reduce 0%
15/04/15 16:14:08 INFO mapreduce.Job:  map 26% reduce 0%
15/04/15 16:14:09 INFO mapreduce.Job:  map 27% reduce 0%
15/04/15 16:14:11 INFO mapreduce.Job:  map 29% reduce 0%
15/04/15 16:14:12 INFO mapreduce.Job:  map 30% reduce 0%
15/04/15 16:14:14 INFO mapreduce.Job:  map 32% reduce 0%
15/04/15 16:14:15 INFO mapreduce.Job:  map 33% reduce 0%
15/04/15 16:14:16 INFO mapreduce.Job:  map 34% reduce 0%
15/04/15 16:14:17 INFO mapreduce.Job:  map 35% reduce 0%
15/04/15 16:14:18 INFO mapreduce.Job:  map 36% reduce 0%
15/04/15 16:14:19 INFO mapreduce.Job:  map 37% reduce 0%
15/04/15 16:14:20 INFO mapreduce.Job:  map 39% reduce 0%
15/04/15 16:14:21 INFO mapreduce.Job:  map 40% reduce 0%
15/04/15 16:14:23 INFO mapreduce.Job:  map 42% reduce 0%
15/04/15 16:14:24 INFO mapreduce.Job:  map 43% reduce 0%
15/04/15 16:14:25 INFO mapreduce.Job:  map 44% reduce 0%
15/04/15 16:14:26 INFO mapreduce.Job:  map 45% reduce 0%
15/04/15 16:14:27 INFO mapreduce.Job:  map 46% reduce 0%
15/04/15 16:14:28 INFO mapreduce.Job:  map 47% reduce 0%
15/04/15 16:14:29 INFO mapreduce.Job:  map 49% reduce 0%
15/04/15 16:14:30 INFO mapreduce.Job:  map 50% reduce 0%
15/04/15 16:14:32 INFO mapreduce.Job:  map 52% reduce 0%
15/04/15 16:14:33 INFO mapreduce.Job:  map 53% reduce 0%
15/04/15 16:14:34 INFO mapreduce.Job:  map 54% reduce 0%
15/04/15 16:14:35 INFO mapreduce.Job:  map 55% reduce 0%
15/04/15 16:14:36 INFO mapreduce.Job:  map 56% reduce 0%
15/04/15 16:14:37 INFO mapreduce.Job:  map 57% reduce 0%
15/04/15 16:14:38 INFO mapreduce.Job:  map 58% reduce 0%
15/04/15 16:14:39 INFO mapreduce.Job:  map 59% reduce 0%
15/04/15 16:14:40 INFO mapreduce.Job:  map 60% reduce 0%
15/04/15 16:14:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_5062_m_000180_0, Status : FAILED
Error: java.lang.RuntimeException: java.io.EOFException
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:334)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRawBytes(TypedBytesInput.java:211)
	at org.apache.hadoop.typedbytes.TypedBytesInput.readRaw(TypedBytesInput.java:152)
	at org.apache.hadoop.streaming.io.TypedBytesOutputReader.readKeyValue(TypedBytesOutputReader.java:51)
	at org.apache.hadoop.streaming.PipeMapRed$MROutputThread.run(PipeMapRed.java:376)

15/04/15 16:14:42 INFO mapreduce.Job:  map 61% reduce 0%
15/04/15 16:14:44 INFO mapreduce.Job:  map 62% reduce 0%
15/04/15 16:14:47 INFO mapreduce.Job:  map 63% reduce 0%
15/04/15 16:14:50 INFO mapreduce.Job:  map 64% reduce 0%
15/04/15 16:14:51 INFO mapreduce.Job:  map 65% reduce 0%
15/04/15 16:14:52 INFO mapreduce.Job:  map 68% reduce 0%
15/04/15 16:14:53 INFO mapreduce.Job:  map 71% reduce 0%
15/04/15 16:14:54 INFO mapreduce.Job:  map 74% reduce 0%
15/04/15 16:14:55 INFO mapreduce.Job:  map 75% reduce 0%
15/04/15 16:14:56 INFO mapreduce.Job:  map 78% reduce 0%
15/04/15 16:14:57 INFO mapreduce.Job:  map 80% reduce 0%
15/04/15 16:14:58 INFO mapreduce.Job:  map 83% reduce 0%
15/04/15 16:14:59 INFO mapreduce.Job:  map 86% reduce 0%
15/04/15 16:15:01 INFO mapreduce.Job:  map 88% reduce 5%
15/04/15 16:15:02 INFO mapreduce.Job:  map 90% reduce 12%
15/04/15 16:15:03 INFO mapreduce.Job:  map 91% reduce 12%
15/04/15 16:15:04 INFO mapreduce.Job:  map 92% reduce 12%
15/04/15 16:15:08 INFO mapreduce.Job:  map 93% reduce 12%
15/04/15 16:15:11 INFO mapreduce.Job:  map 93% reduce 15%
15/04/15 16:15:14 INFO mapreduce.Job:  map 93% reduce 18%
15/04/15 16:15:15 INFO mapreduce.Job:  map 94% reduce 18%
15/04/15 16:15:17 INFO mapreduce.Job:  map 94% reduce 20%
15/04/15 16:15:20 INFO mapreduce.Job:  map 94% reduce 21%
15/04/15 16:15:23 INFO mapreduce.Job:  map 94% reduce 24%
15/04/15 16:15:24 INFO mapreduce.Job:  map 95% reduce 24%
15/04/15 16:15:26 INFO mapreduce.Job:  map 96% reduce 26%
15/04/15 16:15:28 INFO mapreduce.Job:  map 97% reduce 26%
15/04/15 16:15:29 INFO mapreduce.Job:  map 97% reduce 27%
15/04/15 16:15:30 INFO mapreduce.Job:  map 98% reduce 28%
15/04/15 16:15:31 INFO mapreduce.Job:  map 99% reduce 28%
15/04/15 16:15:32 INFO mapreduce.Job:  map 99% reduce 29%
15/04/15 16:15:33 INFO mapreduce.Job:  map 100% reduce 30%
15/04/15 16:15:35 INFO mapreduce.Job:  map 100% reduce 32%
15/04/15 16:15:38 INFO mapreduce.Job:  map 100% reduce 33%
15/04/15 16:16:00 INFO mapreduce.Job:  map 100% reduce 35%
15/04/15 16:16:01 INFO mapreduce.Job:  map 100% reduce 39%
15/04/15 16:16:02 INFO mapreduce.Job:  map 100% reduce 41%
15/04/15 16:16:03 INFO mapreduce.Job:  map 100% reduce 47%
15/04/15 16:16:04 INFO mapreduce.Job:  map 100% reduce 57%
15/04/15 16:16:06 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 16:16:07 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 16:16:09 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 16:16:10 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 16:16:13 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 16:16:34 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 16:16:57 INFO mapreduce.Job:  map 100% reduce 69%
15/04/15 16:17:25 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 16:17:55 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 16:18:31 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 16:19:14 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 16:19:54 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 16:20:41 INFO mapreduce.Job:  map 100% reduce 75%
15/04/15 16:21:39 INFO mapreduce.Job:  map 100% reduce 76%
15/04/15 16:22:52 INFO mapreduce.Job:  map 100% reduce 77%
15/04/15 16:24:09 INFO mapreduce.Job:  map 100% reduce 78%
15/04/15 16:25:46 INFO mapreduce.Job:  map 100% reduce 79%
15/04/15 16:26:53 INFO mapreduce.Job:  map 100% reduce 80%
15/04/15 16:27:47 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 16:28:32 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 16:29:29 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 16:30:31 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 16:31:44 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 16:32:38 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 16:33:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_5062_r_000010_0, Status : FAILED
Container [pid=40538,containerID=container_1422482982071_5062_01_000268] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5062_01_000268 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 40679 40666 40538 40538 (cat) 0 0 4231168 140 cat 
	|- 40678 40666 40538 40538 (cat) 0 25 4231168 143 cat 
	|- 40538 9412 40538 40538 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000268/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000268 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000010_0 268 1>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000268/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000268/stderr  
	|- 40666 40556 40538 40538 (R) 90223 13964 10278567936 2486338 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4805c23addc 
	|- 40556 40538 40538 40538 (java) 5466 933 13312278528 589711 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000268/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000268 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000010_0 268 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:33:33 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 16:33:44 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 16:34:08 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 16:34:20 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 16:34:26 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 16:36:24 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 16:36:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_5062_r_000008_0, Status : FAILED
Container [pid=14881,containerID=container_1422482982071_5062_01_000266] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5062_01_000266 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 14972 14961 14881 14881 (cat) 0 25 4231168 142 cat 
	|- 14973 14961 14881 14881 (cat) 0 0 4231168 136 cat 
	|- 14890 14881 14881 14881 (java) 5856 1099 13313937408 587866 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000266/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000266 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000008_0 266 
	|- 14881 10599 14881 14881 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000266/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000266 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000008_0 266 1>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000266/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000266/stderr  
	|- 14961 14890 14881 14881 (R) 103439 20517 10620506112 2569850 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4805c23addc 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:36:42 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 16:36:43 INFO mapreduce.Job: Task Id : attempt_1422482982071_5062_r_000012_0, Status : FAILED
Container [pid=6411,containerID=container_1422482982071_5062_01_000270] is running beyond physical memory limits. Current usage: 12.1 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5062_01_000270 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 6522 6421 6411 6411 (R) 105358 18550 10649509888 2576917 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4805c23addc 
	|- 6533 6522 6411 6411 (cat) 0 26 4231168 142 cat 
	|- 6534 6522 6411 6411 (cat) 0 0 4231168 134 cat 
	|- 6421 6411 6411 6411 (java) 6194 1289 13312999424 591555 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000270/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000270 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000012_0 270 
	|- 6411 10211 6411 6411 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000270/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000270 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000012_0 270 1>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000270/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000270/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:36:44 INFO mapreduce.Job:  map 100% reduce 79%
15/04/15 16:36:55 INFO mapreduce.Job:  map 100% reduce 80%
15/04/15 16:37:01 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 16:37:12 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 16:37:16 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 16:37:24 INFO mapreduce.Job: Task Id : attempt_1422482982071_5062_r_000013_0, Status : FAILED
Container [pid=9420,containerID=container_1422482982071_5062_01_000271] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5062_01_000271 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 9511 9500 9420 9420 (cat) 0 29 4231168 142 cat 
	|- 9512 9500 9420 9420 (cat) 0 0 4231168 140 cat 
	|- 9500 9429 9420 9420 (R) 96798 30424 10522103808 2520148 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4805c23addc 
	|- 9420 9906 9420 9420 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000271/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000271 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000013_0 271 1>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000271/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000271/stderr  
	|- 9429 9420 9420 9420 (java) 6759 998 13314252800 586388 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000271/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000271 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000013_0 271 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:37:25 INFO mapreduce.Job:  map 100% reduce 79%
15/04/15 16:37:30 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 16:37:31 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 16:37:35 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 16:37:50 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 16:38:12 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 16:38:18 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 16:38:24 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 16:40:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_5062_r_000011_0, Status : FAILED
Container [pid=20152,containerID=container_1422482982071_5062_01_000269] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5062_01_000269 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 20152 10523 20152 20152 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000269/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000269 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000011_0 269 1>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000269/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000269/stderr  
	|- 20259 20248 20152 20152 (cat) 0 30 4231168 142 cat 
	|- 20161 20152 20152 20152 (java) 5642 702 13312126976 588300 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000269/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000269 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000011_0 269 
	|- 20248 20161 20152 20152 (R) 107907 35341 10501640192 2521700 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4805c23addc 
	|- 20260 20248 20152 20152 (cat) 0 0 4231168 140 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:40:01 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 16:40:12 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 16:40:30 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 16:40:42 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 16:40:46 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 16:53:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_5062_r_000010_1, Status : FAILED
Container [pid=40554,containerID=container_1422482982071_5062_01_000273] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5062_01_000273 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 40621 40610 40554 40554 (cat) 0 26 4231168 142 cat 
	|- 40564 40554 40554 40554 (java) 5353 721 13312598016 589437 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000273/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000273 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000010_1 273 
	|- 40622 40610 40554 40554 (cat) 0 0 4231168 140 cat 
	|- 40610 40564 40554 40554 (R) 91114 25139 10314985472 2495230 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4805c23addc 
	|- 40554 8968 40554 40554 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000273/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000273 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000010_1 273 1>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000273/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000273/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:53:51 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 16:54:11 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 16:54:23 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 16:54:36 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 16:54:39 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 16:57:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_5062_r_000012_1, Status : FAILED
Container [pid=41069,containerID=container_1422482982071_5062_01_000275] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 21.7 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5062_01_000275 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 41079 41069 41069 41069 (java) 4954 924 13312868352 656260 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000275/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000275 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000012_1 275 
	|- 41158 41079 41069 41069 (R) 95593 26418 10012712960 2421449 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4805c23addc 
	|- 41069 9412 41069 41069 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000275/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000275 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000012_1 275 1>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000275/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000275/stderr  
	|- 41170 41158 41069 41069 (cat) 0 0 4231168 134 cat 
	|- 41169 41158 41069 41069 (cat) 0 24 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:57:53 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 16:58:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_5062_r_000013_1, Status : FAILED
Container [pid=30603,containerID=container_1422482982071_5062_01_000276] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5062_01_000276 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 30714 30613 30603 30603 (R) 96235 19844 10527809536 2544210 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4805c23addc 
	|- 30726 30714 30603 30603 (cat) 1 30 4231168 142 cat 
	|- 30613 30603 30603 30603 (java) 5849 774 13313904640 591304 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000276/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000276 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000013_1 276 
	|- 30603 9754 30603 30603 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000276/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000276 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000013_1 276 1>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000276/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000276/stderr  
	|- 30728 30714 30603 30603 (cat) 0 0 4231168 140 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 16:58:05 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 16:58:17 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 16:58:26 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 16:58:36 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 16:58:48 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 16:58:51 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 16:58:54 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 17:01:53 INFO mapreduce.Job: Task Id : attempt_1422482982071_5062_r_000008_1, Status : FAILED
Container [pid=41038,containerID=container_1422482982071_5062_01_000274] is running beyond physical memory limits. Current usage: 12.3 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5062_01_000274 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 41048 41038 41038 41038 (java) 4952 853 13312077824 586873 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000274/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000274 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000008_1 274 
	|- 41038 9412 41038 41038 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000274/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000274 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000008_1 274 1>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000274/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000274/stderr  
	|- 41150 41138 41038 41038 (cat) 0 0 4231168 136 cat 
	|- 41138 41048 41038 41038 (R) 114443 31741 10905214976 2639327 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4805c23addc 
	|- 41149 41138 41038 41038 (cat) 0 24 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 17:01:54 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 17:02:12 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 17:02:27 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 17:02:46 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 17:03:09 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 17:08:26 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 17:15:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_5062_r_000010_2, Status : FAILED
Container [pid=43425,containerID=container_1422482982071_5062_01_000278] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5062_01_000278 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 43425 3820 43425 43425 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000278/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000278 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000010_2 278 1>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000278/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000278/stderr  
	|- 43491 43480 43425 43425 (cat) 0 27 103391232 159 cat 
	|- 43492 43480 43425 43425 (cat) 0 0 103391232 157 cat 
	|- 43480 43435 43425 43425 (R) 107027 16072 10446012416 2491515 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4805c23addc 
	|- 43435 43425 43425 43425 (java) 5548 1000 13411835904 588622 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000278/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000278 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000010_2 278 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 17:15:13 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 17:15:34 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 17:15:52 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 17:15:55 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 17:15:58 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 17:23:07 INFO mapreduce.Job: Task Id : attempt_1422482982071_5062_r_000013_2, Status : FAILED
Container [pid=2956,containerID=container_1422482982071_5062_01_000280] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5062_01_000280 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 2966 2956 2956 2956 (java) 5481 922 13313007616 589305 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000280/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000280 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000013_2 280 
	|- 3078 3065 2956 2956 (cat) 0 0 4231168 140 cat 
	|- 3065 2966 2956 2956 (R) 99374 45042 10340507648 2501461 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4805c23addc 
	|- 2956 10269 2956 2956 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000280/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000280 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000013_2 280 1>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000280/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000280/stderr  
	|- 3077 3065 2956 2956 (cat) 1 30 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 17:23:08 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 17:23:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_5062_r_000008_2, Status : FAILED
Container [pid=44411,containerID=container_1422482982071_5062_01_000281] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5062_01_000281 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 44467 44421 44411 44411 (R) 107031 16563 10403684352 2492773 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4805c23addc 
	|- 44411 3817 44411 44411 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000281/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000281 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000008_2 281 1>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000281/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000281/stderr  
	|- 44421 44411 44411 44411 (java) 5974 1037 13413068800 613434 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000281/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000281 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000008_2 281 
	|- 44479 44467 44411 44411 (cat) 0 0 103391232 153 cat 
	|- 44478 44467 44411 44411 (cat) 1 25 103391232 159 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 17:23:21 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 17:23:32 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 17:23:41 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 17:23:51 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 17:23:54 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 17:24:00 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 17:24:13 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 17:26:56 INFO mapreduce.Job: Task Id : attempt_1422482982071_5062_r_000012_2, Status : FAILED
Container [pid=2909,containerID=container_1422482982071_5062_01_000279] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5062_01_000279 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 2919 2909 2909 2909 (java) 6388 1325 13312589824 577410 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000279/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000279 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000012_2 279 
	|- 2909 10269 2909 2909 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5062/container_1422482982071_5062_01_000279/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000279 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.195 53365 attempt_1422482982071_5062_r_000012_2 279 1>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000279/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5062/container_1422482982071_5062_01_000279/stderr  
	|- 3056 3045 2909 2909 (cat) 0 26 4231168 142 cat 
	|- 3057 3045 2909 2909 (cat) 0 0 4231168 135 cat 
	|- 3045 2919 2909 2909 (R) 115623 52390 10649780224 2576984 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce4805c23addc 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 17:26:57 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 17:27:15 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 17:27:37 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 17:27:52 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 17:27:55 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 17:38:28 INFO mapreduce.Job:  map 100% reduce 100%
15/04/15 17:38:28 INFO mapreduce.Job: Job job_1422482982071_5062 failed with state FAILED due to: Task failed task_1422482982071_5062_r_000010
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/15 17:38:28 INFO mapreduce.Job: Counters: 56
	File System Counters
		FILE: Number of bytes read=32427913508
		FILE: Number of bytes written=81931959084
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=27107640365
		HDFS: Number of bytes written=2604107591
		HDFS: Number of read operations=639
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=22
	Job Counters 
		Failed map tasks=1
		Failed reduce tasks=14
		Killed map tasks=1
		Killed reduce tasks=3
		Launched map tasks=204
		Launched reduce tasks=28
		Other local map tasks=2
		Data-local map tasks=150
		Rack-local map tasks=52
		Total time spent by all maps in occupied slots (ms)=34287314
		Total time spent by all reduces in occupied slots (ms)=75819496
		Total time spent by all map tasks (ms)=17143657
		Total time spent by all reduce tasks (ms)=37909748
		Total vcore-seconds taken by all map tasks=17143657
		Total vcore-seconds taken by all reduce tasks=37909748
		Total megabyte-seconds taken by all map tasks=138795047072
		Total megabyte-seconds taken by all reduce tasks=454916976000
	Map-Reduce Framework
		Map input records=632973453
		Map output records=567321079
		Map output bytes=48319023743
		Map output materialized bytes=49483448434
		Input split bytes=31916
		Combine input records=0
		Combine output records=0
		Reduce input groups=43334696
		Reduce shuffle bytes=32427926606
		Reduce input records=415715388
		Reduce output records=43549444
		Spilled Records=983036467
		Shuffled Maps =2222
		Failed Shuffles=0
		Merged Map outputs=2222
		GC time elapsed (ms)=136730
		CPU time spent (ms)=33724680
		Physical memory (bytes) snapshot=418985496576
		Virtual memory (bytes) snapshot=2000777863168
		Total committed heap usage (bytes)=583310929920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27107608449
	File Output Format Counters 
		Bytes Written=2604107591
	rmr
		reduce calls=43334696
15/04/15 17:38:28 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/15 17:38:34 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file48053b8b3f2f

real	85m13.398s
user	0m37.386s
sys	0m4.434s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-202-5-false-googlebooks-eng-all-5gram-20120701-on"

$hadoop$D
[1] "mapreduce.job.maps=202"

$hadoop$D
[1] "mapred.reduce.tasks=5"


15/04/15 17:38:40 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/15 17:38:40 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob6491240172382575524.jar tmpDir=null
15/04/15 17:38:41 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 17:38:41 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 17:38:42 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.149:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.192:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.162:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.163:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.203:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.190:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.199:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/15 17:38:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.195:50010
15/04/15 17:38:42 INFO mapreduce.JobSubmitter: number of splits:202
15/04/15 17:38:42 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_5072
15/04/15 17:38:43 INFO impl.YarnClientImpl: Submitted application application_1422482982071_5072
15/04/15 17:38:43 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_5072/
15/04/15 17:38:43 INFO mapreduce.Job: Running job: job_1422482982071_5072
15/04/15 17:38:47 INFO mapreduce.Job: Job job_1422482982071_5072 running in uber mode : false
15/04/15 17:38:47 INFO mapreduce.Job:  map 0% reduce 0%
15/04/15 17:38:57 INFO mapreduce.Job:  map 1% reduce 0%
15/04/15 17:38:58 INFO mapreduce.Job:  map 2% reduce 0%
15/04/15 17:38:59 INFO mapreduce.Job:  map 4% reduce 0%
15/04/15 17:39:00 INFO mapreduce.Job:  map 5% reduce 0%
15/04/15 17:39:01 INFO mapreduce.Job:  map 6% reduce 0%
15/04/15 17:39:02 INFO mapreduce.Job:  map 7% reduce 0%
15/04/15 17:39:03 INFO mapreduce.Job:  map 8% reduce 0%
15/04/15 17:39:04 INFO mapreduce.Job:  map 9% reduce 0%
15/04/15 17:39:05 INFO mapreduce.Job:  map 10% reduce 0%
15/04/15 17:39:06 INFO mapreduce.Job:  map 11% reduce 0%
15/04/15 17:39:07 INFO mapreduce.Job:  map 12% reduce 0%
15/04/15 17:39:08 INFO mapreduce.Job:  map 13% reduce 0%
15/04/15 17:39:09 INFO mapreduce.Job:  map 14% reduce 0%
15/04/15 17:39:10 INFO mapreduce.Job:  map 16% reduce 0%
15/04/15 17:39:12 INFO mapreduce.Job:  map 17% reduce 0%
15/04/15 17:39:13 INFO mapreduce.Job:  map 19% reduce 0%
15/04/15 17:39:14 INFO mapreduce.Job:  map 20% reduce 0%
15/04/15 17:39:16 INFO mapreduce.Job:  map 22% reduce 0%
15/04/15 17:39:17 INFO mapreduce.Job:  map 23% reduce 0%
15/04/15 17:39:18 INFO mapreduce.Job:  map 24% reduce 0%
15/04/15 17:39:19 INFO mapreduce.Job:  map 25% reduce 0%
15/04/15 17:39:20 INFO mapreduce.Job:  map 26% reduce 0%
15/04/15 17:39:21 INFO mapreduce.Job:  map 27% reduce 0%
15/04/15 17:39:22 INFO mapreduce.Job:  map 28% reduce 0%
15/04/15 17:39:23 INFO mapreduce.Job:  map 29% reduce 0%
15/04/15 17:39:24 INFO mapreduce.Job:  map 30% reduce 0%
15/04/15 17:39:25 INFO mapreduce.Job:  map 32% reduce 0%
15/04/15 17:39:26 INFO mapreduce.Job:  map 33% reduce 0%
15/04/15 17:39:28 INFO mapreduce.Job:  map 35% reduce 0%
15/04/15 17:39:29 INFO mapreduce.Job:  map 36% reduce 0%
15/04/15 17:39:31 INFO mapreduce.Job:  map 38% reduce 0%
15/04/15 17:39:32 INFO mapreduce.Job:  map 39% reduce 0%
15/04/15 17:39:33 INFO mapreduce.Job:  map 40% reduce 0%
15/04/15 17:39:34 INFO mapreduce.Job:  map 41% reduce 0%
15/04/15 17:39:35 INFO mapreduce.Job:  map 42% reduce 0%
15/04/15 17:39:36 INFO mapreduce.Job:  map 43% reduce 0%
15/04/15 17:39:37 INFO mapreduce.Job:  map 45% reduce 0%
15/04/15 17:39:39 INFO mapreduce.Job:  map 46% reduce 0%
15/04/15 17:39:40 INFO mapreduce.Job:  map 48% reduce 0%
15/04/15 17:39:41 INFO mapreduce.Job:  map 49% reduce 0%
15/04/15 17:39:43 INFO mapreduce.Job:  map 51% reduce 0%
15/04/15 17:39:44 INFO mapreduce.Job:  map 52% reduce 0%
15/04/15 17:39:45 INFO mapreduce.Job:  map 53% reduce 0%
15/04/15 17:39:46 INFO mapreduce.Job:  map 54% reduce 0%
15/04/15 17:39:48 INFO mapreduce.Job:  map 55% reduce 0%
15/04/15 17:39:49 INFO mapreduce.Job:  map 56% reduce 0%
15/04/15 17:39:50 INFO mapreduce.Job:  map 57% reduce 0%
15/04/15 17:39:51 INFO mapreduce.Job:  map 58% reduce 0%
15/04/15 17:39:52 INFO mapreduce.Job:  map 59% reduce 0%
15/04/15 17:39:54 INFO mapreduce.Job:  map 60% reduce 0%
15/04/15 17:39:56 INFO mapreduce.Job:  map 61% reduce 0%
15/04/15 17:39:59 INFO mapreduce.Job:  map 62% reduce 0%
15/04/15 17:40:02 INFO mapreduce.Job:  map 63% reduce 0%
15/04/15 17:40:05 INFO mapreduce.Job:  map 65% reduce 0%
15/04/15 17:40:06 INFO mapreduce.Job:  map 68% reduce 0%
15/04/15 17:40:07 INFO mapreduce.Job:  map 71% reduce 0%
15/04/15 17:40:08 INFO mapreduce.Job:  map 74% reduce 0%
15/04/15 17:40:09 INFO mapreduce.Job:  map 77% reduce 0%
15/04/15 17:40:10 INFO mapreduce.Job:  map 80% reduce 0%
15/04/15 17:40:11 INFO mapreduce.Job:  map 82% reduce 0%
15/04/15 17:40:12 INFO mapreduce.Job:  map 85% reduce 0%
15/04/15 17:40:13 INFO mapreduce.Job:  map 86% reduce 0%
15/04/15 17:40:14 INFO mapreduce.Job:  map 87% reduce 0%
15/04/15 17:40:15 INFO mapreduce.Job:  map 89% reduce 0%
15/04/15 17:40:16 INFO mapreduce.Job:  map 89% reduce 4%
15/04/15 17:40:17 INFO mapreduce.Job:  map 90% reduce 4%
15/04/15 17:40:18 INFO mapreduce.Job:  map 91% reduce 4%
15/04/15 17:40:20 INFO mapreduce.Job:  map 92% reduce 4%
15/04/15 17:40:24 INFO mapreduce.Job:  map 93% reduce 5%
15/04/15 17:40:28 INFO mapreduce.Job:  map 93% reduce 6%
15/04/15 17:40:31 INFO mapreduce.Job:  map 94% reduce 7%
15/04/15 17:40:34 INFO mapreduce.Job:  map 94% reduce 8%
15/04/15 17:40:37 INFO mapreduce.Job:  map 94% reduce 9%
15/04/15 17:40:40 INFO mapreduce.Job:  map 94% reduce 11%
15/04/15 17:40:42 INFO mapreduce.Job:  map 96% reduce 11%
15/04/15 17:40:44 INFO mapreduce.Job:  map 97% reduce 11%
15/04/15 17:40:46 INFO mapreduce.Job:  map 98% reduce 13%
15/04/15 17:40:47 INFO mapreduce.Job:  map 99% reduce 13%
15/04/15 17:40:49 INFO mapreduce.Job:  map 100% reduce 14%
15/04/15 17:40:52 INFO mapreduce.Job:  map 100% reduce 15%
15/04/15 17:40:55 INFO mapreduce.Job:  map 100% reduce 16%
15/04/15 17:40:58 INFO mapreduce.Job:  map 100% reduce 18%
15/04/15 17:41:04 INFO mapreduce.Job:  map 100% reduce 20%
15/04/15 17:41:10 INFO mapreduce.Job:  map 100% reduce 21%
15/04/15 17:41:13 INFO mapreduce.Job:  map 100% reduce 22%
15/04/15 17:41:16 INFO mapreduce.Job:  map 100% reduce 23%
15/04/15 17:41:19 INFO mapreduce.Job:  map 100% reduce 24%
15/04/15 17:41:22 INFO mapreduce.Job:  map 100% reduce 25%
15/04/15 17:41:24 INFO mapreduce.Job:  map 100% reduce 26%
15/04/15 17:41:25 INFO mapreduce.Job:  map 100% reduce 27%
15/04/15 17:41:31 INFO mapreduce.Job:  map 100% reduce 28%
15/04/15 17:41:32 INFO mapreduce.Job:  map 100% reduce 29%
15/04/15 17:41:34 INFO mapreduce.Job:  map 100% reduce 30%
15/04/15 17:41:38 INFO mapreduce.Job:  map 100% reduce 31%
15/04/15 17:41:42 INFO mapreduce.Job:  map 100% reduce 32%
15/04/15 17:41:49 INFO mapreduce.Job:  map 100% reduce 35%
15/04/15 17:41:50 INFO mapreduce.Job:  map 100% reduce 36%
15/04/15 17:41:51 INFO mapreduce.Job:  map 100% reduce 43%
15/04/15 17:41:52 INFO mapreduce.Job:  map 100% reduce 45%
15/04/15 17:41:53 INFO mapreduce.Job:  map 100% reduce 49%
15/04/15 17:41:55 INFO mapreduce.Job:  map 100% reduce 51%
15/04/15 17:41:56 INFO mapreduce.Job:  map 100% reduce 54%
15/04/15 17:41:59 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 17:42:04 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 17:44:32 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 17:52:16 INFO mapreduce.Job:  map 100% reduce 69%
15/04/15 17:56:05 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 17:57:20 INFO mapreduce.Job: Task Id : attempt_1422482982071_5072_r_000003_0, Status : FAILED
Container [pid=24850,containerID=container_1422482982071_5072_01_000259] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.8 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5072_01_000259 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 25070 25059 24850 24850 (cat) 0 23 4231168 143 cat 
	|- 25071 25059 24850 24850 (cat) 0 0 4231168 138 cat 
	|- 25059 24860 24850 24850 (R) 79951 13022 10084212736 2438888 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce578f77ea19ca 
	|- 24860 24850 24850 24850 (java) 10649 1617 13313396736 647559 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000259/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000259 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000003_0 259 
	|- 24850 9550 24850 24850 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000259/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000259 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000003_0 259 1>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000259/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000259/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 17:57:21 INFO mapreduce.Job:  map 100% reduce 57%
15/04/15 17:57:42 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 17:57:54 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 17:58:04 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 17:58:22 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 17:58:34 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 17:58:57 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 17:58:59 INFO mapreduce.Job: Task Id : attempt_1422482982071_5072_r_000001_0, Status : FAILED
Container [pid=46932,containerID=container_1422482982071_5072_01_000257] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.8 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5072_01_000257 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 47082 46941 46932 46932 (R) 90222 11955 10076844032 2437122 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce578f77ea19ca 
	|- 46941 46932 46932 46932 (java) 10249 1723 13314961408 655946 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000257/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000257 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000001_0 257 
	|- 46932 9245 46932 46932 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000257/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000257 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000001_0 257 1>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000257/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000257/stderr  
	|- 47093 47082 46932 46932 (cat) 1 39 4231168 142 cat 
	|- 47094 47082 46932 46932 (cat) 0 0 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 17:59:00 INFO mapreduce.Job:  map 100% reduce 49%
15/04/15 17:59:06 INFO mapreduce.Job:  map 100% reduce 50%
15/04/15 17:59:11 INFO mapreduce.Job:  map 100% reduce 51%
15/04/15 17:59:18 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 17:59:20 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 17:59:32 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 17:59:54 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 18:00:06 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 18:00:27 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 18:00:39 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 18:00:51 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 18:00:54 INFO mapreduce.Job:  map 100% reduce 69%
15/04/15 18:00:57 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 18:03:34 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 18:04:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_5072_r_000002_0, Status : FAILED
Container [pid=37480,containerID=container_1422482982071_5072_01_000258] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5072_01_000258 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 37480 9608 37480 37480 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000258/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000258 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000002_0 258 1>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000258/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000258/stderr  
	|- 37663 37652 37480 37480 (cat) 0 25 4231168 142 cat 
	|- 37652 37489 37480 37480 (R) 102636 31222 9869516800 2373713 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce578f77ea19ca 
	|- 37489 37480 37480 37480 (java) 11254 1959 13313613824 713209 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000258/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000258 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000002_0 258 
	|- 37676 37652 37480 37480 (cat) 0 0 4231168 134 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 18:04:18 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 18:04:28 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 18:04:34 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 18:04:52 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 18:05:05 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 18:05:23 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 18:05:32 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 18:05:54 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 18:06:12 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 18:06:15 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 18:10:32 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 18:16:58 INFO mapreduce.Job: Task Id : attempt_1422482982071_5072_r_000000_0, Status : FAILED
Container [pid=19635,containerID=container_1422482982071_5072_01_000256] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5072_01_000256 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 19891 19645 19635 19635 (R) 147238 61964 9893314560 2392314 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce578f77ea19ca 
	|- 19645 19635 19635 19635 (java) 10836 2709 13314129920 691507 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000256/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000256 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000000_0 256 
	|- 19635 9517 19635 19635 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000256/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000256 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000000_0 256 1>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000256/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000256/stderr  
	|- 19897 19891 19635 19635 (cat) 0 50 4231168 142 cat 
	|- 19903 19891 19635 19635 (cat) 0 0 4231168 143 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 18:16:59 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 18:17:09 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 18:17:19 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 18:17:28 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 18:17:49 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 18:17:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_5072_r_000003_1, Status : FAILED
Container [pid=4892,containerID=container_1422482982071_5072_01_000261] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.8 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5072_01_000261 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 4963 4951 4892 4892 (cat) 0 0 4231168 138 cat 
	|- 4902 4892 4892 4892 (java) 12933 2457 13313060864 656596 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000261/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000261 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000003_1 261 
	|- 4892 12336 4892 4892 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000261/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000261 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000003_1 261 1>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000261/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000261/stderr  
	|- 4962 4951 4892 4892 (cat) 0 24 4231168 142 cat 
	|- 4951 4902 4892 4892 (R) 82606 28964 10083897344 2438811 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce578f77ea19ca 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 18:17:53 INFO mapreduce.Job:  map 100% reduce 50%
15/04/15 18:18:04 INFO mapreduce.Job:  map 100% reduce 51%
15/04/15 18:18:10 INFO mapreduce.Job:  map 100% reduce 52%
15/04/15 18:18:19 INFO mapreduce.Job:  map 100% reduce 53%
15/04/15 18:18:23 INFO mapreduce.Job:  map 100% reduce 54%
15/04/15 18:18:35 INFO mapreduce.Job:  map 100% reduce 55%
15/04/15 18:18:56 INFO mapreduce.Job:  map 100% reduce 56%
15/04/15 18:19:02 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 18:19:11 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 18:19:44 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 18:19:53 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 18:20:15 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 18:20:18 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 18:21:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_5072_r_000001_1, Status : FAILED
Container [pid=27357,containerID=container_1422482982071_5072_01_000262] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.7 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5072_01_000262 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 27367 27357 27357 27357 (java) 11758 2103 13314011136 688326 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000262/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000262 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000001_1 262 
	|- 27357 40699 27357 27357 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000262/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000262 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000001_1 262 1>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000262/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000262/stderr  
	|- 27457 27445 27357 27357 (cat) 0 0 4231168 143 cat 
	|- 27456 27445 27357 27357 (cat) 1 40 4231168 142 cat 
	|- 27445 27367 27357 27357 (R) 104449 19268 9974841344 2412218 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce578f77ea19ca 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 18:21:38 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 18:21:49 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 18:21:58 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 18:22:10 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 18:22:22 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 18:22:40 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 18:22:52 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 18:23:17 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 18:23:29 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 18:23:32 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 18:23:35 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 18:23:38 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 18:29:19 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 18:34:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_5072_r_000002_1, Status : FAILED
Container [pid=46386,containerID=container_1422482982071_5072_01_000263] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5072_01_000263 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 46609 46586 46386 46386 (cat) 0 0 4231168 134 cat 
	|- 46386 8968 46386 46386 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000263/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000263 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000002_1 263 1>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000263/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000263/stderr  
	|- 46597 46586 46386 46386 (cat) 0 27 4231168 142 cat 
	|- 46586 46396 46386 46386 (R) 114446 57124 10476498944 2465117 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce578f77ea19ca 
	|- 46396 46386 46386 46386 (java) 11024 2102 13312294912 673651 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000263/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000263 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000002_1 263 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 18:34:51 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 18:35:02 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 18:35:20 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 18:35:38 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 18:35:50 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 18:35:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_5072_r_000003_2, Status : FAILED
Container [pid=45786,containerID=container_1422482982071_5072_01_000265] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.4 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5072_01_000265 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 45850 45796 45786 45786 (R) 80402 12937 10337443840 2460172 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce578f77ea19ca 
	|- 45786 3817 45786 45786 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000265/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000265 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000003_2 265 1>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000265/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000265/stderr  
	|- 45862 45850 45786 45786 (cat) 0 0 103391232 155 cat 
	|- 45861 45850 45786 45786 (cat) 0 24 103391232 159 cat 
	|- 45796 45786 45786 45786 (java) 10557 1686 13412401152 611534 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000265/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000265 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000003_2 265 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 18:35:58 INFO mapreduce.Job:  map 100% reduce 51%
15/04/15 18:36:03 INFO mapreduce.Job:  map 100% reduce 52%
15/04/15 18:36:09 INFO mapreduce.Job:  map 100% reduce 53%
15/04/15 18:36:19 INFO mapreduce.Job:  map 100% reduce 54%
15/04/15 18:36:24 INFO mapreduce.Job:  map 100% reduce 55%
15/04/15 18:36:33 INFO mapreduce.Job:  map 100% reduce 56%
15/04/15 18:36:43 INFO mapreduce.Job:  map 100% reduce 57%
15/04/15 18:36:58 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 18:37:22 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 18:37:25 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 18:37:44 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 18:38:06 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 18:38:09 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 18:40:26 INFO mapreduce.Job: Task Id : attempt_1422482982071_5072_r_000001_2, Status : FAILED
Container [pid=427,containerID=container_1422482982071_5072_01_000266] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5072_01_000266 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 595 584 427 427 (cat) 1 38 4231168 143 cat 
	|- 427 10211 427 427 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000266/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000266 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000001_2 266 1>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000266/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000266/stderr  
	|- 596 584 427 427 (cat) 0 0 4231168 142 cat 
	|- 584 437 427 427 (R) 90386 10458 10384486400 2512197 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce578f77ea19ca 
	|- 437 427 427 427 (java) 10124 1577 13316558848 612939 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000266/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000266 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000001_2 266 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 18:40:27 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 18:40:38 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 18:41:00 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 18:41:12 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 18:41:40 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 18:41:52 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 18:42:04 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 18:42:34 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 18:42:37 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 18:42:40 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 18:45:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_5072_r_000000_1, Status : FAILED
Container [pid=45625,containerID=container_1422482982071_5072_01_000264] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5072_01_000264 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 45734 45723 45625 45625 (cat) 0 50 4231168 142 cat 
	|- 45625 8938 45625 45625 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000264/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000264 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000000_1 264 1>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000264/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000264/stderr  
	|- 45723 45635 45625 45625 (R) 140098 20426 10282852352 2443583 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce578f77ea19ca 
	|- 45635 45625 45625 45625 (java) 10933 1826 13314093056 651843 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5072/container_1422482982071_5072_01_000264/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5072/container_1422482982071_5072_01_000264 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.202 58629 attempt_1422482982071_5072_r_000000_1 264 
	|- 45735 45723 45625 45625 (cat) 0 0 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 18:45:49 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 18:46:01 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 18:46:10 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 18:46:23 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 18:46:44 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 18:46:58 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 18:47:17 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 18:47:29 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 18:47:53 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 18:54:29 INFO mapreduce.Job:  map 100% reduce 100%
15/04/15 18:54:29 INFO mapreduce.Job: Job job_1422482982071_5072 failed with state FAILED due to: Task failed task_1422482982071_5072_r_000003
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/15 18:54:29 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=8609227249
		FILE: Number of bytes written=58112254451
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=27107640365
		HDFS: Number of bytes written=709796723
		HDFS: Number of read operations=609
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed reduce tasks=11
		Killed map tasks=1
		Killed reduce tasks=3
		Launched map tasks=203
		Launched reduce tasks=15
		Data-local map tasks=145
		Rack-local map tasks=58
		Total time spent by all maps in occupied slots (ms)=34708480
		Total time spent by all reduces in occupied slots (ms)=42778532
		Total time spent by all map tasks (ms)=17354240
		Total time spent by all reduce tasks (ms)=21389266
		Total vcore-seconds taken by all map tasks=17354240
		Total vcore-seconds taken by all reduce tasks=21389266
		Total megabyte-seconds taken by all map tasks=140499927040
		Total megabyte-seconds taken by all reduce tasks=256671192000
	Map-Reduce Framework
		Map input records=632973453
		Map output records=567321061
		Map output bytes=48319029689
		Map output materialized bytes=49483442228
		Input split bytes=31916
		Combine input records=0
		Combine output records=0
		Reduce input groups=11812484
		Reduce shuffle bytes=8609228407
		Reduce input records=113540707
		Reduce output records=11870697
		Spilled Records=680861768
		Shuffled Maps =202
		Failed Shuffles=0
		Merged Map outputs=202
		GC time elapsed (ms)=97877
		CPU time spent (ms)=21340770
		Physical memory (bytes) snapshot=395745161216
		Virtual memory (bytes) snapshot=1867716050944
		Total committed heap usage (bytes)=561800519680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27107608449
	File Output Format Counters 
		Bytes Written=709796723
	rmr
		reduce calls=11812484
15/04/15 18:54:29 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/15 18:54:35 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file578fd85acee

real	76m0.464s
user	0m37.166s
sys	0m4.160s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-250-25-false-googlebooks-eng-all-5gram-20120701-on"

$hadoop$D
[1] "mapreduce.job.maps=250"

$hadoop$D
[1] "mapred.reduce.tasks=25"


15/04/15 18:54:41 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/15 18:54:41 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob7558246291515493778.jar tmpDir=null
15/04/15 18:54:41 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 18:54:41 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 18:54:42 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.149:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.192:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.162:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.163:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.203:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.190:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.199:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/15 18:54:42 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.195:50010
15/04/15 18:54:43 INFO mapreduce.JobSubmitter: number of splits:250
15/04/15 18:54:43 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_5076
15/04/15 18:54:44 INFO impl.YarnClientImpl: Submitted application application_1422482982071_5076
15/04/15 18:54:44 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_5076/
15/04/15 18:54:44 INFO mapreduce.Job: Running job: job_1422482982071_5076
15/04/15 18:54:49 INFO mapreduce.Job: Job job_1422482982071_5076 running in uber mode : false
15/04/15 18:54:49 INFO mapreduce.Job:  map 0% reduce 0%
15/04/15 18:55:00 INFO mapreduce.Job:  map 1% reduce 0%
15/04/15 18:55:01 INFO mapreduce.Job:  map 3% reduce 0%
15/04/15 18:55:02 INFO mapreduce.Job:  map 5% reduce 0%
15/04/15 18:55:03 INFO mapreduce.Job:  map 6% reduce 0%
15/04/15 18:55:04 INFO mapreduce.Job:  map 8% reduce 0%
15/04/15 18:55:05 INFO mapreduce.Job:  map 9% reduce 0%
15/04/15 18:55:06 INFO mapreduce.Job:  map 10% reduce 0%
15/04/15 18:55:07 INFO mapreduce.Job:  map 11% reduce 0%
15/04/15 18:55:08 INFO mapreduce.Job:  map 12% reduce 0%
15/04/15 18:55:09 INFO mapreduce.Job:  map 13% reduce 0%
15/04/15 18:55:10 INFO mapreduce.Job:  map 15% reduce 0%
15/04/15 18:55:11 INFO mapreduce.Job:  map 16% reduce 0%
15/04/15 18:55:12 INFO mapreduce.Job:  map 17% reduce 0%
15/04/15 18:55:13 INFO mapreduce.Job:  map 19% reduce 0%
15/04/15 18:55:14 INFO mapreduce.Job:  map 20% reduce 0%
15/04/15 18:55:15 INFO mapreduce.Job:  map 21% reduce 0%
15/04/15 18:55:16 INFO mapreduce.Job:  map 23% reduce 0%
15/04/15 18:55:17 INFO mapreduce.Job:  map 24% reduce 0%
15/04/15 18:55:18 INFO mapreduce.Job:  map 25% reduce 0%
15/04/15 18:55:19 INFO mapreduce.Job:  map 27% reduce 0%
15/04/15 18:55:20 INFO mapreduce.Job:  map 28% reduce 0%
15/04/15 18:55:21 INFO mapreduce.Job:  map 29% reduce 0%
15/04/15 18:55:22 INFO mapreduce.Job:  map 31% reduce 0%
15/04/15 18:55:23 INFO mapreduce.Job:  map 32% reduce 0%
15/04/15 18:55:24 INFO mapreduce.Job:  map 33% reduce 0%
15/04/15 18:55:25 INFO mapreduce.Job:  map 35% reduce 0%
15/04/15 18:55:26 INFO mapreduce.Job:  map 36% reduce 0%
15/04/15 18:55:27 INFO mapreduce.Job:  map 37% reduce 0%
15/04/15 18:55:28 INFO mapreduce.Job:  map 38% reduce 0%
15/04/15 18:55:29 INFO mapreduce.Job:  map 39% reduce 0%
15/04/15 18:55:30 INFO mapreduce.Job:  map 41% reduce 0%
15/04/15 18:55:31 INFO mapreduce.Job:  map 42% reduce 0%
15/04/15 18:55:32 INFO mapreduce.Job:  map 43% reduce 0%
15/04/15 18:55:33 INFO mapreduce.Job:  map 44% reduce 0%
15/04/15 18:55:34 INFO mapreduce.Job:  map 46% reduce 0%
15/04/15 18:55:35 INFO mapreduce.Job:  map 47% reduce 0%
15/04/15 18:55:36 INFO mapreduce.Job:  map 48% reduce 0%
15/04/15 18:55:37 INFO mapreduce.Job:  map 50% reduce 0%
15/04/15 18:55:38 INFO mapreduce.Job:  map 51% reduce 0%
15/04/15 18:55:39 INFO mapreduce.Job:  map 52% reduce 0%
15/04/15 18:55:40 INFO mapreduce.Job:  map 54% reduce 0%
15/04/15 18:55:41 INFO mapreduce.Job:  map 55% reduce 0%
15/04/15 18:55:42 INFO mapreduce.Job:  map 56% reduce 0%
15/04/15 18:55:43 INFO mapreduce.Job:  map 58% reduce 0%
15/04/15 18:55:45 INFO mapreduce.Job:  map 59% reduce 0%
15/04/15 18:55:46 INFO mapreduce.Job:  map 61% reduce 0%
15/04/15 18:55:48 INFO mapreduce.Job:  map 62% reduce 0%
15/04/15 18:55:50 INFO mapreduce.Job:  map 63% reduce 0%
15/04/15 18:55:52 INFO mapreduce.Job:  map 64% reduce 0%
15/04/15 18:55:53 INFO mapreduce.Job:  map 65% reduce 0%
15/04/15 18:55:54 INFO mapreduce.Job:  map 67% reduce 0%
15/04/15 18:55:55 INFO mapreduce.Job:  map 69% reduce 0%
15/04/15 18:55:56 INFO mapreduce.Job:  map 73% reduce 0%
15/04/15 18:55:57 INFO mapreduce.Job:  map 76% reduce 0%
15/04/15 18:55:58 INFO mapreduce.Job:  map 79% reduce 0%
15/04/15 18:55:59 INFO mapreduce.Job:  map 82% reduce 0%
15/04/15 18:56:00 INFO mapreduce.Job:  map 84% reduce 0%
15/04/15 18:56:01 INFO mapreduce.Job:  map 87% reduce 0%
15/04/15 18:56:02 INFO mapreduce.Job:  map 88% reduce 0%
15/04/15 18:56:03 INFO mapreduce.Job:  map 90% reduce 0%
15/04/15 18:56:04 INFO mapreduce.Job:  map 91% reduce 19%
15/04/15 18:56:05 INFO mapreduce.Job:  map 92% reduce 19%
15/04/15 18:56:07 INFO mapreduce.Job:  map 93% reduce 19%
15/04/15 18:56:12 INFO mapreduce.Job:  map 94% reduce 19%
15/04/15 18:56:13 INFO mapreduce.Job:  map 94% reduce 21%
15/04/15 18:56:16 INFO mapreduce.Job:  map 94% reduce 23%
15/04/15 18:56:19 INFO mapreduce.Job:  map 94% reduce 26%
15/04/15 18:56:22 INFO mapreduce.Job:  map 95% reduce 26%
15/04/15 18:56:23 INFO mapreduce.Job:  map 95% reduce 27%
15/04/15 18:56:24 INFO mapreduce.Job:  map 96% reduce 28%
15/04/15 18:56:25 INFO mapreduce.Job:  map 97% reduce 28%
15/04/15 18:56:26 INFO mapreduce.Job:  map 97% reduce 29%
15/04/15 18:56:28 INFO mapreduce.Job:  map 98% reduce 29%
15/04/15 18:56:29 INFO mapreduce.Job:  map 99% reduce 31%
15/04/15 18:56:30 INFO mapreduce.Job:  map 99% reduce 32%
15/04/15 18:56:33 INFO mapreduce.Job:  map 99% reduce 33%
15/04/15 18:56:34 INFO mapreduce.Job:  map 100% reduce 33%
15/04/15 18:56:41 INFO mapreduce.Job:  map 100% reduce 37%
15/04/15 18:56:42 INFO mapreduce.Job:  map 100% reduce 38%
15/04/15 18:56:43 INFO mapreduce.Job:  map 100% reduce 39%
15/04/15 18:56:44 INFO mapreduce.Job:  map 100% reduce 47%
15/04/15 18:56:45 INFO mapreduce.Job:  map 100% reduce 49%
15/04/15 18:56:47 INFO mapreduce.Job:  map 100% reduce 54%
15/04/15 18:56:48 INFO mapreduce.Job:  map 100% reduce 56%
15/04/15 18:56:50 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 18:56:51 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 18:56:53 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 18:56:54 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 18:57:03 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 18:57:15 INFO mapreduce.Job:  map 100% reduce 69%
15/04/15 18:57:27 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 18:57:42 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 18:57:56 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 18:58:06 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 18:58:21 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 18:58:35 INFO mapreduce.Job:  map 100% reduce 75%
15/04/15 18:58:53 INFO mapreduce.Job:  map 100% reduce 76%
15/04/15 18:59:12 INFO mapreduce.Job:  map 100% reduce 77%
15/04/15 18:59:33 INFO mapreduce.Job:  map 100% reduce 78%
15/04/15 18:59:52 INFO mapreduce.Job:  map 100% reduce 79%
15/04/15 19:00:19 INFO mapreduce.Job:  map 100% reduce 80%
15/04/15 19:00:43 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 19:01:07 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 19:01:33 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 19:02:03 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 19:02:34 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 19:03:08 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 19:03:43 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 19:04:26 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 19:05:11 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 19:06:13 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:07:08 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:09:11 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:16:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000021_0, Status : FAILED
Container [pid=4223,containerID=container_1422482982071_5076_01_000326] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000326 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 4351 4340 4223 4223 (cat) 1 28 4231168 142 cat 
	|- 4353 4340 4223 4223 (cat) 0 0 4231168 138 cat 
	|- 4340 4232 4223 4223 (R) 97921 17299 10470363136 2533164 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 4223 8824 4223 4223 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000326/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000326 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000021_0 326 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000326/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000326/stderr  
	|- 4232 4223 4223 4223 (java) 4854 698 13313204224 584803 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000326/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000326 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000021_0 326 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:16:02 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:16:22 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:16:32 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:17:04 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000018_0, Status : FAILED
Container [pid=1633,containerID=container_1422482982071_5076_01_000323] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000323 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 1830 1797 1633 1633 (cat) 0 0 4231168 139 cat 
	|- 1650 1633 1633 1633 (java) 3815 599 13313605632 553384 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000323/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000323 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000018_0 323 
	|- 1810 1797 1633 1633 (cat) 0 26 4231168 142 cat 
	|- 1797 1650 1633 1633 (R) 102103 19738 10445737984 2527152 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 1633 9245 1633 1633 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000323/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000323 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000018_0 323 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000323/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000323/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:17:05 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:17:06 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000013_0, Status : FAILED
Container [pid=3485,containerID=container_1422482982071_5076_01_000318] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000318 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 3593 3494 3485 3485 (R) 105358 16498 10440073216 2525800 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 3494 3485 3485 3485 (java) 4614 572 13312925696 591375 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000318/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000318 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000013_0 318 
	|- 3485 10433 3485 3485 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000318/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000318 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000013_0 318 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000318/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000318/stderr  
	|- 3606 3593 3485 3485 (cat) 0 0 4231168 135 cat 
	|- 3604 3593 3485 3485 (cat) 0 25 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:17:07 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 19:17:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000015_0, Status : FAILED
Container [pid=1632,containerID=container_1422482982071_5076_01_000320] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000320 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 1831 1819 1632 1632 (cat) 0 27 4231168 142 cat 
	|- 1833 1819 1632 1632 (cat) 0 0 4231168 138 cat 
	|- 1651 1632 1632 1632 (java) 3961 653 13312929792 590903 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000320/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000320 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000015_0 320 
	|- 1632 9245 1632 1632 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000320/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000320 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000015_0 320 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000320/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000320/stderr  
	|- 1819 1651 1632 1632 (R) 106036 16259 10341777408 2501802 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:17:12 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 19:17:17 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 19:17:23 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 19:17:27 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 19:17:34 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 19:17:36 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 19:17:38 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:17:42 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:17:44 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:18:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000017_0, Status : FAILED
Container [pid=561,containerID=container_1422482982071_5076_01_000322] is running beyond physical memory limits. Current usage: 12.1 GB of 11.7 GB physical memory used; 22.8 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000322 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 687 570 561 561 (R) 114082 16863 10716381184 2569117 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 700 687 561 561 (cat) 0 0 103391232 157 cat 
	|- 570 561 561 561 (java) 4957 645 13413601280 591244 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000322/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000322 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000017_0 322 
	|- 698 687 561 561 (cat) 0 48 103391232 159 cat 
	|- 561 3820 561 561 (bash) 0 0 108650496 297 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000322/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000322 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000017_0 322 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000322/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000322/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:18:40 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 19:18:52 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:19:01 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:19:14 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:20:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000012_0, Status : FAILED
Container [pid=48742,containerID=container_1422482982071_5076_01_000317] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000317 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 48742 8968 48742 48742 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000317/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000317 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000012_0 317 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000317/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000317/stderr  
	|- 48751 48742 48742 48742 (java) 5024 965 13312724992 590396 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000317/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000317 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000012_0 317 
	|- 48835 48751 48742 48742 (R) 119501 24807 10600148992 2542124 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 48847 48835 48742 48742 (cat) 0 0 4231168 134 cat 
	|- 48846 48835 48742 48742 (cat) 0 26 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:20:51 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:21:19 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:21:28 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:32:27 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000021_1, Status : FAILED
Container [pid=36113,containerID=container_1422482982071_5076_01_000332] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.8 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000332 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 36165 36123 36113 36113 (R) 81318 13801 10742616064 2575524 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 36113 3810 36113 36113 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000332/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000332 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000021_1 332 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000332/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000332/stderr  
	|- 36123 36113 36113 36113 (java) 4185 687 13412229120 497944 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000332/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000332 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000021_1 332 
	|- 36178 36165 36113 36113 (cat) 0 0 103391232 155 cat 
	|- 36176 36165 36113 36113 (cat) 1 26 103391232 159 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:32:28 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:32:49 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:33:01 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:35:51 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000015_1, Status : FAILED
Container [pid=32991,containerID=container_1422482982071_5076_01_000335] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000335 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 33043 33001 32991 32991 (R) 91715 16381 10397999104 2497968 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 33054 33043 32991 32991 (cat) 0 25 4231168 142 cat 
	|- 33056 33043 32991 32991 (cat) 0 0 4231168 138 cat 
	|- 32991 9420 32991 32991 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000335/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000335 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000015_1 335 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000335/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000335/stderr  
	|- 33001 32991 32991 32991 (java) 4621 872 13312655360 589798 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000335/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000335 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000015_1 335 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:35:52 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:36:14 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:36:32 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:37:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000013_1, Status : FAILED
Container [pid=13846,containerID=container_1422482982071_5076_01_000334] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000334 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 13936 13856 13846 13846 (R) 102812 16873 10660884480 2539463 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 13846 9067 13846 13846 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000334/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000334 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000013_1 334 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000334/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000334/stderr  
	|- 13947 13936 13846 13846 (cat) 0 22 4231168 142 cat 
	|- 13856 13846 13846 13846 (java) 4241 673 13313437696 590345 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000334/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000334 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000013_1 334 
	|- 13949 13936 13846 13846 (cat) 0 0 4231168 135 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:37:42 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:38:03 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:38:15 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:39:02 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000018_1, Status : FAILED
Container [pid=13816,containerID=container_1422482982071_5076_01_000333] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000333 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 13826 13816 13816 13816 (java) 4330 752 13313802240 593537 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000333/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000333 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000018_1 333 
	|- 13927 13916 13816 13816 (cat) 0 26 4231168 142 cat 
	|- 13929 13916 13816 13816 (cat) 0 0 4231168 140 cat 
	|- 13916 13826 13816 13816 (R) 105322 22682 10382475264 2511706 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 13816 9067 13816 13816 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000333/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000333 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000018_1 333 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000333/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000333/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:39:03 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:39:24 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:39:36 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:42:00 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000017_1, Status : FAILED
Container [pid=2599,containerID=container_1422482982071_5076_01_000336] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000336 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 2608 2599 2599 2599 (java) 5246 962 13314527232 589836 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000336/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000336 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000017_1 336 
	|- 2662 2651 2599 2599 (cat) 1 49 4231168 142 cat 
	|- 2599 10211 2599 2599 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000336/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000336 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000017_1 336 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000336/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000336/stderr  
	|- 2651 2608 2599 2599 (R) 116091 19908 10445185024 2527016 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 2664 2651 2599 2599 (cat) 0 0 4231168 140 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:42:01 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 19:42:12 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:42:21 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:42:34 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:42:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000012_1, Status : FAILED
Container [pid=39473,containerID=container_1422482982071_5076_01_000337] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000337 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 39483 39473 39473 39473 (java) 5150 998 13411905536 593957 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000337/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000337 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000012_1 337 
	|- 39537 39525 39473 39473 (cat) 0 0 103391232 152 cat 
	|- 39536 39525 39473 39473 (cat) 0 27 103391232 159 cat 
	|- 39525 39483 39473 39473 (R) 107010 19351 10580066304 2523793 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 39473 7712 39473 39473 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000337/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000337 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000012_1 337 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000337/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000337/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:42:36 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 19:42:47 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:43:02 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:43:11 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:51:35 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000021_2, Status : FAILED
Container [pid=43291,containerID=container_1422482982071_5076_01_000338] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000338 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 43359 43346 43291 43291 (cat) 0 0 4231168 138 cat 
	|- 43301 43291 43291 43291 (java) 4470 767 13311975424 588501 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000338/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000338 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000021_2 338 
	|- 43291 11042 43291 43291 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000338/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000338 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000021_2 338 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000338/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000338/stderr  
	|- 43346 43301 43291 43291 (R) 95561 15395 10425151488 2492879 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 43357 43346 43291 43291 (cat) 0 27 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:51:36 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:51:57 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:52:10 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:57:53 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000013_2, Status : FAILED
Container [pid=33576,containerID=container_1422482982071_5076_01_000340] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000340 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 33586 33576 33576 33576 (java) 4746 816 13312700416 590251 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000340/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000340 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000013_2 340 
	|- 33630 33586 33576 33576 (R) 93962 23323 10366656512 2507844 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 33576 10689 33576 33576 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000340/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000340 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000013_2 340 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000340/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000340/stderr  
	|- 33644 33630 33576 33576 (cat) 0 0 4231168 135 cat 
	|- 33641 33630 33576 33576 (cat) 0 23 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:57:54 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:58:15 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:58:27 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 19:59:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000018_2, Status : FAILED
Container [pid=8186,containerID=container_1422482982071_5076_01_000341] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000341 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 8186 10444 8186 8186 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000341/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000341 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000018_2 341 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000341/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000341/stderr  
	|- 8260 8247 8186 8186 (cat) 0 0 4231168 139 cat 
	|- 8247 8196 8186 8186 (R) 98962 17843 10598887424 2564573 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 8196 8186 8186 8186 (java) 4974 846 13313581056 590073 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000341/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000341 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000018_2 341 
	|- 8258 8247 8186 8186 (cat) 0 25 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 19:59:12 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 19:59:33 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 19:59:45 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 20:04:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000015_2, Status : FAILED
Container [pid=30049,containerID=container_1422482982071_5076_01_000339] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000339 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 30059 30049 30049 30049 (java) 4813 831 13312577536 590746 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000339/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000339 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000015_2 339 
	|- 30114 30101 30049 30049 (cat) 0 0 4231168 138 cat 
	|- 30112 30101 30049 30049 (cat) 0 24 4231168 142 cat 
	|- 30101 30059 30049 30049 (R) 95297 74913 10396999680 2515251 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 30049 9763 30049 30049 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000339/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000339 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000015_2 339 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000339/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000339/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:06:55 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000017_2, Status : FAILED
Container [pid=8003,containerID=container_1422482982071_5076_01_000342] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000342 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 8003 12336 8003 8003 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000342/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000342 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000017_2 342 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000342/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000342/stderr  
	|- 8056 8013 8003 8003 (R) 109249 36165 10489278464 2501283 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 8067 8056 8003 8003 (cat) 0 48 4231168 143 cat 
	|- 8094 8056 8003 8003 (cat) 0 0 4231168 140 cat 
	|- 8013 8003 8003 8003 (java) 4624 797 13313384448 587628 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000342/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000342 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000017_2 342 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:06:56 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 20:07:07 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 20:07:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_5076_r_000012_2, Status : FAILED
Container [pid=8071,containerID=container_1422482982071_5076_01_000343] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5076_01_000343 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 8143 8131 8071 8071 (cat) 0 0 4231168 134 cat 
	|- 8142 8131 8071 8071 (cat) 0 25 4231168 143 cat 
	|- 8071 12336 8071 8071 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000343/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000343 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000012_2 343 1>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000343/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000343/stderr  
	|- 8131 8081 8071 8071 (R) 108166 35810 10336722944 2500523 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce5e5f640128eb 
	|- 8081 8071 8071 8071 (java) 3710 745 13312720896 590595 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5076/container_1422482982071_5076_01_000343/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5076/container_1422482982071_5076_01_000343 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.142 56481 attempt_1422482982071_5076_r_000012_2 343 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:07:17 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 20:07:29 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 20:07:32 INFO mapreduce.Job:  map 100% reduce 90%
15/04/15 20:07:44 INFO mapreduce.Job:  map 100% reduce 91%
15/04/15 20:07:53 INFO mapreduce.Job:  map 100% reduce 92%
15/04/15 20:13:36 INFO mapreduce.Job:  map 100% reduce 100%
15/04/15 20:13:36 INFO mapreduce.Job: Job job_1422482982071_5076 failed with state FAILED due to: Task failed task_1422482982071_5076_r_000021
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/15 20:13:36 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=31862592433
		FILE: Number of bytes written=81371476728
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=27107649938
		HDFS: Number of bytes written=2698909750
		HDFS: Number of read operations=807
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=38
	Job Counters 
		Failed reduce tasks=19
		Killed map tasks=2
		Killed reduce tasks=5
		Launched map tasks=252
		Launched reduce tasks=43
		Data-local map tasks=189
		Rack-local map tasks=63
		Total time spent by all maps in occupied slots (ms)=35485770
		Total time spent by all reduces in occupied slots (ms)=85392528
		Total time spent by all map tasks (ms)=17742885
		Total time spent by all reduce tasks (ms)=42696264
		Total vcore-seconds taken by all map tasks=17742885
		Total vcore-seconds taken by all reduce tasks=42696264
		Total megabyte-seconds taken by all map tasks=143646396960
		Total megabyte-seconds taken by all reduce tasks=512355168000
	Map-Reduce Framework
		Map input records=632973453
		Map output records=567302154
		Map output bytes=48318407154
		Map output materialized bytes=49482813914
		Input split bytes=39500
		Combine input records=0
		Combine output records=0
		Reduce input groups=44903856
		Reduce shuffle bytes=31862620699
		Reduce input records=431108910
		Reduce output records=45129824
		Spilled Records=998411064
		Shuffled Maps =4750
		Failed Shuffles=0
		Merged Map outputs=4750
		GC time elapsed (ms)=145105
		CPU time spent (ms)=32118360
		Physical memory (bytes) snapshot=523092516864
		Virtual memory (bytes) snapshot=2548810899456
		Total committed heap usage (bytes)=732425003008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27107610438
	File Output Format Counters 
		Bytes Written=2698909750
	rmr
		reduce calls=44903856
15/04/15 20:13:36 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/15 20:13:42 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file5e5f1f96a79b

real	79m7.370s
user	0m37.573s
sys	0m4.190s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-250-15-false-googlebooks-eng-all-5gram-20120701-on"

$hadoop$D
[1] "mapreduce.job.maps=250"

$hadoop$D
[1] "mapred.reduce.tasks=15"


15/04/15 20:13:48 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/15 20:13:48 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob2779645124571046212.jar tmpDir=null
15/04/15 20:13:49 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 20:13:49 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 20:13:50 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.149:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.192:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.162:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.163:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.203:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.190:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.199:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/15 20:13:50 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.195:50010
15/04/15 20:13:50 INFO mapreduce.JobSubmitter: number of splits:250
15/04/15 20:13:51 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_5078
15/04/15 20:13:51 INFO impl.YarnClientImpl: Submitted application application_1422482982071_5078
15/04/15 20:13:51 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_5078/
15/04/15 20:13:51 INFO mapreduce.Job: Running job: job_1422482982071_5078
15/04/15 20:13:57 INFO mapreduce.Job: Job job_1422482982071_5078 running in uber mode : false
15/04/15 20:13:57 INFO mapreduce.Job:  map 0% reduce 0%
15/04/15 20:14:08 INFO mapreduce.Job:  map 2% reduce 0%
15/04/15 20:14:09 INFO mapreduce.Job:  map 4% reduce 0%
15/04/15 20:14:11 INFO mapreduce.Job:  map 5% reduce 0%
15/04/15 20:14:12 INFO mapreduce.Job:  map 7% reduce 0%
15/04/15 20:14:13 INFO mapreduce.Job:  map 8% reduce 0%
15/04/15 20:14:14 INFO mapreduce.Job:  map 9% reduce 0%
15/04/15 20:14:15 INFO mapreduce.Job:  map 11% reduce 0%
15/04/15 20:14:16 INFO mapreduce.Job:  map 12% reduce 0%
15/04/15 20:14:17 INFO mapreduce.Job:  map 13% reduce 0%
15/04/15 20:14:18 INFO mapreduce.Job:  map 14% reduce 0%
15/04/15 20:14:19 INFO mapreduce.Job:  map 16% reduce 0%
15/04/15 20:14:20 INFO mapreduce.Job:  map 17% reduce 0%
15/04/15 20:14:21 INFO mapreduce.Job:  map 18% reduce 0%
15/04/15 20:14:22 INFO mapreduce.Job:  map 20% reduce 0%
15/04/15 20:14:23 INFO mapreduce.Job:  map 21% reduce 0%
15/04/15 20:14:24 INFO mapreduce.Job:  map 22% reduce 0%
15/04/15 20:14:25 INFO mapreduce.Job:  map 24% reduce 0%
15/04/15 20:14:26 INFO mapreduce.Job:  map 25% reduce 0%
15/04/15 20:14:27 INFO mapreduce.Job:  map 26% reduce 0%
15/04/15 20:14:28 INFO mapreduce.Job:  map 28% reduce 0%
15/04/15 20:14:29 INFO mapreduce.Job:  map 29% reduce 0%
15/04/15 20:14:30 INFO mapreduce.Job:  map 30% reduce 0%
15/04/15 20:14:31 INFO mapreduce.Job:  map 32% reduce 0%
15/04/15 20:14:32 INFO mapreduce.Job:  map 33% reduce 0%
15/04/15 20:14:33 INFO mapreduce.Job:  map 34% reduce 0%
15/04/15 20:14:34 INFO mapreduce.Job:  map 36% reduce 0%
15/04/15 20:14:35 INFO mapreduce.Job:  map 37% reduce 0%
15/04/15 20:14:36 INFO mapreduce.Job:  map 38% reduce 0%
15/04/15 20:14:37 INFO mapreduce.Job:  map 40% reduce 0%
15/04/15 20:14:38 INFO mapreduce.Job:  map 41% reduce 0%
15/04/15 20:14:39 INFO mapreduce.Job:  map 43% reduce 0%
15/04/15 20:14:40 INFO mapreduce.Job:  map 44% reduce 0%
15/04/15 20:14:41 INFO mapreduce.Job:  map 45% reduce 0%
15/04/15 20:14:42 INFO mapreduce.Job:  map 46% reduce 0%
15/04/15 20:14:43 INFO mapreduce.Job:  map 48% reduce 0%
15/04/15 20:14:44 INFO mapreduce.Job:  map 49% reduce 0%
15/04/15 20:14:45 INFO mapreduce.Job:  map 50% reduce 0%
15/04/15 20:14:46 INFO mapreduce.Job:  map 52% reduce 0%
15/04/15 20:14:47 INFO mapreduce.Job:  map 53% reduce 0%
15/04/15 20:14:48 INFO mapreduce.Job:  map 54% reduce 0%
15/04/15 20:14:49 INFO mapreduce.Job:  map 56% reduce 0%
15/04/15 20:14:50 INFO mapreduce.Job:  map 57% reduce 0%
15/04/15 20:14:51 INFO mapreduce.Job:  map 58% reduce 0%
15/04/15 20:14:52 INFO mapreduce.Job:  map 59% reduce 0%
15/04/15 20:14:53 INFO mapreduce.Job:  map 60% reduce 0%
15/04/15 20:14:54 INFO mapreduce.Job:  map 61% reduce 0%
15/04/15 20:14:56 INFO mapreduce.Job:  map 62% reduce 0%
15/04/15 20:14:58 INFO mapreduce.Job:  map 63% reduce 0%
15/04/15 20:15:01 INFO mapreduce.Job:  map 64% reduce 0%
15/04/15 20:15:02 INFO mapreduce.Job:  map 66% reduce 0%
15/04/15 20:15:03 INFO mapreduce.Job:  map 70% reduce 0%
15/04/15 20:15:04 INFO mapreduce.Job:  map 74% reduce 0%
15/04/15 20:15:05 INFO mapreduce.Job:  map 78% reduce 0%
15/04/15 20:15:06 INFO mapreduce.Job:  map 81% reduce 0%
15/04/15 20:15:07 INFO mapreduce.Job:  map 84% reduce 0%
15/04/15 20:15:08 INFO mapreduce.Job:  map 85% reduce 0%
15/04/15 20:15:09 INFO mapreduce.Job:  map 88% reduce 0%
15/04/15 20:15:10 INFO mapreduce.Job:  map 90% reduce 0%
15/04/15 20:15:11 INFO mapreduce.Job:  map 91% reduce 0%
15/04/15 20:15:12 INFO mapreduce.Job:  map 92% reduce 9%
15/04/15 20:15:13 INFO mapreduce.Job:  map 92% reduce 12%
15/04/15 20:15:15 INFO mapreduce.Job:  map 93% reduce 12%
15/04/15 20:15:21 INFO mapreduce.Job:  map 94% reduce 12%
15/04/15 20:15:22 INFO mapreduce.Job:  map 94% reduce 13%
15/04/15 20:15:25 INFO mapreduce.Job:  map 94% reduce 16%
15/04/15 20:15:28 INFO mapreduce.Job:  map 94% reduce 17%
15/04/15 20:15:31 INFO mapreduce.Job:  map 96% reduce 19%
15/04/15 20:15:32 INFO mapreduce.Job:  map 97% reduce 19%
15/04/15 20:15:34 INFO mapreduce.Job:  map 98% reduce 21%
15/04/15 20:15:35 INFO mapreduce.Job:  map 99% reduce 21%
15/04/15 20:15:37 INFO mapreduce.Job:  map 99% reduce 23%
15/04/15 20:15:38 INFO mapreduce.Job:  map 100% reduce 23%
15/04/15 20:15:40 INFO mapreduce.Job:  map 100% reduce 27%
15/04/15 20:15:43 INFO mapreduce.Job:  map 100% reduce 31%
15/04/15 20:15:46 INFO mapreduce.Job:  map 100% reduce 35%
15/04/15 20:15:49 INFO mapreduce.Job:  map 100% reduce 38%
15/04/15 20:15:50 INFO mapreduce.Job:  map 100% reduce 39%
15/04/15 20:15:52 INFO mapreduce.Job:  map 100% reduce 44%
15/04/15 20:15:55 INFO mapreduce.Job:  map 100% reduce 48%
15/04/15 20:15:58 INFO mapreduce.Job:  map 100% reduce 56%
15/04/15 20:15:59 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 20:16:01 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 20:16:07 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 20:16:23 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 20:16:50 INFO mapreduce.Job:  map 100% reduce 69%
15/04/15 20:17:17 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 20:17:51 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 20:18:30 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 20:19:12 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 20:19:57 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 20:20:45 INFO mapreduce.Job:  map 100% reduce 75%
15/04/15 20:21:47 INFO mapreduce.Job:  map 100% reduce 76%
15/04/15 20:22:46 INFO mapreduce.Job:  map 100% reduce 77%
15/04/15 20:23:36 INFO mapreduce.Job:  map 100% reduce 78%
15/04/15 20:25:00 INFO mapreduce.Job:  map 100% reduce 79%
15/04/15 20:26:12 INFO mapreduce.Job:  map 100% reduce 80%
15/04/15 20:27:01 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 20:27:53 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 20:28:49 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 20:29:53 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 20:31:24 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:32:40 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 20:34:12 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 20:35:37 INFO mapreduce.Job: Task Id : attempt_1422482982071_5078_r_000011_0, Status : FAILED
Container [pid=30548,containerID=container_1422482982071_5078_01_000315] is running beyond physical memory limits. Current usage: 12.8 GB of 11.7 GB physical memory used; 23.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5078_01_000315 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 30557 30548 30548 30548 (java) 5776 750 13312909312 598827 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000315/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000315 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000011_0 315 
	|- 30548 10523 30548 30548 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000315/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000315 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000011_0 315 1>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000315/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000315/stderr  
	|- 30629 30557 30548 30548 (R) 103108 14224 11427569664 2766856 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce61a640923882 
	|- 30640 30629 30548 30548 (cat) 0 31 4231168 142 cat 
	|- 30641 30629 30548 30548 (cat) 0 0 4231168 138 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:35:38 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 20:35:44 INFO mapreduce.Job: Task Id : attempt_1422482982071_5078_r_000008_0, Status : FAILED
Container [pid=19595,containerID=container_1422482982071_5078_01_000312] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5078_01_000312 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 19604 19595 19595 19595 (java) 5774 1046 13312344064 589585 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000312/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000312 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000008_0 312 
	|- 19672 19604 19595 19595 (R) 94746 24144 10566168576 2486634 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce61a640923882 
	|- 19595 9906 19595 19595 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000312/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000312 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000008_0 312 1>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000312/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000312/stderr  
	|- 19683 19672 19595 19595 (cat) 0 24 4231168 142 cat 
	|- 19684 19672 19595 19595 (cat) 0 0 4231168 136 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:35:45 INFO mapreduce.Job:  map 100% reduce 78%
15/04/15 20:35:50 INFO mapreduce.Job:  map 100% reduce 79%
15/04/15 20:35:56 INFO mapreduce.Job:  map 100% reduce 80%
15/04/15 20:36:12 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 20:36:15 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 20:36:25 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 20:36:28 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:36:39 INFO mapreduce.Job: Task Id : attempt_1422482982071_5078_r_000010_0, Status : FAILED
Container [pid=9213,containerID=container_1422482982071_5078_01_000314] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5078_01_000314 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 9365 9354 9213 9213 (cat) 0 28 103391232 159 cat 
	|- 9366 9354 9213 9213 (cat) 0 0 103391232 156 cat 
	|- 9213 3816 9213 9213 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000314/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000314 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000010_0 314 1>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000314/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000314/stderr  
	|- 9354 9223 9213 9213 (R) 106611 17077 10558676992 2530616 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce61a640923882 
	|- 9223 9213 9213 9213 (java) 6286 781 13411835904 589369 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000314/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000314 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000010_0 314 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:36:40 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 20:36:45 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 20:36:52 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 20:37:10 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:37:23 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 20:37:26 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 20:37:29 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 20:38:11 INFO mapreduce.Job: Task Id : attempt_1422482982071_5078_r_000013_0, Status : FAILED
Container [pid=1640,containerID=container_1422482982071_5078_01_000317] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5078_01_000317 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 1756 1741 1640 1640 (cat) 0 0 4231168 140 cat 
	|- 1741 1649 1640 1640 (R) 113137 18521 10348531712 2486959 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce61a640923882 
	|- 1752 1741 1640 1640 (cat) 0 31 4231168 142 cat 
	|- 1649 1640 1640 1640 (java) 6142 835 13313417216 594781 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000317/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000317 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000013_0 317 
	|- 1640 8968 1640 1640 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000317/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000317 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000013_0 317 1>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000317/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000317/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:38:12 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 20:38:19 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 20:38:33 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:38:53 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 20:38:58 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 20:39:01 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 20:40:15 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 20:40:15 INFO mapreduce.Job: Task Id : attempt_1422482982071_5078_r_000012_0, Status : FAILED
Container [pid=41901,containerID=container_1422482982071_5078_01_000316] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5078_01_000316 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 41910 41901 41901 41901 (java) 6286 1351 13313118208 589176 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000316/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000316 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000012_0 316 
	|- 41901 6181 41901 41901 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000316/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000316 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000012_0 316 1>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000316/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000316/stderr  
	|- 41980 41910 41901 41901 (R) 121929 23253 10549825536 2498094 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce61a640923882 
	|- 41992 41980 41901 41901 (cat) 0 0 4231168 134 cat 
	|- 41991 41980 41901 41901 (cat) 0 31 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:40:16 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 20:40:28 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:40:44 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 20:41:11 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 20:54:40 INFO mapreduce.Job: Task Id : attempt_1422482982071_5078_r_000011_1, Status : FAILED
Container [pid=4479,containerID=container_1422482982071_5078_01_000319] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5078_01_000319 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 4544 4533 4479 4479 (cat) 0 30 4231168 142 cat 
	|- 4545 4533 4479 4479 (cat) 0 0 4231168 139 cat 
	|- 4479 10211 4479 4479 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000319/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000319 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000011_1 319 1>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000319/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000319/stderr  
	|- 4533 4489 4479 4479 (R) 93703 15251 10247421952 2478734 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce61a640923882 
	|- 4489 4479 4479 4479 (java) 6195 1029 13312000000 599495 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000319/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000319 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000011_1 319 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:54:41 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:55:02 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 20:55:15 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 20:55:27 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 20:55:31 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 20:56:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_5078_r_000008_1, Status : FAILED
Container [pid=17092,containerID=container_1422482982071_5078_01_000320] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.7 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5078_01_000320 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 17157 17102 17092 17092 (R) 104175 16058 10669150208 2496147 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce61a640923882 
	|- 17168 17157 17092 17092 (cat) 0 23 103391232 159 cat 
	|- 17169 17157 17092 17092 (cat) 0 0 103391232 153 cat 
	|- 17102 17092 17092 17092 (java) 5471 689 13411336192 586176 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000320/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000320 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000008_1 320 
	|- 17092 3946 17092 17092 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000320/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000320 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000008_1 320 1>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000320/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000320/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:56:48 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:56:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_5078_r_000013_1, Status : FAILED
Container [pid=32356,containerID=container_1422482982071_5078_01_000322] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5078_01_000322 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 32462 32451 32356 32356 (cat) 0 30 4231168 142 cat 
	|- 32463 32451 32356 32356 (cat) 0 0 4231168 140 cat 
	|- 32451 32366 32356 32356 (R) 88173 18431 10372243456 2509207 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce61a640923882 
	|- 32366 32356 32356 32356 (java) 6255 1092 13313609728 590224 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000322/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000322 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000013_1 322 
	|- 32356 40699 32356 32356 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000322/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000322 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000013_1 322 1>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000322/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000322/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 20:56:53 INFO mapreduce.Job:  map 100% reduce 80%
15/04/15 20:56:59 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 20:57:04 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 20:57:13 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 20:57:22 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 20:57:32 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 20:57:35 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 20:57:38 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 20:57:39 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 21:00:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_5078_r_000010_1, Status : FAILED
Container [pid=17911,containerID=container_1422482982071_5078_01_000321] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.2 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5078_01_000321 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 17921 17911 17911 17911 (java) 6109 1075 13312884736 588322 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000321/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000321 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000010_1 321 
	|- 17911 9000 17911 17911 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000321/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000321 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000010_1 321 1>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000321/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000321/stderr  
	|- 17975 17964 17911 17911 (cat) 0 29 4231168 142 cat 
	|- 17977 17964 17911 17911 (cat) 0 0 4231168 140 cat 
	|- 17964 17921 17911 17911 (R) 111317 28416 10453360640 2529023 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce61a640923882 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:00:51 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 21:01:13 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 21:01:25 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 21:01:37 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 21:01:40 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 21:02:18 INFO mapreduce.Job: Task Id : attempt_1422482982071_5078_r_000012_1, Status : FAILED
Container [pid=13413,containerID=container_1422482982071_5078_01_000323] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5078_01_000323 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 13467 13423 13413 13413 (R) 106776 19519 10436603904 2524022 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce61a640923882 
	|- 13478 13467 13413 13413 (cat) 0 27 4231168 143 cat 
	|- 13479 13467 13413 13413 (cat) 0 0 4231168 134 cat 
	|- 13423 13413 13413 13413 (java) 6874 1446 13312876544 595307 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000323/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000323 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000012_1 323 
	|- 13413 10269 13413 13413 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000323/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000323 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000012_1 323 1>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000323/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000323/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:02:19 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 21:02:40 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 21:02:59 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 21:03:23 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 21:15:54 INFO mapreduce.Job: Task Id : attempt_1422482982071_5078_r_000011_2, Status : FAILED
Container [pid=40733,containerID=container_1422482982071_5078_01_000324] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.7 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5078_01_000324 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 40786 40743 40733 40733 (R) 104902 17023 10601254912 2541011 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce61a640923882 
	|- 40733 7712 40733 40733 (bash) 0 0 108650496 297 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000324/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000324 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000011_2 324 1>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000324/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000324/stderr  
	|- 40743 40733 40733 40733 (java) 5956 980 13411418112 586895 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000324/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000324 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000011_2 324 
	|- 40798 40786 40733 40733 (cat) 0 32 103391232 159 cat 
	|- 40799 40786 40733 40733 (cat) 0 0 103391232 156 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:15:55 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 21:16:14 INFO mapreduce.Job: Task Id : attempt_1422482982071_5078_r_000013_2, Status : FAILED
Container [pid=34019,containerID=container_1422482982071_5078_01_000326] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.5 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5078_01_000326 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 34144 34132 34019 34019 (cat) 0 0 4231168 140 cat 
	|- 34132 34029 34019 34019 (R) 96632 14539 10860371968 2518844 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce61a640923882 
	|- 34019 10365 34019 34019 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000326/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000326 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000013_2 326 1>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000326/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000326/stderr  
	|- 34029 34019 34019 34019 (java) 4689 737 13313155072 605246 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000326/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000326 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000013_2 326 
	|- 34143 34132 34019 34019 (cat) 0 29 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:16:15 INFO mapreduce.Job:  map 100% reduce 81%
15/04/15 21:16:27 INFO mapreduce.Job:  map 100% reduce 82%
15/04/15 21:16:28 INFO mapreduce.Job:  map 100% reduce 83%
15/04/15 21:16:40 INFO mapreduce.Job:  map 100% reduce 84%
15/04/15 21:16:49 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 21:16:58 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 21:17:01 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 21:17:07 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 21:18:08 INFO mapreduce.Job: Task Id : attempt_1422482982071_5078_r_000008_2, Status : FAILED
Container [pid=33971,containerID=container_1422482982071_5078_01_000325] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5078_01_000325 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 33981 33971 33971 33971 (java) 4694 768 13312155648 590437 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000325/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000325 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000008_2 325 
	|- 34123 34112 33971 33971 (cat) 0 25 4231168 143 cat 
	|- 34112 33981 33971 33971 (R) 105972 17100 10588815360 2562101 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce61a640923882 
	|- 34124 34112 33971 33971 (cat) 0 0 4231168 136 cat 
	|- 33971 10365 33971 33971 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000325/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000325 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000008_2 325 1>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000325/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000325/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:18:09 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 21:18:30 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 21:18:49 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 21:19:04 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 21:21:17 INFO mapreduce.Job: Task Id : attempt_1422482982071_5078_r_000012_2, Status : FAILED
Container [pid=4203,containerID=container_1422482982071_5078_01_000328] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 22.4 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5078_01_000328 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 4213 4203 4203 4203 (java) 6651 1335 13411852288 595137 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000328/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000328 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000012_2 328 
	|- 4203 3817 4203 4203 (bash) 1 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000328/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000328 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000012_2 328 1>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000328/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000328/stderr  
	|- 4269 4258 4203 4203 (cat) 1 25 103391232 159 cat 
	|- 4258 4213 4203 4203 (R) 90632 16461 10363781120 2483020 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce61a640923882 
	|- 4270 4258 4203 4203 (cat) 0 0 103391232 151 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:21:18 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 21:21:36 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 21:21:58 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 21:22:16 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 21:29:31 INFO mapreduce.Job: Task Id : attempt_1422482982071_5078_r_000010_2, Status : FAILED
Container [pid=25184,containerID=container_1422482982071_5078_01_000327] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.1 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5078_01_000327 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 25260 25248 25184 25184 (cat) 0 0 4231168 140 cat 
	|- 25184 11693 25184 25184 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000327/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000327 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000010_2 327 1>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000327/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000327/stderr  
	|- 25194 25184 25184 25184 (java) 6095 1106 13312614400 589619 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5078/container_1422482982071_5078_01_000327/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5078/container_1422482982071_5078_01_000327 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.153 52613 attempt_1422482982071_5078_r_000010_2 327 
	|- 25259 25248 25184 25184 (cat) 0 27 4231168 143 cat 
	|- 25248 25194 25184 25184 (R) 101766 64826 10380627968 2511255 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce61a640923882 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:29:32 INFO mapreduce.Job:  map 100% reduce 85%
15/04/15 21:29:54 INFO mapreduce.Job:  map 100% reduce 86%
15/04/15 21:30:06 INFO mapreduce.Job:  map 100% reduce 87%
15/04/15 21:30:27 INFO mapreduce.Job:  map 100% reduce 88%
15/04/15 21:30:31 INFO mapreduce.Job:  map 100% reduce 89%
15/04/15 21:33:54 INFO mapreduce.Job:  map 100% reduce 100%
15/04/15 21:33:55 INFO mapreduce.Job: Job job_1422482982071_5078 failed with state FAILED due to: Task failed task_1422482982071_5078_r_000013
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/15 21:33:55 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=28819878957
		FILE: Number of bytes written=78327811406
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=27107649938
		HDFS: Number of bytes written=2367340750
		HDFS: Number of read operations=780
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=20
	Job Counters 
		Failed reduce tasks=16
		Killed map tasks=1
		Killed reduce tasks=4
		Launched map tasks=251
		Launched reduce tasks=30
		Data-local map tasks=184
		Rack-local map tasks=67
		Total time spent by all maps in occupied slots (ms)=34863790
		Total time spent by all reduces in occupied slots (ms)=75505376
		Total time spent by all map tasks (ms)=17431895
		Total time spent by all reduce tasks (ms)=37752688
		Total vcore-seconds taken by all map tasks=17431895
		Total vcore-seconds taken by all reduce tasks=37752688
		Total megabyte-seconds taken by all map tasks=141128621920
		Total megabyte-seconds taken by all reduce tasks=453032256000
	Map-Reduce Framework
		Map input records=632973453
		Map output records=567302140
		Map output bytes=48318396000
		Map output materialized bytes=49482787728
		Input split bytes=39500
		Combine input records=0
		Combine output records=0
		Reduce input groups=39395274
		Reduce shuffle bytes=28819893747
		Reduce input records=377683316
		Reduce output records=39590209
		Spilled Records=944985456
		Shuffled Maps =2500
		Failed Shuffles=0
		Merged Map outputs=2500
		GC time elapsed (ms)=142564
		CPU time spent (ms)=31998000
		Physical memory (bytes) snapshot=510596120576
		Virtual memory (bytes) snapshot=2428686872576
		Total committed heap usage (bytes)=713731547136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27107610438
	File Output Format Counters 
		Bytes Written=2367340750
	rmr
		reduce calls=39395274
15/04/15 21:33:55 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/15 21:34:01 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file61a659926c39

real	80m18.507s
user	0m37.634s
sys	0m4.229s
Loading required package: methods
Please review your hadoop settings. See help(hadoop.settings)
NULL
$hadoop
$hadoop$D
[1] "mapred.job.name=rhadoop-250-5-false-googlebooks-eng-all-5gram-20120701-on"

$hadoop$D
[1] "mapreduce.job.maps=250"

$hadoop$D
[1] "mapred.reduce.tasks=5"


15/04/15 21:34:07 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
15/04/15 21:34:07 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.3.0-cdh5.1.0.jar] /tmp/streamjob8616761031457914874.jar tmpDir=null
15/04/15 21:34:07 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 21:34:07 INFO client.RMProxy: Connecting to ResourceManager at name.rustler.tacc.utexas.edu/129.114.57.132:8032
15/04/15 21:34:08 INFO mapred.FileInputFormat: Total input paths to process : 1
15/04/15 21:34:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.141:50010
15/04/15 21:34:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.189:50010
15/04/15 21:34:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.196:50010
15/04/15 21:34:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.181:50010
15/04/15 21:34:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.143:50010
15/04/15 21:34:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.179:50010
15/04/15 21:34:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.187:50010
15/04/15 21:34:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.198:50010
15/04/15 21:34:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.160:50010
15/04/15 21:34:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.174:50010
15/04/15 21:34:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.183:50010
15/04/15 21:34:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.184:50010
15/04/15 21:34:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.168:50010
15/04/15 21:34:08 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.202:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.164:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.186:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.144:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.171:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.165:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.147:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.200:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.149:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.192:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.193:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.178:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.162:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.163:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.140:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.182:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.191:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.169:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.177:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.173:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.188:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.203:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.190:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.175:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.172:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.197:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.199:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.194:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.176:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.180:50010
15/04/15 21:34:09 INFO net.NetworkTopology: Adding a new node: /default-rack/129.114.57.195:50010
15/04/15 21:34:09 INFO mapreduce.JobSubmitter: number of splits:250
15/04/15 21:34:09 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1422482982071_5081
15/04/15 21:34:10 INFO impl.YarnClientImpl: Submitted application application_1422482982071_5081
15/04/15 21:34:10 INFO mapreduce.Job: The url to track the job: http://name.rustler.tacc.utexas.edu:8088/proxy/application_1422482982071_5081/
15/04/15 21:34:10 INFO mapreduce.Job: Running job: job_1422482982071_5081
15/04/15 21:34:16 INFO mapreduce.Job: Job job_1422482982071_5081 running in uber mode : false
15/04/15 21:34:16 INFO mapreduce.Job:  map 0% reduce 0%
15/04/15 21:34:27 INFO mapreduce.Job:  map 2% reduce 0%
15/04/15 21:34:28 INFO mapreduce.Job:  map 4% reduce 0%
15/04/15 21:34:29 INFO mapreduce.Job:  map 5% reduce 0%
15/04/15 21:34:30 INFO mapreduce.Job:  map 7% reduce 0%
15/04/15 21:34:31 INFO mapreduce.Job:  map 8% reduce 0%
15/04/15 21:34:32 INFO mapreduce.Job:  map 9% reduce 0%
15/04/15 21:34:33 INFO mapreduce.Job:  map 10% reduce 0%
15/04/15 21:34:34 INFO mapreduce.Job:  map 12% reduce 0%
15/04/15 21:34:35 INFO mapreduce.Job:  map 13% reduce 0%
15/04/15 21:34:36 INFO mapreduce.Job:  map 14% reduce 0%
15/04/15 21:34:37 INFO mapreduce.Job:  map 16% reduce 0%
15/04/15 21:34:39 INFO mapreduce.Job:  map 18% reduce 0%
15/04/15 21:34:40 INFO mapreduce.Job:  map 19% reduce 0%
15/04/15 21:34:41 INFO mapreduce.Job:  map 20% reduce 0%
15/04/15 21:34:42 INFO mapreduce.Job:  map 21% reduce 0%
15/04/15 21:34:43 INFO mapreduce.Job:  map 23% reduce 0%
15/04/15 21:34:45 INFO mapreduce.Job:  map 24% reduce 0%
15/04/15 21:34:46 INFO mapreduce.Job:  map 26% reduce 0%
15/04/15 21:34:47 INFO mapreduce.Job:  map 27% reduce 0%
15/04/15 21:34:48 INFO mapreduce.Job:  map 28% reduce 0%
15/04/15 21:34:49 INFO mapreduce.Job:  map 30% reduce 0%
15/04/15 21:34:51 INFO mapreduce.Job:  map 31% reduce 0%
15/04/15 21:34:52 INFO mapreduce.Job:  map 33% reduce 0%
15/04/15 21:34:53 INFO mapreduce.Job:  map 34% reduce 0%
15/04/15 21:34:54 INFO mapreduce.Job:  map 35% reduce 0%
15/04/15 21:34:55 INFO mapreduce.Job:  map 37% reduce 0%
15/04/15 21:34:56 INFO mapreduce.Job:  map 38% reduce 0%
15/04/15 21:34:57 INFO mapreduce.Job:  map 39% reduce 0%
15/04/15 21:34:58 INFO mapreduce.Job:  map 41% reduce 0%
15/04/15 21:35:00 INFO mapreduce.Job:  map 42% reduce 0%
15/04/15 21:35:01 INFO mapreduce.Job:  map 44% reduce 0%
15/04/15 21:35:02 INFO mapreduce.Job:  map 45% reduce 0%
15/04/15 21:35:03 INFO mapreduce.Job:  map 46% reduce 0%
15/04/15 21:35:04 INFO mapreduce.Job:  map 48% reduce 0%
15/04/15 21:35:05 INFO mapreduce.Job:  map 49% reduce 0%
15/04/15 21:35:06 INFO mapreduce.Job:  map 50% reduce 0%
15/04/15 21:35:07 INFO mapreduce.Job:  map 52% reduce 0%
15/04/15 21:35:09 INFO mapreduce.Job:  map 53% reduce 0%
15/04/15 21:35:10 INFO mapreduce.Job:  map 55% reduce 0%
15/04/15 21:35:11 INFO mapreduce.Job:  map 56% reduce 0%
15/04/15 21:35:12 INFO mapreduce.Job:  map 57% reduce 0%
15/04/15 21:35:13 INFO mapreduce.Job:  map 59% reduce 0%
15/04/15 21:35:15 INFO mapreduce.Job:  map 60% reduce 0%
15/04/15 21:35:16 INFO mapreduce.Job:  map 61% reduce 0%
15/04/15 21:35:18 INFO mapreduce.Job:  map 62% reduce 0%
15/04/15 21:35:20 INFO mapreduce.Job:  map 63% reduce 0%
15/04/15 21:35:23 INFO mapreduce.Job:  map 64% reduce 0%
15/04/15 21:35:25 INFO mapreduce.Job:  map 65% reduce 0%
15/04/15 21:35:26 INFO mapreduce.Job:  map 67% reduce 0%
15/04/15 21:35:27 INFO mapreduce.Job:  map 70% reduce 0%
15/04/15 21:35:28 INFO mapreduce.Job:  map 73% reduce 0%
15/04/15 21:35:29 INFO mapreduce.Job:  map 75% reduce 0%
15/04/15 21:35:30 INFO mapreduce.Job:  map 78% reduce 0%
15/04/15 21:35:31 INFO mapreduce.Job:  map 81% reduce 0%
15/04/15 21:35:32 INFO mapreduce.Job:  map 83% reduce 0%
15/04/15 21:35:33 INFO mapreduce.Job:  map 86% reduce 0%
15/04/15 21:35:34 INFO mapreduce.Job:  map 88% reduce 0%
15/04/15 21:35:35 INFO mapreduce.Job:  map 90% reduce 0%
15/04/15 21:35:36 INFO mapreduce.Job:  map 91% reduce 0%
15/04/15 21:35:38 INFO mapreduce.Job:  map 92% reduce 4%
15/04/15 21:35:39 INFO mapreduce.Job:  map 93% reduce 4%
15/04/15 21:35:41 INFO mapreduce.Job:  map 93% reduce 5%
15/04/15 21:35:44 INFO mapreduce.Job:  map 94% reduce 5%
15/04/15 21:35:50 INFO mapreduce.Job:  map 94% reduce 6%
15/04/15 21:35:53 INFO mapreduce.Job:  map 94% reduce 7%
15/04/15 21:35:56 INFO mapreduce.Job:  map 95% reduce 8%
15/04/15 21:35:57 INFO mapreduce.Job:  map 96% reduce 8%
15/04/15 21:35:58 INFO mapreduce.Job:  map 97% reduce 8%
15/04/15 21:35:59 INFO mapreduce.Job:  map 98% reduce 9%
15/04/15 21:36:02 INFO mapreduce.Job:  map 99% reduce 10%
15/04/15 21:36:04 INFO mapreduce.Job:  map 100% reduce 10%
15/04/15 21:36:05 INFO mapreduce.Job:  map 100% reduce 11%
15/04/15 21:36:11 INFO mapreduce.Job:  map 100% reduce 13%
15/04/15 21:36:14 INFO mapreduce.Job:  map 100% reduce 14%
15/04/15 21:36:20 INFO mapreduce.Job:  map 100% reduce 15%
15/04/15 21:36:24 INFO mapreduce.Job:  map 100% reduce 17%
15/04/15 21:36:27 INFO mapreduce.Job:  map 100% reduce 18%
15/04/15 21:36:33 INFO mapreduce.Job:  map 100% reduce 19%
15/04/15 21:36:36 INFO mapreduce.Job:  map 100% reduce 20%
15/04/15 21:36:38 INFO mapreduce.Job:  map 100% reduce 21%
15/04/15 21:36:41 INFO mapreduce.Job:  map 100% reduce 22%
15/04/15 21:36:46 INFO mapreduce.Job:  map 100% reduce 23%
15/04/15 21:36:48 INFO mapreduce.Job:  map 100% reduce 24%
15/04/15 21:36:51 INFO mapreduce.Job:  map 100% reduce 25%
15/04/15 21:36:55 INFO mapreduce.Job:  map 100% reduce 26%
15/04/15 21:37:00 INFO mapreduce.Job:  map 100% reduce 28%
15/04/15 21:37:04 INFO mapreduce.Job:  map 100% reduce 29%
15/04/15 21:37:08 INFO mapreduce.Job:  map 100% reduce 30%
15/04/15 21:37:12 INFO mapreduce.Job:  map 100% reduce 31%
15/04/15 21:37:16 INFO mapreduce.Job:  map 100% reduce 32%
15/04/15 21:37:20 INFO mapreduce.Job:  map 100% reduce 33%
15/04/15 21:37:22 INFO mapreduce.Job:  map 100% reduce 39%
15/04/15 21:37:25 INFO mapreduce.Job:  map 100% reduce 46%
15/04/15 21:37:26 INFO mapreduce.Job:  map 100% reduce 47%
15/04/15 21:37:28 INFO mapreduce.Job:  map 100% reduce 48%
15/04/15 21:37:29 INFO mapreduce.Job:  map 100% reduce 53%
15/04/15 21:37:31 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 21:37:32 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 21:37:35 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 21:37:38 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 21:40:05 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 21:47:31 INFO mapreduce.Job:  map 100% reduce 69%
15/04/15 21:50:59 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 21:52:57 INFO mapreduce.Job: Task Id : attempt_1422482982071_5081_r_000003_0, Status : FAILED
Container [pid=41583,containerID=container_1422482982071_5081_01_000308] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5081_01_000308 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 41792 41781 41583 41583 (cat) 1 25 103391232 159 cat 
	|- 41781 41593 41583 41583 (R) 80697 11813 9856729088 2359241 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce663e2c707bd3 
	|- 41793 41781 41583 41583 (cat) 0 0 103391232 156 cat 
	|- 41593 41583 41583 41583 (java) 13375 2138 13413847040 742892 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000308/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000308 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000003_0 308 
	|- 41583 7712 41583 41583 (bash) 0 0 108650496 296 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000308/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000308 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000003_0 308 1>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000308/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000308/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:52:58 INFO mapreduce.Job:  map 100% reduce 57%
15/04/15 21:53:10 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 21:53:37 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 21:53:46 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 21:53:58 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 21:54:19 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 21:54:28 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 21:54:49 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 21:55:11 INFO mapreduce.Job:  map 100% reduce 68%
15/04/15 21:55:14 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 21:55:47 INFO mapreduce.Job: Task Id : attempt_1422482982071_5081_r_000001_0, Status : FAILED
Container [pid=5815,containerID=container_1422482982071_5081_01_000306] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.9 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5081_01_000306 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 5824 5815 5815 5815 (java) 13783 2147 13314469888 626560 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000306/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000306 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000001_0 306 
	|- 5815 10211 5815 5815 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000306/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000306 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000001_0 306 1>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000306/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000306/stderr  
	|- 6025 6010 5815 5815 (cat) 0 0 4231168 143 cat 
	|- 6021 6010 5815 5815 (cat) 1 41 4231168 142 cat 
	|- 6010 5824 5815 5815 (R) 97823 10835 10231324672 2474804 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce663e2c707bd3 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:55:48 INFO mapreduce.Job:  map 100% reduce 57%
15/04/15 21:55:59 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 21:56:08 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 21:56:20 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 21:56:30 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 21:57:00 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 21:57:12 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 21:57:25 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 21:57:37 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 21:57:40 INFO mapreduce.Job:  map 100% reduce 69%
15/04/15 21:57:43 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 21:57:46 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 21:58:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_5081_r_000002_0, Status : FAILED
Container [pid=26784,containerID=container_1422482982071_5081_01_000307] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5081_01_000307 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 26946 26935 26784 26784 (cat) 0 31 4231168 142 cat 
	|- 26793 26784 26784 26784 (java) 13024 2614 13314990080 626047 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000307/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000307 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000002_0 307 
	|- 26935 26793 26784 26784 (R) 110611 17253 10305765376 2492996 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce663e2c707bd3 
	|- 26784 9517 26784 26784 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000307/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000307 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000002_0 307 1>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000307/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000307/stderr  
	|- 26947 26935 26784 26784 (cat) 0 0 4231168 134 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 21:58:51 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 21:59:02 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 21:59:17 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 21:59:29 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 21:59:47 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 21:59:59 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:00:18 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:00:36 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:00:45 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 22:00:48 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 22:04:52 INFO mapreduce.Job: Task Id : attempt_1422482982071_5081_r_000000_0, Status : FAILED
Container [pid=26380,containerID=container_1422482982071_5081_01_000305] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5081_01_000305 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 26569 26557 26380 26380 (cat) 0 0 4231168 142 cat 
	|- 26389 26380 26380 26380 (java) 12926 2387 13313536000 643472 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000305/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000305 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000000_0 305 
	|- 26557 26389 26380 26380 (R) 145242 19417 10241048576 2477209 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce663e2c707bd3 
	|- 26380 10599 26380 26380 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000305/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000305 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000000_0 305 1>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000305/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000305/stderr  
	|- 26568 26557 26380 26380 (cat) 0 50 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:04:53 INFO mapreduce.Job:  map 100% reduce 58%
15/04/15 22:05:04 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 22:05:14 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 22:05:29 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:05:42 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:06:06 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:06:21 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:06:46 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:07:17 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 22:11:02 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 22:13:50 INFO mapreduce.Job: Task Id : attempt_1422482982071_5081_r_000003_1, Status : FAILED
Container [pid=4775,containerID=container_1422482982071_5081_01_000310] is running beyond physical memory limits. Current usage: 11.9 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5081_01_000310 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 4785 4775 4775 4775 (java) 11501 1706 13312131072 630876 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000310/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000310 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000003_1 310 
	|- 4851 4838 4775 4775 (cat) 0 0 4231168 138 cat 
	|- 4775 9412 4775 4775 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000310/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000310 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000003_1 310 1>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000310/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000310/stderr  
	|- 4849 4838 4775 4775 (cat) 0 26 4231168 142 cat 
	|- 4838 4785 4775 4775 (R) 90923 20780 10247557120 2478768 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce663e2c707bd3 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:13:51 INFO mapreduce.Job:  map 100% reduce 59%
15/04/15 22:14:02 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 22:14:11 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:14:20 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:14:41 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:14:53 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:15:18 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:15:36 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 22:15:48 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 22:15:52 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 22:19:01 INFO mapreduce.Job: Task Id : attempt_1422482982071_5081_r_000001_1, Status : FAILED
Container [pid=42016,containerID=container_1422482982071_5081_01_000311] is running beyond physical memory limits. Current usage: 12.0 GB of 11.7 GB physical memory used; 22.6 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5081_01_000311 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 42083 42071 42016 42016 (cat) 1 42 103391232 159 cat 
	|- 42084 42071 42016 42016 (cat) 0 0 103391232 159 cat 
	|- 42071 42026 42016 42016 (R) 113153 13778 10559664128 2530888 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce663e2c707bd3 
	|- 42016 7712 42016 42016 (bash) 0 0 108650496 297 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000311/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000311 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000001_1 311 1>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000311/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000311/stderr  
	|- 42026 42016 42016 42016 (java) 10484 1523 13413408768 608139 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000311/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000311 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000001_1 311 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:19:02 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 22:19:14 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:19:32 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:19:48 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:20:04 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:20:16 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:20:40 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 22:20:52 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 22:20:55 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 22:20:58 INFO mapreduce.Job:  map 100% reduce 71%
15/04/15 22:21:01 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 22:21:41 INFO mapreduce.Job:  map 100% reduce 80%
15/04/15 22:21:41 INFO mapreduce.Job: Task Id : attempt_1422482982071_5081_r_000002_1, Status : FAILED
Container [pid=18427,containerID=container_1422482982071_5081_01_000312] is running beyond physical memory limits. Current usage: 12.3 GB of 11.7 GB physical memory used; 22.4 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5081_01_000312 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 18427 10211 18427 18427 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000312/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000312 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000002_1 312 1>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000312/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000312/stderr  
	|- 18489 18437 18427 18427 (R) 107523 17817 10685734912 2580501 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce663e2c707bd3 
	|- 18501 18489 18427 18427 (cat) 0 0 4231168 134 cat 
	|- 18437 18427 18427 18427 (java) 10517 1812 13313216512 634854 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000312/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000312 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000002_1 312 
	|- 18500 18489 18427 18427 (cat) 0 26 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:21:42 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 22:21:53 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:22:02 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:22:20 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:22:39 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:22:51 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:23:09 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 22:23:21 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 22:23:42 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 22:23:45 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 22:32:12 INFO mapreduce.Job: Task Id : attempt_1422482982071_5081_r_000003_2, Status : FAILED
Container [pid=18198,containerID=container_1422482982071_5081_01_000314] is running beyond physical memory limits. Current usage: 11.7 GB of 11.7 GB physical memory used; 21.9 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5081_01_000314 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 18198 9067 18198 18198 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000314/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000314 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000003_2 314 1>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000314/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000314/stderr  
	|- 18598 18565 18198 18198 (cat) 0 24 4231168 143 cat 
	|- 18565 18208 18198 18198 (R) 82311 15617 10207727616 2421151 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce663e2c707bd3 
	|- 18208 18198 18198 18198 (java) 10795 1878 13313961984 651364 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000314/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000314 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000003_2 314 
	|- 18601 18565 18198 18198 (cat) 0 0 4231168 138 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:32:13 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:32:24 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:32:46 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:32:56 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:33:20 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:33:32 INFO mapreduce.Job: Task Id : attempt_1422482982071_5081_r_000000_1, Status : FAILED
Container [pid=13677,containerID=container_1422482982071_5081_01_000313] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 21.7 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5081_01_000313 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 13759 13747 13677 13677 (cat) 0 47 4231168 142 cat 
	|- 13760 13747 13677 13677 (cat) 0 0 4231168 143 cat 
	|- 13686 13677 13677 13677 (java) 11390 2688 13314686976 691407 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000313/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000313 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000000_1 313 
	|- 13677 9143 13677 13677 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000313/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000313 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000000_1 313 1>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000313/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000313/stderr  
	|- 13747 13686 13677 13677 (R) 133201 24183 9941676032 2404122 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce663e2c707bd3 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:33:33 INFO mapreduce.Job:  map 100% reduce 52%
15/04/15 22:33:44 INFO mapreduce.Job:  map 100% reduce 53%
15/04/15 22:33:53 INFO mapreduce.Job:  map 100% reduce 54%
15/04/15 22:33:56 INFO mapreduce.Job:  map 100% reduce 55%
15/04/15 22:34:08 INFO mapreduce.Job:  map 100% reduce 56%
15/04/15 22:34:17 INFO mapreduce.Job:  map 100% reduce 57%
15/04/15 22:34:27 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:34:35 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:34:56 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 22:35:05 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 22:35:26 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 22:41:48 INFO mapreduce.Job: Task Id : attempt_1422482982071_5081_r_000001_2, Status : FAILED
Container [pid=38881,containerID=container_1422482982071_5081_01_000315] is running beyond physical memory limits. Current usage: 11.8 GB of 11.7 GB physical memory used; 22.0 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5081_01_000315 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 38946 38891 38881 38881 (R) 106946 17388 10269683712 2484201 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce663e2c707bd3 
	|- 38891 38881 38881 38881 (java) 11393 1864 13316001792 613301 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000315/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000315 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000001_2 315 
	|- 38881 9261 38881 38881 (bash) 0 0 9457664 271 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000315/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000315 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000001_2 315 1>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000315/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000315/stderr  
	|- 38958 38946 38881 38881 (cat) 0 0 4231168 142 cat 
	|- 38957 38946 38881 38881 (cat) 0 41 4231168 142 cat 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:41:49 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 22:41:59 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:42:09 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:42:21 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:42:46 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:43:04 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:43:17 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 22:43:47 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 22:43:50 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 22:43:53 INFO mapreduce.Job:  map 100% reduce 72%
15/04/15 22:43:56 INFO mapreduce.Job:  map 100% reduce 73%
15/04/15 22:44:39 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 22:45:16 INFO mapreduce.Job: Task Id : attempt_1422482982071_5081_r_000002_2, Status : FAILED
Container [pid=47061,containerID=container_1422482982071_5081_01_000316] is running beyond physical memory limits. Current usage: 12.3 GB of 11.7 GB physical memory used; 22.3 GB of 24.6 GB virtual memory used. Killing container.
Dump of the process-tree for container_1422482982071_5081_01_000316 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 47071 47061 47061 47061 (java) 12025 2241 13312634880 671273 /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000316/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000316 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000002_2 316 
	|- 47134 47123 47061 47061 (cat) 0 25 4231168 142 cat 
	|- 47123 47071 47061 47061 (R) 108887 19447 10568634368 2557174 /usr/lib64/R/bin/exec/R --slave --no-restore --vanilla --file=./rmr-streaming-reduce663e2c707bd3 
	|- 47135 47123 47061 47061 (cat) 0 0 4231168 134 cat 
	|- 47061 9608 47061 47061 (bash) 0 0 9457664 272 /bin/bash -c /usr/java/jdk1.7.0_67/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx12000m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1 -Djava.io.tmpdir=/hdfs/1/tmp/hadoop-yarn/nm-local-dir/usercache/dotcz12/appcache/application_1422482982071_5081/container_1422482982071_5081_01_000316/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000316 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 129.114.57.149 45094 attempt_1422482982071_5081_r_000002_2 316 1>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000316/stdout 2>/var/log/hadoop-yarn/containers/application_1422482982071_5081/container_1422482982071_5081_01_000316/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

15/04/15 22:45:17 INFO mapreduce.Job:  map 100% reduce 60%
15/04/15 22:45:30 INFO mapreduce.Job:  map 100% reduce 61%
15/04/15 22:45:39 INFO mapreduce.Job:  map 100% reduce 62%
15/04/15 22:45:57 INFO mapreduce.Job:  map 100% reduce 63%
15/04/15 22:46:10 INFO mapreduce.Job:  map 100% reduce 64%
15/04/15 22:46:28 INFO mapreduce.Job:  map 100% reduce 65%
15/04/15 22:46:37 INFO mapreduce.Job:  map 100% reduce 66%
15/04/15 22:46:58 INFO mapreduce.Job:  map 100% reduce 67%
15/04/15 22:47:16 INFO mapreduce.Job:  map 100% reduce 70%
15/04/15 22:47:19 INFO mapreduce.Job:  map 100% reduce 74%
15/04/15 22:52:33 INFO mapreduce.Job:  map 100% reduce 100%
15/04/15 22:52:34 INFO mapreduce.Job: Job job_1422482982071_5081 failed with state FAILED due to: Task failed task_1422482982071_5081_r_000003
Job failed as tasks failed. failedMaps:0 failedReduces:1

15/04/15 22:52:35 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=8608986398
		FILE: Number of bytes written=58115994974
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=27107649938
		HDFS: Number of bytes written=709787409
		HDFS: Number of read operations=753
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed reduce tasks=12
		Killed map tasks=1
		Killed reduce tasks=3
		Launched map tasks=251
		Launched reduce tasks=16
		Data-local map tasks=183
		Rack-local map tasks=68
		Total time spent by all maps in occupied slots (ms)=38192664
		Total time spent by all reduces in occupied slots (ms)=44339870
		Total time spent by all map tasks (ms)=19096332
		Total time spent by all reduce tasks (ms)=22169935
		Total vcore-seconds taken by all map tasks=19096332
		Total vcore-seconds taken by all reduce tasks=22169935
		Total megabyte-seconds taken by all map tasks=154603903872
		Total megabyte-seconds taken by all reduce tasks=266039220000
	Map-Reduce Framework
		Map input records=632973453
		Map output records=567302129
		Map output bytes=48318414638
		Map output materialized bytes=49482791355
		Input split bytes=39500
		Combine input records=0
		Combine output records=0
		Reduce input groups=11812484
		Reduce shuffle bytes=8608987844
		Reduce input records=113536069
		Reduce output records=11870631
		Spilled Records=680838198
		Shuffled Maps =250
		Failed Shuffles=0
		Merged Map outputs=250
		GC time elapsed (ms)=116091
		CPU time spent (ms)=23269200
		Physical memory (bytes) snapshot=488980021248
		Virtual memory (bytes) snapshot=2308173381632
		Total committed heap usage (bytes)=694638219264
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27107610438
	File Output Format Counters 
		Bytes Written=709787409
	rmr
		reduce calls=11812484
15/04/15 22:52:35 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  : 
  hadoop streaming failed with error code 1
Calls: wordcount -> mapreduce -> mr
Execution halted
15/04/15 22:52:41 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /tmp/file663e64b9fa00

real	78m39.667s
user	0m36.930s
sys	0m4.291s
